{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating an image classifier able to find sneakers in instagram posts\n",
    "\n",
    "The data comprises of few thousand images of sneakers collected using google images and instagram\n",
    "and few thousand images of sneakers.    \n",
    "Your goal is to use what you learned from previous examples and create a sneaker-not-sneaker binary classifier.\n",
    "\n",
    "The task comprises of multiple sub-tasks that you need to do to build the classifier.\n",
    "\n",
    "1. Create a dataset able to load data from new_meta_sneakers.csv\n",
    "2. Create a fine tune binary classification architecture.\n",
    "3. Create a training loop and train your model.\n",
    "\n",
    "![title](sneakers.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On the bottom of the following cell you see the data you will work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from torch import nn\n",
    "import easyimages\n",
    "import pandas as pd\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pretrainedmodels.models import resnet50\n",
    "from torchvision.transforms import transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch \n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>image_path</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16572</th>\n",
       "      <td>16572</td>\n",
       "      <td>/media/i008/ssd500/fashion_classify_data/sneak...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45581</th>\n",
       "      <td>45581</td>\n",
       "      <td>/media/i008/ssd500/fashion_classify_data/sneak...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27500</th>\n",
       "      <td>27500</td>\n",
       "      <td>/media/i008/ssd500/fashion_classify_data/sneak...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45655</th>\n",
       "      <td>45655</td>\n",
       "      <td>/media/i008/ssd500/fashion_classify_data/sneak...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34567</th>\n",
       "      <td>34567</td>\n",
       "      <td>/media/i008/ssd500/fashion_classify_data/negat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                         image_path  tags\n",
       "16572       16572  /media/i008/ssd500/fashion_classify_data/sneak...     1\n",
       "45581       45581  /media/i008/ssd500/fashion_classify_data/sneak...     1\n",
       "27500       27500  /media/i008/ssd500/fashion_classify_data/sneak...     1\n",
       "45655       45655  /media/i008/ssd500/fashion_classify_data/sneak...     1\n",
       "34567       34567  /media/i008/ssd500/fashion_classify_data/negat...     0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATASET_USAGE_PERCENTAGE = 0.1\n",
    "\n",
    "base_path ='/media/i008/ssd500/fashion_classify_data/'\n",
    "df = pd.read_csv(os.path.join(base_path,'new_meta_sneakers.csv')).sample(frac=1)\n",
    "df.image_path = base_path +df.image_path\n",
    "df.tags = df.tags.map({'sneakers': 1, 'negatives': 0})\n",
    "df = df.sample(frac=DATASET_USAGE_PERCENTAGE)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the torch Dataset.\n",
    "\n",
    "First thing we need to do is create a dataset able to load our data. Since our metadata is stored in a csv file, our \n",
    "dataset should accept this file as a base source of what needs to be loaded.\n",
    "\n",
    "Our dataset should also support augumentations and a \"inference\" mode wich disables them for predicting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "from PIL import Image\n",
    "import io\n",
    "import requests\n",
    "import torch\n",
    "\n",
    "\n",
    "class OneClassImageClassificationDataset(Dataset):\n",
    "    def __init__(self, annotations, image_transform):\n",
    "        \"\"\"\n",
    "        annotations is a pandas dataframe\n",
    "        \n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.annotations = annotations\n",
    "        self.image_transform = image_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Return the length of the annotations dataframe\n",
    "        \"\"\"\n",
    "        # your code here\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Using methods you wrote:\n",
    "        1 - load image from disk for given index  (self.load_from_disk)\n",
    "        2 - transform image (self.image_transform)\n",
    "        3 - Load target (self.load_target)\n",
    "        return Xi, yi\n",
    "        \"\"\"\n",
    "        \n",
    "        # YOUR CODE HERE\n",
    "\n",
    "        return Xi, yi\n",
    "\n",
    "    def load_to_pil(self, uri):\n",
    "        \"\"\"\n",
    "        Write a helper function that uses PIL.Image to load a file and convert to RGB and returns it\n",
    "        \n",
    "        \"\"\"\n",
    "        image_pil =  # YOUR CODE HERE\n",
    "        return image_pil\n",
    "\n",
    "\n",
    "    def load_from_disk(self, index):\n",
    "        \"\"\"\n",
    "        Loads an image from disk given a index.\n",
    "        It gets the path of an image with the corresponding index from the metadata \n",
    "        It passes the URI to the self.load_to_pil and returns a PIL.Image\n",
    "        \"\"\"\n",
    "        image_path = # YOUR CODE HERE\n",
    "        return self.load_to_pil(image_path)\n",
    "\n",
    "    def load_target(self, index):\n",
    "        \"\"\"\n",
    "        This function should get the tag for a given index from the annotations dataframe\n",
    "        You .iloc can become useful.    \n",
    "        This methods should return, either a 0 or a 1.\n",
    "        \"\"\"\n",
    "        \n",
    "        #label = # YOUR CODE HERE\n",
    "\n",
    "        return label\n",
    "    \n",
    "    \n",
    "class BaseSampler(Sampler):\n",
    "    def __init__(self, df, n_samples):\n",
    "        self.df = df\n",
    "        self.n_samples = n_samples\n",
    "        \n",
    "    def __iter__(self):\n",
    "        return iter(self._get_sample())\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "    \n",
    "    def _get_sample(self):\n",
    "        return np.random.choice(len(self.df), self.n_samples, replace=False)\n",
    "        \n",
    "\n",
    "def binary_classification_model():\n",
    "    \"\"\"\n",
    "    Write a function that loads a resnet50 model from pretrainedmodels. \n",
    "    - freezes its layers\n",
    "    - replaces the last_linear with the proper output number. As we did in previous example.\n",
    "    - replace avgpool with adaptiv pooling.\n",
    "    \"\"\"\n",
    "    model = resnet50()\n",
    "\n",
    "    # model = YOUR CODE HERE\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/i008/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# YOUR CODE HERE:\n",
    "# SPLIT the dataframe into df_train, df_test (thing about using sklearn.model_selection.train_test_split)\n",
    "df_train, df_test = train_test_split(df, train_size=0.8)\n",
    "df_train = df_train.reset_index()\n",
    "df_test = df_test.reset_index()\n",
    "\n",
    "MEAN = [0.485, 0.456, 0.406]\n",
    "STD = [0.229, 0.224, 0.225]\n",
    "N_EPOCHS = 10\n",
    "BATCH_SIZE = 32\n",
    "IMAGE_SIZE = 32\n",
    "\n",
    "image_transform_train = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=MEAN, std=STD)])\n",
    "\n",
    "# YOUR CODE define image_transform_test\n",
    "image_transform_test = ?\n",
    "\n",
    "# YOUR CODE define the crieterion\n",
    "criterion = ? \n",
    "\n",
    "\n",
    "net = binary_classification_model()\n",
    "\n",
    "optimizer = ?\n",
    "# initialize the BaseSampler with 1000 samples per epoch\n",
    "bs = ?\n",
    "\n",
    "# YOUR CODE\n",
    "# Instantiate the OneClassImageClassificationDatasets\n",
    "train_ds = ?\n",
    "test_ds = ?\n",
    "\n",
    "#YOUR CODE\n",
    "#Initialize your DataLoader (using datasets)\n",
    "train_dl = ?\n",
    "test_dl = ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "def evaluate_model(model, loader, print_info=False):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        collect_results = []\n",
    "        collect_target = []\n",
    "        for batch in loader:\n",
    "            X, y = batch\n",
    "            X = X.to(DEVICE)\n",
    "            y = y.to(DEVICE).detach().cpu().numpy()\n",
    "            pred = model(X)\n",
    "            collect_results.append(pred.sigmoid().detach().cpu().numpy())\n",
    "            collect_target.append(y) \n",
    "    \n",
    "        preds_proba = np.concatenate(collect_results)\n",
    "        preds = preds_proba.argmax(axis=1)\n",
    "        \n",
    "        targets = np.concatenate(collect_target)\n",
    "        \n",
    "        ll = log_loss(targets, preds_proba)\n",
    "        acc = accuracy_score(targets, preds)\n",
    "        if print_info:\n",
    "            print(\"test log-loss: {}\".format(ll))\n",
    "            print(\"overall accuracy:  {}\".format(acc))\n",
    "            #print(classification_report(targets, preds))\n",
    "        model.train()\n",
    "        \n",
    "        return ll, acc\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "metrics = []\n",
    "metrics_names = ['loss_train','loss_test','acc_train','acc_test']\n",
    "losses = []\n",
    "net.to(DEVICE)\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    for X, y in train_dl:\n",
    "        X = X.to(DEVICE)\n",
    "        y = y.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        ypred=net(X)\n",
    "        loss = criterion(ypred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.detach().cpu().numpy())\n",
    "        \n",
    "    testll, testacc = evaluate_model(net, test_dl)\n",
    "    trainll, trainacc = evaluate_model(net, train_dl)\n",
    "    print(\"test: {} {}\".format(testll, testacc))\n",
    "    print(\"train: {} {}\".format(trainll, trainacc))\n",
    "    metrics.append([trainll, testll, trainacc, testacc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load sns.ipynb\n",
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### Creating an image classifier able to find sneakers in instagram posts\\n\",\n",
    "    \"\\n\",\n",
    "    \"The data comprises of few thousand images of sneakers collected using google images and instagram\\n\",\n",
    "    \"and few thousand images of sneakers.    \\n\",\n",
    "    \"Your goal is to use what you learned from previous examples and create a sneaker-not-sneaker binary classifier.\\n\",\n",
    "    \"\\n\",\n",
    "    \"The task comprises of multiple sub-tasks that you need to do to build the classifier.\\n\",\n",
    "    \"\\n\",\n",
    "    \"1. Create a dataset able to load data from new_meta_sneakers.csv\\n\",\n",
    "    \"2. Create a fine tune binary classification architecture.\\n\",\n",
    "    \"3. Create a training loop and train your model.\\n\",\n",
    "    \"\\n\",\n",
    "    \"![title](sneakers.png)\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### On the bottom of the following cell you see the data you will work with\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 112,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"%matplotlib inline\\n\",\n",
    "    \"from torch import nn\\n\",\n",
    "    \"import easyimages\\n\",\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"import os\\n\",\n",
    "    \"from torch.utils.data import Dataset, DataLoader\\n\",\n",
    "    \"from pretrainedmodels.models import resnet50\\n\",\n",
    "    \"from torchvision.transforms import transforms\\n\",\n",
    "    \"from sklearn.model_selection import train_test_split\\n\",\n",
    "    \"from sklearn.metrics import log_loss, accuracy_score\\n\",\n",
    "    \"\\n\",\n",
    "    \"import matplotlib.pyplot as plt\\n\",\n",
    "    \"import torch \\n\",\n",
    "    \"DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 113,\n",
    "   \"metadata\": {\n",
    "    \"scrolled\": true\n",
    "   },\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"DATASET_USAGE_PERCENTAGE = 0.1\\n\",\n",
    "    \"\\n\",\n",
    "    \"base_path ='/media/i008/ssd500/fashion_classify_data/'\\n\",\n",
    "    \"df = pd.read_csv(os.path.join(base_path,'new_meta_sneakers.csv')).sample(frac=1)\\n\",\n",
    "    \"df.image_path = base_path +df.image_path\\n\",\n",
    "    \"df.tags = df.tags.map({'sneakers': 1, 'negatives': 0})\\n\",\n",
    "    \"df = df.sample(frac=DATASET_USAGE_PERCENTAGE)\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### Creating the torch Dataset.\\n\",\n",
    "    \"\\n\",\n",
    "    \"First thing we need to do is create a dataset able to load our data. Since our metadata is stored in a csv file, our \\n\",\n",
    "    \"dataset should accept this file as a base source of what needs to be loaded.\\n\",\n",
    "    \"\\n\",\n",
    "    \"Our dataset should also support augumentations and a \\\"inference\\\" mode wich disables them for predicting.\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 168,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"import PIL\\n\",\n",
    "    \"from PIL import Image\\n\",\n",
    "    \"import io\\n\",\n",
    "    \"import requests\\n\",\n",
    "    \"import torch\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"class OneClassImageClassificationDataset(Dataset):\\n\",\n",
    "    \"    def __init__(self, annotations, image_transform):\\n\",\n",
    "    \"        \\\"\\\"\\\"\\n\",\n",
    "    \"        annotations is a pandas dataframe\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        \\\"\\\"\\\"\\n\",\n",
    "    \"        super().__init__()\\n\",\n",
    "    \"        self.annotations = annotations\\n\",\n",
    "    \"        self.image_transform = image_transform\\n\",\n",
    "    \"\\n\",\n",
    "    \"    def __len__(self):\\n\",\n",
    "    \"        \\\"\\\"\\\"\\n\",\n",
    "    \"        Return the length of the annotations dataframe\\n\",\n",
    "    \"        \\\"\\\"\\\"\\n\",\n",
    "    \"        # your code here\\n\",\n",
    "    \"        return len(self.annotations)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    def __getitem__(self, index):\\n\",\n",
    "    \"        \\\"\\\"\\\"\\n\",\n",
    "    \"        Using methods you wrote:\\n\",\n",
    "    \"        1 - load image from disk for given index  (self.load_from_disk)\\n\",\n",
    "    \"        2 - transform image (self.image_transform)\\n\",\n",
    "    \"        3 - Load target (self.load_target)\\n\",\n",
    "    \"        return Xi, yi\\n\",\n",
    "    \"        \\\"\\\"\\\"\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # YOUR CODE HERE\\n\",\n",
    "    \"\\n\",\n",
    "    \"        Xi = self.load_from_disk(index)\\n\",\n",
    "    \"        Xi = self.image_transform(Xi)\\n\",\n",
    "    \"        yi = self.load_target(index)\\n\",\n",
    "    \"        return Xi, yi\\n\",\n",
    "    \"\\n\",\n",
    "    \"    def load_to_pil(self, uri):\\n\",\n",
    "    \"        \\\"\\\"\\\"\\n\",\n",
    "    \"        Write a helper function that uses PIL.Image to load a file and returns it\\n\",\n",
    "    \"        \\\"\\\"\\\"\\n\",\n",
    "    \"\\n\",\n",
    "    \"        image_pil = Image.open(uri)\\n\",\n",
    "    \"        image_pil = image_pil.convert(\\\"RGB\\\")\\n\",\n",
    "    \"        # image_pil = YOUR CODE HERE\\n\",\n",
    "    \"        return image_pil\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"    def load_from_disk(self, index):\\n\",\n",
    "    \"        \\\"\\\"\\\"\\n\",\n",
    "    \"        Loads an image from disk given a index.\\n\",\n",
    "    \"        It gets the path of an image with the corresponding index from the metadata \\n\",\n",
    "    \"        It passes the URI to the self.load_to_pil and returns a PIL.Image\\n\",\n",
    "    \"        \\\"\\\"\\\"\\n\",\n",
    "    \"        image_path = self.annotations.iloc[index]['image_path']\\n\",\n",
    "    \"        #image_path = # YOUR CODE HERE\\n\",\n",
    "    \"        return self.load_to_pil(image_path)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    def load_target(self, index):\\n\",\n",
    "    \"        \\\"\\\"\\\"\\n\",\n",
    "    \"        This function should get the tag for a given index from the annotations dataframe\\n\",\n",
    "    \"        You .iloc can become useful.    \\n\",\n",
    "    \"        This methods should return, either a 0 or a 1.\\n\",\n",
    "    \"        \\\"\\\"\\\"\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        #label = # YOUR CODE HERE\\n\",\n",
    "    \"        label = self.annotations.iloc[index]['tags']\\n\",\n",
    "    \"\\n\",\n",
    "    \"        return label\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    \\n\",\n",
    "    \"class BaseSampler(Sampler):\\n\",\n",
    "    \"    def __init__(self, df, n_samples):\\n\",\n",
    "    \"        self.df = df\\n\",\n",
    "    \"        self.n_samples = n_samples\\n\",\n",
    "    \"        \\n\",\n",
    "    \"    def __iter__(self):\\n\",\n",
    "    \"        return iter(self._get_sample())\\n\",\n",
    "    \"        \\n\",\n",
    "    \"    def __len__(self):\\n\",\n",
    "    \"        return self.n_samples\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    def _get_sample(self):\\n\",\n",
    "    \"        return np.random.choice(len(self.df), self.n_samples, replace=False)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"\\n\",\n",
    "    \"def binary_classification_model():\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    Write a function that loads a resnet50 model from pretrainedmodels, freezes its layers\\n\",\n",
    "    \"    replaces the last_linear with the proper output number. As we did in previous example.\\n\",\n",
    "    \"    replace avgpool with adaptiv pooling.\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    model = resnet50()\\n\",\n",
    "    \"    for p in model.parameters():\\n\",\n",
    "    \"        p.requires_grad = False\\n\",\n",
    "    \"    inft = model.last_linear.in_features\\n\",\n",
    "    \"    model.last_linear = nn.Linear(in_features=inft, out_features=2)\\n\",\n",
    "    \"    model.avgpool = nn.AdaptiveAvgPool2d(1)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # model = YOUR CODE HERE\\n\",\n",
    "    \"    return model\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"from imgaug import augmenters as iaa\\n\",\n",
    "    \"\\n\",\n",
    "    \"aug_seq = iaa.Sequential([\\n\",\n",
    "    \"    iaa.Fliplr(p=0.5),\\n\",\n",
    "    \"    iaa.Sometimes(\\n\",\n",
    "    \"        0.3,\\n\",\n",
    "    \"        iaa.Multiply((0.9, 1.2))\\n\",\n",
    "    \"    ),\\n\",\n",
    "    \"    iaa.Sometimes(\\n\",\n",
    "    \"        0.3,\\n\",\n",
    "    \"        iaa.AdditiveGaussianNoise()\\n\",\n",
    "    \"    ),\\n\",\n",
    "    \"    iaa.Affine(\\n\",\n",
    "    \"        scale=(0.5, 2),\\n\",\n",
    "    \"        translate_percent=(-0.2, 0.2)\\n\",\n",
    "    \"    )\\n\",\n",
    "    \"])\\n\",\n",
    "    \"def augment(self, augmenter, image):\\n\",\n",
    "    \"    augmenter = augmenter.to_deterministic()\\n\",\n",
    "    \"    img_aug = augmenter.augment_image(np.array(image))\\n\",\n",
    "    \"    img_aug = Image.fromarray(img_aug)\\n\",\n",
    "    \"    return img_aug\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 175,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stderr\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"/home/i008/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\\n\",\n",
    "      \"  FutureWarning)\\n\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"\\n\",\n",
    "    \"# YOUR CODE HERE:\\n\",\n",
    "    \"# SPLIT the dataframe into df_train, df_test (thing about using sklearn.model_selection.train_test_split)\\n\",\n",
    "    \"df_train, df_test = train_test_split(df, train_size=0.8)\\n\",\n",
    "    \"df_train = df_train.reset_index()\\n\",\n",
    "    \"df_test = df_test.reset_index()\\n\",\n",
    "    \"\\n\",\n",
    "    \"MEAN = [0.485, 0.456, 0.406]\\n\",\n",
    "    \"STD = [0.229, 0.224, 0.225]\\n\",\n",
    "    \"N_EPOCHS = 10\\n\",\n",
    "    \"BATCH_SIZE = 32\\n\",\n",
    "    \"IMAGE_SIZE = 32\\n\",\n",
    "    \"\\n\",\n",
    "    \"image_transform_train = transforms.Compose([\\n\",\n",
    "    \"    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\\n\",\n",
    "    \"    transforms.ToTensor(),\\n\",\n",
    "    \"    transforms.Normalize(mean=MEAN, std=STD)])\\n\",\n",
    "    \"\\n\",\n",
    "    \"# YOUR CODE define image_transform_test\\n\",\n",
    "    \"image_transform_test = transforms.Compose([\\n\",\n",
    "    \"    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\\n\",\n",
    "    \"    transforms.ToTensor(),\\n\",\n",
    "    \"    transforms.Normalize(mean=MEAN, std=STD)])\\n\",\n",
    "    \"\\n\",\n",
    "    \"# YOUR CODE define the crieterion\\n\",\n",
    "    \"criterion = nn.CrossEntropyLoss()\\n\",\n",
    "    \"\\n\",\n",
    "    \"net = binary_classification_model()\\n\",\n",
    "    \"\\n\",\n",
    "    \"optimizer = torch.optim.Adam(net.parameters(), lr=0.0001)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# initialize the BaseSampler\\n\",\n",
    "    \"bs = BaseSampler(train_ds, 1000)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# YOUR CODE\\n\",\n",
    "    \"# Instantiate the OneClassImageClassificationDatasets\\n\",\n",
    "    \"train_ds = OneClassImageClassificationDataset(df_train, image_transform=image_transform_train)\\n\",\n",
    "    \"test_ds = OneClassImageClassificationDataset(df_test, image_transform=image_transform_test)\\n\",\n",
    "    \"\\n\",\n",
    "    \"#YOUR CODE\\n\",\n",
    "    \"#Initialize your DataLoader (using datasets)\\n\",\n",
    "    \"train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, sampler=bs)\\n\",\n",
    "    \"test_dl = DataLoader(test_ds, batch_size=BATCH_SIZE)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 176,\n",
    "   \"metadata\": {\n",
    "    \"scrolled\": true\n",
    "   },\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"test: 0.6851049539626844 0.5550335570469799\\n\",\n",
    "      \"train: 0.6767495510429143 0.579\\n\",\n",
    "      \"test: 0.6824289217291263 0.5718120805369128\\n\",\n",
    "      \"train: 0.6819015721082687 0.581\\n\",\n",
    "      \"test: 0.6811918862101516 0.6161073825503356\\n\",\n",
    "      \"train: 0.6855373743530363 0.62\\n\",\n",
    "      \"test: 0.6765110107951317 0.6073825503355704\\n\",\n",
    "      \"train: 0.6636039858073928 0.621\\n\",\n",
    "      \"test: 0.6719322499876917 0.6241610738255033\\n\",\n",
    "      \"train: 0.6605288547966629 0.634\\n\"\n",
    "     ]\n",
    "    },\n",
    "    {\n",
    "     \"ename\": \"KeyboardInterrupt\",\n",
    "     \"evalue\": \"\",\n",
    "     \"output_type\": \"error\",\n",
    "     \"traceback\": [\n",
    "      \"\\u001b[0;31m---------------------------------------------------------------------------\\u001b[0m\",\n",
    "      \"\\u001b[0;31mKeyboardInterrupt\\u001b[0m                         Traceback (most recent call last)\",\n",
    "      \"\\u001b[0;32m<ipython-input-176-f8e01ef63f78>\\u001b[0m in \\u001b[0;36m<module>\\u001b[0;34m()\\u001b[0m\\n\\u001b[1;32m     46\\u001b[0m \\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m     47\\u001b[0m     \\u001b[0mtestll\\u001b[0m\\u001b[0;34m,\\u001b[0m \\u001b[0mtestacc\\u001b[0m \\u001b[0;34m=\\u001b[0m \\u001b[0mevaluate_model\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0mnet\\u001b[0m\\u001b[0;34m,\\u001b[0m \\u001b[0mtest_dl\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[0;32m---> 48\\u001b[0;31m     \\u001b[0mtrainll\\u001b[0m\\u001b[0;34m,\\u001b[0m \\u001b[0mtrainacc\\u001b[0m \\u001b[0;34m=\\u001b[0m \\u001b[0mevaluate_model\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0mnet\\u001b[0m\\u001b[0;34m,\\u001b[0m \\u001b[0mtrain_dl\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[0m\\u001b[1;32m     49\\u001b[0m     \\u001b[0mprint\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0;34m\\\"test: {} {}\\\"\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0mformat\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0mtestll\\u001b[0m\\u001b[0;34m,\\u001b[0m \\u001b[0mtestacc\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m     50\\u001b[0m     \\u001b[0mprint\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0;34m\\\"train: {} {}\\\"\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0mformat\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0mtrainll\\u001b[0m\\u001b[0;34m,\\u001b[0m \\u001b[0mtrainacc\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\",\n",
    "      \"\\u001b[0;32m<ipython-input-176-f8e01ef63f78>\\u001b[0m in \\u001b[0;36mevaluate_model\\u001b[0;34m(model, loader, print_info)\\u001b[0m\\n\\u001b[1;32m      5\\u001b[0m         \\u001b[0mcollect_results\\u001b[0m \\u001b[0;34m=\\u001b[0m \\u001b[0;34m[\\u001b[0m\\u001b[0;34m]\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m      6\\u001b[0m         \\u001b[0mcollect_target\\u001b[0m \\u001b[0;34m=\\u001b[0m \\u001b[0;34m[\\u001b[0m\\u001b[0;34m]\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[0;32m----> 7\\u001b[0;31m         \\u001b[0;32mfor\\u001b[0m \\u001b[0mbatch\\u001b[0m \\u001b[0;32min\\u001b[0m \\u001b[0mloader\\u001b[0m\\u001b[0;34m:\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[0m\\u001b[1;32m      8\\u001b[0m             \\u001b[0mX\\u001b[0m\\u001b[0;34m,\\u001b[0m \\u001b[0my\\u001b[0m \\u001b[0;34m=\\u001b[0m \\u001b[0mbatch\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m      9\\u001b[0m             \\u001b[0mX\\u001b[0m \\u001b[0;34m=\\u001b[0m \\u001b[0mX\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0mto\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0mDEVICE\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\",\n",
    "      \"\\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\\u001b[0m in \\u001b[0;36m__next__\\u001b[0;34m(self)\\u001b[0m\\n\\u001b[1;32m    613\\u001b[0m         \\u001b[0;32mif\\u001b[0m \\u001b[0mself\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0mnum_workers\\u001b[0m \\u001b[0;34m==\\u001b[0m \\u001b[0;36m0\\u001b[0m\\u001b[0;34m:\\u001b[0m  \\u001b[0;31m# same-process loading\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m    614\\u001b[0m             \\u001b[0mindices\\u001b[0m \\u001b[0;34m=\\u001b[0m \\u001b[0mnext\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0mself\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0msample_iter\\u001b[0m\\u001b[0;34m)\\u001b[0m  \\u001b[0;31m# may raise StopIteration\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[0;32m--> 615\\u001b[0;31m             \\u001b[0mbatch\\u001b[0m \\u001b[0;34m=\\u001b[0m \\u001b[0mself\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0mcollate_fn\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0;34m[\\u001b[0m\\u001b[0mself\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0mdataset\\u001b[0m\\u001b[0;34m[\\u001b[0m\\u001b[0mi\\u001b[0m\\u001b[0;34m]\\u001b[0m \\u001b[0;32mfor\\u001b[0m \\u001b[0mi\\u001b[0m \\u001b[0;32min\\u001b[0m \\u001b[0mindices\\u001b[0m\\u001b[0;34m]\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[0m\\u001b[1;32m    616\\u001b[0m             \\u001b[0;32mif\\u001b[0m \\u001b[0mself\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0mpin_memory\\u001b[0m\\u001b[0;34m:\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m    617\\u001b[0m                 \\u001b[0mbatch\\u001b[0m \\u001b[0;34m=\\u001b[0m \\u001b[0mpin_memory_batch\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0mbatch\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\",\n",
    "      \"\\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\\u001b[0m in \\u001b[0;36m<listcomp>\\u001b[0;34m(.0)\\u001b[0m\\n\\u001b[1;32m    613\\u001b[0m         \\u001b[0;32mif\\u001b[0m \\u001b[0mself\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0mnum_workers\\u001b[0m \\u001b[0;34m==\\u001b[0m \\u001b[0;36m0\\u001b[0m\\u001b[0;34m:\\u001b[0m  \\u001b[0;31m# same-process loading\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m    614\\u001b[0m             \\u001b[0mindices\\u001b[0m \\u001b[0;34m=\\u001b[0m \\u001b[0mnext\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0mself\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0msample_iter\\u001b[0m\\u001b[0;34m)\\u001b[0m  \\u001b[0;31m# may raise StopIteration\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[0;32m--> 615\\u001b[0;31m             \\u001b[0mbatch\\u001b[0m \\u001b[0;34m=\\u001b[0m \\u001b[0mself\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0mcollate_fn\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0;34m[\\u001b[0m\\u001b[0mself\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0mdataset\\u001b[0m\\u001b[0;34m[\\u001b[0m\\u001b[0mi\\u001b[0m\\u001b[0;34m]\\u001b[0m \\u001b[0;32mfor\\u001b[0m \\u001b[0mi\\u001b[0m \\u001b[0;32min\\u001b[0m \\u001b[0mindices\\u001b[0m\\u001b[0;34m]\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[0m\\u001b[1;32m    616\\u001b[0m             \\u001b[0;32mif\\u001b[0m \\u001b[0mself\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0mpin_memory\\u001b[0m\\u001b[0;34m:\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m    617\\u001b[0m                 \\u001b[0mbatch\\u001b[0m \\u001b[0;34m=\\u001b[0m \\u001b[0mpin_memory_batch\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0mbatch\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\",\n",
    "      \"\\u001b[0;32m<ipython-input-168-715f597598a7>\\u001b[0m in \\u001b[0;36m__getitem__\\u001b[0;34m(self, index)\\u001b[0m\\n\\u001b[1;32m     34\\u001b[0m         \\u001b[0;31m# YOUR CODE HERE\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m     35\\u001b[0m \\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[0;32m---> 36\\u001b[0;31m         \\u001b[0mXi\\u001b[0m \\u001b[0;34m=\\u001b[0m \\u001b[0mself\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0mload_from_disk\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0mindex\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[0m\\u001b[1;32m     37\\u001b[0m         \\u001b[0mXi\\u001b[0m \\u001b[0;34m=\\u001b[0m \\u001b[0mself\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0mimage_transform\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0mXi\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m     38\\u001b[0m         \\u001b[0myi\\u001b[0m \\u001b[0;34m=\\u001b[0m \\u001b[0mself\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0mload_target\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0mindex\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\",\n",
    "      \"\\u001b[0;32m<ipython-input-168-715f597598a7>\\u001b[0m in \\u001b[0;36mload_from_disk\\u001b[0;34m(self, index)\\u001b[0m\\n\\u001b[1;32m     58\\u001b[0m         \\u001b[0mimage_path\\u001b[0m \\u001b[0;34m=\\u001b[0m \\u001b[0mself\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0mannotations\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0miloc\\u001b[0m\\u001b[0;34m[\\u001b[0m\\u001b[0mindex\\u001b[0m\\u001b[0;34m]\\u001b[0m\\u001b[0;34m[\\u001b[0m\\u001b[0;34m'image_path'\\u001b[0m\\u001b[0;34m]\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m     59\\u001b[0m         \\u001b[0;31m#image_path = # YOUR CODE HERE\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[0;32m---> 60\\u001b[0;31m         \\u001b[0;32mreturn\\u001b[0m \\u001b[0mself\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0mload_to_pil\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0mimage_path\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[0m\\u001b[1;32m     61\\u001b[0m \\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m     62\\u001b[0m     \\u001b[0;32mdef\\u001b[0m \\u001b[0mload_target\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0mself\\u001b[0m\\u001b[0;34m,\\u001b[0m \\u001b[0mindex\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m:\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\",\n",
    "      \"\\u001b[0;32m<ipython-input-168-715f597598a7>\\u001b[0m in \\u001b[0;36mload_to_pil\\u001b[0;34m(self, uri)\\u001b[0m\\n\\u001b[1;32m     45\\u001b[0m \\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m     46\\u001b[0m         \\u001b[0mimage_pil\\u001b[0m \\u001b[0;34m=\\u001b[0m \\u001b[0mImage\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0mopen\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0muri\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[0;32m---> 47\\u001b[0;31m         \\u001b[0mimage_pil\\u001b[0m \\u001b[0;34m=\\u001b[0m \\u001b[0mimage_pil\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0mconvert\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0;34m\\\"RGB\\\"\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[0m\\u001b[1;32m     48\\u001b[0m         \\u001b[0;31m# image_pil = YOUR CODE HERE\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m     49\\u001b[0m         \\u001b[0;32mreturn\\u001b[0m \\u001b[0mimage_pil\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\",\n",
    "      \"\\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/PIL/Image.py\\u001b[0m in \\u001b[0;36mconvert\\u001b[0;34m(self, mode, matrix, dither, palette, colors)\\u001b[0m\\n\\u001b[1;32m    890\\u001b[0m         \\\"\\\"\\\"\\n\\u001b[1;32m    891\\u001b[0m \\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[0;32m--> 892\\u001b[0;31m         \\u001b[0mself\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0mload\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[0m\\u001b[1;32m    893\\u001b[0m \\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m    894\\u001b[0m         \\u001b[0;32mif\\u001b[0m \\u001b[0;32mnot\\u001b[0m \\u001b[0mmode\\u001b[0m \\u001b[0;32mand\\u001b[0m \\u001b[0mself\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0mmode\\u001b[0m \\u001b[0;34m==\\u001b[0m \\u001b[0;34m\\\"P\\\"\\u001b[0m\\u001b[0;34m:\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\",\n",
    "      \"\\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/PIL/ImageFile.py\\u001b[0m in \\u001b[0;36mload\\u001b[0;34m(self)\\u001b[0m\\n\\u001b[1;32m    233\\u001b[0m \\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m    234\\u001b[0m                             \\u001b[0mb\\u001b[0m \\u001b[0;34m=\\u001b[0m \\u001b[0mb\\u001b[0m \\u001b[0;34m+\\u001b[0m \\u001b[0ms\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[0;32m--> 235\\u001b[0;31m                             \\u001b[0mn\\u001b[0m\\u001b[0;34m,\\u001b[0m \\u001b[0merr_code\\u001b[0m \\u001b[0;34m=\\u001b[0m \\u001b[0mdecoder\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0mdecode\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0mb\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[0m\\u001b[1;32m    236\\u001b[0m                             \\u001b[0;32mif\\u001b[0m \\u001b[0mn\\u001b[0m \\u001b[0;34m<\\u001b[0m \\u001b[0;36m0\\u001b[0m\\u001b[0;34m:\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m    237\\u001b[0m                                 \\u001b[0;32mbreak\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\",\n",
    "      \"\\u001b[0;31mKeyboardInterrupt\\u001b[0m: \"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"import numpy as np \\n\",\n",
    "    \"def evaluate_model(model, loader, print_info=False):\\n\",\n",
    "    \"    with torch.no_grad():\\n\",\n",
    "    \"        model.eval()\\n\",\n",
    "    \"        collect_results = []\\n\",\n",
    "    \"        collect_target = []\\n\",\n",
    "    \"        for batch in loader:\\n\",\n",
    "    \"            X, y = batch\\n\",\n",
    "    \"            X = X.to(DEVICE)\\n\",\n",
    "    \"            y = y.to(DEVICE).detach().cpu().numpy()\\n\",\n",
    "    \"            pred = model(X)\\n\",\n",
    "    \"            collect_results.append(pred.sigmoid().detach().cpu().numpy())\\n\",\n",
    "    \"            collect_target.append(y) \\n\",\n",
    "    \"    \\n\",\n",
    "    \"        preds_proba = np.concatenate(collect_results)\\n\",\n",
    "    \"        preds = preds_proba.argmax(axis=1)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        targets = np.concatenate(collect_target)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        ll = log_loss(targets, preds_proba)\\n\",\n",
    "    \"        acc = accuracy_score(targets, preds)\\n\",\n",
    "    \"        if print_info:\\n\",\n",
    "    \"            print(\\\"test log-loss: {}\\\".format(ll))\\n\",\n",
    "    \"            print(\\\"overall accuracy:  {}\\\".format(acc))\\n\",\n",
    "    \"            #print(classification_report(targets, preds))\\n\",\n",
    "    \"        model.train()\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        return ll, acc\\n\",\n",
    "    \"    \\n\",\n",
    "    \"metrics = []\\n\",\n",
    "    \"metrics_names = ['loss_train','loss_test','acc_train','acc_test']\\n\",\n",
    "    \"losses = []\\n\",\n",
    "    \"\\n\",\n",
    "    \"net.to(DEVICE)\\n\",\n",
    "    \"\\n\",\n",
    "    \"for epoch in range(N_EPOCHS):\\n\",\n",
    "    \"    for X, y in train_dl:\\n\",\n",
    "    \"        X = X.to(DEVICE)\\n\",\n",
    "    \"        y = y.to(DEVICE)\\n\",\n",
    "    \"        optimizer.zero_grad()\\n\",\n",
    "    \"        ypred=net(X)\\n\",\n",
    "    \"        loss = criterion(ypred, y)\\n\",\n",
    "    \"        loss.backward()\\n\",\n",
    "    \"        optimizer.step()\\n\",\n",
    "    \"        losses.append(loss.detach().cpu().numpy())\\n\",\n",
    "    \"        \\n\",\n",
    "    \"    testll, testacc = evaluate_model(net, test_dl)\\n\",\n",
    "    \"    trainll, trainacc = evaluate_model(net, train_dl)\\n\",\n",
    "    \"    print(\\\"test: {} {}\\\".format(testll, testacc))\\n\",\n",
    "    \"    print(\\\"train: {} {}\\\".format(trainll, trainacc))\\n\",\n",
    "    \"    metrics.append([trainll, testll, trainacc, testacc])\\n\",\n",
    "    \"        \"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python [default]\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.6.4\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 2\n",
    "}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
