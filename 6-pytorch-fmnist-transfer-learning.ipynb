{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms \n",
    "import pandas as pd\n",
    "import PIL\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from easyimages import EasyImageList\n",
    "from torch import nn\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, classification_report, log_loss\n",
    "from pretrainedmodels.models import resnet18, resnet50\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For details related to dataloading check the previous notebook (pytorch-fmnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {\n",
    " 0: 'T-shirt/top',\n",
    " 1: 'Trouser',\n",
    " 2: 'Pullover',\n",
    " 3: 'Dress',\n",
    " 4: 'Coat',\n",
    " 5: 'Sandal',\n",
    " 6: 'Shirt',\n",
    " 7: 'Sneaker',\n",
    " 8: 'Bag',\n",
    " 9: 'Ankle boot'\n",
    "}\n",
    "\n",
    "class FashionMnist(Dataset):\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.metadata_df)\n",
    "\n",
    "    def __init__(self, metadata_df,\n",
    "                 transform=None):\n",
    "        \n",
    "        self.metadata_df = metadata_df.copy()\n",
    "        self.transform = transform\n",
    "    \n",
    "    def load_image_and_target(self,index):\n",
    "        # .iloc is short for integer loc it returns a row of data based on its ored not index-value(if not the same)\n",
    "        oneimage = self.metadata_df.iloc[index]\n",
    "        image, y = PIL.Image.fromarray(\n",
    "            np.array(oneimage[1:]).reshape(28, 28).astype('uint8'), 'L').convert('RGB'), oneimage[0]\n",
    "        return image, y\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        X, y = self.load_image_and_target(index)\n",
    "        # We can transform the output images here, cast to torch data-format and/or do augmentations\n",
    "        X = self.transform(X)\n",
    "            \n",
    "        return X, y\n",
    "\n",
    "    def collate_func(self, batch):\n",
    "        pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Understanding AdaptiveAveragePooling\n",
    "\n",
    "In a moment you will see that we change one of the pretrained models by swaping  the AveragePool operation for AdaptiveAveragePooling.\n",
    "\n",
    "The ideas is that adaptive pooling always returns our desired shape. This is useful if you want your NN to support different images shapes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128, 1, 1])\n",
      "torch.Size([1, 128, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.randn((1, 128, 8, 8))\n",
    "\n",
    "print(nn.AdaptiveAvgPool2d((1, 1))(tensor).shape)\n",
    "print(nn.AvgPool2d((3,3))(tensor).shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adapting a pretrained model to be used for different number of classes\n",
    "By default many of the pretrained models require a input image of a given shape (usually 224x224x3) This is not our case so we need to chaged that, one way to do it is to change the network architecture of the model as described in Adaptive Pooling Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
      "              ReLU-7           [-1, 64, 56, 56]               0\n",
      "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
      "             ReLU-10           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-11           [-1, 64, 56, 56]               0\n",
      "           Conv2d-12           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-13           [-1, 64, 56, 56]             128\n",
      "             ReLU-14           [-1, 64, 56, 56]               0\n",
      "           Conv2d-15           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-16           [-1, 64, 56, 56]             128\n",
      "             ReLU-17           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-18           [-1, 64, 56, 56]               0\n",
      "           Conv2d-19          [-1, 128, 28, 28]          73,728\n",
      "      BatchNorm2d-20          [-1, 128, 28, 28]             256\n",
      "             ReLU-21          [-1, 128, 28, 28]               0\n",
      "           Conv2d-22          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-23          [-1, 128, 28, 28]             256\n",
      "           Conv2d-24          [-1, 128, 28, 28]           8,192\n",
      "      BatchNorm2d-25          [-1, 128, 28, 28]             256\n",
      "             ReLU-26          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-27          [-1, 128, 28, 28]               0\n",
      "           Conv2d-28          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-29          [-1, 128, 28, 28]             256\n",
      "             ReLU-30          [-1, 128, 28, 28]               0\n",
      "           Conv2d-31          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-32          [-1, 128, 28, 28]             256\n",
      "             ReLU-33          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-34          [-1, 128, 28, 28]               0\n",
      "           Conv2d-35          [-1, 256, 14, 14]         294,912\n",
      "      BatchNorm2d-36          [-1, 256, 14, 14]             512\n",
      "             ReLU-37          [-1, 256, 14, 14]               0\n",
      "           Conv2d-38          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-39          [-1, 256, 14, 14]             512\n",
      "           Conv2d-40          [-1, 256, 14, 14]          32,768\n",
      "      BatchNorm2d-41          [-1, 256, 14, 14]             512\n",
      "             ReLU-42          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-43          [-1, 256, 14, 14]               0\n",
      "           Conv2d-44          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-45          [-1, 256, 14, 14]             512\n",
      "             ReLU-46          [-1, 256, 14, 14]               0\n",
      "           Conv2d-47          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-48          [-1, 256, 14, 14]             512\n",
      "             ReLU-49          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-50          [-1, 256, 14, 14]               0\n",
      "           Conv2d-51            [-1, 512, 7, 7]       1,179,648\n",
      "      BatchNorm2d-52            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-53            [-1, 512, 7, 7]               0\n",
      "           Conv2d-54            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-55            [-1, 512, 7, 7]           1,024\n",
      "           Conv2d-56            [-1, 512, 7, 7]         131,072\n",
      "      BatchNorm2d-57            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-58            [-1, 512, 7, 7]               0\n",
      "       BasicBlock-59            [-1, 512, 7, 7]               0\n",
      "           Conv2d-60            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-61            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-62            [-1, 512, 7, 7]               0\n",
      "           Conv2d-63            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-64            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-65            [-1, 512, 7, 7]               0\n",
      "       BasicBlock-66            [-1, 512, 7, 7]               0\n",
      "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
      "           Linear-68                 [-1, 1024]         525,312\n",
      "           Linear-69                   [-1, 10]          10,250\n",
      "================================================================\n",
      "Total params: 11,712,074\n",
      "Trainable params: 11,712,074\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 62.79\n",
      "Params size (MB): 44.68\n",
      "Estimated Total Size (MB): 108.05\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "N_CLASSES = 10\n",
    "\n",
    "def freeze_model(model):\n",
    "    model.eval()\n",
    "    for params in model.parameters():\n",
    "        params.requires_grad = False\n",
    "        \n",
    "cnn = resnet18(pretrained='imagenet')\n",
    "# freeze_model(cnn)\n",
    "cnn.avgpool = nn.AdaptiveAvgPool2d(1) # This will allow to use different input sizes\n",
    "cnn.last_linear = nn.Sequential(nn.Linear(cnn.last_linear.in_features, 1024), \n",
    "                                nn.Linear(1024, 10))\n",
    "\n",
    "from torchsummary import torchsummary\n",
    "\n",
    "torchsummary.summary(cnn.cuda(), input_size=(3, 224,224))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define your loss function / crieterion, optimizers and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.5282)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR= 0.005\n",
    "BATCH_SIZE = 8\n",
    "DATASET_USAGE_SIZE = 0.15\n",
    "N_CLASSES = 10\n",
    "\n",
    "MEAN = [0.485, 0.456, 0.406]\n",
    "STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "OPTIMIZER = 'SGD' # one of ['ASGD','Adadelta', 'Adagrad','Adam', 'Adamax','LBFGS', 'RMSprop','Rprop','SGD',SparseAdam']\n",
    "optimizer = getattr(torch.optim, OPTIMIZER)(cnn.parameters(), lr=LR)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "cnn.to(DEVICE)\n",
    "\n",
    "# Create dataset loaders\n",
    "    \n",
    "PATH_TO_FMNIST_TRAIN = './data/fashion-mnist_train.csv'\n",
    "PATH_TO_FMNIST_TEST = './data/fashion-mnist_test.csv'\n",
    "\n",
    "\n",
    "dftrain = pd.read_csv(PATH_TO_FMNIST_TRAIN).sample(frac=DATASET_USAGE_SIZE)\n",
    "dftest = pd.read_csv(PATH_TO_FMNIST_TEST).sample(frac=0.1)\n",
    "\n",
    "transform_train = transforms.Compose([transforms.Resize(34), \n",
    "                                      transforms.ToTensor(), \n",
    "                                      transforms.Normalize(mean=MEAN, std=STD)\n",
    "                                     ]\n",
    "                                    )\n",
    "fmnist_train = FashionMnist(dftrain, transform=transform_train)\n",
    "\n",
    "transform_test = transforms.Compose([transforms.Resize(34), \n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize(mean=MEAN, std=STD)\n",
    "                                    ])\n",
    "fmnist_test = FashionMnist(dftest, transform=transform_test)\n",
    "\n",
    "fmnist_train_dl = DataLoader(fmnist_train, batch_size=BATCH_SIZE)\n",
    "fmnist_test_dl = DataLoader(fmnist_test, batch_size=BATCH_SIZE)\n",
    "\n",
    "# Lets try to use the criterion with dummy data\n",
    "yp = torch.randn(BATCH_SIZE, 10)\n",
    "yt = torch.randint(10, (BATCH_SIZE,))\n",
    "criterion(yp, yt.long())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test: loss: 1.4739263507127762  acc: 0.862\n",
      "train: loss: 1.469683728562461  acc: 0.8712222222222222\n",
      "test: loss: 1.4466450746059418  acc: 0.867\n",
      "train: loss: 1.4374936942524381  acc: 0.8966666666666666\n",
      "test: loss: 1.4236784858703613  acc: 0.892\n",
      "train: loss: 1.4104776178995768  acc: 0.9188888888888889\n",
      "test: loss: 1.4379491866827012  acc: 0.864\n",
      "train: loss: 1.4206103569401636  acc: 0.9097777777777778\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-d15ad8695585>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mcollect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, test_loader, print_info=False):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        collect_results = []\n",
    "        collect_target = []\n",
    "        for batch in test_loader:\n",
    "            X, y = batch\n",
    "#             X = X.repeat(1, 3, 1, 1)\n",
    "            X = X.to(DEVICE)\n",
    "            y = y.to(DEVICE).detach().cpu().numpy()\n",
    "            pred = cnn(X)\n",
    "            collect_results.append(pred.sigmoid().detach().cpu().numpy())\n",
    "            collect_target.append(y) \n",
    "        \n",
    "    preds_proba = np.concatenate(collect_results)\n",
    "    preds = preds_proba.argmax(axis=1)\n",
    "    targets = np.concatenate(collect_target)\n",
    "\n",
    "    ll = log_loss(targets, preds_proba)\n",
    "    acc = accuracy_score(targets, preds)\n",
    "    if print_info:\n",
    "        print(\"test log-loss: {}\".format(ll))\n",
    "        print(\"overall accuracy:  {}\".format(ac))\n",
    "#         print(classification_report(targets, preds))\n",
    "    model.train()\n",
    "#         freeze_model(model)\n",
    "        \n",
    "    return ll, acc\n",
    "            \n",
    "collect = []\n",
    "for epoch in range(50):\n",
    "    lossacc = 0\n",
    "    for i, batch in enumerate(fmnist_train_dl):\n",
    "        optimizer.zero_grad()\n",
    "        X, y = batch\n",
    "#         X = X.repeat(1, 3, 1, 1)\n",
    "        X = X.to(DEVICE)\n",
    "        y = y.to(DEVICE)\n",
    "        y_pred = cnn(X)\n",
    "        \n",
    "        loss = criterion(y_pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()  \n",
    "        collect.append(float(loss.detach().cpu().numpy()))  \n",
    "        \n",
    "    lltest, acctest = evaluate_model(cnn, fmnist_test_dl)\n",
    "    lltrain, acctrain = evaluate_model(cnn, fmnist_train_dl)\n",
    "    print(\"test: loss: {}  acc: {}\".format(lltest, acctest))\n",
    "    print(\"train: loss: {}  acc: {}\".format(lltrain, acctrain))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "\n",
    "- What do you think of the results?\n",
    "- Try training the model without freezing. What do you observe?\n",
    "- Visualize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff2c8b3a810>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "plt.plot(collect[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "history": [],
  "kernelspec": {
   "display_name": "Python [conda env:dl]",
   "language": "python",
   "name": "conda-env-dl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "neptune": {
   "notebookId": "e79d9601-dbae-479e-adc4-09f7dabee6a2"
  },
  "uuid": "22f8e5a2-5805-454e-bfe0-bbbe88dddae8"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
