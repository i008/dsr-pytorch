{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pathlib\n",
    "from torchvision.transforms import ToTensor, Normalize, Resize, ToPILImage\n",
    "import PIL\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "class ImageLoader(Dataset):\n",
    "    def __init__(self, path='/media/i008/ssd500/small_sneaker_not_sneaker/sneaker'):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.path = path\n",
    "        \n",
    "        path = pathlib.Path(path)\n",
    "        self.image_list = list(path.glob(\"*.jpg\"))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_list)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, ix):\n",
    "        image = PIL.Image.open(self.image_list[ix]).convert(\"RGB\")\n",
    "        image = Resize((256, 256))(image)\n",
    "        image = ToTensor()(image)\n",
    "        \n",
    "        return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     def forward(self, image_list, feature_maps):\n",
    "#         grid_sizes = tuple([feature_map.shape[-2:] for feature_map in feature_maps])\n",
    "#         image_size = image_list.tensors.shape[-2:]\n",
    "#         strides = tuple((image_size[0] / g[0], image_size[1] / g[1]) for g in grid_sizes)\n",
    "#         dtype, device = feature_maps[0].dtype, feature_maps[0].device\n",
    "#         self.set_cell_anchors(dtype, device)\n",
    "#         anchors_over_all_feature_maps = self.cached_grid_anchors(grid_sizes, strides)\n",
    "#         anchors = []\n",
    "#         for i, (image_height, image_width) in enumerate(image_list.image_sizes):\n",
    "#             anchors_in_image = []\n",
    "#             for anchors_per_feature_map in anchors_over_all_feature_maps:\n",
    "#                 anchors_in_image.append(anchors_per_feature_map)\n",
    "#             anchors.append(anchors_in_image)\n",
    "#         anchors = [torch.cat(anchors_per_image) for anchors_per_image in anchors]\n",
    "#         return anchors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models.detection.rpn import AnchorGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "anch = AnchorGenerator(sizes=((128,),(64,)), aspect_ratios=((1.0,),(1.0,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n"
     ]
    }
   ],
   "source": [
    "%pdb 1\n",
    "\n",
    "from collections import namedtuple\n",
    "\n",
    "t = namedtuple('bla', ['tensors','image_sizes'])\n",
    "\n",
    "# \n",
    "ok = anch(image_list=t(torch.rand(1, 1), \n",
    "                       torch.tensor([[32,32],[32,32]])),\n",
    "          \n",
    "          feature_maps=[torch.rand(2, 1, 8, 8)])#, torch.rand(1,1,4,4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-90-1772b66b7dd9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mok\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m<ipython-input-90-1772b66b7dd9>\u001b[0m(1)\u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m----> 1 \u001b[0;31m\u001b[0mok\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> q\n"
     ]
    }
   ],
   "source": [
    "ok[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "\n",
    "# load a model pre-trained pre-trained on COCO\n",
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "\n",
    "# replace the classifier with a new one, that has\n",
    "# num_classes which is user-defined\n",
    "num_classes = 2  # 1 class (person) + background\n",
    "# get number of input features for the classifier\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "# replace the pre-trained head with a new one\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FasterRCNN(\n",
       "  (transform): GeneralizedRCNNTransform()\n",
       "  (backbone): BackboneWithFPN(\n",
       "    (body): IntermediateLayerGetter(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): FrozenBatchNorm2d()\n",
       "      (relu): ReLU(inplace)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): FrozenBatchNorm2d()\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d()\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d()\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d()\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fpn): FeaturePyramidNetwork(\n",
       "      (inner_blocks): ModuleList(\n",
       "        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (layer_blocks): ModuleList(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (extra_blocks): LastLevelMaxPool()\n",
       "    )\n",
       "  )\n",
       "  (rpn): RegionProposalNetwork(\n",
       "    (anchor_generator): AnchorGenerator()\n",
       "    (head): RPNHead(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (roi_heads): RoIHeads(\n",
       "    (box_roi_pool): MultiScaleRoIAlign()\n",
       "    (box_head): TwoMLPHead(\n",
       "      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
       "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (box_predictor): FastRCNNPredictor(\n",
       "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
       "      (bbox_pred): Linear(in_features=1024, out_features=8, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class DenseBlock(nn.Block):\n",
    "#     def __init__(self, num_convs, num_channels, **kwargs):\n",
    "#         super(DenseBlock, self).__init__(**kwargs)\n",
    "#         self.net = nn.Sequential()\n",
    "#         for _ in range(num_convs):\n",
    "#             self.net.add(conv_block(num_channels))\n",
    "\n",
    "#     def forward(self, X):\n",
    "#         for blk in self.net:\n",
    "#             Y = blk(X)\n",
    "#             # Concatenate the input and output of each block on the channel\n",
    "#             # dimension\n",
    "#             X = nd.concat(X, Y, dim=1)\n",
    "#         return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bla(torch.nn.Module):\n",
    "    \n",
    "        def __init__(self):\n",
    "            super(Bla, self).__init__()\n",
    "            self.m = torch.nn.Sequential(*[torch.nn.Conv2d(32, 32, 3) for a in range(6)])\n",
    "            \n",
    "        def forward(self, X):\n",
    "            for m in self.m:\n",
    "                Y = m(X)\n",
    "                torch.cat([X, Y], dim=1)\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "bla = Bla(to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n"
     ]
    }
   ],
   "source": [
    "for m in bla.m:\n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size 32 32 3 3, expected input[1, 3, 224, 224] to have 32 channels, but got 3 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-109-ea0c6a9a1824>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbla\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-107-746e04191c15>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                 \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m                 \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    336\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    337\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 338\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size 32 32 3 3, expected input[1, 3, 224, 224] to have 32 channels, but got 3 channels instead"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/home/i008/anaconda3/envs/dl/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m(338)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    336 \u001b[0;31m                            _pair(0), self.dilation, self.groups)\n",
      "\u001b[0m\u001b[0;32m    337 \u001b[0;31m        return F.conv2d(input, self.weight, self.bias, self.stride,\n",
      "\u001b[0m\u001b[0;32m--> 338 \u001b[0;31m                        self.padding, self.dilation, self.groups)\n",
      "\u001b[0m\u001b[0;32m    339 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    340 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> q\n"
     ]
    }
   ],
   "source": [
    "bla(torch.rand(1, 3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models.densenet import densenet121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = densenet121()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "       BatchNorm2d-5           [-1, 64, 56, 56]             128\n",
      "              ReLU-6           [-1, 64, 56, 56]               0\n",
      "            Conv2d-7          [-1, 128, 56, 56]           8,192\n",
      "       BatchNorm2d-8          [-1, 128, 56, 56]             256\n",
      "              ReLU-9          [-1, 128, 56, 56]               0\n",
      "           Conv2d-10           [-1, 32, 56, 56]          36,864\n",
      "      BatchNorm2d-11           [-1, 96, 56, 56]             192\n",
      "             ReLU-12           [-1, 96, 56, 56]               0\n",
      "           Conv2d-13          [-1, 128, 56, 56]          12,288\n",
      "      BatchNorm2d-14          [-1, 128, 56, 56]             256\n",
      "             ReLU-15          [-1, 128, 56, 56]               0\n",
      "           Conv2d-16           [-1, 32, 56, 56]          36,864\n",
      "      BatchNorm2d-17          [-1, 128, 56, 56]             256\n",
      "             ReLU-18          [-1, 128, 56, 56]               0\n",
      "           Conv2d-19          [-1, 128, 56, 56]          16,384\n",
      "      BatchNorm2d-20          [-1, 128, 56, 56]             256\n",
      "             ReLU-21          [-1, 128, 56, 56]               0\n",
      "           Conv2d-22           [-1, 32, 56, 56]          36,864\n",
      "      BatchNorm2d-23          [-1, 160, 56, 56]             320\n",
      "             ReLU-24          [-1, 160, 56, 56]               0\n",
      "           Conv2d-25          [-1, 128, 56, 56]          20,480\n",
      "      BatchNorm2d-26          [-1, 128, 56, 56]             256\n",
      "             ReLU-27          [-1, 128, 56, 56]               0\n",
      "           Conv2d-28           [-1, 32, 56, 56]          36,864\n",
      "      BatchNorm2d-29          [-1, 192, 56, 56]             384\n",
      "             ReLU-30          [-1, 192, 56, 56]               0\n",
      "           Conv2d-31          [-1, 128, 56, 56]          24,576\n",
      "      BatchNorm2d-32          [-1, 128, 56, 56]             256\n",
      "             ReLU-33          [-1, 128, 56, 56]               0\n",
      "           Conv2d-34           [-1, 32, 56, 56]          36,864\n",
      "      BatchNorm2d-35          [-1, 224, 56, 56]             448\n",
      "             ReLU-36          [-1, 224, 56, 56]               0\n",
      "           Conv2d-37          [-1, 128, 56, 56]          28,672\n",
      "      BatchNorm2d-38          [-1, 128, 56, 56]             256\n",
      "             ReLU-39          [-1, 128, 56, 56]               0\n",
      "           Conv2d-40           [-1, 32, 56, 56]          36,864\n",
      "      BatchNorm2d-41          [-1, 256, 56, 56]             512\n",
      "             ReLU-42          [-1, 256, 56, 56]               0\n",
      "           Conv2d-43          [-1, 128, 56, 56]          32,768\n",
      "        AvgPool2d-44          [-1, 128, 28, 28]               0\n",
      "      BatchNorm2d-45          [-1, 128, 28, 28]             256\n",
      "             ReLU-46          [-1, 128, 28, 28]               0\n",
      "           Conv2d-47          [-1, 128, 28, 28]          16,384\n",
      "      BatchNorm2d-48          [-1, 128, 28, 28]             256\n",
      "             ReLU-49          [-1, 128, 28, 28]               0\n",
      "           Conv2d-50           [-1, 32, 28, 28]          36,864\n",
      "      BatchNorm2d-51          [-1, 160, 28, 28]             320\n",
      "             ReLU-52          [-1, 160, 28, 28]               0\n",
      "           Conv2d-53          [-1, 128, 28, 28]          20,480\n",
      "      BatchNorm2d-54          [-1, 128, 28, 28]             256\n",
      "             ReLU-55          [-1, 128, 28, 28]               0\n",
      "           Conv2d-56           [-1, 32, 28, 28]          36,864\n",
      "      BatchNorm2d-57          [-1, 192, 28, 28]             384\n",
      "             ReLU-58          [-1, 192, 28, 28]               0\n",
      "           Conv2d-59          [-1, 128, 28, 28]          24,576\n",
      "      BatchNorm2d-60          [-1, 128, 28, 28]             256\n",
      "             ReLU-61          [-1, 128, 28, 28]               0\n",
      "           Conv2d-62           [-1, 32, 28, 28]          36,864\n",
      "      BatchNorm2d-63          [-1, 224, 28, 28]             448\n",
      "             ReLU-64          [-1, 224, 28, 28]               0\n",
      "           Conv2d-65          [-1, 128, 28, 28]          28,672\n",
      "      BatchNorm2d-66          [-1, 128, 28, 28]             256\n",
      "             ReLU-67          [-1, 128, 28, 28]               0\n",
      "           Conv2d-68           [-1, 32, 28, 28]          36,864\n",
      "      BatchNorm2d-69          [-1, 256, 28, 28]             512\n",
      "             ReLU-70          [-1, 256, 28, 28]               0\n",
      "           Conv2d-71          [-1, 128, 28, 28]          32,768\n",
      "      BatchNorm2d-72          [-1, 128, 28, 28]             256\n",
      "             ReLU-73          [-1, 128, 28, 28]               0\n",
      "           Conv2d-74           [-1, 32, 28, 28]          36,864\n",
      "      BatchNorm2d-75          [-1, 288, 28, 28]             576\n",
      "             ReLU-76          [-1, 288, 28, 28]               0\n",
      "           Conv2d-77          [-1, 128, 28, 28]          36,864\n",
      "      BatchNorm2d-78          [-1, 128, 28, 28]             256\n",
      "             ReLU-79          [-1, 128, 28, 28]               0\n",
      "           Conv2d-80           [-1, 32, 28, 28]          36,864\n",
      "      BatchNorm2d-81          [-1, 320, 28, 28]             640\n",
      "             ReLU-82          [-1, 320, 28, 28]               0\n",
      "           Conv2d-83          [-1, 128, 28, 28]          40,960\n",
      "      BatchNorm2d-84          [-1, 128, 28, 28]             256\n",
      "             ReLU-85          [-1, 128, 28, 28]               0\n",
      "           Conv2d-86           [-1, 32, 28, 28]          36,864\n",
      "      BatchNorm2d-87          [-1, 352, 28, 28]             704\n",
      "             ReLU-88          [-1, 352, 28, 28]               0\n",
      "           Conv2d-89          [-1, 128, 28, 28]          45,056\n",
      "      BatchNorm2d-90          [-1, 128, 28, 28]             256\n",
      "             ReLU-91          [-1, 128, 28, 28]               0\n",
      "           Conv2d-92           [-1, 32, 28, 28]          36,864\n",
      "      BatchNorm2d-93          [-1, 384, 28, 28]             768\n",
      "             ReLU-94          [-1, 384, 28, 28]               0\n",
      "           Conv2d-95          [-1, 128, 28, 28]          49,152\n",
      "      BatchNorm2d-96          [-1, 128, 28, 28]             256\n",
      "             ReLU-97          [-1, 128, 28, 28]               0\n",
      "           Conv2d-98           [-1, 32, 28, 28]          36,864\n",
      "      BatchNorm2d-99          [-1, 416, 28, 28]             832\n",
      "            ReLU-100          [-1, 416, 28, 28]               0\n",
      "          Conv2d-101          [-1, 128, 28, 28]          53,248\n",
      "     BatchNorm2d-102          [-1, 128, 28, 28]             256\n",
      "            ReLU-103          [-1, 128, 28, 28]               0\n",
      "          Conv2d-104           [-1, 32, 28, 28]          36,864\n",
      "     BatchNorm2d-105          [-1, 448, 28, 28]             896\n",
      "            ReLU-106          [-1, 448, 28, 28]               0\n",
      "          Conv2d-107          [-1, 128, 28, 28]          57,344\n",
      "     BatchNorm2d-108          [-1, 128, 28, 28]             256\n",
      "            ReLU-109          [-1, 128, 28, 28]               0\n",
      "          Conv2d-110           [-1, 32, 28, 28]          36,864\n",
      "     BatchNorm2d-111          [-1, 480, 28, 28]             960\n",
      "            ReLU-112          [-1, 480, 28, 28]               0\n",
      "          Conv2d-113          [-1, 128, 28, 28]          61,440\n",
      "     BatchNorm2d-114          [-1, 128, 28, 28]             256\n",
      "            ReLU-115          [-1, 128, 28, 28]               0\n",
      "          Conv2d-116           [-1, 32, 28, 28]          36,864\n",
      "     BatchNorm2d-117          [-1, 512, 28, 28]           1,024\n",
      "            ReLU-118          [-1, 512, 28, 28]               0\n",
      "          Conv2d-119          [-1, 256, 28, 28]         131,072\n",
      "       AvgPool2d-120          [-1, 256, 14, 14]               0\n",
      "     BatchNorm2d-121          [-1, 256, 14, 14]             512\n",
      "            ReLU-122          [-1, 256, 14, 14]               0\n",
      "          Conv2d-123          [-1, 128, 14, 14]          32,768\n",
      "     BatchNorm2d-124          [-1, 128, 14, 14]             256\n",
      "            ReLU-125          [-1, 128, 14, 14]               0\n",
      "          Conv2d-126           [-1, 32, 14, 14]          36,864\n",
      "     BatchNorm2d-127          [-1, 288, 14, 14]             576\n",
      "            ReLU-128          [-1, 288, 14, 14]               0\n",
      "          Conv2d-129          [-1, 128, 14, 14]          36,864\n",
      "     BatchNorm2d-130          [-1, 128, 14, 14]             256\n",
      "            ReLU-131          [-1, 128, 14, 14]               0\n",
      "          Conv2d-132           [-1, 32, 14, 14]          36,864\n",
      "     BatchNorm2d-133          [-1, 320, 14, 14]             640\n",
      "            ReLU-134          [-1, 320, 14, 14]               0\n",
      "          Conv2d-135          [-1, 128, 14, 14]          40,960\n",
      "     BatchNorm2d-136          [-1, 128, 14, 14]             256\n",
      "            ReLU-137          [-1, 128, 14, 14]               0\n",
      "          Conv2d-138           [-1, 32, 14, 14]          36,864\n",
      "     BatchNorm2d-139          [-1, 352, 14, 14]             704\n",
      "            ReLU-140          [-1, 352, 14, 14]               0\n",
      "          Conv2d-141          [-1, 128, 14, 14]          45,056\n",
      "     BatchNorm2d-142          [-1, 128, 14, 14]             256\n",
      "            ReLU-143          [-1, 128, 14, 14]               0\n",
      "          Conv2d-144           [-1, 32, 14, 14]          36,864\n",
      "     BatchNorm2d-145          [-1, 384, 14, 14]             768\n",
      "            ReLU-146          [-1, 384, 14, 14]               0\n",
      "          Conv2d-147          [-1, 128, 14, 14]          49,152\n",
      "     BatchNorm2d-148          [-1, 128, 14, 14]             256\n",
      "            ReLU-149          [-1, 128, 14, 14]               0\n",
      "          Conv2d-150           [-1, 32, 14, 14]          36,864\n",
      "     BatchNorm2d-151          [-1, 416, 14, 14]             832\n",
      "            ReLU-152          [-1, 416, 14, 14]               0\n",
      "          Conv2d-153          [-1, 128, 14, 14]          53,248\n",
      "     BatchNorm2d-154          [-1, 128, 14, 14]             256\n",
      "            ReLU-155          [-1, 128, 14, 14]               0\n",
      "          Conv2d-156           [-1, 32, 14, 14]          36,864\n",
      "     BatchNorm2d-157          [-1, 448, 14, 14]             896\n",
      "            ReLU-158          [-1, 448, 14, 14]               0\n",
      "          Conv2d-159          [-1, 128, 14, 14]          57,344\n",
      "     BatchNorm2d-160          [-1, 128, 14, 14]             256\n",
      "            ReLU-161          [-1, 128, 14, 14]               0\n",
      "          Conv2d-162           [-1, 32, 14, 14]          36,864\n",
      "     BatchNorm2d-163          [-1, 480, 14, 14]             960\n",
      "            ReLU-164          [-1, 480, 14, 14]               0\n",
      "          Conv2d-165          [-1, 128, 14, 14]          61,440\n",
      "     BatchNorm2d-166          [-1, 128, 14, 14]             256\n",
      "            ReLU-167          [-1, 128, 14, 14]               0\n",
      "          Conv2d-168           [-1, 32, 14, 14]          36,864\n",
      "     BatchNorm2d-169          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-170          [-1, 512, 14, 14]               0\n",
      "          Conv2d-171          [-1, 128, 14, 14]          65,536\n",
      "     BatchNorm2d-172          [-1, 128, 14, 14]             256\n",
      "            ReLU-173          [-1, 128, 14, 14]               0\n",
      "          Conv2d-174           [-1, 32, 14, 14]          36,864\n",
      "     BatchNorm2d-175          [-1, 544, 14, 14]           1,088\n",
      "            ReLU-176          [-1, 544, 14, 14]               0\n",
      "          Conv2d-177          [-1, 128, 14, 14]          69,632\n",
      "     BatchNorm2d-178          [-1, 128, 14, 14]             256\n",
      "            ReLU-179          [-1, 128, 14, 14]               0\n",
      "          Conv2d-180           [-1, 32, 14, 14]          36,864\n",
      "     BatchNorm2d-181          [-1, 576, 14, 14]           1,152\n",
      "            ReLU-182          [-1, 576, 14, 14]               0\n",
      "          Conv2d-183          [-1, 128, 14, 14]          73,728\n",
      "     BatchNorm2d-184          [-1, 128, 14, 14]             256\n",
      "            ReLU-185          [-1, 128, 14, 14]               0\n",
      "          Conv2d-186           [-1, 32, 14, 14]          36,864\n",
      "     BatchNorm2d-187          [-1, 608, 14, 14]           1,216\n",
      "            ReLU-188          [-1, 608, 14, 14]               0\n",
      "          Conv2d-189          [-1, 128, 14, 14]          77,824\n",
      "     BatchNorm2d-190          [-1, 128, 14, 14]             256\n",
      "            ReLU-191          [-1, 128, 14, 14]               0\n",
      "          Conv2d-192           [-1, 32, 14, 14]          36,864\n",
      "     BatchNorm2d-193          [-1, 640, 14, 14]           1,280\n",
      "            ReLU-194          [-1, 640, 14, 14]               0\n",
      "          Conv2d-195          [-1, 128, 14, 14]          81,920\n",
      "     BatchNorm2d-196          [-1, 128, 14, 14]             256\n",
      "            ReLU-197          [-1, 128, 14, 14]               0\n",
      "          Conv2d-198           [-1, 32, 14, 14]          36,864\n",
      "     BatchNorm2d-199          [-1, 672, 14, 14]           1,344\n",
      "            ReLU-200          [-1, 672, 14, 14]               0\n",
      "          Conv2d-201          [-1, 128, 14, 14]          86,016\n",
      "     BatchNorm2d-202          [-1, 128, 14, 14]             256\n",
      "            ReLU-203          [-1, 128, 14, 14]               0\n",
      "          Conv2d-204           [-1, 32, 14, 14]          36,864\n",
      "     BatchNorm2d-205          [-1, 704, 14, 14]           1,408\n",
      "            ReLU-206          [-1, 704, 14, 14]               0\n",
      "          Conv2d-207          [-1, 128, 14, 14]          90,112\n",
      "     BatchNorm2d-208          [-1, 128, 14, 14]             256\n",
      "            ReLU-209          [-1, 128, 14, 14]               0\n",
      "          Conv2d-210           [-1, 32, 14, 14]          36,864\n",
      "     BatchNorm2d-211          [-1, 736, 14, 14]           1,472\n",
      "            ReLU-212          [-1, 736, 14, 14]               0\n",
      "          Conv2d-213          [-1, 128, 14, 14]          94,208\n",
      "     BatchNorm2d-214          [-1, 128, 14, 14]             256\n",
      "            ReLU-215          [-1, 128, 14, 14]               0\n",
      "          Conv2d-216           [-1, 32, 14, 14]          36,864\n",
      "     BatchNorm2d-217          [-1, 768, 14, 14]           1,536\n",
      "            ReLU-218          [-1, 768, 14, 14]               0\n",
      "          Conv2d-219          [-1, 128, 14, 14]          98,304\n",
      "     BatchNorm2d-220          [-1, 128, 14, 14]             256\n",
      "            ReLU-221          [-1, 128, 14, 14]               0\n",
      "          Conv2d-222           [-1, 32, 14, 14]          36,864\n",
      "     BatchNorm2d-223          [-1, 800, 14, 14]           1,600\n",
      "            ReLU-224          [-1, 800, 14, 14]               0\n",
      "          Conv2d-225          [-1, 128, 14, 14]         102,400\n",
      "     BatchNorm2d-226          [-1, 128, 14, 14]             256\n",
      "            ReLU-227          [-1, 128, 14, 14]               0\n",
      "          Conv2d-228           [-1, 32, 14, 14]          36,864\n",
      "     BatchNorm2d-229          [-1, 832, 14, 14]           1,664\n",
      "            ReLU-230          [-1, 832, 14, 14]               0\n",
      "          Conv2d-231          [-1, 128, 14, 14]         106,496\n",
      "     BatchNorm2d-232          [-1, 128, 14, 14]             256\n",
      "            ReLU-233          [-1, 128, 14, 14]               0\n",
      "          Conv2d-234           [-1, 32, 14, 14]          36,864\n",
      "     BatchNorm2d-235          [-1, 864, 14, 14]           1,728\n",
      "            ReLU-236          [-1, 864, 14, 14]               0\n",
      "          Conv2d-237          [-1, 128, 14, 14]         110,592\n",
      "     BatchNorm2d-238          [-1, 128, 14, 14]             256\n",
      "            ReLU-239          [-1, 128, 14, 14]               0\n",
      "          Conv2d-240           [-1, 32, 14, 14]          36,864\n",
      "     BatchNorm2d-241          [-1, 896, 14, 14]           1,792\n",
      "            ReLU-242          [-1, 896, 14, 14]               0\n",
      "          Conv2d-243          [-1, 128, 14, 14]         114,688\n",
      "     BatchNorm2d-244          [-1, 128, 14, 14]             256\n",
      "            ReLU-245          [-1, 128, 14, 14]               0\n",
      "          Conv2d-246           [-1, 32, 14, 14]          36,864\n",
      "     BatchNorm2d-247          [-1, 928, 14, 14]           1,856\n",
      "            ReLU-248          [-1, 928, 14, 14]               0\n",
      "          Conv2d-249          [-1, 128, 14, 14]         118,784\n",
      "     BatchNorm2d-250          [-1, 128, 14, 14]             256\n",
      "            ReLU-251          [-1, 128, 14, 14]               0\n",
      "          Conv2d-252           [-1, 32, 14, 14]          36,864\n",
      "     BatchNorm2d-253          [-1, 960, 14, 14]           1,920\n",
      "            ReLU-254          [-1, 960, 14, 14]               0\n",
      "          Conv2d-255          [-1, 128, 14, 14]         122,880\n",
      "     BatchNorm2d-256          [-1, 128, 14, 14]             256\n",
      "            ReLU-257          [-1, 128, 14, 14]               0\n",
      "          Conv2d-258           [-1, 32, 14, 14]          36,864\n",
      "     BatchNorm2d-259          [-1, 992, 14, 14]           1,984\n",
      "            ReLU-260          [-1, 992, 14, 14]               0\n",
      "          Conv2d-261          [-1, 128, 14, 14]         126,976\n",
      "     BatchNorm2d-262          [-1, 128, 14, 14]             256\n",
      "            ReLU-263          [-1, 128, 14, 14]               0\n",
      "          Conv2d-264           [-1, 32, 14, 14]          36,864\n",
      "     BatchNorm2d-265         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-266         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-267          [-1, 512, 14, 14]         524,288\n",
      "       AvgPool2d-268            [-1, 512, 7, 7]               0\n",
      "     BatchNorm2d-269            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-270            [-1, 512, 7, 7]               0\n",
      "          Conv2d-271            [-1, 128, 7, 7]          65,536\n",
      "     BatchNorm2d-272            [-1, 128, 7, 7]             256\n",
      "            ReLU-273            [-1, 128, 7, 7]               0\n",
      "          Conv2d-274             [-1, 32, 7, 7]          36,864\n",
      "     BatchNorm2d-275            [-1, 544, 7, 7]           1,088\n",
      "            ReLU-276            [-1, 544, 7, 7]               0\n",
      "          Conv2d-277            [-1, 128, 7, 7]          69,632\n",
      "     BatchNorm2d-278            [-1, 128, 7, 7]             256\n",
      "            ReLU-279            [-1, 128, 7, 7]               0\n",
      "          Conv2d-280             [-1, 32, 7, 7]          36,864\n",
      "     BatchNorm2d-281            [-1, 576, 7, 7]           1,152\n",
      "            ReLU-282            [-1, 576, 7, 7]               0\n",
      "          Conv2d-283            [-1, 128, 7, 7]          73,728\n",
      "     BatchNorm2d-284            [-1, 128, 7, 7]             256\n",
      "            ReLU-285            [-1, 128, 7, 7]               0\n",
      "          Conv2d-286             [-1, 32, 7, 7]          36,864\n",
      "     BatchNorm2d-287            [-1, 608, 7, 7]           1,216\n",
      "            ReLU-288            [-1, 608, 7, 7]               0\n",
      "          Conv2d-289            [-1, 128, 7, 7]          77,824\n",
      "     BatchNorm2d-290            [-1, 128, 7, 7]             256\n",
      "            ReLU-291            [-1, 128, 7, 7]               0\n",
      "          Conv2d-292             [-1, 32, 7, 7]          36,864\n",
      "     BatchNorm2d-293            [-1, 640, 7, 7]           1,280\n",
      "            ReLU-294            [-1, 640, 7, 7]               0\n",
      "          Conv2d-295            [-1, 128, 7, 7]          81,920\n",
      "     BatchNorm2d-296            [-1, 128, 7, 7]             256\n",
      "            ReLU-297            [-1, 128, 7, 7]               0\n",
      "          Conv2d-298             [-1, 32, 7, 7]          36,864\n",
      "     BatchNorm2d-299            [-1, 672, 7, 7]           1,344\n",
      "            ReLU-300            [-1, 672, 7, 7]               0\n",
      "          Conv2d-301            [-1, 128, 7, 7]          86,016\n",
      "     BatchNorm2d-302            [-1, 128, 7, 7]             256\n",
      "            ReLU-303            [-1, 128, 7, 7]               0\n",
      "          Conv2d-304             [-1, 32, 7, 7]          36,864\n",
      "     BatchNorm2d-305            [-1, 704, 7, 7]           1,408\n",
      "            ReLU-306            [-1, 704, 7, 7]               0\n",
      "          Conv2d-307            [-1, 128, 7, 7]          90,112\n",
      "     BatchNorm2d-308            [-1, 128, 7, 7]             256\n",
      "            ReLU-309            [-1, 128, 7, 7]               0\n",
      "          Conv2d-310             [-1, 32, 7, 7]          36,864\n",
      "     BatchNorm2d-311            [-1, 736, 7, 7]           1,472\n",
      "            ReLU-312            [-1, 736, 7, 7]               0\n",
      "          Conv2d-313            [-1, 128, 7, 7]          94,208\n",
      "     BatchNorm2d-314            [-1, 128, 7, 7]             256\n",
      "            ReLU-315            [-1, 128, 7, 7]               0\n",
      "          Conv2d-316             [-1, 32, 7, 7]          36,864\n",
      "     BatchNorm2d-317            [-1, 768, 7, 7]           1,536\n",
      "            ReLU-318            [-1, 768, 7, 7]               0\n",
      "          Conv2d-319            [-1, 128, 7, 7]          98,304\n",
      "     BatchNorm2d-320            [-1, 128, 7, 7]             256\n",
      "            ReLU-321            [-1, 128, 7, 7]               0\n",
      "          Conv2d-322             [-1, 32, 7, 7]          36,864\n",
      "     BatchNorm2d-323            [-1, 800, 7, 7]           1,600\n",
      "            ReLU-324            [-1, 800, 7, 7]               0\n",
      "          Conv2d-325            [-1, 128, 7, 7]         102,400\n",
      "     BatchNorm2d-326            [-1, 128, 7, 7]             256\n",
      "            ReLU-327            [-1, 128, 7, 7]               0\n",
      "          Conv2d-328             [-1, 32, 7, 7]          36,864\n",
      "     BatchNorm2d-329            [-1, 832, 7, 7]           1,664\n",
      "            ReLU-330            [-1, 832, 7, 7]               0\n",
      "          Conv2d-331            [-1, 128, 7, 7]         106,496\n",
      "     BatchNorm2d-332            [-1, 128, 7, 7]             256\n",
      "            ReLU-333            [-1, 128, 7, 7]               0\n",
      "          Conv2d-334             [-1, 32, 7, 7]          36,864\n",
      "     BatchNorm2d-335            [-1, 864, 7, 7]           1,728\n",
      "            ReLU-336            [-1, 864, 7, 7]               0\n",
      "          Conv2d-337            [-1, 128, 7, 7]         110,592\n",
      "     BatchNorm2d-338            [-1, 128, 7, 7]             256\n",
      "            ReLU-339            [-1, 128, 7, 7]               0\n",
      "          Conv2d-340             [-1, 32, 7, 7]          36,864\n",
      "     BatchNorm2d-341            [-1, 896, 7, 7]           1,792\n",
      "            ReLU-342            [-1, 896, 7, 7]               0\n",
      "          Conv2d-343            [-1, 128, 7, 7]         114,688\n",
      "     BatchNorm2d-344            [-1, 128, 7, 7]             256\n",
      "            ReLU-345            [-1, 128, 7, 7]               0\n",
      "          Conv2d-346             [-1, 32, 7, 7]          36,864\n",
      "     BatchNorm2d-347            [-1, 928, 7, 7]           1,856\n",
      "            ReLU-348            [-1, 928, 7, 7]               0\n",
      "          Conv2d-349            [-1, 128, 7, 7]         118,784\n",
      "     BatchNorm2d-350            [-1, 128, 7, 7]             256\n",
      "            ReLU-351            [-1, 128, 7, 7]               0\n",
      "          Conv2d-352             [-1, 32, 7, 7]          36,864\n",
      "     BatchNorm2d-353            [-1, 960, 7, 7]           1,920\n",
      "            ReLU-354            [-1, 960, 7, 7]               0\n",
      "          Conv2d-355            [-1, 128, 7, 7]         122,880\n",
      "     BatchNorm2d-356            [-1, 128, 7, 7]             256\n",
      "            ReLU-357            [-1, 128, 7, 7]               0\n",
      "          Conv2d-358             [-1, 32, 7, 7]          36,864\n",
      "     BatchNorm2d-359            [-1, 992, 7, 7]           1,984\n",
      "            ReLU-360            [-1, 992, 7, 7]               0\n",
      "          Conv2d-361            [-1, 128, 7, 7]         126,976\n",
      "     BatchNorm2d-362            [-1, 128, 7, 7]             256\n",
      "            ReLU-363            [-1, 128, 7, 7]               0\n",
      "          Conv2d-364             [-1, 32, 7, 7]          36,864\n",
      "     BatchNorm2d-365           [-1, 1024, 7, 7]           2,048\n",
      "          Linear-366                 [-1, 1000]       1,025,000\n",
      "================================================================\n",
      "Total params: 7,978,856\n",
      "Trainable params: 7,978,856\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 294.20\n",
      "Params size (MB): 30.44\n",
      "Estimated Total Size (MB): 325.21\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(d.cuda(), (3, 224, 224))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dl]",
   "language": "python",
   "name": "conda-env-dl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
