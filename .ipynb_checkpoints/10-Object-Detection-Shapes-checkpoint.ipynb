{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Shot Multi Scale Object Detection Tutorial\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "import os\n",
    "\n",
    "import PIL\n",
    "import matplotlib\n",
    "\n",
    "import torch\n",
    "from easyimages.utils import change_box_order, vis_image\n",
    "from livelossplot import PlotLosses\n",
    "from pycocotools.coco import COCO\n",
    "from retinanet.encoder import DataEncoder\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import RandomSampler\n",
    "from torchvision.transforms import ToPILImage, ToTensor\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from retinanet.utils import one_hot_embedding\n",
    "from retinanet.loss import FocalLoss\n",
    "\n",
    "\n",
    "matplotlib.rcParams['figure.figsize'] = [14, 10]\n",
    "\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Detection\n",
    "\n",
    "Object detection is the process of localizing and classyfing a region of interest in an image. Usually by prediting the coordinates of a bounding box enclosing this object.\n",
    "\n",
    "In this notebook we focus on single shot methods detection which means that the detection happens during a single forward pass. There is no second network learning object proposals which would be the case in RCNN architectures.\n",
    "\n",
    "\n",
    "\n",
    "# Example (Synthetic) Object Detection Dataset\n",
    "\n",
    "Our problem boils down to predicting the coordinates and label of the red box given an input image.\n",
    "\n",
    "![alt text](static/shapes-coco.png \"Title\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COCO Dataset Annotations Format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COCO format  is the standard for storing object detection and segmentation data so we will work on an example  following the same.\n",
    "\n",
    "In COCO we follow the **xywh** convention or as i like to call it *tlwh*: **(top-left-width-height)**\n",
    "that way you can not confuse it with for instance *cwh*: **(center-point, w, h)**\n",
    "\n",
    "![alt text](static/cocodsformat.jpg \"Title\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bounding Box Encoding\n",
    "\n",
    "Probably the most challenging concept to grasp while learning  object detection is the way how we encode our ground truth information. This is a crucial step in most applications in  deep learning, usually its not that complicated for instance encoding categories as one-hot encoded vectors is a straight forward task, but it can get quite challenging for example in NLP problems where its common to have variable sequence lenghts.\n",
    "\n",
    "In a regular bounding box setup your image can have different number of boxes and classes per image. So how do you encode this information into a fixed size target-tensor?\n",
    "\n",
    "The solution to this problem are **Anchor Boxes** also known as prior boxes.\n",
    "\n",
    "Essentialy Anchor Boxes are a finite set of boundig boxes with different sizes and aspect ratios for each position in the feature map. Usually there are thousands of anchor boxes in modern OD architectures - but only few will \"match\" with our ground truth.\n",
    "\n",
    "\n",
    "![alt text](static/anchors3.png \"All\")\n",
    "\n",
    "Here we visualize 100 random anchor boxes. Next up we will find which ones match our ground-truth using a crieteria known as IoU (Intersection over union)\n",
    "\n",
    "![alt text](static/iou.png \"All\")\n",
    "\n",
    "\n",
    "![alt text](static/matched_anchors.png \"All\")\n",
    "\n",
    "\n",
    "# Bounding Box Regression Coefficients\n",
    "\n",
    "Since predicting the anchor itself would be suboptimal (having IoU's close to 1.0 is unlikely even with a very high number of anchors) Thats why we want our network to predict an offset between the real box (T) and the Anchor (O) and for the width and height we learn the ratio between the Target width and Anchor width. Furthermore its quite common to log-transform this target for more efficient training.\n",
    "\n",
    "We will only use coefficients coming from Anchor boxes with high IoU (usually above 0.5) the rest is ignored in regression loss computation.\n",
    "\n",
    "![alt text](static/anchor_coef.png \"All\")\n",
    "\n",
    "Now the question arises how do you predict those offsets, the trick to this is attaching the detection heads to regular feature maps of a convolutiona neural network (base network)\n",
    "\n",
    "To understand what it means here is a qucik recap of a typical CNN architecture w.r.t Object Detection an important concept is the receptive field of a neuron and the fact that the deeper you go in regular CNN you trade resolution for \"broad-knowledge\" neurons deep in a neural network are more context aware.\n",
    "\n",
    "![alt text](static/cnn.jpg \"All\")\n",
    "\n",
    "Given that it would make sense to use higher resolution feature maps (for instance the 56x56 f-map) to predict small objects and lower resolution ones for big objects. And thats exactly the idea behind **multi scale object detection**\n",
    "\n",
    "\n",
    "\n",
    "# Regression and Detection Heads\n",
    "\n",
    "A regression and detection head is nothing else then a Conv2D block that is convolving a particular feature map. In the most simplified scennario it would work like this:\n",
    "\n",
    "```python\n",
    "num_classes = 3\n",
    "fmap1 = torch.random(BS, 256, 9, 9) # Lets assume this is a 9x9 feature map with depth=256.\n",
    "bbox_regression_head = nn.Conv2d(32, n_anchors * 4, 3, padding=1)\n",
    "bbox_classification_head = nn.Conv2d(32, n_anchors * num_classes, 3, padding=1)\n",
    "\n",
    "bbox_offsets = bbox_regression_head(fmap1)\n",
    "bbox_cls_pred = bbox_classification_head(fmap1)\n",
    "\n",
    "```\n",
    "n_anchors is the number of anchor per location (its pretty common this number is 9 as we have 3 scale ratios and 3 aspect ratios) so the product of those is 9.\n",
    "For regression we multiple this by **4** (we need 4 floats for each anchor to predict the offsets tx,ty,tw,th)\n",
    "\n",
    "Notice how elegant this solution actually is - we have a fully convolutional architecture (which is usually quite efficient memory and speed-wise) it also makes sense intuitivly - convolution is nothing else but sliding a filter on each position of the feature maps, and we know that those neurons have 'knowledge' about a particular part of the image (among other things)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Encoding steps put together\n",
    "\n",
    "To recap the above:  here are the steps neccesery to encode our target bounding boxes:\n",
    "\n",
    "- For each feature map that we want to use for predictions generate a set of anchor-boxes with different size and aspect ratios\n",
    "- Calculate the IoU between your target boxes and anchor boxes\n",
    "- For anchors that had the biggest IoU  calculate the offset values.\n",
    "    tx = (x - anchor_x) / anchor_w\n",
    "    ty = (y - anchor_y) / anchor_h\n",
    "    tw = log(w / anchor_w)\n",
    "    th = log(h / anchor_h)\n",
    "\n",
    "- For box regression only offsets  that matched with an IoU > 0.5 will be used during loss computation\n",
    "- For box classification only boxes with IoU > 0.5 and  IoU < 0.4 will be used during loss computetion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Encoding Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12321, 4])\n",
      "torch.Size([2916, 4])\n",
      "torch.Size([729, 4])\n",
      "tensor([[ 16.6667,  16.6667, 141.4214, 282.8427],\n",
      "        [ 16.6667,  16.6667, 176.7767, 353.5534],\n",
      "        [ 16.6667,  16.6667, 212.1320, 424.2641],\n",
      "        ...,\n",
      "        [283.3333, 283.3333, 282.8427, 141.4214],\n",
      "        [283.3333, 283.3333, 353.5534, 176.7767],\n",
      "        [283.3333, 283.3333, 424.2641, 212.1320]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "de = DataEncoder(anchor_areas=[50*50, 100*100, 200*200],\n",
    "                 aspect_ratios=[0.5, 1, 2],\n",
    "                 scale_ratios=[1.0, 1.25, 1.5],\n",
    "                 fm_sizes=torch.tensor([(37, 37),\n",
    "                                        (18, 18),\n",
    "                                        (9, 9)]).float(),\n",
    "\n",
    "                 min_iou=0.5\n",
    "                 )\n",
    "\n",
    "anchors, anchors_per_fm = de._get_anchor_boxes(torch.Tensor((300, 300)))\n",
    "\n",
    "for fms in anchors_per_fm:\n",
    "    print(fms.shape)\n",
    "    \n",
    "print(fms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets make sure we understand where the number are coming from:\n",
    "\n",
    "- We have 12321 anchors on fm1 (37 * 37 *9)\n",
    "- We have 2916 anchors on fm2 (18 * 18 * 9)\n",
    "- We have 729 anchors on fm3 (9 * 9 * 9)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrapping COCO dataset into a pytorch dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "coco = COCO(annotation_file='generate-shapes/coco_shapes_100_200/100_200.json')\n",
    "\n",
    "\n",
    "class CoCoDS():\n",
    "    def __init__(self, coco, base_path, encoder):\n",
    "        self.coco = coco\n",
    "        self.base_path = base_path\n",
    "        self.encoder = encoder\n",
    "        self.all_images = coco.getImgIds()\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "\n",
    "        image_id = self.all_images[i]\n",
    "        image_meta = coco.loadImgs(ids=[image_id])[0]\n",
    "        image = PIL.Image.open(os.path.join(self.base_path, image_id))\n",
    "        image = ToTensor()(image)\n",
    "\n",
    "        w, h = image_meta['width'], image_meta['height']\n",
    "        annot = coco.loadAnns(ids=coco.getAnnIds(imgIds=[image_id]))\n",
    "        boxes = torch.tensor([a['bbox'] for a in annot]).float()\n",
    "        labels = torch.tensor([a['category_id']for a in annot]).float()\n",
    "        boxes = change_box_order(\n",
    "            boxes, input_order='tlwh', output_order='tlbr')\n",
    "\n",
    "        loc_targets, cls_targets = self.encoder.encode(boxes, labels, (w, h))\n",
    "\n",
    "        return image, loc_targets, cls_targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.coco.getImgIds())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15966, 4])\n",
      "torch.Size([15966])\n"
     ]
    }
   ],
   "source": [
    "cocds = CoCoDS(coco, 'generate-shapes/coco_shapes_100_200/images', de)\n",
    "\n",
    "_, loc, cls = cocds[0]\n",
    "\n",
    "print(loc.shape)\n",
    "print(cls.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets model a very simple network\n",
    "Our network is really simple it consists of 5 downsample steps. Each downsample is a **Conv2->BN->Relu->Conv2->BN->Relu->MaxPool2D** block. \n",
    "\n",
    "We will attach our detection heads to f-map3 f-map4 and f-map5. Lets caculate the shapes of those feature maps:\n",
    "\n",
    "outpu shape  after step 3 -> 300 / 2 / 2 / 2 = 37   \n",
    "output shape after step 4 -> 300 / 2 / 2 / 2 / 2  = 18   \n",
    "output shape after step 5 -> 300 / 2 / 2 / 2 / 2 / 2 = 9   \n",
    "\n",
    "As you can imagine the Anchor boxes reflect this architecture. In the end all the shape must match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SimpleSSD(nn.Module):\n",
    "\n",
    "    def __init__(self, n_cls=1, num_anchors=9):\n",
    "        super(SimpleSSD, self).__init__()\n",
    "\n",
    "        self.n_cls = n_cls\n",
    "        self.num_anchors = num_anchors\n",
    "\n",
    "        # Base CNN (think resnet/vgg or other base network)\n",
    "        self.step1 = self.down_sample(3, 128)\n",
    "        self.step2 = self.down_sample(128, 128)\n",
    "        self.step3 = self.down_sample(128, 128)\n",
    "        self.step4 = self.down_sample(128, 128)\n",
    "        self.step5 = self.down_sample(128, 128)\n",
    "\n",
    "        self.cls_head1 = self.create_cls_head(\n",
    "            128, self.n_cls, self.num_anchors)\n",
    "        self.bbox_head1 = self.create_bbox_head(128, self.num_anchors)\n",
    "\n",
    "        self.cls_head2 = self.create_cls_head(\n",
    "            128, self.n_cls, self.num_anchors)\n",
    "        self.bbox_head2 = self.create_bbox_head(128, self.num_anchors)\n",
    "\n",
    "        self.cls_head3 = self.create_cls_head(\n",
    "            128, self.n_cls, self.num_anchors)\n",
    "        self.bbox_head3 = self.create_bbox_head(128, self.num_anchors)\n",
    "\n",
    "    @staticmethod\n",
    "    def down_sample(in_channels, out_channels):\n",
    "\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def create_cls_head(n_in, n_cls, num_anchors):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(n_in, 92, 3, padding=1),\n",
    "            nn.BatchNorm2d(92),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(92, 64, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, num_anchors * n_cls, 3, stride=1, padding=1),\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def create_bbox_head(n_in, num_anchors):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(n_in, 92, 3, padding=1),\n",
    "            nn.BatchNorm2d(92),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(92, 64, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64,  num_anchors * 4, 3, stride=1, padding=1))\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # x -> [BS, 3, 300, 300]\n",
    "\n",
    "        step1 = self.step1(x)\n",
    "        step2 = self.step2(step1)\n",
    "        step3 = self.step3(step2)\n",
    "        step4 = self.step4(step3)\n",
    "        step5 = self.step5(step4)\n",
    "\n",
    "        cls1 = self.cls_head1(step3)\n",
    "        bbox1 = self.bbox_head1(step3)\n",
    "\n",
    "        cls2 = self.cls_head2(step4)\n",
    "        bbox2 = self.bbox_head2(step4)\n",
    "\n",
    "        cls3 = self.cls_head3(step5)\n",
    "        bbox3 = self.bbox_head3(step5)\n",
    "\n",
    "        cls1 = cls1.permute(0, 2, 3, 1).contiguous().view(\n",
    "            x.size(0), -1, self.n_cls)\n",
    "        cls2 = cls2.permute(0, 2, 3, 1).contiguous().view(\n",
    "            x.size(0), -1, self.n_cls)\n",
    "        cls3 = cls3.permute(0, 2, 3, 1).contiguous().view(\n",
    "            x.size(0), -1, self.n_cls)\n",
    "\n",
    "        bbox1 = bbox1.permute(0, 2, 3, 1).contiguous().view(x.size(0), -1, 4)\n",
    "        bbox2 = bbox2.permute(0, 2, 3, 1).contiguous().view(x.size(0), -1, 4)\n",
    "        bbox3 = bbox3.permute(0, 2, 3, 1).contiguous().view(x.size(0), -1, 4)\n",
    "\n",
    "        cls_pred = torch.cat([cls1, cls2, cls3], dim=1)\n",
    "        bbox_pred = torch.cat([bbox1, bbox2, bbox3], dim=1)\n",
    "\n",
    "        return bbox_pred, cls_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "lines_to_next_cell": 2,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-e2762a44a5a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mplot_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0mplot_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.7/site-packages/livelossplot/generic_plot.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    114\u001b[0m                       \u001b[0mskip_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskip_first\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                       \u001b[0mextra_plots\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_plots\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m                       fig_path=self.fig_path)\n\u001b[0m\u001b[1;32m    117\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics_extrema\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m                 print_extrema(self.logs,\n",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.7/site-packages/livelossplot/core.py\u001b[0m in \u001b[0;36mdraw_plot\u001b[0;34m(logs, metrics, figsize, max_epoch, max_cols, series_fmt, metric2title, skip_first, extra_plots, fig_path)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfig_path\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m def print_extrema(logs,\n",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.7/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    267\u001b[0m     \"\"\"\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0m_show\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_show\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.7/site-packages/ipykernel/pylab/backend_inline.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(close, block)\u001b[0m\n\u001b[1;32m     37\u001b[0m             display(\n\u001b[1;32m     38\u001b[0m                 \u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m                 \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_fetch_figure_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m             )\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.7/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mdisplay\u001b[0;34m(include, exclude, metadata, transient, display_id, *objs, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0mpublish_display_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m             \u001b[0mformat_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mformat_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m                 \u001b[0;31m# nothing to display (e.g. _ipython_display_ took over)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.7/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mformat\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m                 \u001b[0;31m# FIXME: log the exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m</home/i008/anaconda3/envs/dl/lib/python3.7/site-packages/decorator.py:decorator-gen-9>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.7/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mcatch_format_error\u001b[0;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;34m\"\"\"show traceback on failed format call\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;31m# don't warn on NotImplementedErrors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.7/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    339\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m             \u001b[0;31m# Finally look for special method names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.7/site-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(fig)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'png'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'retina'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'png2x'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mretina_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.7/site-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0mbytes_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'svg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.7/site-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m   2065\u001b[0m                     \u001b[0mbbox_artists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bbox_extra_artists\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2066\u001b[0m                     bbox_inches = self.figure.get_tightbbox(renderer,\n\u001b[0;32m-> 2067\u001b[0;31m                             bbox_extra_artists=bbox_artists)\n\u001b[0m\u001b[1;32m   2068\u001b[0m                     \u001b[0mpad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pad_inches\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2069\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mpad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.7/site-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36mget_tightbbox\u001b[0;34m(self, renderer, bbox_extra_artists)\u001b[0m\n\u001b[1;32m   2365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2366\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2367\u001b[0;31m             \u001b[0mbbox\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tightbbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2368\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbbox\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwidth\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mbbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheight\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2369\u001b[0m                 \u001b[0mbb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.7/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mget_tightbbox\u001b[0;34m(self, renderer, call_axes_locator, bbox_extra_artists)\u001b[0m\n\u001b[1;32m   4359\u001b[0m                 \u001b[0mbb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbb_xaxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4361\u001b[0;31m             \u001b[0mbb_yaxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myaxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tightbbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4362\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbb_yaxis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4363\u001b[0m                 \u001b[0mbb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbb_yaxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.7/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mget_tightbbox\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   1162\u001b[0m         \u001b[0mticks_to_draw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_ticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1164\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_label_position\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1166\u001b[0m         \u001b[0;31m# go back to just this axis's tick labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.7/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m_update_label_position\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   2307\u001b[0m         \u001b[0;31m# get bounding boxes for this axis and any siblings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2308\u001b[0m         \u001b[0;31m# that have been set by `fig.align_ylabels()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2309\u001b[0;31m         \u001b[0mbboxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbboxes2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tick_boxes_siblings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2311\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_position\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.7/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m_get_tick_boxes_siblings\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   2291\u001b[0m         \u001b[0;31m# if we want to align labels from other axes:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2292\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_siblings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2293\u001b[0;31m             \u001b[0mticks_to_draw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myaxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_ticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2294\u001b[0m             \u001b[0mtlb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtlb2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myaxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tick_bboxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticks_to_draw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2295\u001b[0m             \u001b[0mbboxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtlb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.7/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m_update_ticks\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1085\u001b[0m             \u001b[0mtick\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_label1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1086\u001b[0m             \u001b[0mtick\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_label2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1087\u001b[0;31m         \u001b[0mminor_locs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_minorticklocs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1088\u001b[0m         \u001b[0mminor_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_ticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminor_locs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m         \u001b[0mminor_ticks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_minor_ticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminor_locs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.7/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mget_minorticklocs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1327\u001b[0m         \u001b[0;34m\"\"\"Get the array of minor tick locations in data coordinates.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1328\u001b[0m         \u001b[0;31m# Remove minor ticks duplicating major ticks.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m         \u001b[0mmajor_locs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmajor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1330\u001b[0m         \u001b[0mminor_locs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m         \u001b[0mtransform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_scale\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.7/site-packages/matplotlib/ticker.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2079\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2080\u001b[0m         \u001b[0mvmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_view_interval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2081\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtick_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2083\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtick_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.7/site-packages/matplotlib/ticker.py\u001b[0m in \u001b[0;36mtick_values\u001b[0;34m(self, vmin, vmax)\u001b[0m\n\u001b[1;32m   2087\u001b[0m         vmin, vmax = mtransforms.nonsingular(\n\u001b[1;32m   2088\u001b[0m             vmin, vmax, expander=1e-13, tiny=1e-14)\n\u001b[0;32m-> 2089\u001b[0;31m         \u001b[0mlocs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raw_ticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2091\u001b[0m         \u001b[0mprune\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prune\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.7/site-packages/matplotlib/ticker.py\u001b[0m in \u001b[0;36m_raw_ticks\u001b[0;34m(self, vmin, vmax)\u001b[0m\n\u001b[1;32m   2026\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nbins\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'auto'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2027\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2028\u001b[0;31m                 nbins = np.clip(self.axis.get_tick_space(),\n\u001b[0m\u001b[1;32m   2029\u001b[0m                                 max(1, self._min_n_ticks - 1), 9)\n\u001b[1;32m   2030\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.7/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mget_tick_space\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2489\u001b[0m         \u001b[0mends\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransAxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2490\u001b[0m         \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mends\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mends\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdpi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m72\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2491\u001b[0;31m         \u001b[0mtick\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tick\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2492\u001b[0m         \u001b[0;31m# Having a spacing of at least 2 just looks good.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2493\u001b[0m         \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtick\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.7/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m_get_tick\u001b[0;34m(self, major)\u001b[0m\n\u001b[1;32m   2221\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2222\u001b[0m             \u001b[0mtick_kw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_minor_tick_kw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2223\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mYTick\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmajor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmajor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtick_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2225\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.7/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, axes, loc, label, size, width, color, tickdir, pad, labelsize, labelcolor, zorder, gridOn, tick1On, tick2On, label1On, label2On, major, labelrotation, grid_color, grid_linestyle, grid_linewidth, grid_alpha, **kw)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtick1line\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tick1line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtick2line\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tick2line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgridline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_gridline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_text1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.7/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m_get_tick2line\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    595\u001b[0m                           \u001b[0mmarkersize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m                           \u001b[0mmarkeredgewidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_width\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m                           zorder=self._zorder)\n\u001b[0m\u001b[1;32m    598\u001b[0m         \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_yaxis_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwhich\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'tick2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_artist_props\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.7/site-packages/matplotlib/lines.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, xdata, ydata, linewidth, linestyle, color, marker, markersize, markeredgewidth, markeredgecolor, markerfacecolor, markerfacecoloralt, fillstyle, antialiased, dash_capstyle, solid_capstyle, dash_joinstyle, solid_joinstyle, pickradius, drawstyle, markevery, **kwargs)\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0mmarkersize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrcParams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lines.markersize'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mantialiased\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m             \u001b[0mantialiased\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrcParams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lines.antialiased'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdash_capstyle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0mdash_capstyle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrcParams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lines.dash_capstyle'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "de = DataEncoder(anchor_areas=[50*50, 100*100, 200*200],\n",
    "                 aspect_ratios=[0.5, 1, 2],\n",
    "                 scale_ratios=[1.0, 1.25, 1.5],\n",
    "                 fm_sizes=torch.tensor([(37, 37),\n",
    "                                        (18, 18),\n",
    "                                        (9, 9)]).float(),\n",
    "\n",
    "                 min_iou=0.5\n",
    "                 )\n",
    "\n",
    "coco = COCO(annotation_file='generate-shapes/coco_shapes_50_100/50_100.json')\n",
    "coco_ds = CoCoDS(coco, 'generate-shapes/coco_shapes_50_100/images', de)\n",
    "coco_dl = DataLoader(coco_ds, batch_size=4, sampler=RandomSampler(coco_ds))\n",
    "\n",
    "model = SimpleSSD(n_cls=3)\n",
    "model = model.to(device)\n",
    "criterion = FocalLoss(num_classes=3)\n",
    "plot_losses = PlotLosses()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "collect = []\n",
    "for epoch in range(10):\n",
    "    for i, b in enumerate(coco_dl):\n",
    "        logs = {}\n",
    "        optimizer.zero_grad()\n",
    "        image, bounding_boxes, labels = b\n",
    "        image = image.to(device)\n",
    "        bounding_boxes = bounding_boxes.to(device)\n",
    "        labels = labels.to(device)\n",
    "        loc_pred, cls_pred = model(image)\n",
    "        total_loss = criterion(loc_pred, bounding_boxes, cls_pred, labels)\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        collect.append([total_loss.detach().cpu().numpy()])\n",
    "        logs['loss'] = total_loss.item()\n",
    "        if i % 1 == 0:\n",
    "            plot_losses.update(logs)\n",
    "            plot_losses.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cls_pred.shape\n",
    "it = iter(coco_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "image, _, _ = next(it)\n",
    "model = model.cuda()\n",
    "model.eval()\n",
    "loc_pred, cls_pred = model(image.cuda())\n",
    "\n",
    "i = 1\n",
    "bbspred, labelpred, score = de.decode(\n",
    "    loc_pred[i].float().cpu(),\n",
    "    cls_pred[i].float().cpu(),\n",
    "    torch.Tensor([300, 300]).float().cpu(),\n",
    "    cls_thresh=0.2, nms_thresh=0.01\n",
    ")\n",
    "imagepil = ToPILImage()(image[1])\n",
    "\n",
    "d = {0: 'circle', 1: 'triangle',  2: 'rectanglee'}\n",
    "B = bbspred.detach().cpu().numpy()\n",
    "L = labelpred.detach().cpu().numpy()\n",
    "S = score.detach().cpu().numpy()\n",
    "\n",
    "L = [d[i] for i in L]\n",
    "f = vis_image(imagepil, bbspred.detach().numpy(), label_names=L, scores=S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "history": [],
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "uuid": "d29f5467-c5cd-48fb-83bf-d890816a35d0"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
