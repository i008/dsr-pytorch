{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms \n",
    "import pandas as pd\n",
    "import PIL\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from easyimages import EasyImageList\n",
    "from torch import nn\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, classification_report, log_loss\n",
    "from pretrainedmodels.models import resnet18, resnet50\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For details related to dataloading check the previous notebook (pytorch-fmnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {\n",
    " 0: 'T-shirt/top',\n",
    " 1: 'Trouser',\n",
    " 2: 'Pullover',\n",
    " 3: 'Dress',\n",
    " 4: 'Coat',\n",
    " 5: 'Sandal',\n",
    " 6: 'Shirt',\n",
    " 7: 'Sneaker',\n",
    " 8: 'Bag',\n",
    " 9: 'Ankle boot'\n",
    "}\n",
    "\n",
    "class FashionMnist(Dataset):\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.metadata_df)\n",
    "\n",
    "    def __init__(self, metadata_df,\n",
    "                 transform=None):\n",
    "        \n",
    "        self.metadata_df = metadata_df.copy()\n",
    "        self.transform = transform\n",
    "    \n",
    "    def load_image_and_target(self,index):\n",
    "        # .iloc is short for integer loc it returns a row of data based on its ored not index-value(if not the same)\n",
    "        oneimage = self.metadata_df.iloc[index]\n",
    "        image, y = PIL.Image.fromarray(\n",
    "            np.array(oneimage[1:]).reshape(28, 28).astype('uint8'), 'L').convert('RGB'), oneimage[0]\n",
    "        return image, y\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        X, y = self.load_image_and_target(index)\n",
    "        # We can transform the output images here, cast to torch data-format and/or do augmentations\n",
    "        X = self.transform(X)\n",
    "            \n",
    "        return X, y\n",
    "\n",
    "    def collate_func(self, batch):\n",
    "        pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Understanding AdaptiveAveragePooling\n",
    "\n",
    "In a moment you will see that we change one of the pretrained models by swaping  the AveragePool operation for AdaptiveAveragePooling.\n",
    "\n",
    "The ideas is that adaptive pooling always returns our desired shape. This is useful if you want your NN to support different images shapes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128, 1, 1])\n",
      "torch.Size([1, 128, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.randn((1, 128, 8, 8))\n",
    "\n",
    "print(nn.AdaptiveAvgPool2d((1, 1))(tensor).shape)\n",
    "print(nn.AvgPool2d((3,3))(tensor).shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adapting a pretrained model to be used for different number of classes\n",
    "By default many of the pretrained models require a input image of a given shape (usually 224x224x3) This is not our case so we need to chaged that, one way to do it is to change the network architecture of the model as described in Adaptive Pooling Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CLASSES = 10\n",
    "\n",
    "def freeze_model(model):\n",
    "    model.eval()\n",
    "    for params in model.parameters():\n",
    "        params.requires_grad = False\n",
    "        \n",
    "cnn = resnet18(pretrained='imagenet')\n",
    "# freeze_model(cnn)\n",
    "cnn.avgpool = nn.AdaptiveAvgPool2d(1) # This will allow to use different input sizes\n",
    "cnn.last_linear = nn.Sequential(nn.Linear(cnn.last_linear.in_features, 1024), \n",
    "                                nn.Linear(1024, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define your loss function / crieterion, optimizers and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.7091)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR= 0.005\n",
    "BATCH_SIZE = 8\n",
    "DATASET_USAGE_SIZE = 0.15\n",
    "N_CLASSES = 10\n",
    "\n",
    "MEAN = [0.485, 0.456, 0.406]\n",
    "STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "OPTIMIZER = 'Adam' # one of ['ASGD','Adadelta', 'Adagrad','Adam', 'Adamax','LBFGS', 'RMSprop','Rprop','SGD',SparseAdam']\n",
    "optimizer = getattr(torch.optim, OPTIMIZER)(cnn.parameters(), lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "cnn.to(DEVICE)\n",
    "\n",
    "# Create dataset loaders\n",
    "    \n",
    "PATH_TO_FMNIST_TRAIN = './data/fashion-mnist_train.csv'\n",
    "PATH_TO_FMNIST_TEST = './data/fashion-mnist_test.csv'\n",
    "\n",
    "\n",
    "dftrain = pd.read_csv(PATH_TO_FMNIST_TRAIN).sample(frac=DATASET_USAGE_SIZE)\n",
    "dftest = pd.read_csv(PATH_TO_FMNIST_TEST).sample(frac=0.1)\n",
    "\n",
    "transform_train = transforms.Compose([transforms.Resize(34), \n",
    "                                      transforms.ToTensor(), \n",
    "                                      transforms.Normalize(mean=MEAN, std=STD)\n",
    "                                     ]\n",
    "                                    )\n",
    "fmnist_train = FashionMnist(dftrain, transform=transform_train)\n",
    "\n",
    "transform_test = transforms.Compose([transforms.Resize(34), \n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize(mean=MEAN, std=STD)\n",
    "                                    ])\n",
    "fmnist_test = FashionMnist(dftest, transform=transform_test)\n",
    "\n",
    "fmnist_train_dl = DataLoader(fmnist_train, batch_size=BATCH_SIZE)\n",
    "fmnist_test_dl = DataLoader(fmnist_test, batch_size=BATCH_SIZE)\n",
    "\n",
    "# Lets try to use the criterion with dummy data\n",
    "yp = torch.randn(BATCH_SIZE, 10)\n",
    "yt = torch.randint(10, (BATCH_SIZE,))\n",
    "criterion(yp, yt.long())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test: loss: 1.6768976382017136  acc: 0.547\n",
      "train: loss: 1.6915408404668173  acc: 0.5197777777777778\n",
      "test: loss: 1.6449326812028884  acc: 0.553\n",
      "train: loss: 1.6561578958961698  acc: 0.5331111111111111\n",
      "test: loss: 1.5951210781335832  acc: 0.73\n",
      "train: loss: 1.6039669265482162  acc: 0.7266666666666667\n",
      "test: loss: 1.5353054026961326  acc: 0.765\n",
      "train: loss: 1.545490874575244  acc: 0.7573333333333333\n",
      "test: loss: 1.4871611064076424  acc: 0.792\n",
      "train: loss: 1.4924853188859093  acc: 0.7634444444444445\n",
      "test: loss: 1.5486449759602547  acc: 0.797\n",
      "train: loss: 1.553244815574752  acc: 0.7897777777777778\n",
      "test: loss: 1.4761469951868058  acc: 0.812\n",
      "train: loss: 1.4690399421917069  acc: 0.8155555555555556\n",
      "test: loss: 1.491809894502163  acc: 0.819\n",
      "train: loss: 1.500557583934731  acc: 0.8164444444444444\n",
      "test: loss: 1.4995366852879524  acc: 0.84\n",
      "train: loss: 1.5039279583493868  acc: 0.8483333333333334\n",
      "test: loss: 1.4508595105409623  acc: 0.836\n",
      "train: loss: 1.456500511460834  acc: 0.8402222222222222\n",
      "test: loss: 1.4648755895495416  acc: 0.838\n",
      "train: loss: 1.4552841137184036  acc: 0.8455555555555555\n",
      "test: loss: 1.498585737645626  acc: 0.865\n",
      "train: loss: 1.5026653259396554  acc: 0.8723333333333333\n",
      "test: loss: 1.432514740884304  acc: 0.846\n",
      "train: loss: 1.4317820316619343  acc: 0.8738888888888889\n",
      "test: loss: 1.4231029656529426  acc: 0.864\n",
      "train: loss: 1.4269925295644337  acc: 0.8883333333333333\n",
      "test: loss: 1.4270024080276489  acc: 0.868\n",
      "train: loss: 1.4301809501714176  acc: 0.8917777777777778\n",
      "test: loss: 1.4141931645274162  acc: 0.872\n",
      "train: loss: 1.4111589584218132  acc: 0.9025555555555556\n",
      "test: loss: 1.4826057666540147  acc: 0.865\n",
      "train: loss: 1.4793610979848437  acc: 0.8888888888888888\n",
      "test: loss: 1.4659273935556412  acc: 0.877\n",
      "train: loss: 1.4599612815909915  acc: 0.8991111111111111\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, test_loader, print_info=False):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        collect_results = []\n",
    "        collect_target = []\n",
    "        for batch in test_loader:\n",
    "            X, y = batch\n",
    "#             X = X.repeat(1, 3, 1, 1)\n",
    "            X = X.to(DEVICE)\n",
    "            y = y.to(DEVICE).detach().cpu().numpy()\n",
    "            pred = cnn(X)\n",
    "            collect_results.append(pred.sigmoid().detach().cpu().numpy())\n",
    "            collect_target.append(y) \n",
    "        \n",
    "    preds_proba = np.concatenate(collect_results)\n",
    "    preds = preds_proba.argmax(axis=1)\n",
    "    targets = np.concatenate(collect_target)\n",
    "\n",
    "    ll = log_loss(targets, preds_proba)\n",
    "    acc = accuracy_score(targets, preds)\n",
    "    if print_info:\n",
    "        print(\"test log-loss: {}\".format(ll))\n",
    "        print(\"overall accuracy:  {}\".format(ac))\n",
    "#         print(classification_report(targets, preds))\n",
    "    model.train()\n",
    "#         freeze_model(model)\n",
    "        \n",
    "    return ll, acc\n",
    "            \n",
    "collect = []\n",
    "for epoch in range(50):\n",
    "    lossacc = 0\n",
    "    for i, batch in enumerate(fmnist_train_dl):\n",
    "        optimizer.zero_grad()\n",
    "        X, y = batch\n",
    "#         X = X.repeat(1, 3, 1, 1)\n",
    "        X = X.to(DEVICE)\n",
    "        y = y.to(DEVICE)\n",
    "        y_pred = cnn(X)\n",
    "        \n",
    "        loss = criterion(y_pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()  \n",
    "        collect.append(float(loss.detach().cpu().numpy()))  \n",
    "        \n",
    "    lltest, acctest = evaluate_model(cnn, fmnist_test_dl)\n",
    "    lltrain, acctrain = evaluate_model(cnn, fmnist_train_dl)\n",
    "    print(\"test: loss: {}  acc: {}\".format(lltest, acctest))\n",
    "    print(\"train: loss: {}  acc: {}\".format(lltrain, acctrain))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Exercises\n",
    "\n",
    "- What do you think of the results?\n",
    "- Try training the model without freezing. What do you observe?\n",
    "- Visualize the results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
