{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms \n",
    "import pandas as pd\n",
    "import PIL\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from easyimages import EasyImageList\n",
    "from torch import nn\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, classification_report, log_loss\n",
    "from pretrainedmodels.models import resnet18, resnet50\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For details related to dataloading check the previous notebook (pytorch-fmnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {\n",
    " 0: 'T-shirt/top',\n",
    " 1: 'Trouser',\n",
    " 2: 'Pullover',\n",
    " 3: 'Dress',\n",
    " 4: 'Coat',\n",
    " 5: 'Sandal',\n",
    " 6: 'Shirt',\n",
    " 7: 'Sneaker',\n",
    " 8: 'Bag',\n",
    " 9: 'Ankle boot'\n",
    "}\n",
    "\n",
    "class FashionMnist(Dataset):\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.metadata_df)\n",
    "\n",
    "    def __init__(self, metadata_df,\n",
    "                 transform=None):\n",
    "        \n",
    "        self.metadata_df = metadata_df.copy()\n",
    "        self.transform = transform\n",
    "    \n",
    "    def load_image_and_target(self,index):\n",
    "        # .iloc is short for integer loc it returns a row of data based on its ored not index-value(if not the same)\n",
    "        oneimage = self.metadata_df.iloc[index]\n",
    "        image, y = PIL.Image.fromarray(\n",
    "            np.array(oneimage[1:]).reshape(28, 28).astype('uint8'), 'L').convert('RGB'), oneimage[0]\n",
    "        return image, y\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        X, y = self.load_image_and_target(index)\n",
    "        # We can transform the output images here, cast to torch data-format and/or do augmentations\n",
    "        X = self.transform(X)\n",
    "            \n",
    "        return X, y\n",
    "\n",
    "    def collate_func(self, batch):\n",
    "        pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Understanding AdaptiveAveragePooling\n",
    "\n",
    "In a moment you will see that we change one of the pretrained models by swaping  the AveragePool operation for AdaptiveAveragePooling.\n",
    "\n",
    "The ideas is that adaptive pooling always returns our desired shape. This is useful if you want your NN to support different images shapes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128, 1, 1])\n",
      "torch.Size([1, 128, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.randn((1, 128, 8, 8))\n",
    "\n",
    "print(nn.AdaptiveAvgPool2d((1, 1))(tensor).shape)\n",
    "print(nn.AvgPool2d((3,3))(tensor).shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adapting a pretrained model to be used for different number of classes\n",
    "By default many of the pretrained models require a input image of a given shape (usually 224x224x3) This is not our case so we need to chaged that, one way to do it is to change the network architecture of the model as described in Adaptive Pooling Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
      "              ReLU-7           [-1, 64, 56, 56]               0\n",
      "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
      "             ReLU-10           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-11           [-1, 64, 56, 56]               0\n",
      "           Conv2d-12           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-13           [-1, 64, 56, 56]             128\n",
      "             ReLU-14           [-1, 64, 56, 56]               0\n",
      "           Conv2d-15           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-16           [-1, 64, 56, 56]             128\n",
      "             ReLU-17           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-18           [-1, 64, 56, 56]               0\n",
      "           Conv2d-19          [-1, 128, 28, 28]          73,728\n",
      "      BatchNorm2d-20          [-1, 128, 28, 28]             256\n",
      "             ReLU-21          [-1, 128, 28, 28]               0\n",
      "           Conv2d-22          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-23          [-1, 128, 28, 28]             256\n",
      "           Conv2d-24          [-1, 128, 28, 28]           8,192\n",
      "      BatchNorm2d-25          [-1, 128, 28, 28]             256\n",
      "             ReLU-26          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-27          [-1, 128, 28, 28]               0\n",
      "           Conv2d-28          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-29          [-1, 128, 28, 28]             256\n",
      "             ReLU-30          [-1, 128, 28, 28]               0\n",
      "           Conv2d-31          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-32          [-1, 128, 28, 28]             256\n",
      "             ReLU-33          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-34          [-1, 128, 28, 28]               0\n",
      "           Conv2d-35          [-1, 256, 14, 14]         294,912\n",
      "      BatchNorm2d-36          [-1, 256, 14, 14]             512\n",
      "             ReLU-37          [-1, 256, 14, 14]               0\n",
      "           Conv2d-38          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-39          [-1, 256, 14, 14]             512\n",
      "           Conv2d-40          [-1, 256, 14, 14]          32,768\n",
      "      BatchNorm2d-41          [-1, 256, 14, 14]             512\n",
      "             ReLU-42          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-43          [-1, 256, 14, 14]               0\n",
      "           Conv2d-44          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-45          [-1, 256, 14, 14]             512\n",
      "             ReLU-46          [-1, 256, 14, 14]               0\n",
      "           Conv2d-47          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-48          [-1, 256, 14, 14]             512\n",
      "             ReLU-49          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-50          [-1, 256, 14, 14]               0\n",
      "           Conv2d-51            [-1, 512, 7, 7]       1,179,648\n",
      "      BatchNorm2d-52            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-53            [-1, 512, 7, 7]               0\n",
      "           Conv2d-54            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-55            [-1, 512, 7, 7]           1,024\n",
      "           Conv2d-56            [-1, 512, 7, 7]         131,072\n",
      "      BatchNorm2d-57            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-58            [-1, 512, 7, 7]               0\n",
      "       BasicBlock-59            [-1, 512, 7, 7]               0\n",
      "           Conv2d-60            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-61            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-62            [-1, 512, 7, 7]               0\n",
      "           Conv2d-63            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-64            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-65            [-1, 512, 7, 7]               0\n",
      "       BasicBlock-66            [-1, 512, 7, 7]               0\n",
      "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
      "           Linear-68                 [-1, 1024]         525,312\n",
      "           Linear-69                   [-1, 10]          10,250\n",
      "================================================================\n",
      "Total params: 11,712,074\n",
      "Trainable params: 11,712,074\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 62.79\n",
      "Params size (MB): 44.68\n",
      "Estimated Total Size (MB): 108.05\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "N_CLASSES = 10\n",
    "\n",
    "def freeze_model(model):\n",
    "    model.eval()\n",
    "    for params in model.parameters():\n",
    "        params.requires_grad = False\n",
    "        \n",
    "cnn = resnet18(pretrained='imagenet')\n",
    "# freeze_model(cnn)\n",
    "cnn.avgpool = nn.AdaptiveAvgPool2d(1) # This will allow to use different input sizes\n",
    "cnn.last_linear = nn.Sequential(nn.Linear(cnn.last_linear.in_features, 1024), \n",
    "                                nn.Linear(1024, 10))\n",
    "\n",
    "from torchsummary import torchsummary\n",
    "\n",
    "torchsummary.summary(cnn.cuda(), input_size=(3, 224,224))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define your loss function / crieterion, optimizers and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.9994)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR= 0.005\n",
    "BATCH_SIZE = 8\n",
    "DATASET_USAGE_SIZE = 0.15\n",
    "N_CLASSES = 10\n",
    "\n",
    "MEAN = [0.485, 0.456, 0.406]\n",
    "STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "OPTIMIZER = 'SGD' # one of ['ASGD','Adadelta', 'Adagrad','Adam', 'Adamax','LBFGS', 'RMSprop','Rprop','SGD',SparseAdam']\n",
    "optimizer = getattr(torch.optim, OPTIMIZER)(cnn.parameters(), lr=LR)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "cnn.to(DEVICE)\n",
    "\n",
    "# Create dataset loaders\n",
    "    \n",
    "PATH_TO_FMNIST_TRAIN = './data/fashion-mnist_train.csv'\n",
    "PATH_TO_FMNIST_TEST = './data/fashion-mnist_test.csv'\n",
    "\n",
    "\n",
    "dftrain = pd.read_csv(PATH_TO_FMNIST_TRAIN).sample(frac=DATASET_USAGE_SIZE)\n",
    "dftest = pd.read_csv(PATH_TO_FMNIST_TEST).sample(frac=0.1)\n",
    "\n",
    "transform_train = transforms.Compose([transforms.Resize(34), \n",
    "                                      transforms.ToTensor(), \n",
    "                                      transforms.Normalize(mean=MEAN, std=STD)\n",
    "                                     ]\n",
    "                                    )\n",
    "fmnist_train = FashionMnist(dftrain, transform=transform_train)\n",
    "\n",
    "transform_test = transforms.Compose([transforms.Resize(34), \n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize(mean=MEAN, std=STD)\n",
    "                                    ])\n",
    "fmnist_test = FashionMnist(dftest, transform=transform_test)\n",
    "\n",
    "fmnist_train_dl = DataLoader(fmnist_train, batch_size=BATCH_SIZE)\n",
    "fmnist_test_dl = DataLoader(fmnist_test, batch_size=BATCH_SIZE)\n",
    "\n",
    "# Lets try to use the criterion with dummy data\n",
    "yp = torch.randn(BATCH_SIZE, 10)\n",
    "yt = torch.randint(10, (BATCH_SIZE,))\n",
    "criterion(yp, yt.long())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test: loss: 1.4284896233677864  acc: 0.873\n",
      "train: loss: 1.4208202751874923  acc: 0.8747777777777778\n",
      "test: loss: 1.4051646388173102  acc: 0.891\n",
      "train: loss: 1.3933831292523278  acc: 0.9005555555555556\n",
      "test: loss: 1.3928274946212769  acc: 0.871\n",
      "train: loss: 1.372860410756535  acc: 0.914\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-d15ad8695585>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mlossacc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfmnist_train_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-58b960898c0c>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_image_and_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0;31m# We can transform the output images here, cast to torch data-format and/or do augmentations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-58b960898c0c>\u001b[0m in \u001b[0;36mload_image_and_target\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload_image_and_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# .iloc is short for integer loc it returns a row of data based on its ored not index-value(if not the same)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0moneimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         image, y = PIL.Image.fromarray(\n\u001b[1;32m     29\u001b[0m             np.array(oneimage[1:]).reshape(28, 28).astype('uint8'), 'L').convert('RGB'), oneimage[0]\n",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1423\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1424\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1426\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   2157\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2159\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2161\u001b[0m     \u001b[0;31m# raise_missing is included for compat with the parent class signature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_loc\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ixs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_ixs\u001b[0;34m(self, i, axis)\u001b[0m\n\u001b[1;32m   2938\u001b[0m                 \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m                 \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2940\u001b[0;31m                 \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2941\u001b[0m             )\n\u001b[1;32m   2942\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_is_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    312\u001b[0m                     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msanitize_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_cast_failure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSingleBlockManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36msanitize_array\u001b[0;34m(data, index, dtype, copy, raise_cast_failure)\u001b[0m\n\u001b[1;32m    662\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m             \u001b[0;31m# we will try to copy be-definition here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m             \u001b[0msubarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_try_cast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_cast_failure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExtensionArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_try_cast\u001b[0;34m(arr, dtype, copy, raise_cast_failure)\u001b[0m\n\u001b[1;32m    773\u001b[0m     \u001b[0;31m# perf shortcut as this is the most common case\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    774\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 775\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mmaybe_castable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    776\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.7/site-packages/pandas/core/dtypes/cast.py\u001b[0m in \u001b[0;36mmaybe_castable\u001b[0;34m(arr)\u001b[0m\n\u001b[1;32m    875\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mis_timedelta64_ns_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 877\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_POSSIBLY_CAST_DTYPES\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.7/site-packages/numpy/core/_dtype.py\u001b[0m in \u001b[0;36m_name_get\u001b[0;34m(dtype)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0m_name_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m     \u001b[0;31m# provides dtype.name.__get__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, test_loader, print_info=False):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        collect_results = []\n",
    "        collect_target = []\n",
    "        for batch in test_loader:\n",
    "            X, y = batch\n",
    "#             X = X.repeat(1, 3, 1, 1)\n",
    "            X = X.to(DEVICE)\n",
    "            y = y.to(DEVICE).detach().cpu().numpy()\n",
    "            pred = cnn(X)\n",
    "            collect_results.append(pred.sigmoid().detach().cpu().numpy())\n",
    "            collect_target.append(y) \n",
    "        \n",
    "    preds_proba = np.concatenate(collect_results)\n",
    "    preds = preds_proba.argmax(axis=1)\n",
    "    targets = np.concatenate(collect_target)\n",
    "\n",
    "    ll = log_loss(targets, preds_proba)\n",
    "    acc = accuracy_score(targets, preds)\n",
    "    if print_info:\n",
    "        print(\"test log-loss: {}\".format(ll))\n",
    "        print(\"overall accuracy:  {}\".format(ac))\n",
    "#         print(classification_report(targets, preds))\n",
    "    model.train()\n",
    "#         freeze_model(model)\n",
    "        \n",
    "    return ll, acc\n",
    "            \n",
    "collect = []\n",
    "for epoch in range(50):\n",
    "    lossacc = 0\n",
    "    for i, batch in enumerate(fmnist_train_dl):\n",
    "        optimizer.zero_grad()\n",
    "        X, y = batch\n",
    "#         X = X.repeat(1, 3, 1, 1)\n",
    "        X = X.to(DEVICE)\n",
    "        y = y.to(DEVICE)\n",
    "        y_pred = cnn(X)\n",
    "        \n",
    "        loss = criterion(y_pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()  \n",
    "        collect.append(float(loss.detach().cpu().numpy()))  \n",
    "        \n",
    "    lltest, acctest = evaluate_model(cnn, fmnist_test_dl)\n",
    "    lltrain, acctrain = evaluate_model(cnn, fmnist_train_dl)\n",
    "    print(\"test: loss: {}  acc: {}\".format(lltest, acctest))\n",
    "    print(\"train: loss: {}  acc: {}\".format(lltrain, acctrain))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "\n",
    "- What do you think of the results?\n",
    "- Try training the model without freezing. What do you observe?\n",
    "- Visualize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fb64c67b290>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "plt.plot(collect[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "history": [],
  "kernelspec": {
   "display_name": "Python [conda env:dl] *",
   "language": "python",
   "name": "conda-env-dl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "neptune": {
   "notebookId": "e79d9601-dbae-479e-adc4-09f7dabee6a2"
  },
  "uuid": "22f8e5a2-5805-454e-bfe0-bbbe88dddae8"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
