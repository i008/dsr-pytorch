{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TABULAR EMBEDDINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import scikitplot as skplt\n",
    "import torch\n",
    "from ignite.engine import (\n",
    "    Events,\n",
    "    create_supervised_evaluator,\n",
    "    create_supervised_trainer,\n",
    ")\n",
    "from ignite.metrics import CategoricalAccuracy, Loss\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import (\n",
    "    LabelBinarizer,\n",
    "    LabelEncoder,\n",
    "    MinMaxScaler,\n",
    "    OneHotEncoder,\n",
    "    StandardScaler,\n",
    ")\n",
    "from torch import nn\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_train(df, cat_columns, num_columns, target):\n",
    "    \n",
    "    encoders = {c: LabelEncoder() for c in cat_columns}\n",
    "    scalers = {c: MinMaxScaler() for c in num_columns}\n",
    "    \n",
    "    df = df[target + cat_columns + num_columns]\n",
    "\n",
    "    df_train, df_val = train_test_split(df, train_size=0.8)\n",
    "\n",
    "    for cat_column in cat_columns:\n",
    "        df[cat_column] = encoders[cat_column].fit_transform((df[cat_column]))\n",
    "        \n",
    "    for cat_column in cat_columns:\n",
    "        df_train[cat_column] = encoders[cat_column].transform((df_train[cat_column]))\n",
    "        \n",
    "    for cat_column in cat_columns:\n",
    "        df_val[cat_column] = encoders[cat_column].transform((df_val[cat_column]))     \n",
    "        \n",
    "    for num_column in num_columns:\n",
    "        df_train[num_column] = scalers[num_column].fit_transform(df_train[num_column].values.reshape(-1,1))\\\n",
    "    \n",
    "    for num_column in num_columns:\n",
    "        df_val[num_column] = scalers[num_column].transform(df_val[num_column].values.reshape(-1,1))\n",
    "        \n",
    "    target_binarizer = LabelBinarizer()\n",
    "    df_train[target] = target_binarizer.fit_transform(df_train[target])\n",
    "    df_val[target] = target_binarizer.transform(df_val[target])\n",
    "    embedding_dict = {cat_column: df[cat_column].unique().shape[0] for cat_column in cat_columns}\n",
    "    \n",
    "    return df_train, df_val, embedding_dict, encoders, scalers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabEmbedModel(nn.Module):\n",
    "    def __init__(self,out_features=1, n_num_column=1, embedding_dict={}):\n",
    "        super(TabEmbedModel, self).__init__()\n",
    "    \n",
    "        self.out_features = out_features\n",
    "        embdding_output_sizes = sum([v // 2 for  v in embedding_dict.values()])\n",
    "\n",
    "        total_dens_layers = n_num_column + embdding_output_sizes\n",
    "        \n",
    "        for embed, value in embedding_dict.items():\n",
    "            setattr(self, embed, nn.Embedding(value, value // 2))\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(total_dens_layers, 100),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm1d(100),\n",
    "            nn.Linear(100, 100),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm1d(100,100),\n",
    "            nn.Linear(100, self.out_features)\n",
    "        \n",
    "        )\n",
    "        \n",
    "      \n",
    "    def forward(self, X):  \n",
    "        num_x, cat_x = X\n",
    "        embeddings_collect = []\n",
    "\n",
    "        for i, c in enumerate(embedding_dict):\n",
    "            embed = getattr(self, c)(cat_x[:, i])\n",
    "            embeddings_collect.append(embed)\n",
    "            \n",
    "        embeddings_cat = torch.cat(embeddings_collect, dim=1).float()\n",
    "        X = torch.cat([num_x, embeddings_cat], dim=1)\n",
    "        ypred = self.layers(X)\n",
    "        \n",
    "        return ypred.float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "class TabDataset(Dataset):\n",
    "    def __init__(self, df, cat_columns, num_columns, target_column):\n",
    "        self.df = df\n",
    "        self.cat_columns = cat_columns\n",
    "        self.num_columns = num_columns\n",
    "        self.target_column = target_column\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, ix):\n",
    "        \n",
    "        row = self.df.iloc[ix]\n",
    "        \n",
    "\n",
    "        cat_values = torch.from_numpy(row[self.cat_columns].values)\n",
    "        num_values = torch.from_numpy(row[self.num_columns].values.astype(float))\n",
    "        target = torch.from_numpy(row[[self.target_column]].values)\n",
    "        \n",
    "        return num_values, cat_values, target \n",
    "      \n",
    "    def collate_func(self, batch):\n",
    "        num = torch.stack([n[0] for n in batch], dim=0).float()\n",
    "        cat = torch.stack([n[1] for n in batch], dim=0).long()\n",
    "        target = torch.stack([n[2] for n in batch], dim=0)\n",
    "        \n",
    "        return (num, cat), target.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "LR = 2e-3\n",
    "\n",
    "df = pd.read_csv('data/adult.csv', dtype={'age':int, \n",
    "                                          'education':'category',\n",
    "                                          'native.country': 'category',\n",
    "                                          'income':object,\n",
    "                                          'capital.loss': float,\n",
    "                                         })\n",
    "# \n",
    "df = df.rename(columns={c: c.replace('.', '-') for c in df.columns if '.' in c})\n",
    "target = ['income']\n",
    "cat_columns = ['education',\n",
    "               'native-country',\n",
    "               'marital-status',\n",
    "               'occupation',\n",
    "               'race',\n",
    "               'gender',\n",
    "               'capital-gain',\n",
    "               'workclass',\n",
    "               'relationship',\n",
    "               'educational-num',\n",
    "              ]\n",
    "\n",
    "num_columns = ['capital-loss',\n",
    "               'age',\n",
    "               'fnlwgt',\n",
    "               'hours-per-week',\n",
    "              ]\n",
    "\n",
    "\n",
    "df_train, df_val, embedding_dict, encoders, scalers = process_train(df, cat_columns, num_columns, target)\n",
    "\n",
    "model = TabEmbedModel(1, n_num_column=len(num_columns), embedding_dict=embedding_dict)\n",
    "model = model.cuda()\n",
    "\n",
    "ds = TabDataset(df_train, cat_columns, num_columns, 'income')\n",
    "dsval = TabDataset(df_val, cat_columns, num_columns, 'income')\n",
    "\n",
    "dltrain = DataLoader(ds, batch_size=BATCH_SIZE, \n",
    "                     collate_fn=ds.collate_func, \n",
    "                     shuffle=True, drop_last=False)\n",
    "\n",
    "dlval = DataLoader(dsval, batch_size=BATCH_SIZE, \n",
    "                   collate_fn=ds.collate_func, \n",
    "                   shuffle=True, drop_last=False)\n",
    "\n",
    "\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=LR)\n",
    "loss = BCEWithLogitsLoss()\n",
    "trainer = create_supervised_trainer(model, optimizer, loss, device='cuda')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this shows us how many categories are there for each of the categorical-variables.\n",
    "# its important as we need to know how big our embedding matrix has to be.\n",
    "embedding_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def thresholded_output_transform(output):\n",
    "    y_pred, y = output\n",
    "    y_pred = torch.round(y_pred)\n",
    "    return y_pred, y.long()\n",
    "\n",
    "acc = CategoricalAccuracy(thresholded_output_transform)\n",
    "\n",
    "evaluator = create_supervised_evaluator(model,\n",
    "                                        device='cuda',\n",
    "                                        metrics={\n",
    "                                            'accuracy': acc,\n",
    "                                            'nll': Loss(loss)\n",
    "                                            })\n",
    "\n",
    "model.cuda()\n",
    "\n",
    "@trainer.on(Events.ITERATION_COMPLETED)\n",
    "def log_trainig_loss(trainer):\n",
    "    print(\"Epoch[{}] Loss: {:.2f}\".format(trainer.state.epoch, trainer.state.output))\n",
    "\n",
    "    \n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_validation_results(engine):\n",
    "    evaluator.run(dlval)\n",
    "    metrics = evaluator.state.metrics\n",
    "    print(\"Validation Results - Epoch: {}  Avg accuracy: {:.2f} Avg loss: {:.2f}\"\n",
    "          .format(engine.state.epoch, metrics['accuracy'], metrics['nll']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "trainer.run(dltrain, max_epochs=1)\n",
    "\n",
    "collect = []\n",
    "y_true = []\n",
    "for b in dlval:\n",
    "    X, y = b \n",
    "    model.eval()\n",
    "    r = model.cpu()(X)\n",
    "    collect.append(r)\n",
    "    y_true.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = torch.cat(collect).sigmoid().round()\n",
    "proba = torch.cat(collect)\n",
    "true = torch.cat(y_true)\n",
    "\n",
    "proba = torch.stack([1 - proba, proba], dim=1).squeeze()\n",
    "skplt.metrics.plot_precision_recall_curve(true.detach().cpu().numpy(), \n",
    "                                          proba.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true.detach().cpu().numpy()\n",
    "\n",
    "proba.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_train(df, cat_columns, num_columns, target):\n",
    "    \n",
    "    encoders = {c: LabelEncoder() for c in cat_columns}\n",
    "    scalers = {c: MinMaxScaler() for c in num_columns}\n",
    "    \n",
    "    df = df[target + cat_columns + num_columns]\n",
    "\n",
    "    df_train, df_val = train_test_split(df, train_size=0.8)\n",
    "\n",
    "    for cat_column in cat_columns:\n",
    "        df[cat_column] = encoders[cat_column].fit_transform((df[cat_column]))\n",
    "        \n",
    "    for cat_column in cat_columns:\n",
    "        df_train[cat_column] = encoders[cat_column].transform((df_train[cat_column]))\n",
    "        \n",
    "    for cat_column in cat_columns:\n",
    "        df_val[cat_column] = encoders[cat_column].transform((df_val[cat_column]))     \n",
    "        \n",
    "    for num_column in num_columns:\n",
    "        df_train[num_column] = scalers[num_column].fit_transform(df_train[num_column].values.reshape(-1,1))\\\n",
    "    \n",
    "    for num_column in num_columns:\n",
    "        df_val[num_column] = scalers[num_column].transform(df_val[num_column].values.reshape(-1,1))\n",
    "        \n",
    "    target_binarizer = LabelBinarizer()\n",
    "    df_train[target] = target_binarizer.fit_transform(df_train[target])\n",
    "    df_val[target] = target_binarizer.transform(df_val[target])\n",
    "    embedding_dict = {cat_column: df[cat_column].unique().shape[0] for cat_column in cat_columns}\n",
    "    \n",
    "    return df_train, df_val, embedding_dict, encoders, scalers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_train_non_nn(df, cat_columns, num_columns, target):\n",
    "    cat  = pd.get_dummies(df, columns=cat_columns)\n",
    "    df = pd.concat([df.drop(cat_columns + ['income'], axis=1), cat], axis=1)\n",
    "\n",
    "    df_train, df_val = train_test_split(df, train_size=0.8)\n",
    "    \n",
    "    target_binarizer = LabelBinarizer()\n",
    "    df_train[target] = target_binarizer.fit_transform(df_train[target])\n",
    "    df_val[target] = target_binarizer.transform(df_val[target])\n",
    "\n",
    "    return df_train, df_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "df_train, df_val  = process_train_non_nn(df, cat_columns, num_columns, target)\n",
    "y_train = df_train.pop('income')\n",
    "y_test = df_val.pop('income')\n",
    "\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=10)\n",
    "rfc.fit(df_train,  y_train)\n",
    "\n",
    "p = rfc.predict(df_val)\n",
    "pred = rfc.predict_proba(df_val)\n",
    "skplt.metrics.plot_precision_recall_curve(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
