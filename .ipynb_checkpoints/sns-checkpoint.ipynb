{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating an image classifier able to find sneakers in instagram posts\n",
    "\n",
    "The data comprises of few thousand images of sneakers collected using google images and instagram\n",
    "and few thousand images of sneakers.    \n",
    "Your goal is to use what you learned from previous examples and create a sneaker-not-sneaker binary classifier.\n",
    "\n",
    "The task comprises of multiple sub-tasks that you need to do to build the classifier.\n",
    "\n",
    "1. Create a dataset able to load data from new_meta_sneakers.csv\n",
    "2. Create a fine tune binary classification architecture.\n",
    "3. Create a training loop and train your model.\n",
    "\n",
    "![title](sneakers.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On the bottom of the following cell you see the data you will work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/i008/anaconda3/lib/python3.6/site-packages/easyimages/utils.py:7: UserWarning: \n",
      "This call to matplotlib.use() has no effect because the backend has already\n",
      "been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "The backend was *originally* set to 'module://ipykernel.pylab.backend_inline' by the following code:\n",
      "  File \"/home/i008/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/home/i008/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/i008/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py\", line 3, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/home/i008/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/home/i008/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 499, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/home/i008/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 810, in start\n",
      "    self._run_callback(callback)\n",
      "  File \"/home/i008/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 592, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/home/i008/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/i008/anaconda3/lib/python3.6/site-packages/tornado/gen.py\", line 963, in <lambda>\n",
      "    self.future, lambda f: self.run())\n",
      "  File \"/home/i008/anaconda3/lib/python3.6/site-packages/tornado/gen.py\", line 879, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/home/i008/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 346, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/home/i008/anaconda3/lib/python3.6/site-packages/tornado/gen.py\", line 230, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/home/i008/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 259, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/home/i008/anaconda3/lib/python3.6/site-packages/tornado/gen.py\", line 230, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/home/i008/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 513, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/home/i008/anaconda3/lib/python3.6/site-packages/tornado/gen.py\", line 230, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/home/i008/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/home/i008/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/home/i008/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/home/i008/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/home/i008/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2901, in run_ast_nodes\n",
      "    if self.run_code(code, result):\n",
      "  File \"/home/i008/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2961, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-1-e88ad8df8274>\", line 1, in <module>\n",
      "    get_ipython().run_line_magic('matplotlib', 'inline')\n",
      "  File \"/home/i008/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2131, in run_line_magic\n",
      "    result = fn(*args,**kwargs)\n",
      "  File \"<decorator-gen-107>\", line 2, in matplotlib\n",
      "  File \"/home/i008/anaconda3/lib/python3.6/site-packages/IPython/core/magic.py\", line 187, in <lambda>\n",
      "    call = lambda f, *a, **k: f(*a, **k)\n",
      "  File \"/home/i008/anaconda3/lib/python3.6/site-packages/IPython/core/magics/pylab.py\", line 99, in matplotlib\n",
      "    gui, backend = self.shell.enable_matplotlib(args.gui)\n",
      "  File \"/home/i008/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3049, in enable_matplotlib\n",
      "    pt.activate_matplotlib(backend)\n",
      "  File \"/home/i008/anaconda3/lib/python3.6/site-packages/IPython/core/pylabtools.py\", line 311, in activate_matplotlib\n",
      "    matplotlib.pyplot.switch_backend(backend)\n",
      "  File \"/home/i008/anaconda3/lib/python3.6/site-packages/matplotlib/pyplot.py\", line 231, in switch_backend\n",
      "    matplotlib.use(newbackend, warn=False, force=True)\n",
      "  File \"/home/i008/anaconda3/lib/python3.6/site-packages/matplotlib/__init__.py\", line 1410, in use\n",
      "    reload(sys.modules['matplotlib.backends'])\n",
      "  File \"/home/i008/anaconda3/lib/python3.6/importlib/__init__.py\", line 166, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"/home/i008/anaconda3/lib/python3.6/site-packages/matplotlib/backends/__init__.py\", line 16, in <module>\n",
      "    line for line in traceback.format_stack()\n",
      "\n",
      "\n",
      "  mpl.use('agg')\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from torch import nn\n",
    "import easyimages\n",
    "import pandas as pd\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pretrainedmodels.models import resnet50\n",
    "from torchvision.transforms import transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch \n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>image_path</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16572</th>\n",
       "      <td>16572</td>\n",
       "      <td>/media/i008/ssd500/fashion_classify_data/sneak...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45581</th>\n",
       "      <td>45581</td>\n",
       "      <td>/media/i008/ssd500/fashion_classify_data/sneak...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27500</th>\n",
       "      <td>27500</td>\n",
       "      <td>/media/i008/ssd500/fashion_classify_data/sneak...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45655</th>\n",
       "      <td>45655</td>\n",
       "      <td>/media/i008/ssd500/fashion_classify_data/sneak...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34567</th>\n",
       "      <td>34567</td>\n",
       "      <td>/media/i008/ssd500/fashion_classify_data/negat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                         image_path  tags\n",
       "16572       16572  /media/i008/ssd500/fashion_classify_data/sneak...     1\n",
       "45581       45581  /media/i008/ssd500/fashion_classify_data/sneak...     1\n",
       "27500       27500  /media/i008/ssd500/fashion_classify_data/sneak...     1\n",
       "45655       45655  /media/i008/ssd500/fashion_classify_data/sneak...     1\n",
       "34567       34567  /media/i008/ssd500/fashion_classify_data/negat...     0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATASET_USAGE_PERCENTAGE = 0.1\n",
    "\n",
    "base_path ='/media/i008/ssd500/fashion_classify_data/'\n",
    "df = pd.read_csv(os.path.join(base_path,'new_meta_sneakers.csv')).sample(frac=1)\n",
    "df.image_path = base_path +df.image_path\n",
    "df.tags = df.tags.map({'sneakers': 1, 'negatives': 0})\n",
    "df = df.sample(frac=DATASET_USAGE_PERCENTAGE)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the torch Dataset.\n",
    "\n",
    "First thing we need to do is create a dataset able to load our data. Since our metadata is stored in a csv file, our \n",
    "dataset should accept this file as a base source of what needs to be loaded.\n",
    "\n",
    "Our dataset should also support augumentations and a \"inference\" mode wich disables them for predicting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "from PIL import Image\n",
    "import io\n",
    "import requests\n",
    "import torch\n",
    "\n",
    "\n",
    "class OneClassImageClassificationDataset(Dataset):\n",
    "    def __init__(self, annotations, image_transform):\n",
    "        \"\"\"\n",
    "        annotations is a pandas dataframe\n",
    "        \n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.annotations = annotations\n",
    "        self.image_transform = image_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Return the length of the annotations dataframe\n",
    "        \"\"\"\n",
    "        # your code here\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Using methods you wrote:\n",
    "        1 - load image from disk for given index  (self.load_from_disk)\n",
    "        2 - transform image (self.image_transform)\n",
    "        3 - Load target (self.load_target)\n",
    "        return Xi, yi\n",
    "        \"\"\"\n",
    "        \n",
    "        # YOUR CODE HERE\n",
    "\n",
    "        return Xi, yi\n",
    "\n",
    "    def load_to_pil(self, uri):\n",
    "        \"\"\"\n",
    "        Write a helper function that uses PIL.Image to load a file and convert to RGB and returns it\n",
    "        \n",
    "        \"\"\"\n",
    "        image_pil =  # YOUR CODE HERE\n",
    "        return image_pil\n",
    "\n",
    "\n",
    "    def load_from_disk(self, index):\n",
    "        \"\"\"\n",
    "        Loads an image from disk given a index.\n",
    "        It gets the path of an image with the corresponding index from the metadata \n",
    "        It passes the URI to the self.load_to_pil and returns a PIL.Image\n",
    "        \"\"\"\n",
    "        image_path = # YOUR CODE HERE\n",
    "        return self.load_to_pil(image_path)\n",
    "\n",
    "    def load_target(self, index):\n",
    "        \"\"\"\n",
    "        This function should get the tag for a given index from the annotations dataframe\n",
    "        You .iloc can become useful.    \n",
    "        This methods should return, either a 0 or a 1.\n",
    "        \"\"\"\n",
    "        \n",
    "        #label = # YOUR CODE HERE\n",
    "\n",
    "        return label\n",
    "    \n",
    "    \n",
    "class BaseSampler(Sampler):\n",
    "    def __init__(self, df, n_samples):\n",
    "        self.df = df\n",
    "        self.n_samples = n_samples\n",
    "        \n",
    "    def __iter__(self):\n",
    "        return iter(self._get_sample())\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "    \n",
    "    def _get_sample(self):\n",
    "        return np.random.choice(len(self.df), self.n_samples, replace=False)\n",
    "        \n",
    "\n",
    "def binary_classification_model():\n",
    "    \"\"\"\n",
    "    Write a function that loads a resnet50 model from pretrainedmodels. \n",
    "    - freezes its layers\n",
    "    - replaces the last_linear with the proper output number. As we did in previous example.\n",
    "    - replace avgpool with adaptiv pooling.\n",
    "    \"\"\"\n",
    "    model = resnet50()\n",
    "\n",
    "    # model = YOUR CODE HERE\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/i008/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# YOUR CODE HERE:\n",
    "# SPLIT the dataframe into df_train, df_test (thing about using sklearn.model_selection.train_test_split)\n",
    "df_train, df_test = train_test_split(df, train_size=0.8)\n",
    "df_train = df_train.reset_index()\n",
    "df_test = df_test.reset_index()\n",
    "\n",
    "MEAN = [0.485, 0.456, 0.406]\n",
    "STD = [0.229, 0.224, 0.225]\n",
    "N_EPOCHS = 10\n",
    "BATCH_SIZE = 32\n",
    "IMAGE_SIZE = 32\n",
    "\n",
    "image_transform_train = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=MEAN, std=STD)])\n",
    "\n",
    "# YOUR CODE define image_transform_test\n",
    "image_transform_test = ?\n",
    "\n",
    "# YOUR CODE define the crieterion\n",
    "criterion = ? \n",
    "\n",
    "\n",
    "net = binary_classification_model()\n",
    "\n",
    "optimizer = ?\n",
    "# initialize the BaseSampler with 1000 samples per epoch\n",
    "bs = ?\n",
    "\n",
    "# YOUR CODE\n",
    "# Instantiate the OneClassImageClassificationDatasets\n",
    "train_ds = ?\n",
    "test_ds = ?\n",
    "\n",
    "#YOUR CODE\n",
    "#Initialize your DataLoader (using datasets)\n",
    "train_dl = ?\n",
    "test_dl = ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "def evaluate_model(model, loader, print_info=False):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        collect_results = []\n",
    "        collect_target = []\n",
    "        for batch in loader:\n",
    "            X, y = batch\n",
    "            X = X.to(DEVICE)\n",
    "            y = y.to(DEVICE).detach().cpu().numpy()\n",
    "            pred = model(X)\n",
    "            collect_results.append(pred.sigmoid().detach().cpu().numpy())\n",
    "            collect_target.append(y) \n",
    "    \n",
    "        preds_proba = np.concatenate(collect_results)\n",
    "        preds = preds_proba.argmax(axis=1)\n",
    "        \n",
    "        targets = np.concatenate(collect_target)\n",
    "        \n",
    "        ll = log_loss(targets, preds_proba)\n",
    "        acc = accuracy_score(targets, preds)\n",
    "        if print_info:\n",
    "            print(\"test log-loss: {}\".format(ll))\n",
    "            print(\"overall accuracy:  {}\".format(acc))\n",
    "            #print(classification_report(targets, preds))\n",
    "        model.train()\n",
    "        \n",
    "        return ll, acc\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "metrics = []\n",
    "metrics_names = ['loss_train','loss_test','acc_train','acc_test']\n",
    "losses = []\n",
    "net.to(DEVICE)\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    for X, y in train_dl:\n",
    "        X = X.to(DEVICE)\n",
    "        y = y.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        ypred=net(X)\n",
    "        loss = criterion(ypred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.detach().cpu().numpy())\n",
    "        \n",
    "    testll, testacc = evaluate_model(net, test_dl)\n",
    "    trainll, trainacc = evaluate_model(net, train_dl)\n",
    "    print(\"test: {} {}\".format(testll, testacc))\n",
    "    print(\"train: {} {}\".format(trainll, trainacc))\n",
    "    metrics.append([trainll, testll, trainacc, testacc])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
