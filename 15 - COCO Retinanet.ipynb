{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "loading annotations into memory...\n",
      "Done (t=0.52s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "# !pip install pycocotools\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload \n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "from torchvision.datasets import CocoDetection\n",
    "import torch.utils.data as data\n",
    "import torch.utils.data as data\n",
    "from PIL import Image\n",
    "import os\n",
    "import os.path\n",
    "from albumentations import Resize, Compose\n",
    "\n",
    "from retinanet.retinanet import RetinaNet\n",
    "\n",
    "from torchvision import transforms\n",
    "from urllib.request import urlopen\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from albumentations import (\n",
    "    HorizontalFlip,\n",
    "    VerticalFlip,\n",
    "    Resize,\n",
    "    CenterCrop,\n",
    "    RandomCrop,\n",
    "    Crop,\n",
    "    Compose\n",
    ")\n",
    "import json\n",
    "import torch\n",
    "import numpy as np \n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.rcParams['figure.figsize'] = [14, 10]\n",
    "from torch.utils.data import Dataset\n",
    "from retinanet.encoder import DataEncoder\n",
    "import imgaug as ia\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from retinanet.retinanet import RetinaNet\n",
    "from retinanet.loss import FocalLoss\n",
    "from pikachu_dataset import load_data_pikachu\n",
    "from torch import nn\n",
    "\n",
    "device  = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "MEAN = [0.485, 0.456, 0.406]\n",
    "STD = [0.229, 0.224, 0.225]\n",
    "N_EPOCHS = 10\n",
    "BATCH_SIZE = 32\n",
    "IMAGE_SIZE = 32\n",
    "\n",
    "image_transform_train = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=MEAN, std=STD)])\n",
    "\n",
    "\n",
    "class CocoDetection(data.Dataset):\n",
    "\n",
    "    def __init__(self, root, annFile, transform=None, target_transform=None):\n",
    "        from pycocotools.coco import COCO\n",
    "        self.root = root\n",
    "        self.coco = COCO(annFile)\n",
    "        self.imw = 256\n",
    "        self.imh = 256\n",
    "        self.ids = list(self.coco.imgs.keys())\n",
    "        self.aug = get_aug([Resize(256, 256)])\n",
    "        self.encoder = DataEncoder()\n",
    "#         self.encoder.anchor_areas =[8*8.,16*16.,32*32]\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "  \n",
    "        coco = self.coco\n",
    "        img_id = self.ids[index]\n",
    "        ann_ids = coco.getAnnIds(imgIds=img_id)\n",
    "        target = coco.loadAnns(ann_ids)\n",
    "\n",
    "        path = coco.loadImgs(img_id)[0]['file_name']\n",
    "        img = Image.open(os.path.join(self.root, path)).convert('RGB')\n",
    "        \n",
    "        \n",
    "        annot = {'image': np.array(img), \n",
    "                 'bboxes': [b['bbox'] for b in target], \n",
    "                 'category_id':[b['category_id'] for b in target]}\n",
    "    \n",
    "        \n",
    "        annot = self.aug(**annot)\n",
    "        \n",
    "        \n",
    "        boxes = torch.Tensor(annot['bboxes'])\n",
    "        labels = torch.Tensor(annot['category_id'])\n",
    "        \n",
    "        \n",
    "        \n",
    "        if boxes.shape[0] == 0:\n",
    "            return self[index + 1]\n",
    "            import pdb\n",
    "            pdb.set_trace()\n",
    "        if sum(labels>0) == 0:\n",
    "            import pdb \n",
    "            pdb.set_trace()\n",
    "            return self[index + 1]\n",
    "\n",
    "        \n",
    "        boxes = torch.cat([boxes[:, :2], boxes[:, :2] + boxes[:, 2:]], dim=1)\n",
    "        encoded = self.encoder.encode(boxes, labels, torch.Tensor([256, 256]))\n",
    "        \n",
    "        how_many_encoded = (encoded[1]>0).sum()\n",
    "        if  how_many_encoded <= 0:\n",
    "            print(how_many_encoded)\n",
    "            print(\"skipping\")\n",
    "            print(labels)\n",
    "            return self[index + 1]\n",
    "        \n",
    "        return image_transform_train(annot['image']), encoded\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "    \n",
    "    \n",
    "def get_aug(aug, min_area=0., min_visibility=0.):\n",
    "        return Compose(aug, bbox_params={'format': 'coco', 'min_area': min_area, \n",
    "                                         'min_visibility': min_visibility, \n",
    "                                         'label_fields': ['category_id']})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "ds = CocoDetection(root='/media/i008/ssd500/val2017',\n",
    "                   annFile='/media/i008/ssd500/annotations/instances_val2017.json',\n",
    "                   \n",
    "                  )\n",
    "\n",
    "dl = torch.utils.data.DataLoader(ds, batch_size=8)\n",
    "\n",
    "def init_weights_retina(module, pi=0.01):\n",
    "    if hasattr(module, 'name'):\n",
    "        b = -log((1 - pi) / pi)\n",
    "        if module.name == 'final_layer':\n",
    "            module.bias.data.fill_(b)\n",
    "        elif module.name == 'head_layer':\n",
    "            module.weight.data.normal_(0, pi)\n",
    "            module.bias.data.fill_(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model= SimpleSSD(100)\n",
    "model = RetinaNet(100)\n",
    "model.freeze_bn()\n",
    "for param in model.fpn.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = FocalLoss(num_classes=100)\n",
    "\n",
    "model = model.apply(init_weights_retina)\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.00001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/i008/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:2351: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
      "/home/i008/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:2423: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
      "/home/i008/anaconda3/lib/python3.6/site-packages/torch/nn/_reduction.py:49: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 2016.5760498046875  loc loss 49.83682632446289\n",
      "cls loss 2412.391845703125  loc loss 72.04943084716797\n",
      "cls loss 2324.8935546875  loc loss 57.1633415222168\n",
      "cls loss 2068.5458984375  loc loss 38.609886169433594\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21.])\n",
      "cls loss 1984.1070556640625  loc loss 26.238601684570312\n",
      "cls loss 2040.5955810546875  loc loss 63.22724533081055\n",
      "cls loss 2308.67529296875  loc loss 66.28096008300781\n",
      "cls loss 1941.0013427734375  loc loss 36.90963363647461\n",
      "cls loss 2185.80517578125  loc loss 53.462684631347656\n",
      "cls loss 3196.036376953125  loc loss 92.59921264648438\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 42., 42.,  1.,  1.])\n",
      "cls loss 1796.30224609375  loc loss 44.953792572021484\n",
      "cls loss 1460.038818359375  loc loss 38.695281982421875\n",
      "cls loss 1884.4219970703125  loc loss 54.11900329589844\n",
      "cls loss 2156.44482421875  loc loss 86.153076171875\n",
      "cls loss 1774.6898193359375  loc loss 42.878658294677734\n",
      "cls loss 2036.60205078125  loc loss 73.9549789428711\n",
      "cls loss 2207.2021484375  loc loss 70.79293823242188\n",
      "cls loss 2540.642333984375  loc loss 62.094093322753906\n",
      "cls loss 1990.367919921875  loc loss 50.69513702392578\n",
      "cls loss 1791.4302978515625  loc loss 40.64519500732422\n",
      "cls loss 1922.114501953125  loc loss 27.71864891052246\n",
      "cls loss 1939.1220703125  loc loss 55.850128173828125\n",
      "cls loss 2188.97705078125  loc loss 77.18940734863281\n",
      "cls loss 2175.703125  loc loss 48.13051986694336\n",
      "cls loss 2083.006103515625  loc loss 63.20329666137695\n",
      "cls loss 2243.27099609375  loc loss 51.99102783203125\n",
      "cls loss 2697.6396484375  loc loss 85.48654174804688\n",
      "cls loss 2190.29638671875  loc loss 62.249874114990234\n",
      "cls loss 2476.828857421875  loc loss 65.1467514038086\n",
      "cls loss 1595.6627197265625  loc loss 32.70786666870117\n",
      "cls loss 2285.06396484375  loc loss 54.98171615600586\n",
      "cls loss 2175.470703125  loc loss 51.92083740234375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 5., 5., 5., 5., 5., 5.])\n",
      "cls loss 1805.1826171875  loc loss 42.005157470703125\n",
      "cls loss 1853.9515380859375  loc loss 50.68387985229492\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([13.])\n",
      "cls loss 1555.48583984375  loc loss 28.121379852294922\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([44., 10.,  1.,  1.,  1.])\n",
      "cls loss 1686.1502685546875  loc loss 31.563791275024414\n",
      "cls loss 2300.91943359375  loc loss 54.35122299194336\n",
      "cls loss 1895.066162109375  loc loss 46.773277282714844\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19., 19., 19., 19., 19., 19., 19.])\n",
      "cls loss 2205.940673828125  loc loss 61.13900375366211\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([56.])\n",
      "cls loss 3315.640625  loc loss 109.7614517211914\n",
      "cls loss 2233.732421875  loc loss 70.83187866210938\n",
      "cls loss 2875.371826171875  loc loss 90.60542297363281\n",
      "cls loss 2402.6220703125  loc loss 91.016357421875\n",
      "cls loss 1709.340087890625  loc loss 49.88444519042969\n",
      "cls loss 2434.08935546875  loc loss 89.63335418701172\n",
      "cls loss 1996.841552734375  loc loss 43.72861099243164\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 36.])\n",
      "cls loss 2131.7353515625  loc loss 49.66004943847656\n",
      "cls loss 1791.5833740234375  loc loss 55.08330535888672\n",
      "cls loss 2045.74267578125  loc loss 44.94704055786133\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5.])\n",
      "cls loss 2005.681396484375  loc loss 54.034034729003906\n",
      "cls loss 1555.5751953125  loc loss 29.691911697387695\n",
      "cls loss 2333.028076171875  loc loss 74.62262725830078\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "cls loss 2345.36279296875  loc loss 71.35128784179688\n",
      "cls loss 2197.272216796875  loc loss 61.58347702026367\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 1914.538818359375  loc loss 66.27710723876953\n",
      "cls loss 2260.48779296875  loc loss 73.65865325927734\n",
      "cls loss 1871.4287109375  loc loss 74.81546783447266\n",
      "cls loss 1680.3740234375  loc loss 47.8796501159668\n",
      "cls loss 1859.64990234375  loc loss 55.05060577392578\n",
      "cls loss 1866.99951171875  loc loss 50.90289306640625\n",
      "cls loss 2426.43798828125  loc loss 74.71672821044922\n",
      "cls loss 1565.1005859375  loc loss 29.46331787109375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 11., 15., 10., 10., 10., 10., 10.])\n",
      "cls loss 2776.3896484375  loc loss 92.95299530029297\n",
      "cls loss 1889.066162109375  loc loss 49.356624603271484\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3.])\n",
      "cls loss 1787.6092529296875  loc loss 49.13025665283203\n",
      "cls loss 1823.3251953125  loc loss 39.339454650878906\n",
      "cls loss 1832.143798828125  loc loss 42.3525390625\n",
      "cls loss 2175.64404296875  loc loss 51.85980987548828\n",
      "cls loss 1516.75732421875  loc loss 26.0528507232666\n",
      "cls loss 2043.598876953125  loc loss 43.139305114746094\n",
      "cls loss 2045.6895751953125  loc loss 64.11560821533203\n",
      "cls loss 1636.612548828125  loc loss 58.10394287109375\n",
      "cls loss 2940.925048828125  loc loss 129.55133056640625\n",
      "cls loss 2305.66650390625  loc loss 88.29042053222656\n",
      "cls loss 1853.5631103515625  loc loss 57.292415618896484\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  9.,  9.,  9.,  6.,  6., 85., 85.,  8.,  1.,  1.,  1.,  1.,\n",
      "         6.,  6.])\n",
      "cls loss 1445.156982421875  loc loss 38.13093185424805\n",
      "cls loss 2388.916015625  loc loss 90.27188110351562\n",
      "cls loss 2876.3935546875  loc loss 99.16371154785156\n",
      "cls loss 2117.18505859375  loc loss 70.98008728027344\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10.,  3.,  3., 10.])\n",
      "cls loss 1532.3818359375  loc loss 39.73712158203125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([7.])\n",
      "cls loss 1672.9163818359375  loc loss 75.05052947998047\n",
      "cls loss 1834.0205078125  loc loss 54.869163513183594\n",
      "cls loss 1746.52197265625  loc loss 61.717613220214844\n",
      "cls loss 1935.1314697265625  loc loss 87.75005340576172\n",
      "cls loss 1895.740966796875  loc loss 55.266143798828125\n",
      "cls loss 2203.833984375  loc loss 78.97660064697266\n",
      "cls loss 2830.95166015625  loc loss 90.204833984375\n",
      "cls loss 1933.761474609375  loc loss 58.66286087036133\n",
      "cls loss 1868.5784912109375  loc loss 66.97445678710938\n",
      "cls loss 1760.259765625  loc loss 56.46508026123047\n",
      "cls loss 2016.3270263671875  loc loss 86.75958251953125\n",
      "cls loss 2227.87060546875  loc loss 57.29188537597656\n",
      "cls loss 1644.4788818359375  loc loss 40.44320297241211\n",
      "cls loss 1982.142333984375  loc loss 86.948974609375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([62.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([62.])\n",
      "cls loss 1156.105224609375  loc loss 25.947622299194336\n",
      "cls loss 1891.7845458984375  loc loss 60.812198638916016\n",
      "cls loss 1817.3052978515625  loc loss 53.578365325927734\n",
      "cls loss 1595.1912841796875  loc loss 28.340599060058594\n",
      "cls loss 2114.4658203125  loc loss 72.6473159790039\n",
      "cls loss 2102.55517578125  loc loss 66.60552978515625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([28.])\n",
      "cls loss 2289.672607421875  loc loss 67.3054428100586\n",
      "cls loss 2067.674072265625  loc loss 71.26305389404297\n",
      "cls loss 2097.497314453125  loc loss 68.209716796875\n",
      "cls loss 2106.0673828125  loc loss 72.77110290527344\n",
      "cls loss 2634.9833984375  loc loss 100.27909851074219\n",
      "cls loss 1813.577880859375  loc loss 47.597381591796875\n",
      "cls loss 1947.045654296875  loc loss 59.94211959838867\n",
      "cls loss 2089.25537109375  loc loss 74.42833709716797\n",
      "cls loss 2543.3310546875  loc loss 103.0671615600586\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([81.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 2283.74365234375  loc loss 57.89440155029297\n",
      "cls loss 1689.1446533203125  loc loss 37.714996337890625\n",
      "cls loss 1577.732421875  loc loss 41.82355499267578\n",
      "cls loss 1517.7115478515625  loc loss 28.133831024169922\n",
      "cls loss 1618.955078125  loc loss 42.05897903442383\n",
      "cls loss 1565.593017578125  loc loss 44.5109977722168\n",
      "cls loss 1906.720947265625  loc loss 46.95549774169922\n",
      "cls loss 2046.858642578125  loc loss 77.01337432861328\n",
      "cls loss 2125.310302734375  loc loss 69.70036315917969\n",
      "cls loss 3637.781982421875  loc loss 142.22500610351562\n",
      "cls loss 1813.205810546875  loc loss 43.445003509521484\n",
      "cls loss 1722.2352294921875  loc loss 70.39588165283203\n",
      "cls loss 1547.5867919921875  loc loss 52.35892105102539\n",
      "cls loss 2041.03515625  loc loss 51.93148422241211\n",
      "cls loss 1659.09716796875  loc loss 48.373268127441406\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([44., 44.])\n",
      "cls loss 1590.87109375  loc loss 38.364994049072266\n",
      "cls loss 1589.6861572265625  loc loss 49.38034439086914\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15.])\n",
      "cls loss 2015.56103515625  loc loss 48.97235107421875\n",
      "cls loss 1406.449462890625  loc loss 26.770586013793945\n",
      "cls loss 1835.074951171875  loc loss 55.110679626464844\n",
      "cls loss 1400.9306640625  loc loss 32.47142028808594\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0)\n",
      "skipping\n",
      "tensor([1., 3., 3.])\n",
      "cls loss 1266.58935546875  loc loss 42.9893684387207\n",
      "cls loss 1488.732421875  loc loss 27.00591468811035\n",
      "cls loss 1961.826171875  loc loss 47.76154708862305\n",
      "cls loss 1954.0545654296875  loc loss 58.4026985168457\n",
      "cls loss 1772.25048828125  loc loss 51.02895736694336\n",
      "cls loss 1797.4892578125  loc loss 60.77574157714844\n",
      "cls loss 1448.093017578125  loc loss 54.44807434082031\n",
      "cls loss 1797.41015625  loc loss 60.801063537597656\n",
      "cls loss 1796.172119140625  loc loss 50.35157775878906\n",
      "cls loss 1671.287109375  loc loss 67.33851623535156\n",
      "cls loss 1106.629150390625  loc loss 39.64860534667969\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 1946.774169921875  loc loss 60.51439666748047\n",
      "cls loss 2144.438232421875  loc loss 71.40278625488281\n",
      "cls loss 1912.0128173828125  loc loss 78.41940307617188\n",
      "cls loss 1723.57470703125  loc loss 69.1744384765625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10., 10., 10.,  1.,  1.,  1.,  1.,  1.,  1.,  8.,  8.,\n",
      "         1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10., 10., 10.,  1.,  1.,  1.,  1.,  1.,  1.,  8.,  8.,\n",
      "         1.])\n",
      "cls loss 2116.40185546875  loc loss 62.86167526245117\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 3., 3., 3.])\n",
      "cls loss 1830.4739990234375  loc loss 49.93140411376953\n",
      "cls loss 1418.0419921875  loc loss 32.720176696777344\n",
      "cls loss 1283.6612548828125  loc loss 26.8939266204834\n",
      "cls loss 1471.45703125  loc loss 54.63936996459961\n",
      "cls loss 1479.78515625  loc loss 31.749080657958984\n",
      "cls loss 1397.465576171875  loc loss 44.84656524658203\n",
      "cls loss 1710.6455078125  loc loss 48.26998519897461\n",
      "cls loss 1994.395263671875  loc loss 82.04248046875\n",
      "cls loss 2035.284912109375  loc loss 60.14268112182617\n",
      "cls loss 1725.727294921875  loc loss 60.66484451293945\n",
      "cls loss 2075.905517578125  loc loss 66.62841796875\n",
      "cls loss 1732.980224609375  loc loss 57.27432632446289\n",
      "cls loss 2164.69287109375  loc loss 100.94658660888672\n",
      "cls loss 1482.22021484375  loc loss 40.76873779296875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 1961.272705078125  loc loss 62.37696075439453\n",
      "cls loss 1194.9061279296875  loc loss 28.877117156982422\n",
      "cls loss 2374.57373046875  loc loss 87.89793395996094\n",
      "cls loss 1533.359619140625  loc loss 39.77458953857422\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 34.])\n",
      "cls loss 2084.50927734375  loc loss 56.75828170776367\n",
      "cls loss 1193.091064453125  loc loss 33.45648193359375\n",
      "cls loss 1961.216796875  loc loss 59.238609313964844\n",
      "cls loss 1118.7197265625  loc loss 24.868389129638672\n",
      "cls loss 1966.3321533203125  loc loss 57.09845733642578\n",
      "cls loss 1615.5865478515625  loc loss 65.74337768554688\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 38.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16., 16., 16.,  9.,  9.,  9., 16., 16., 16., 85.,  9.])\n",
      "cls loss 1647.6318359375  loc loss 50.5195198059082\n",
      "cls loss 1581.7197265625  loc loss 70.20105743408203\n",
      "cls loss 2626.628662109375  loc loss 89.32994842529297\n",
      "cls loss 2742.27490234375  loc loss 125.38348388671875\n",
      "cls loss 1253.939453125  loc loss 26.937257766723633\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3., 10.,  8.,  8., 10., 10., 10.,  3.,  3., 14.])\n",
      "cls loss 1679.216064453125  loc loss 34.671756744384766\n",
      "cls loss 2063.7734375  loc loss 63.64111328125\n",
      "cls loss 1156.4775390625  loc loss 18.623435974121094\n",
      "cls loss 1523.785400390625  loc loss 36.71780776977539\n",
      "cls loss 1784.552978515625  loc loss 63.651329040527344\n",
      "cls loss 1551.9976806640625  loc loss 57.75307846069336\n",
      "cls loss 1431.27001953125  loc loss 32.705665588378906\n",
      "cls loss 1327.287353515625  loc loss 36.56148147583008\n",
      "cls loss 1590.91357421875  loc loss 54.96075439453125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42., 42.,  1.])\n",
      "cls loss 1586.78271484375  loc loss 57.03554153442383\n",
      "cls loss 1528.333984375  loc loss 44.070743560791016\n",
      "cls loss 1740.491943359375  loc loss 67.62548828125\n",
      "cls loss 2058.54931640625  loc loss 69.2598876953125\n",
      "cls loss 1686.7840576171875  loc loss 48.309288024902344\n",
      "cls loss 1633.865966796875  loc loss 68.7629165649414\n",
      "cls loss 1361.76953125  loc loss 40.20174026489258\n",
      "cls loss 1377.995361328125  loc loss 42.478721618652344\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20.])\n",
      "cls loss 1227.742919921875  loc loss 33.01195526123047\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([11.])\n",
      "cls loss 1436.22119140625  loc loss 34.81471633911133\n",
      "cls loss 1296.870361328125  loc loss 29.141708374023438\n",
      "cls loss 1729.783447265625  loc loss 78.65384674072266\n",
      "cls loss 1130.29638671875  loc loss 24.41532325744629\n",
      "cls loss 1537.099365234375  loc loss 56.566429138183594\n",
      "cls loss 1217.32666015625  loc loss 28.53013801574707\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 35., 27.])\n",
      "cls loss 1577.9912109375  loc loss 59.1613655090332\n",
      "cls loss 1831.8394775390625  loc loss 69.5081558227539\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 1405.4853515625  loc loss 48.35845184326172\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([42.,  1.])\n",
      "cls loss 1487.6678466796875  loc loss 71.2705307006836\n",
      "cls loss 1464.33984375  loc loss 46.67386245727539\n",
      "cls loss 1845.7626953125  loc loss 55.71445846557617\n",
      "cls loss 1944.412841796875  loc loss 69.96199035644531\n",
      "cls loss 1807.8074951171875  loc loss 67.11194610595703\n",
      "cls loss 1289.3896484375  loc loss 48.598575592041016\n",
      "cls loss 1372.1376953125  loc loss 46.61762237548828\n",
      "cls loss 1207.62744140625  loc loss 19.785791397094727\n",
      "cls loss 1540.740478515625  loc loss 41.85537338256836\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 1., 1.])\n",
      "cls loss 1338.392333984375  loc loss 43.72779083251953\n",
      "cls loss 1273.933837890625  loc loss 57.32080841064453\n",
      "cls loss 1470.6961669921875  loc loss 51.441619873046875\n",
      "cls loss 1346.8348388671875  loc loss 45.31564712524414\n",
      "cls loss 1431.910888671875  loc loss 50.33771896362305\n",
      "cls loss 1316.602783203125  loc loss 58.672607421875\n",
      "cls loss 2138.528564453125  loc loss 70.63387298583984\n",
      "cls loss 1753.322265625  loc loss 74.27631378173828\n",
      "cls loss 1710.384765625  loc loss 56.01951599121094\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 1326.8302001953125  loc loss 54.5678596496582\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 1693.857177734375  loc loss 37.046234130859375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([81.])\n",
      "cls loss 1900.303466796875  loc loss 69.44840240478516\n",
      "cls loss 1398.1026611328125  loc loss 45.160133361816406\n",
      "cls loss 1192.9656982421875  loc loss 29.970396041870117\n",
      "cls loss 1561.213134765625  loc loss 36.656185150146484\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3.,  1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 19.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 19.])\n",
      "cls loss 1876.05859375  loc loss 64.54759216308594\n",
      "cls loss 1323.40576171875  loc loss 27.76160430908203\n",
      "cls loss 1321.706787109375  loc loss 32.75154113769531\n",
      "cls loss 1989.6312255859375  loc loss 80.30174255371094\n",
      "cls loss 1320.548828125  loc loss 36.62953567504883\n",
      "cls loss 1333.21533203125  loc loss 52.53759002685547\n",
      "cls loss 1518.568359375  loc loss 62.8615837097168\n",
      "cls loss 1253.264892578125  loc loss 44.643402099609375\n",
      "cls loss 1578.22607421875  loc loss 51.37343978881836\n",
      "cls loss 1567.28125  loc loss 64.04247283935547\n",
      "cls loss 1768.5401611328125  loc loss 100.38521575927734\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 81.])\n",
      "cls loss 1501.927734375  loc loss 48.46761703491211\n",
      "cls loss 1415.7081298828125  loc loss 40.407562255859375\n",
      "cls loss 1551.0570068359375  loc loss 45.4525146484375\n",
      "cls loss 1390.2813720703125  loc loss 31.614215850830078\n",
      "cls loss 1312.290771484375  loc loss 34.98969268798828\n",
      "cls loss 1442.618896484375  loc loss 46.93558883666992\n",
      "cls loss 1143.957763671875  loc loss 41.244117736816406\n",
      "cls loss 1180.1806640625  loc loss 34.08564758300781\n",
      "cls loss 1220.45654296875  loc loss 40.557350158691406\n",
      "cls loss 1491.278076171875  loc loss 51.29692077636719\n",
      "cls loss 1277.9161376953125  loc loss 45.993282318115234\n",
      "cls loss 1385.9739990234375  loc loss 46.45185852050781\n",
      "cls loss 964.847412109375  loc loss 31.705995559692383\n",
      "cls loss 2284.810546875  loc loss 99.50308990478516\n",
      "cls loss 1711.2060546875  loc loss 68.2009506225586\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 1354.872802734375  loc loss 46.812538146972656\n",
      "cls loss 1459.2059326171875  loc loss 58.87513732910156\n",
      "cls loss 1277.5262451171875  loc loss 37.124359130859375\n",
      "cls loss 1599.57568359375  loc loss 58.205230712890625\n",
      "cls loss 1501.433349609375  loc loss 61.38130569458008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 1407.4932861328125  loc loss 53.53163146972656\n",
      "cls loss 1382.738037109375  loc loss 40.05186080932617\n",
      "cls loss 1043.257080078125  loc loss 31.62001609802246\n",
      "cls loss 1435.6650390625  loc loss 49.444000244140625\n",
      "cls loss 1508.671630859375  loc loss 59.54993438720703\n",
      "cls loss 1789.7010498046875  loc loss 44.24514389038086\n",
      "cls loss 1927.220458984375  loc loss 69.84855651855469\n",
      "cls loss 1864.212158203125  loc loss 77.26632690429688\n",
      "cls loss 1657.11083984375  loc loss 51.460845947265625\n",
      "cls loss 1456.199462890625  loc loss 76.40437316894531\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1., 38., 47.,  1.,  1.,  1.,  1.,  1., 62.])\n",
      "cls loss 1399.06005859375  loc loss 39.01949691772461\n",
      "cls loss 1754.6949462890625  loc loss 52.20128631591797\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 1517.06396484375  loc loss 57.49260330200195\n",
      "cls loss 1975.905029296875  loc loss 73.24713897705078\n",
      "cls loss 1376.23193359375  loc loss 40.77899169921875\n",
      "cls loss 1389.4659423828125  loc loss 62.705623626708984\n",
      "cls loss 1411.2562255859375  loc loss 48.13466262817383\n",
      "cls loss 1178.5634765625  loc loss 21.103092193603516\n",
      "cls loss 1347.283203125  loc loss 44.21906280517578\n",
      "cls loss 1091.47216796875  loc loss 31.389278411865234\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1., 35.])\n",
      "cls loss 1302.0921630859375  loc loss 40.33601379394531\n",
      "cls loss 1968.424072265625  loc loss 61.47718048095703\n",
      "cls loss 1597.093505859375  loc loss 62.474300384521484\n",
      "cls loss 1355.14697265625  loc loss 70.06694793701172\n",
      "cls loss 1249.19775390625  loc loss 55.98863983154297\n",
      "cls loss 1391.044677734375  loc loss 67.63182067871094\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 965.453125  loc loss 31.884288787841797\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 1514.73583984375  loc loss 44.91195297241211\n",
      "cls loss 2029.7171630859375  loc loss 78.85942077636719\n",
      "cls loss 2234.31201171875  loc loss 103.57964324951172\n",
      "cls loss 1469.4884033203125  loc loss 45.86227798461914\n",
      "cls loss 1284.778564453125  loc loss 39.21725845336914\n",
      "cls loss 1295.2159423828125  loc loss 42.85159683227539\n",
      "cls loss 1451.7978515625  loc loss 58.30482482910156\n",
      "cls loss 1313.3297119140625  loc loss 32.2180061340332\n",
      "cls loss 1795.689208984375  loc loss 78.28453063964844\n",
      "cls loss 1459.175048828125  loc loss 54.331661224365234\n",
      "cls loss 1274.796142578125  loc loss 30.586469650268555\n",
      "cls loss 1718.966552734375  loc loss 52.43985366821289\n",
      "cls loss 1769.9521484375  loc loss 80.8198013305664\n",
      "cls loss 1703.5345458984375  loc loss 59.26101303100586\n",
      "cls loss 1486.1748046875  loc loss 46.74483108520508\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.])\n",
      "cls loss 1476.708251953125  loc loss 54.87982940673828\n",
      "cls loss 1326.323486328125  loc loss 49.071571350097656\n",
      "cls loss 1971.973388671875  loc loss 59.280513763427734\n",
      "cls loss 2165.533203125  loc loss 110.52477264404297\n",
      "cls loss 1415.2381591796875  loc loss 33.20539474487305\n",
      "cls loss 1392.09619140625  loc loss 43.76464080810547\n",
      "cls loss 1323.6336669921875  loc loss 40.23889923095703\n",
      "cls loss 1211.005126953125  loc loss 43.979248046875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 21., 21., 21.])\n",
      "cls loss 1403.6259765625  loc loss 44.41837692260742\n",
      "cls loss 1299.156982421875  loc loss 39.622581481933594\n",
      "cls loss 1316.589111328125  loc loss 44.09846878051758\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 35.])\n",
      "cls loss 2059.7080078125  loc loss 71.42383575439453\n",
      "cls loss 967.252685546875  loc loss 24.791202545166016\n",
      "cls loss 1154.0537109375  loc loss 38.99540710449219\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 1111.9180908203125  loc loss 37.7900276184082\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 38., 38.,  9., 38.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1.,  1.])\n",
      "cls loss 1122.752685546875  loc loss 48.84344482421875\n",
      "cls loss 1717.456787109375  loc loss 77.43840789794922\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 2.,  1., 77., 31., 10., 10.,  1.,  4., 10.])\n",
      "cls loss 1249.715087890625  loc loss 34.318626403808594\n",
      "cls loss 1732.748291015625  loc loss 58.611087799072266\n",
      "cls loss 2900.96142578125  loc loss 140.7648468017578\n",
      "cls loss 1182.31005859375  loc loss 39.76459884643555\n",
      "cls loss 1460.760498046875  loc loss 73.72256469726562\n",
      "cls loss 1297.723876953125  loc loss 38.055057525634766\n",
      "cls loss 1280.94091796875  loc loss 38.47861099243164\n",
      "cls loss 1420.6898193359375  loc loss 44.237701416015625\n",
      "cls loss 1545.957763671875  loc loss 55.003719329833984\n",
      "cls loss 1415.0557861328125  loc loss 54.340576171875\n",
      "cls loss 1197.04248046875  loc loss 33.0386962890625\n",
      "cls loss 1430.802734375  loc loss 38.632972717285156\n",
      "cls loss 2222.84326171875  loc loss 83.86544799804688\n",
      "cls loss 1967.2652587890625  loc loss 78.78394317626953\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1., 42., 42., 42., 42., 42., 42.,  1.,\n",
      "         1.,  1.,  1., 42.,  1.,  1., 42.,  1.])\n",
      "cls loss 1257.670654296875  loc loss 50.246604919433594\n",
      "cls loss 1651.763671875  loc loss 62.74555587768555\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.])\n",
      "cls loss 866.7901611328125  loc loss 31.306743621826172\n",
      "cls loss 1473.58447265625  loc loss 67.34944915771484\n",
      "cls loss 1371.05126953125  loc loss 53.39186096191406\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([11.])\n",
      "cls loss 1007.0399169921875  loc loss 26.7426815032959\n",
      "cls loss 1204.79345703125  loc loss 25.95063018798828\n",
      "cls loss 1294.322998046875  loc loss 32.72235870361328\n",
      "cls loss 1381.039794921875  loc loss 52.38949203491211\n",
      "cls loss 1313.91748046875  loc loss 52.68243408203125\n",
      "cls loss 1308.522216796875  loc loss 58.27156066894531\n",
      "cls loss 1827.71240234375  loc loss 69.50450897216797\n",
      "cls loss 1184.28271484375  loc loss 43.127532958984375\n",
      "cls loss 1814.313232421875  loc loss 92.59478759765625\n",
      "cls loss 1167.318603515625  loc loss 38.904666900634766\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 1038.01513671875  loc loss 39.344642639160156\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1., 38., 38., 42.])\n",
      "cls loss 1135.8204345703125  loc loss 57.74137878417969\n",
      "cls loss 1162.55224609375  loc loss 40.326908111572266\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 1158.301513671875  loc loss 44.2442626953125\n",
      "cls loss 2064.5634765625  loc loss 90.50894927978516\n",
      "cls loss 1392.52685546875  loc loss 58.4599723815918\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10.,  3.,  3.,  6.,  8.,  8.,  1.,  1.,  1., 10.])\n",
      "cls loss 1258.308349609375  loc loss 46.58528137207031\n",
      "cls loss 963.1663818359375  loc loss 18.795528411865234\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10.,  3.])\n",
      "cls loss 1376.881103515625  loc loss 38.95772171020508\n",
      "cls loss 925.26123046875  loc loss 24.27663803100586\n",
      "cls loss 1433.6611328125  loc loss 63.205284118652344\n",
      "cls loss 1336.7747802734375  loc loss 59.654823303222656\n",
      "cls loss 1224.472900390625  loc loss 36.84882354736328\n",
      "cls loss 1154.8798828125  loc loss 25.76758575439453\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 34.])\n",
      "cls loss 1657.04833984375  loc loss 66.6658935546875\n",
      "cls loss 1896.494384765625  loc loss 87.98184204101562\n",
      "cls loss 1319.876953125  loc loss 63.75165939331055\n",
      "cls loss 1012.6739501953125  loc loss 44.51956558227539\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.,  1.])\n",
      "cls loss 1197.1031494140625  loc loss 35.39353942871094\n",
      "cls loss 1555.370361328125  loc loss 82.75369262695312\n",
      "cls loss 2108.28857421875  loc loss 105.87727355957031\n",
      "cls loss 1859.1103515625  loc loss 73.96470642089844\n",
      "cls loss 1263.530517578125  loc loss 48.14600372314453\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 1613.11474609375  loc loss 52.064857482910156\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10.])\n",
      "cls loss 1006.7511596679688  loc loss 34.437889099121094\n",
      "cls loss 1301.63134765625  loc loss 43.407405853271484\n",
      "cls loss 1382.9427490234375  loc loss 45.97235870361328\n",
      "cls loss 1114.6158447265625  loc loss 34.32046127319336\n",
      "cls loss 1222.1541748046875  loc loss 50.740596771240234\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21.,\n",
      "        21.])\n",
      "cls loss 1553.744873046875  loc loss 61.06499099731445\n",
      "cls loss 1371.713134765625  loc loss 54.829376220703125\n",
      "cls loss 1202.131103515625  loc loss 23.841886520385742\n",
      "cls loss 1525.948974609375  loc loss 63.53357696533203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 1316.340576171875  loc loss 60.330753326416016\n",
      "cls loss 1013.03662109375  loc loss 38.941280364990234\n",
      "cls loss 1748.4423828125  loc loss 88.2361831665039\n",
      "cls loss 2047.845947265625  loc loss 97.62325286865234\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15., 85.])\n",
      "cls loss 1590.318115234375  loc loss 62.56393814086914\n",
      "cls loss 1244.41064453125  loc loss 72.34661865234375\n",
      "cls loss 1527.8463134765625  loc loss 64.49982452392578\n",
      "cls loss 1537.64599609375  loc loss 58.330135345458984\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 8., 8.])\n",
      "cls loss 940.6525268554688  loc loss 34.983123779296875\n",
      "cls loss 1371.6998291015625  loc loss 40.843299865722656\n",
      "cls loss 1301.48193359375  loc loss 46.771366119384766\n",
      "cls loss 1161.16064453125  loc loss 37.59967041015625\n",
      "cls loss 1191.1396484375  loc loss 46.682762145996094\n",
      "cls loss 1561.240966796875  loc loss 53.496376037597656\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1., 35., 27., 27.,  1., 27.,  1.])\n",
      "cls loss 2244.95654296875  loc loss 87.427490234375\n",
      "cls loss 991.1607666015625  loc loss 49.08452606201172\n",
      "cls loss 1310.0499267578125  loc loss 52.89768600463867\n",
      "cls loss 1174.30126953125  loc loss 59.52200698852539\n",
      "cls loss 1213.585693359375  loc loss 52.753021240234375\n",
      "cls loss 1216.249267578125  loc loss 53.527587890625\n",
      "cls loss 1104.510009765625  loc loss 54.58718490600586\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  2.,  2.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  2.,  2.])\n",
      "cls loss 900.7425537109375  loc loss 21.640872955322266\n",
      "cls loss 1601.542236328125  loc loss 67.20222473144531\n",
      "cls loss 1283.7020263671875  loc loss 41.08243942260742\n",
      "cls loss 1588.1947021484375  loc loss 83.62362670898438\n",
      "cls loss 967.0238037109375  loc loss 35.10464096069336\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 19., 19., 19., 16.])\n",
      "cls loss 1076.782470703125  loc loss 31.48603630065918\n",
      "cls loss 917.466552734375  loc loss 19.85545539855957\n",
      "cls loss 1382.0615234375  loc loss 33.54848861694336\n",
      "cls loss 1531.9517822265625  loc loss 54.704017639160156\n",
      "cls loss 890.0698852539062  loc loss 36.139060974121094\n",
      "cls loss 1470.502197265625  loc loss 66.46920776367188\n",
      "cls loss 1067.1522216796875  loc loss 52.212852478027344\n",
      "cls loss 1230.54638671875  loc loss 50.713951110839844\n",
      "cls loss 1470.22998046875  loc loss 62.47431564331055\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 1652.8240966796875  loc loss 48.858070373535156\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 2107.02099609375  loc loss 99.7585220336914\n",
      "cls loss 2327.68310546875  loc loss 146.81130981445312\n",
      "cls loss 1186.96484375  loc loss 54.44499969482422\n",
      "cls loss 1112.31005859375  loc loss 49.01369094848633\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3.,  3.,  3.,  3.,  3., 10.])\n",
      "cls loss 839.4522094726562  loc loss 21.97225570678711\n",
      "cls loss 1311.7547607421875  loc loss 47.277286529541016\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 1., 1., 1., 3., 3., 3., 3.])\n",
      "cls loss 1155.794677734375  loc loss 45.318965911865234\n",
      "cls loss 1724.6915283203125  loc loss 97.50431823730469\n",
      "cls loss 1276.884521484375  loc loss 61.337284088134766\n",
      "cls loss 1098.029052734375  loc loss 42.67792510986328\n",
      "cls loss 1542.938232421875  loc loss 73.72820281982422\n",
      "cls loss 1139.585693359375  loc loss 43.703651428222656\n",
      "cls loss 1480.3990478515625  loc loss 71.46529388427734\n",
      "cls loss 976.2438354492188  loc loss 63.609474182128906\n",
      "cls loss 1363.4976806640625  loc loss 51.012779235839844\n",
      "cls loss 2082.69189453125  loc loss 122.06531524658203\n",
      "cls loss 1409.2281494140625  loc loss 67.82110595703125\n",
      "cls loss 1048.173828125  loc loss 34.47166442871094\n",
      "cls loss 840.5845336914062  loc loss 21.328136444091797\n",
      "cls loss 916.237060546875  loc loss 32.356685638427734\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3., 10., 10., 10., 10., 10., 10., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10., 10., 10., 10., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 11., 10., 10., 10., 10., 10.,  3.,  3.,  3.,  3.,  3.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 11., 10., 10., 10., 10., 10.,  3.,  3.,  3.,  3.,  3.])\n",
      "cls loss 1075.489501953125  loc loss 27.518508911132812\n",
      "cls loss 1105.780029296875  loc loss 31.80362319946289\n",
      "cls loss 896.3449096679688  loc loss 30.55185317993164\n",
      "cls loss 955.431884765625  loc loss 23.803953170776367\n",
      "cls loss 980.4503173828125  loc loss 45.87546157836914\n",
      "cls loss 1008.3167114257812  loc loss 22.813974380493164\n",
      "cls loss 1354.3226318359375  loc loss 66.63922882080078\n",
      "cls loss 1308.0462646484375  loc loss 62.34355163574219\n",
      "cls loss 1887.399169921875  loc loss 79.79248046875\n",
      "cls loss 991.253173828125  loc loss 43.22306442260742\n",
      "cls loss 1543.526611328125  loc loss 75.02764129638672\n",
      "cls loss 1441.9649658203125  loc loss 63.85875701904297\n",
      "cls loss 1390.16064453125  loc loss 59.44204330444336\n",
      "cls loss 1160.46533203125  loc loss 63.13969039916992\n",
      "cls loss 1638.7410888671875  loc loss 76.74202728271484\n",
      "cls loss 1618.4000244140625  loc loss 72.88650512695312\n",
      "cls loss 944.6919555664062  loc loss 30.555267333984375\n",
      "cls loss 1355.9168701171875  loc loss 67.27275848388672\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 10.,  1., 18.])\n",
      "cls loss 927.4512939453125  loc loss 38.383941650390625\n",
      "cls loss 1079.323974609375  loc loss 22.463775634765625\n",
      "cls loss 1487.08740234375  loc loss 51.110801696777344\n",
      "cls loss 1870.3275146484375  loc loss 89.54817199707031\n",
      "cls loss 1587.566162109375  loc loss 54.136314392089844\n",
      "cls loss 1594.85986328125  loc loss 70.98284912109375\n",
      "cls loss 1309.23583984375  loc loss 53.16005325317383\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.,  1.,  1.])\n",
      "cls loss 1617.571044921875  loc loss 75.50550842285156\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1., 38.,  1.])\n",
      "cls loss 1545.7684326171875  loc loss 60.457881927490234\n",
      "cls loss 1844.5439453125  loc loss 94.04029846191406\n",
      "cls loss 1219.45556640625  loc loss 55.97919464111328\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 1240.242919921875  loc loss 59.696163177490234\n",
      "cls loss 1483.948974609375  loc loss 49.00369644165039\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3., 10.,  8.,  3., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.])\n",
      "cls loss 1321.487548828125  loc loss 59.96949768066406\n",
      "cls loss 1078.78271484375  loc loss 41.05950927734375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3.,  3., 11.,  3., 10., 10.,  3.,  3., 10.])\n",
      "cls loss 1249.2593994140625  loc loss 47.08472442626953\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3., 10., 10., 10.])\n",
      "cls loss 1136.63671875  loc loss 56.931888580322266\n",
      "cls loss 1170.18212890625  loc loss 39.93244171142578\n",
      "cls loss 1063.6343994140625  loc loss 54.69853210449219\n",
      "cls loss 1630.435546875  loc loss 75.30681610107422\n",
      "cls loss 1171.7825927734375  loc loss 53.870059967041016\n",
      "cls loss 754.732177734375  loc loss 44.90788650512695\n",
      "cls loss 1056.3388671875  loc loss 46.747962951660156\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 9.,  9., 85., 85.])\n",
      "cls loss 889.904052734375  loc loss 36.54804992675781\n",
      "cls loss 1142.5224609375  loc loss 48.8947639465332\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 1658.70849609375  loc loss 86.49907684326172\n",
      "cls loss 1492.042724609375  loc loss 55.240447998046875\n",
      "cls loss 1780.791015625  loc loss 78.89006042480469\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10., 10., 10., 10.])\n",
      "cls loss 1080.86083984375  loc loss 47.464176177978516\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([13.])\n",
      "cls loss 1475.735107421875  loc loss 98.46896362304688\n",
      "cls loss 822.9278564453125  loc loss 21.482959747314453\n",
      "cls loss 822.9244384765625  loc loss 27.32444953918457\n",
      "cls loss 1093.5321044921875  loc loss 44.07368469238281\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19.,  1.,  1.,  1., 19., 19.])\n",
      "cls loss 1142.4202880859375  loc loss 43.8946418762207\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 766.421630859375  loc loss 44.234371185302734\n",
      "cls loss 1224.4801025390625  loc loss 64.1574935913086\n",
      "cls loss 886.416259765625  loc loss 38.40482711791992\n",
      "cls loss 1373.028076171875  loc loss 60.3841552734375\n",
      "cls loss 1439.3994140625  loc loss 72.42025756835938\n",
      "cls loss 1196.330078125  loc loss 46.008636474609375\n",
      "cls loss 1531.0667724609375  loc loss 77.39990997314453\n",
      "cls loss 963.0606689453125  loc loss 23.27474021911621\n",
      "cls loss 1194.4637451171875  loc loss 53.3152961730957\n",
      "cls loss 1161.8726806640625  loc loss 33.98905944824219\n",
      "cls loss 926.5806274414062  loc loss 36.20634460449219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 1203.0703125  loc loss 63.486778259277344\n",
      "cls loss 1522.6357421875  loc loss 47.43035125732422\n",
      "cls loss 1784.868408203125  loc loss 69.01612854003906\n",
      "cls loss 1178.3836669921875  loc loss 52.66206741333008\n",
      "cls loss 1326.1259765625  loc loss 60.27587890625\n",
      "cls loss 1667.921630859375  loc loss 84.78022766113281\n",
      "cls loss 1082.208740234375  loc loss 57.73779296875\n",
      "cls loss 1155.574462890625  loc loss 52.294986724853516\n",
      "cls loss 1590.535400390625  loc loss 77.29119110107422\n",
      "cls loss 1443.8153076171875  loc loss 75.73878479003906\n",
      "cls loss 1737.5172119140625  loc loss 83.96986389160156\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 5.])\n",
      "cls loss 884.2053833007812  loc loss 17.347482681274414\n",
      "cls loss 863.1881103515625  loc loss 28.727426528930664\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 13.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 6., 8., 8.])\n",
      "cls loss 816.7869873046875  loc loss 23.12999153137207\n",
      "cls loss 953.5985107421875  loc loss 32.58026885986328\n",
      "cls loss 1470.03466796875  loc loss 77.9661636352539\n",
      "cls loss 956.9634399414062  loc loss 25.653575897216797\n",
      "cls loss 1313.24169921875  loc loss 63.133995056152344\n",
      "cls loss 1896.96337890625  loc loss 80.982666015625\n",
      "cls loss 1281.811767578125  loc loss 56.50180435180664\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([42., 42.,  1.,  1.,  1.,  1.,  1.,  1.,  1., 42., 42.])\n",
      "cls loss 1450.83154296875  loc loss 48.62397003173828\n",
      "cls loss 1479.2830810546875  loc loss 83.62239074707031\n",
      "cls loss 1215.6473388671875  loc loss 66.07714080810547\n",
      "cls loss 1050.1982421875  loc loss 34.85643768310547\n",
      "cls loss 1335.98681640625  loc loss 50.84514236450195\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 2033.052490234375  loc loss 71.39688873291016\n",
      "cls loss 1357.8370361328125  loc loss 62.85503005981445\n",
      "cls loss 962.9423217773438  loc loss 34.8237419128418\n",
      "cls loss 880.322265625  loc loss 29.09454917907715\n",
      "cls loss 1095.103515625  loc loss 45.281463623046875\n",
      "cls loss 1354.5474853515625  loc loss 60.696876525878906\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15.])\n",
      "cls loss 927.449462890625  loc loss 26.165979385375977\n",
      "cls loss 1212.123046875  loc loss 49.41930389404297\n",
      "cls loss 1053.4990234375  loc loss 42.86198806762695\n",
      "cls loss 1429.764892578125  loc loss 80.85926818847656\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19.,  7.])\n",
      "cls loss 1069.85888671875  loc loss 42.82473373413086\n",
      "cls loss 1966.4212646484375  loc loss 82.40185546875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 1717.2940673828125  loc loss 66.8826675415039\n",
      "cls loss 1352.127197265625  loc loss 68.4918212890625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([38., 38.,  1., 18.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1., 18., 18.,  1.])\n",
      "cls loss 1039.8450927734375  loc loss 39.6363639831543\n",
      "cls loss 1328.7568359375  loc loss 33.625545501708984\n",
      "cls loss 1442.4912109375  loc loss 93.353271484375\n",
      "cls loss 1307.514892578125  loc loss 56.69324493408203\n",
      "cls loss 1411.109375  loc loss 46.591941833496094\n",
      "cls loss 895.9478149414062  loc loss 40.308876037597656\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.])\n",
      "cls loss 729.0491943359375  loc loss 22.4666805267334\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([32.])\n",
      "cls loss 1244.9334716796875  loc loss 40.9548225402832\n",
      "cls loss 1114.46337890625  loc loss 43.49935531616211\n",
      "cls loss 1206.1236572265625  loc loss 77.45927429199219\n",
      "cls loss 1360.148681640625  loc loss 51.77129364013672\n",
      "cls loss 1047.51708984375  loc loss 48.59233093261719\n",
      "cls loss 1514.8076171875  loc loss 63.14598083496094\n",
      "cls loss 1373.1376953125  loc loss 79.07461547851562\n",
      "cls loss 1263.104248046875  loc loss 66.18482971191406\n",
      "cls loss 1069.26171875  loc loss 46.708251953125\n",
      "cls loss 1581.0078125  loc loss 79.96733093261719\n",
      "cls loss 1201.0496826171875  loc loss 37.015899658203125\n",
      "cls loss 1619.843505859375  loc loss 91.5209732055664\n",
      "cls loss 1303.37255859375  loc loss 53.23046875\n",
      "cls loss 1036.9697265625  loc loss 53.59999465942383\n",
      "cls loss 1162.250732421875  loc loss 34.198055267333984\n",
      "cls loss 948.830810546875  loc loss 40.599571228027344\n",
      "cls loss 1244.423583984375  loc loss 62.37761688232422\n",
      "cls loss 1346.864501953125  loc loss 70.99195861816406\n",
      "cls loss 845.196533203125  loc loss 35.20249557495117\n",
      "cls loss 1459.6312255859375  loc loss 69.37306213378906\n",
      "cls loss 1624.4154052734375  loc loss 76.8673095703125\n",
      "cls loss 741.1861572265625  loc loss 29.326765060424805\n",
      "cls loss 1590.4754638671875  loc loss 79.38855743408203\n",
      "cls loss 1013.552490234375  loc loss 64.00282287597656\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 1433.710205078125  loc loss 83.4428939819336\n",
      "cls loss 961.9888916015625  loc loss 24.49803924560547\n",
      "cls loss 1077.379638671875  loc loss 48.43329620361328\n",
      "cls loss 1218.639404296875  loc loss 53.45484924316406\n",
      "cls loss 917.42822265625  loc loss 45.236328125\n",
      "cls loss 811.0869140625  loc loss 23.306026458740234\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 9., 9., 1., 9., 9., 9., 9., 1., 9.])\n",
      "cls loss 1907.0101318359375  loc loss 125.0151138305664\n",
      "cls loss 1231.40576171875  loc loss 50.22642517089844\n",
      "cls loss 1576.8135986328125  loc loss 98.03019714355469\n",
      "cls loss 837.0830078125  loc loss 38.367950439453125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 42., 42.])\n",
      "cls loss 1281.2745361328125  loc loss 70.92488861083984\n",
      "cls loss 1485.150634765625  loc loss 69.45983123779297\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  2.,  1.,  1.,  1., 38.,\n",
      "         1.,  1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 38., 38., 38.,  1., 38., 38., 38.,  1.,  1., 38.,  1.,\n",
      "         1.])\n",
      "cls loss 939.1593017578125  loc loss 40.0267448425293\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  8.,  8.])\n",
      "cls loss 1865.871826171875  loc loss 87.62715148925781\n",
      "cls loss 1583.8946533203125  loc loss 92.38273620605469\n",
      "cls loss 836.9151611328125  loc loss 32.52313995361328\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([4., 1., 1., 4.])\n",
      "cls loss 1132.45703125  loc loss 54.294437408447266\n",
      "cls loss 1345.09326171875  loc loss 58.763511657714844\n",
      "cls loss 817.0779418945312  loc loss 22.357097625732422\n",
      "cls loss 1151.90625  loc loss 34.20543670654297\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([51.,  1.])\n",
      "cls loss 884.5225830078125  loc loss 20.17281723022461\n",
      "cls loss 941.7271728515625  loc loss 36.10912322998047\n",
      "cls loss 1329.7176513671875  loc loss 61.79411697387695\n",
      "cls loss 1500.3369140625  loc loss 88.10558319091797\n",
      "cls loss 1982.7137451171875  loc loss 89.45416259765625\n",
      "cls loss 2382.240966796875  loc loss 117.35446166992188\n",
      "cls loss 1406.5670166015625  loc loss 48.6415901184082\n",
      "cls loss 1276.1776123046875  loc loss 77.52584838867188\n",
      "cls loss 1455.3770751953125  loc loss 84.23423767089844\n",
      "cls loss 1093.634765625  loc loss 46.90708923339844\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  3.,  1.,  1.,  1.,  3.,  1.,  1.,\n",
      "         1.,  1.,  1.])\n",
      "cls loss 1229.863037109375  loc loss 51.70931625366211\n",
      "cls loss 1338.6741943359375  loc loss 55.898189544677734\n",
      "cls loss 1289.1492919921875  loc loss 52.687320709228516\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "cls loss 1060.517578125  loc loss 46.39823913574219\n",
      "cls loss 755.3199462890625  loc loss 34.36064910888672\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3.])\n",
      "cls loss 876.1927490234375  loc loss 24.45297622680664\n",
      "cls loss 1154.9454345703125  loc loss 52.91032409667969\n",
      "cls loss 820.451904296875  loc loss 38.99250411987305\n",
      "cls loss 1340.116943359375  loc loss 80.0540542602539\n",
      "cls loss 1150.6334228515625  loc loss 34.55982971191406\n",
      "cls loss 919.692138671875  loc loss 42.365657806396484\n",
      "cls loss 2255.389404296875  loc loss 123.60838317871094\n",
      "cls loss 1346.256591796875  loc loss 53.831398010253906\n",
      "cls loss 833.60888671875  loc loss 44.857948303222656\n",
      "cls loss 945.9541015625  loc loss 40.22550582885742\n",
      "cls loss 839.1251220703125  loc loss 46.068450927734375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 1382.9566650390625  loc loss 77.09762573242188\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  9., 64., 64., 64., 64., 64., 64., 64., 64., 64.,  9.,  9.,  9.,\n",
      "         9.])\n",
      "cls loss 1134.7081298828125  loc loss 39.042083740234375\n",
      "cls loss 1554.9351806640625  loc loss 115.33987426757812\n",
      "cls loss 1043.6763916015625  loc loss 49.41582489013672\n",
      "cls loss 1365.28857421875  loc loss 74.8488998413086\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.,  3.,  3.])\n",
      "cls loss 1009.1576538085938  loc loss 45.90771484375\n",
      "cls loss 1059.694580078125  loc loss 45.44071960449219\n",
      "cls loss 944.0747680664062  loc loss 58.99879837036133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 1229.748779296875  loc loss 50.250526428222656\n",
      "cls loss 1140.12548828125  loc loss 60.58683395385742\n",
      "cls loss 1009.051025390625  loc loss 56.29519271850586\n",
      "cls loss 1172.84814453125  loc loss 55.17823028564453\n",
      "cls loss 983.4962158203125  loc loss 49.89909362792969\n",
      "cls loss 1394.4669189453125  loc loss 70.43942260742188\n",
      "cls loss 1107.9560546875  loc loss 56.030433654785156\n",
      "cls loss 1012.5638427734375  loc loss 35.64237594604492\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21.])\n",
      "cls loss 976.39111328125  loc loss 24.649877548217773\n",
      "cls loss 1017.5201416015625  loc loss 60.652984619140625\n",
      "cls loss 1187.4365234375  loc loss 65.27082824707031\n",
      "cls loss 835.0714111328125  loc loss 36.317806243896484\n",
      "cls loss 1258.8006591796875  loc loss 52.784420013427734\n",
      "cls loss 2005.73828125  loc loss 91.72499084472656\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 42., 42.,  1.,  1.])\n",
      "cls loss 1049.1273193359375  loc loss 42.820377349853516\n",
      "cls loss 750.3115844726562  loc loss 35.13636016845703\n",
      "cls loss 1025.090087890625  loc loss 51.550559997558594\n",
      "cls loss 1178.298828125  loc loss 79.8440170288086\n",
      "cls loss 1089.098388671875  loc loss 40.84189987182617\n",
      "cls loss 1299.1771240234375  loc loss 67.55436706542969\n",
      "cls loss 1245.822021484375  loc loss 67.99410247802734\n",
      "cls loss 1447.62841796875  loc loss 58.382362365722656\n",
      "cls loss 995.5711059570312  loc loss 48.330604553222656\n",
      "cls loss 860.4202880859375  loc loss 39.9332275390625\n",
      "cls loss 1003.7203979492188  loc loss 25.23978042602539\n",
      "cls loss 997.8140869140625  loc loss 54.55569076538086\n",
      "cls loss 1208.681640625  loc loss 76.41532897949219\n",
      "cls loss 1283.5162353515625  loc loss 46.750667572021484\n",
      "cls loss 1134.597412109375  loc loss 61.457637786865234\n",
      "cls loss 1372.535400390625  loc loss 49.794822692871094\n",
      "cls loss 1662.86865234375  loc loss 84.54317474365234\n",
      "cls loss 1279.62890625  loc loss 61.795841217041016\n",
      "cls loss 1673.0126953125  loc loss 63.03038787841797\n",
      "cls loss 1071.278564453125  loc loss 30.825220108032227\n",
      "cls loss 1297.4786376953125  loc loss 53.10704040527344\n",
      "cls loss 1299.8876953125  loc loss 50.96722412109375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 5., 5., 5., 5., 5., 5.])\n",
      "cls loss 873.9440307617188  loc loss 40.09764862060547\n",
      "cls loss 941.2200927734375  loc loss 48.35523986816406\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([13.])\n",
      "cls loss 879.7867431640625  loc loss 26.93448257446289\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([44., 10.,  1.,  1.,  1.])\n",
      "cls loss 881.3203735351562  loc loss 29.990644454956055\n",
      "cls loss 1203.196533203125  loc loss 52.2908821105957\n",
      "cls loss 1064.81982421875  loc loss 43.75090026855469\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19., 19., 19., 19., 19., 19., 19.])\n",
      "cls loss 1223.376953125  loc loss 58.51081466674805\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([56.])\n",
      "cls loss 2309.468505859375  loc loss 104.26335906982422\n",
      "cls loss 1281.01708984375  loc loss 68.92112731933594\n",
      "cls loss 1778.97021484375  loc loss 86.8728256225586\n",
      "cls loss 1461.531982421875  loc loss 89.10518646240234\n",
      "cls loss 927.90966796875  loc loss 47.23831558227539\n",
      "cls loss 1550.745849609375  loc loss 85.4661636352539\n",
      "cls loss 1150.498779296875  loc loss 42.21611404418945\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 36.])\n",
      "cls loss 1140.7222900390625  loc loss 48.142242431640625\n",
      "cls loss 903.3560791015625  loc loss 52.82016372680664\n",
      "cls loss 1128.9815673828125  loc loss 43.28398513793945\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5.])\n",
      "cls loss 1100.635986328125  loc loss 51.70149612426758\n",
      "cls loss 794.364013671875  loc loss 29.35967445373535\n",
      "cls loss 1388.1363525390625  loc loss 69.24325561523438\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "cls loss 1271.5234375  loc loss 69.8768539428711\n",
      "cls loss 1272.9278564453125  loc loss 59.32985305786133\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 1257.657470703125  loc loss 63.288177490234375\n",
      "cls loss 1473.349609375  loc loss 71.19316101074219\n",
      "cls loss 1154.494140625  loc loss 72.98155212402344\n",
      "cls loss 1109.05615234375  loc loss 45.83000564575195\n",
      "cls loss 1118.2574462890625  loc loss 52.532859802246094\n",
      "cls loss 1051.41357421875  loc loss 48.92497634887695\n",
      "cls loss 1481.21240234375  loc loss 71.4621353149414\n",
      "cls loss 832.9137573242188  loc loss 28.751813888549805\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 11., 15., 10., 10., 10., 10., 10.])\n",
      "cls loss 1591.818359375  loc loss 89.54507446289062\n",
      "cls loss 1009.96728515625  loc loss 47.06658172607422\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3.])\n",
      "cls loss 1067.7388916015625  loc loss 47.79405975341797\n",
      "cls loss 911.36376953125  loc loss 38.830711364746094\n",
      "cls loss 1002.7200317382812  loc loss 41.14982604980469\n",
      "cls loss 1288.443115234375  loc loss 51.13731384277344\n",
      "cls loss 925.6307373046875  loc loss 25.116472244262695\n",
      "cls loss 1317.1220703125  loc loss 41.796630859375\n",
      "cls loss 1233.2200927734375  loc loss 61.350852966308594\n",
      "cls loss 932.2239990234375  loc loss 54.8738899230957\n",
      "cls loss 1842.02001953125  loc loss 125.45611572265625\n",
      "cls loss 1417.611572265625  loc loss 85.57843017578125\n",
      "cls loss 1075.80126953125  loc loss 55.58951187133789\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  9.,  9.,  9.,  6.,  6., 85., 85.,  8.,  1.,  1.,  1.,  1.,\n",
      "         6.,  6.])\n",
      "cls loss 727.4404907226562  loc loss 36.01436233520508\n",
      "cls loss 1617.692138671875  loc loss 85.87686920166016\n",
      "cls loss 1773.3150634765625  loc loss 95.11482238769531\n",
      "cls loss 1156.2025146484375  loc loss 67.18064880371094\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10.,  3.,  3., 10.])\n",
      "cls loss 816.3787841796875  loc loss 37.660926818847656\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([7.])\n",
      "cls loss 1022.3282470703125  loc loss 70.70196533203125\n",
      "cls loss 1040.19677734375  loc loss 51.41128158569336\n",
      "cls loss 1090.013671875  loc loss 58.43898391723633\n",
      "cls loss 1298.08154296875  loc loss 85.5302963256836\n",
      "cls loss 1148.9619140625  loc loss 54.12224197387695\n",
      "cls loss 1421.44775390625  loc loss 74.66777801513672\n",
      "cls loss 1764.88916015625  loc loss 86.74929809570312\n",
      "cls loss 1185.648681640625  loc loss 55.86917495727539\n",
      "cls loss 1169.892822265625  loc loss 64.69815826416016\n",
      "cls loss 1008.821533203125  loc loss 52.850154876708984\n",
      "cls loss 1260.1005859375  loc loss 83.6138916015625\n",
      "cls loss 1343.519287109375  loc loss 55.651397705078125\n",
      "cls loss 1002.1311645507812  loc loss 38.98250198364258\n",
      "cls loss 1250.135986328125  loc loss 83.77417755126953\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([62.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([62.])\n",
      "cls loss 646.6188354492188  loc loss 25.776533126831055\n",
      "cls loss 1009.7353515625  loc loss 59.80913543701172\n",
      "cls loss 1070.901123046875  loc loss 51.132225036621094\n",
      "cls loss 969.552001953125  loc loss 27.900527954101562\n",
      "cls loss 1250.919189453125  loc loss 71.26703643798828\n",
      "cls loss 1339.7236328125  loc loss 62.8698616027832\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([28.])\n",
      "cls loss 1349.800048828125  loc loss 63.56416702270508\n",
      "cls loss 1235.271484375  loc loss 67.28901672363281\n",
      "cls loss 1281.567626953125  loc loss 64.27096557617188\n",
      "cls loss 1295.7633056640625  loc loss 69.24852752685547\n",
      "cls loss 1612.5767822265625  loc loss 95.48736572265625\n",
      "cls loss 1091.469970703125  loc loss 46.54484558105469\n",
      "cls loss 1186.28759765625  loc loss 57.761600494384766\n",
      "cls loss 1317.637451171875  loc loss 72.03376007080078\n",
      "cls loss 1661.884033203125  loc loss 98.00778198242188\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([81.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 1357.655029296875  loc loss 53.957759857177734\n",
      "cls loss 1025.143310546875  loc loss 37.26107406616211\n",
      "cls loss 889.1585693359375  loc loss 40.574676513671875\n",
      "cls loss 831.5164794921875  loc loss 26.735179901123047\n",
      "cls loss 876.54931640625  loc loss 40.8017692565918\n",
      "cls loss 874.055908203125  loc loss 42.980682373046875\n",
      "cls loss 1074.555908203125  loc loss 46.11885070800781\n",
      "cls loss 1314.006103515625  loc loss 73.76029205322266\n",
      "cls loss 1369.65185546875  loc loss 67.2242660522461\n",
      "cls loss 2427.99365234375  loc loss 135.840087890625\n",
      "cls loss 1075.9517822265625  loc loss 41.08021545410156\n",
      "cls loss 1088.2703857421875  loc loss 66.50125885009766\n",
      "cls loss 872.2977294921875  loc loss 50.2679443359375\n",
      "cls loss 1175.583740234375  loc loss 49.86869812011719\n",
      "cls loss 1020.138916015625  loc loss 46.41703796386719\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([44., 44.])\n",
      "cls loss 899.197509765625  loc loss 36.35299301147461\n",
      "cls loss 938.302734375  loc loss 48.53445816040039\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 1099.466796875  loc loss 47.173439025878906\n",
      "cls loss 661.9341430664062  loc loss 24.82577133178711\n",
      "cls loss 1085.3037109375  loc loss 53.52182388305664\n",
      "cls loss 761.7889404296875  loc loss 31.127716064453125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([1., 3., 3.])\n",
      "cls loss 721.440673828125  loc loss 42.32109832763672\n",
      "cls loss 802.742431640625  loc loss 25.04288101196289\n",
      "cls loss 1159.0638427734375  loc loss 46.213409423828125\n",
      "cls loss 1153.068603515625  loc loss 54.768070220947266\n",
      "cls loss 1170.19384765625  loc loss 48.75431442260742\n",
      "cls loss 1057.2093505859375  loc loss 58.79637145996094\n",
      "cls loss 901.9920654296875  loc loss 51.99557113647461\n",
      "cls loss 1122.552734375  loc loss 58.03015899658203\n",
      "cls loss 1088.831298828125  loc loss 49.133277893066406\n",
      "cls loss 1096.0201416015625  loc loss 65.14909362792969\n",
      "cls loss 654.0531005859375  loc loss 36.2346305847168\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 1370.260498046875  loc loss 59.338714599609375\n",
      "cls loss 1320.697021484375  loc loss 68.03823852539062\n",
      "cls loss 1273.267333984375  loc loss 76.30439758300781\n",
      "cls loss 1135.866943359375  loc loss 66.05062866210938\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10., 10., 10.,  1.,  1.,  1.,  1.,  1.,  1.,  8.,  8.,\n",
      "         1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10., 10., 10.,  1.,  1.,  1.,  1.,  1.,  1.,  8.,  8.,\n",
      "         1.])\n",
      "cls loss 1355.88818359375  loc loss 59.51142120361328\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 3., 3., 3.])\n",
      "cls loss 1127.30859375  loc loss 48.06953811645508\n",
      "cls loss 837.755615234375  loc loss 31.499422073364258\n",
      "cls loss 680.227783203125  loc loss 25.824371337890625\n",
      "cls loss 929.7335205078125  loc loss 52.45641326904297\n",
      "cls loss 866.0454711914062  loc loss 31.985143661499023\n",
      "cls loss 881.5645141601562  loc loss 43.775203704833984\n",
      "cls loss 1069.572998046875  loc loss 46.83831787109375\n",
      "cls loss 1370.404052734375  loc loss 78.84562683105469\n",
      "cls loss 1279.490234375  loc loss 57.88908386230469\n",
      "cls loss 1033.056396484375  loc loss 56.431175231933594\n",
      "cls loss 1250.2098388671875  loc loss 64.38150024414062\n",
      "cls loss 1097.276123046875  loc loss 55.5062255859375\n",
      "cls loss 1401.6268310546875  loc loss 96.48001098632812\n",
      "cls loss 839.760498046875  loc loss 38.67000961303711\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 1264.196044921875  loc loss 60.50611877441406\n",
      "cls loss 647.4835815429688  loc loss 27.99896812438965\n",
      "cls loss 1374.562255859375  loc loss 83.91874694824219\n",
      "cls loss 871.5564575195312  loc loss 38.52707290649414\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 34.])\n",
      "cls loss 1248.45703125  loc loss 54.0561408996582\n",
      "cls loss 719.093017578125  loc loss 32.43071746826172\n",
      "cls loss 1323.34375  loc loss 57.503055572509766\n",
      "cls loss 599.6597900390625  loc loss 23.95535659790039\n",
      "cls loss 1367.8885498046875  loc loss 56.78202819824219\n",
      "cls loss 1169.48193359375  loc loss 60.978919982910156\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 38.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16., 16., 16.,  9.,  9.,  9., 16., 16., 16., 85.,  9.])\n",
      "cls loss 1046.9132080078125  loc loss 48.040611267089844\n",
      "cls loss 996.1211547851562  loc loss 67.1331558227539\n",
      "cls loss 1661.151123046875  loc loss 87.90673828125\n",
      "cls loss 1881.061767578125  loc loss 120.95074462890625\n",
      "cls loss 747.6605834960938  loc loss 25.60465431213379\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3., 10.,  8.,  8., 10., 10., 10.,  3.,  3., 14.])\n",
      "cls loss 1019.8477783203125  loc loss 32.54920196533203\n",
      "cls loss 1252.030517578125  loc loss 59.78466033935547\n",
      "cls loss 658.4674072265625  loc loss 17.574296951293945\n",
      "cls loss 896.5233154296875  loc loss 34.764617919921875\n",
      "cls loss 1175.259521484375  loc loss 61.27998733520508\n",
      "cls loss 929.7457885742188  loc loss 56.53266906738281\n",
      "cls loss 881.1744384765625  loc loss 31.72716522216797\n",
      "cls loss 749.7398071289062  loc loss 35.165626525878906\n",
      "cls loss 1005.3663330078125  loc loss 52.406253814697266\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42., 42.,  1.])\n",
      "cls loss 927.4122924804688  loc loss 55.45357894897461\n",
      "cls loss 1060.08203125  loc loss 42.472251892089844\n",
      "cls loss 1184.5626220703125  loc loss 65.35968780517578\n",
      "cls loss 1383.50537109375  loc loss 66.82492065429688\n",
      "cls loss 1087.022216796875  loc loss 45.77827453613281\n",
      "cls loss 1073.2325439453125  loc loss 65.90730285644531\n",
      "cls loss 813.6148071289062  loc loss 38.175575256347656\n",
      "cls loss 911.7987670898438  loc loss 40.670021057128906\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20.])\n",
      "cls loss 644.71630859375  loc loss 31.007183074951172\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([11.])\n",
      "cls loss 851.863525390625  loc loss 32.994468688964844\n",
      "cls loss 718.7001342773438  loc loss 27.085119247436523\n",
      "cls loss 1146.3516845703125  loc loss 77.28018188476562\n",
      "cls loss 655.5347900390625  loc loss 23.575464248657227\n",
      "cls loss 1019.238037109375  loc loss 53.84588623046875\n",
      "cls loss 819.4898681640625  loc loss 27.420989990234375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 35., 27.])\n",
      "cls loss 1013.335693359375  loc loss 56.06581115722656\n",
      "cls loss 1127.392333984375  loc loss 66.79869079589844\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 898.2471923828125  loc loss 47.143531799316406\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([42.,  1.])\n",
      "cls loss 935.6709594726562  loc loss 68.72473907470703\n",
      "cls loss 958.8067626953125  loc loss 44.20281982421875\n",
      "cls loss 1204.079833984375  loc loss 52.89699172973633\n",
      "cls loss 1351.9412841796875  loc loss 67.49049377441406\n",
      "cls loss 1157.95361328125  loc loss 65.44883728027344\n",
      "cls loss 803.444580078125  loc loss 46.62510299682617\n",
      "cls loss 818.0013427734375  loc loss 43.819026947021484\n",
      "cls loss 785.3466796875  loc loss 19.125173568725586\n",
      "cls loss 933.6094970703125  loc loss 41.26142883300781\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 1., 1.])\n",
      "cls loss 784.5894775390625  loc loss 41.93925857543945\n",
      "cls loss 836.304443359375  loc loss 55.68326950073242\n",
      "cls loss 950.122802734375  loc loss 49.14690399169922\n",
      "cls loss 929.6751708984375  loc loss 43.52934265136719\n",
      "cls loss 892.276123046875  loc loss 48.64640808105469\n",
      "cls loss 935.2586669921875  loc loss 56.803199768066406\n",
      "cls loss 1439.886962890625  loc loss 67.01726531982422\n",
      "cls loss 1143.1668701171875  loc loss 71.07247924804688\n",
      "cls loss 1118.09912109375  loc loss 52.80976486206055\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 898.3814697265625  loc loss 51.252525329589844\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 1261.6043701171875  loc loss 35.670833587646484\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([81.])\n",
      "cls loss 1225.3544921875  loc loss 67.01673889160156\n",
      "cls loss 840.216796875  loc loss 43.537513732910156\n",
      "cls loss 754.3275146484375  loc loss 29.227434158325195\n",
      "cls loss 1026.4658203125  loc loss 35.21570587158203\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3.,  1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 19.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 19.])\n",
      "cls loss 1109.7060546875  loc loss 62.87504577636719\n",
      "cls loss 804.3068237304688  loc loss 25.8548526763916\n",
      "cls loss 801.21875  loc loss 31.720258712768555\n",
      "cls loss 1260.1507568359375  loc loss 76.83808135986328\n",
      "cls loss 778.2454833984375  loc loss 34.678321838378906\n",
      "cls loss 909.8828125  loc loss 50.36297607421875\n",
      "cls loss 927.2138061523438  loc loss 59.62699508666992\n",
      "cls loss 799.8540649414062  loc loss 43.08580780029297\n",
      "cls loss 1008.6995239257812  loc loss 49.42003631591797\n",
      "cls loss 1053.49365234375  loc loss 63.11896896362305\n",
      "cls loss 1257.044921875  loc loss 95.64710998535156\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 81.])\n",
      "cls loss 942.9721069335938  loc loss 46.614097595214844\n",
      "cls loss 957.14892578125  loc loss 38.73627853393555\n",
      "cls loss 974.0531005859375  loc loss 44.21287536621094\n",
      "cls loss 893.32958984375  loc loss 30.288124084472656\n",
      "cls loss 771.9707641601562  loc loss 33.804840087890625\n",
      "cls loss 888.79296875  loc loss 44.165626525878906\n",
      "cls loss 687.5235595703125  loc loss 39.2536506652832\n",
      "cls loss 674.8143920898438  loc loss 31.856863021850586\n",
      "cls loss 772.4462890625  loc loss 40.35757827758789\n",
      "cls loss 944.3201904296875  loc loss 49.11812210083008\n",
      "cls loss 848.396728515625  loc loss 44.798709869384766\n",
      "cls loss 935.9532470703125  loc loss 45.379859924316406\n",
      "cls loss 564.6647338867188  loc loss 30.145309448242188\n",
      "cls loss 1634.863525390625  loc loss 95.76156616210938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 1091.9786376953125  loc loss 64.98579406738281\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 858.1666870117188  loc loss 45.49015808105469\n",
      "cls loss 990.009033203125  loc loss 56.0897102355957\n",
      "cls loss 903.8876953125  loc loss 35.52649688720703\n",
      "cls loss 1040.734619140625  loc loss 56.05631637573242\n",
      "cls loss 1003.3045043945312  loc loss 59.096378326416016\n",
      "cls loss 929.0980224609375  loc loss 51.08946990966797\n",
      "cls loss 972.9754638671875  loc loss 37.748130798339844\n",
      "cls loss 674.34716796875  loc loss 30.226667404174805\n",
      "cls loss 880.85986328125  loc loss 47.28546142578125\n",
      "cls loss 986.8419189453125  loc loss 57.706790924072266\n",
      "cls loss 1206.261962890625  loc loss 42.59917068481445\n",
      "cls loss 1404.413330078125  loc loss 68.50941467285156\n",
      "cls loss 1403.58935546875  loc loss 74.89811706542969\n",
      "cls loss 1085.903564453125  loc loss 48.12944030761719\n",
      "cls loss 1044.818359375  loc loss 74.16629028320312\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1., 38., 47.,  1.,  1.,  1.,  1.,  1., 62.])\n",
      "cls loss 884.2568359375  loc loss 37.94669723510742\n",
      "cls loss 1142.9501953125  loc loss 49.539024353027344\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 1079.491455078125  loc loss 55.12299346923828\n",
      "cls loss 1508.627197265625  loc loss 70.93891906738281\n",
      "cls loss 837.6852416992188  loc loss 37.503517150878906\n",
      "cls loss 890.7333984375  loc loss 59.91755676269531\n",
      "cls loss 885.57568359375  loc loss 46.8713264465332\n",
      "cls loss 696.7232666015625  loc loss 20.56608009338379\n",
      "cls loss 844.4655151367188  loc loss 42.89908981323242\n",
      "cls loss 750.5137329101562  loc loss 30.17236328125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1., 35.])\n",
      "cls loss 852.431884765625  loc loss 37.900936126708984\n",
      "cls loss 1391.34423828125  loc loss 59.092857360839844\n",
      "cls loss 1171.510009765625  loc loss 60.0123176574707\n",
      "cls loss 930.9212646484375  loc loss 67.58216857910156\n",
      "cls loss 839.74658203125  loc loss 53.558738708496094\n",
      "cls loss 956.9381713867188  loc loss 64.87361145019531\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 618.5106201171875  loc loss 30.35247802734375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 1011.189697265625  loc loss 41.79032897949219\n",
      "cls loss 1394.267822265625  loc loss 74.43836212158203\n",
      "cls loss 1525.849609375  loc loss 100.21119689941406\n",
      "cls loss 961.1212158203125  loc loss 42.583133697509766\n",
      "cls loss 793.279052734375  loc loss 37.997432708740234\n",
      "cls loss 807.677978515625  loc loss 41.717994689941406\n",
      "cls loss 848.8173828125  loc loss 56.25531768798828\n",
      "cls loss 844.8108520507812  loc loss 30.607759475708008\n",
      "cls loss 1226.2393798828125  loc loss 76.56974029541016\n",
      "cls loss 1045.876220703125  loc loss 52.14149856567383\n",
      "cls loss 762.1084594726562  loc loss 29.543184280395508\n",
      "cls loss 1216.37060546875  loc loss 50.55829620361328\n",
      "cls loss 1263.876953125  loc loss 78.1421890258789\n",
      "cls loss 1159.765380859375  loc loss 56.65831756591797\n",
      "cls loss 995.0180053710938  loc loss 44.07426071166992\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.])\n",
      "cls loss 1060.62060546875  loc loss 52.721336364746094\n",
      "cls loss 935.0906982421875  loc loss 47.475616455078125\n",
      "cls loss 1398.025634765625  loc loss 57.510162353515625\n",
      "cls loss 1437.1962890625  loc loss 107.09152221679688\n",
      "cls loss 998.7103271484375  loc loss 31.98472785949707\n",
      "cls loss 931.5233764648438  loc loss 43.12162780761719\n",
      "cls loss 867.3873291015625  loc loss 39.1376953125\n",
      "cls loss 804.8720703125  loc loss 41.97002029418945\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 21., 21., 21.])\n",
      "cls loss 950.9547119140625  loc loss 42.50534439086914\n",
      "cls loss 925.3568115234375  loc loss 37.098819732666016\n",
      "cls loss 922.0745849609375  loc loss 43.1756477355957\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 35.])\n",
      "cls loss 1341.668701171875  loc loss 69.34883117675781\n",
      "cls loss 574.8756713867188  loc loss 22.887453079223633\n",
      "cls loss 727.0472412109375  loc loss 37.97177505493164\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 736.6730346679688  loc loss 36.729923248291016\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 38., 38.,  9., 38.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1.,  1.])\n",
      "cls loss 733.2543334960938  loc loss 45.65396499633789\n",
      "cls loss 1189.619873046875  loc loss 74.47261810302734\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 2.,  1., 77., 31., 10., 10.,  1.,  4., 10.])\n",
      "cls loss 833.447265625  loc loss 33.696739196777344\n",
      "cls loss 1189.3680419921875  loc loss 57.07734680175781\n",
      "cls loss 1987.2064208984375  loc loss 136.2520294189453\n",
      "cls loss 726.4430541992188  loc loss 38.480072021484375\n",
      "cls loss 943.77685546875  loc loss 71.849853515625\n",
      "cls loss 856.7867431640625  loc loss 36.797874450683594\n",
      "cls loss 840.22021484375  loc loss 35.62558364868164\n",
      "cls loss 966.6802978515625  loc loss 42.933414459228516\n",
      "cls loss 1079.380126953125  loc loss 52.99018859863281\n",
      "cls loss 987.0816040039062  loc loss 52.38190460205078\n",
      "cls loss 823.7860107421875  loc loss 31.585922241210938\n",
      "cls loss 1031.236083984375  loc loss 36.58806610107422\n",
      "cls loss 1731.686767578125  loc loss 80.09075927734375\n",
      "cls loss 1368.10693359375  loc loss 76.32207489013672\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1., 42., 42., 42., 42., 42., 42.,  1.,\n",
      "         1.,  1.,  1., 42.,  1.,  1., 42.,  1.])\n",
      "cls loss 887.9808349609375  loc loss 47.42462158203125\n",
      "cls loss 1074.3450927734375  loc loss 60.22893142700195\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.])\n",
      "cls loss 579.6511840820312  loc loss 30.25746726989746\n",
      "cls loss 1023.5570068359375  loc loss 64.40553283691406\n",
      "cls loss 858.8262939453125  loc loss 50.339599609375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([11.])\n",
      "cls loss 642.0010986328125  loc loss 25.32518196105957\n",
      "cls loss 841.9744873046875  loc loss 26.128978729248047\n",
      "cls loss 846.071533203125  loc loss 31.992055892944336\n",
      "cls loss 919.7099609375  loc loss 51.33207321166992\n",
      "cls loss 875.3295288085938  loc loss 50.474422454833984\n",
      "cls loss 870.0631103515625  loc loss 56.69112777709961\n",
      "cls loss 1262.17333984375  loc loss 66.68704986572266\n",
      "cls loss 795.3182373046875  loc loss 40.54410171508789\n",
      "cls loss 1281.7384033203125  loc loss 88.25926971435547\n",
      "cls loss 875.48388671875  loc loss 37.027591705322266\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 680.8945922851562  loc loss 37.79563903808594\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1., 38., 38., 42.])\n",
      "cls loss 805.2083740234375  loc loss 55.52922439575195\n",
      "cls loss 796.4158935546875  loc loss 37.59457778930664\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 795.5919189453125  loc loss 41.626869201660156\n",
      "cls loss 1465.0870361328125  loc loss 87.6814956665039\n",
      "cls loss 951.4732666015625  loc loss 56.58441925048828\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10.,  3.,  3.,  6.,  8.,  8.,  1.,  1.,  1., 10.])\n",
      "cls loss 895.654052734375  loc loss 44.61648941040039\n",
      "cls loss 582.158203125  loc loss 17.69938087463379\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10.,  3.])\n",
      "cls loss 1016.26123046875  loc loss 37.06223678588867\n",
      "cls loss 527.4520263671875  loc loss 23.442935943603516\n",
      "cls loss 953.5474243164062  loc loss 61.130367279052734\n",
      "cls loss 941.1326904296875  loc loss 57.45119857788086\n",
      "cls loss 765.4259033203125  loc loss 35.83231735229492\n",
      "cls loss 825.0081176757812  loc loss 24.3529052734375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 34.])\n",
      "cls loss 1244.737548828125  loc loss 63.53092956542969\n",
      "cls loss 1395.0235595703125  loc loss 86.50531768798828\n",
      "cls loss 921.619873046875  loc loss 61.511260986328125\n",
      "cls loss 670.3017578125  loc loss 42.399261474609375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.,  1.])\n",
      "cls loss 869.2925415039062  loc loss 33.75664520263672\n",
      "cls loss 1115.8760986328125  loc loss 79.47235107421875\n",
      "cls loss 1576.810546875  loc loss 101.3966064453125\n",
      "cls loss 1349.9302978515625  loc loss 71.01567077636719\n",
      "cls loss 815.6963500976562  loc loss 46.51599884033203\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 1149.342529296875  loc loss 49.57590866088867\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10.])\n",
      "cls loss 674.306884765625  loc loss 33.048194885253906\n",
      "cls loss 892.0250244140625  loc loss 41.3726806640625\n",
      "cls loss 1068.210205078125  loc loss 43.02199935913086\n",
      "cls loss 726.00537109375  loc loss 32.75853729248047\n",
      "cls loss 832.9758911132812  loc loss 49.25056457519531\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21.,\n",
      "        21.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 1060.509033203125  loc loss 57.799415588378906\n",
      "cls loss 941.62548828125  loc loss 52.874664306640625\n",
      "cls loss 795.2351684570312  loc loss 22.79136085510254\n",
      "cls loss 1162.7158203125  loc loss 61.920555114746094\n",
      "cls loss 887.5679321289062  loc loss 58.03366470336914\n",
      "cls loss 671.1451416015625  loc loss 37.392730712890625\n",
      "cls loss 1259.2781982421875  loc loss 87.28884887695312\n",
      "cls loss 1463.4010009765625  loc loss 94.12464141845703\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15., 85.])\n",
      "cls loss 1149.093017578125  loc loss 60.423004150390625\n",
      "cls loss 909.3734130859375  loc loss 69.93440246582031\n",
      "cls loss 1175.955322265625  loc loss 62.84093475341797\n",
      "cls loss 1073.357177734375  loc loss 57.158931732177734\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 8., 8.])\n",
      "cls loss 638.3814697265625  loc loss 31.959074020385742\n",
      "cls loss 951.3026123046875  loc loss 39.686767578125\n",
      "cls loss 939.7115478515625  loc loss 44.99732971191406\n",
      "cls loss 828.9278564453125  loc loss 36.45732498168945\n",
      "cls loss 901.8833618164062  loc loss 44.61685562133789\n",
      "cls loss 1169.183349609375  loc loss 51.8011474609375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1., 35., 27., 27.,  1., 27.,  1.])\n",
      "cls loss 1567.231201171875  loc loss 85.6463623046875\n",
      "cls loss 678.8245849609375  loc loss 47.270164489746094\n",
      "cls loss 900.5240478515625  loc loss 51.55147171020508\n",
      "cls loss 808.302978515625  loc loss 56.99853515625\n",
      "cls loss 886.8663330078125  loc loss 50.84008026123047\n",
      "cls loss 875.447509765625  loc loss 53.01755905151367\n",
      "cls loss 777.92724609375  loc loss 52.366233825683594\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  2.,  2.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  2.,  2.])\n",
      "cls loss 566.846923828125  loc loss 20.31276512145996\n",
      "cls loss 1264.7259521484375  loc loss 64.70558166503906\n",
      "cls loss 884.2418212890625  loc loss 39.38419723510742\n",
      "cls loss 1151.923583984375  loc loss 81.07540893554688\n",
      "cls loss 622.6683349609375  loc loss 33.57888412475586\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 19., 19., 19., 16.])\n",
      "cls loss 655.6654052734375  loc loss 30.466251373291016\n",
      "cls loss 625.5145263671875  loc loss 19.698406219482422\n",
      "cls loss 887.4505615234375  loc loss 32.48967361450195\n",
      "cls loss 1029.21826171875  loc loss 51.838844299316406\n",
      "cls loss 542.879150390625  loc loss 34.44589614868164\n",
      "cls loss 1121.7291259765625  loc loss 63.959163665771484\n",
      "cls loss 723.4383544921875  loc loss 49.9970588684082\n",
      "cls loss 889.3272705078125  loc loss 48.36930847167969\n",
      "cls loss 1045.89599609375  loc loss 60.3515510559082\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 1193.283447265625  loc loss 47.61319351196289\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 1530.021484375  loc loss 97.21540832519531\n",
      "cls loss 1727.33740234375  loc loss 143.44114685058594\n",
      "cls loss 828.8048095703125  loc loss 53.527992248535156\n",
      "cls loss 729.7980346679688  loc loss 48.21277618408203\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3.,  3.,  3.,  3.,  3., 10.])\n",
      "cls loss 535.52685546875  loc loss 20.081729888916016\n",
      "cls loss 882.7631225585938  loc loss 45.84961700439453\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 1., 1., 1., 3., 3., 3., 3.])\n",
      "cls loss 845.952880859375  loc loss 44.26579284667969\n",
      "cls loss 1273.572265625  loc loss 92.52449798583984\n",
      "cls loss 930.64892578125  loc loss 59.87586975097656\n",
      "cls loss 805.4267578125  loc loss 40.323402404785156\n",
      "cls loss 1122.5059814453125  loc loss 71.6768569946289\n",
      "cls loss 816.3316650390625  loc loss 43.58135223388672\n",
      "cls loss 1105.2203369140625  loc loss 68.77308654785156\n",
      "cls loss 760.4491577148438  loc loss 61.007965087890625\n",
      "cls loss 1077.5528564453125  loc loss 49.20123291015625\n",
      "cls loss 1528.51708984375  loc loss 118.24909973144531\n",
      "cls loss 1099.601806640625  loc loss 65.39221954345703\n",
      "cls loss 763.850341796875  loc loss 33.02809524536133\n",
      "cls loss 586.4196166992188  loc loss 20.63579559326172\n",
      "cls loss 622.2452392578125  loc loss 30.5715274810791\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3., 10., 10., 10., 10., 10., 10., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10., 10., 10., 10., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 11., 10., 10., 10., 10., 10.,  3.,  3.,  3.,  3.,  3.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 11., 10., 10., 10., 10., 10.,  3.,  3.,  3.,  3.,  3.])\n",
      "cls loss 736.8572998046875  loc loss 26.586130142211914\n",
      "cls loss 760.447509765625  loc loss 30.40979766845703\n",
      "cls loss 614.0010986328125  loc loss 29.58775520324707\n",
      "cls loss 673.1207885742188  loc loss 22.617509841918945\n",
      "cls loss 671.7184448242188  loc loss 43.65864562988281\n",
      "cls loss 756.1884765625  loc loss 21.98936653137207\n",
      "cls loss 986.3734741210938  loc loss 65.36566925048828\n",
      "cls loss 908.2197875976562  loc loss 60.385276794433594\n",
      "cls loss 1363.1380615234375  loc loss 77.76057434082031\n",
      "cls loss 685.7078247070312  loc loss 41.68381118774414\n",
      "cls loss 1190.008544921875  loc loss 72.06393432617188\n",
      "cls loss 1005.3619384765625  loc loss 61.8261833190918\n",
      "cls loss 969.900390625  loc loss 56.02421569824219\n",
      "cls loss 872.1482543945312  loc loss 60.83716583251953\n",
      "cls loss 1172.03271484375  loc loss 74.70367431640625\n",
      "cls loss 1124.9112548828125  loc loss 69.48929595947266\n",
      "cls loss 658.114013671875  loc loss 29.197837829589844\n",
      "cls loss 1015.461181640625  loc loss 66.95647430419922\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 10.,  1., 18.])\n",
      "cls loss 646.4190673828125  loc loss 36.573272705078125\n",
      "cls loss 714.735107421875  loc loss 21.77313804626465\n",
      "cls loss 1098.736572265625  loc loss 48.9144172668457\n",
      "cls loss 1387.619873046875  loc loss 86.23748016357422\n",
      "cls loss 1286.529052734375  loc loss 52.81382751464844\n",
      "cls loss 1250.74169921875  loc loss 68.68315887451172\n",
      "cls loss 1051.0885009765625  loc loss 51.60741424560547\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.,  1.,  1.])\n",
      "cls loss 1265.1806640625  loc loss 72.16531372070312\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1., 38.,  1.])\n",
      "cls loss 1139.2822265625  loc loss 58.303062438964844\n",
      "cls loss 1451.507568359375  loc loss 91.84622192382812\n",
      "cls loss 846.0855712890625  loc loss 53.063453674316406\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 933.6182861328125  loc loss 57.62998962402344\n",
      "cls loss 1054.013427734375  loc loss 48.791290283203125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3., 10.,  8.,  3., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.])\n",
      "cls loss 949.88330078125  loc loss 56.39260482788086\n",
      "cls loss 755.2650146484375  loc loss 39.64994812011719\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3.,  3., 11.,  3., 10., 10.,  3.,  3., 10.])\n",
      "cls loss 864.827880859375  loc loss 44.75236511230469\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3., 10., 10., 10.])\n",
      "cls loss 816.477783203125  loc loss 55.6663818359375\n",
      "cls loss 788.4736328125  loc loss 38.024654388427734\n",
      "cls loss 769.5914306640625  loc loss 53.546958923339844\n",
      "cls loss 1239.6358642578125  loc loss 73.33226013183594\n",
      "cls loss 843.1241455078125  loc loss 52.05779266357422\n",
      "cls loss 555.23046875  loc loss 43.1952018737793\n",
      "cls loss 753.0684814453125  loc loss 45.092674255371094\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 9.,  9., 85., 85.])\n",
      "cls loss 664.423583984375  loc loss 35.53792190551758\n",
      "cls loss 824.9437255859375  loc loss 47.48638916015625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 1214.7552490234375  loc loss 83.02901458740234\n",
      "cls loss 1118.4151611328125  loc loss 53.7357177734375\n",
      "cls loss 1349.625732421875  loc loss 77.0772476196289\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10., 10., 10., 10.])\n",
      "cls loss 777.4015502929688  loc loss 44.50432586669922\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([13.])\n",
      "cls loss 1112.632080078125  loc loss 95.37848663330078\n",
      "cls loss 547.6445922851562  loc loss 21.141090393066406\n",
      "cls loss 581.7884521484375  loc loss 26.85601234436035\n",
      "cls loss 846.1423950195312  loc loss 42.165096282958984\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19.,  1.,  1.,  1., 19., 19.])\n",
      "cls loss 939.9620361328125  loc loss 43.18596649169922\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 573.7936401367188  loc loss 44.38422393798828\n",
      "cls loss 907.740478515625  loc loss 61.89576721191406\n",
      "cls loss 658.3534545898438  loc loss 36.87936782836914\n",
      "cls loss 1002.6827392578125  loc loss 57.78903579711914\n",
      "cls loss 1127.844482421875  loc loss 70.2302017211914\n",
      "cls loss 901.228515625  loc loss 43.73604202270508\n",
      "cls loss 1144.5029296875  loc loss 76.0185546875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 678.8379516601562  loc loss 22.017229080200195\n",
      "cls loss 867.8887939453125  loc loss 51.3721809387207\n",
      "cls loss 834.6557006835938  loc loss 32.22211456298828\n",
      "cls loss 683.4349365234375  loc loss 34.91702651977539\n",
      "cls loss 942.69384765625  loc loss 62.001319885253906\n",
      "cls loss 1056.05908203125  loc loss 45.66594314575195\n",
      "cls loss 1453.0263671875  loc loss 67.1636734008789\n",
      "cls loss 848.272705078125  loc loss 50.483642578125\n",
      "cls loss 960.548828125  loc loss 57.87587356567383\n",
      "cls loss 1298.51953125  loc loss 82.71207427978516\n",
      "cls loss 795.1876831054688  loc loss 55.76595687866211\n",
      "cls loss 912.9970703125  loc loss 49.64521026611328\n",
      "cls loss 1254.6973876953125  loc loss 74.12374114990234\n",
      "cls loss 1113.7412109375  loc loss 73.51441192626953\n",
      "cls loss 1385.079833984375  loc loss 80.42900085449219\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 5.])\n",
      "cls loss 635.92236328125  loc loss 16.062917709350586\n",
      "cls loss 599.5258178710938  loc loss 26.866722106933594\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 13.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 6., 8., 8.])\n",
      "cls loss 559.6431274414062  loc loss 21.921184539794922\n",
      "cls loss 669.2789306640625  loc loss 31.54091453552246\n",
      "cls loss 1091.884521484375  loc loss 79.06462860107422\n",
      "cls loss 736.108642578125  loc loss 24.016803741455078\n",
      "cls loss 979.4757080078125  loc loss 60.50548553466797\n",
      "cls loss 1527.5277099609375  loc loss 78.26524353027344\n",
      "cls loss 961.72509765625  loc loss 53.369503021240234\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([42., 42.,  1.,  1.,  1.,  1.,  1.,  1.,  1., 42., 42.])\n",
      "cls loss 1110.356201171875  loc loss 47.838016510009766\n",
      "cls loss 1208.036865234375  loc loss 81.2707290649414\n",
      "cls loss 951.9368896484375  loc loss 63.723533630371094\n",
      "cls loss 796.9835815429688  loc loss 33.97645950317383\n",
      "cls loss 996.6478271484375  loc loss 49.629207611083984\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 1479.906494140625  loc loss 69.7236328125\n",
      "cls loss 1005.4578247070312  loc loss 61.685585021972656\n",
      "cls loss 728.280517578125  loc loss 34.27082443237305\n",
      "cls loss 706.75390625  loc loss 28.501953125\n",
      "cls loss 800.2174682617188  loc loss 43.422855377197266\n",
      "cls loss 1038.2742919921875  loc loss 58.63971710205078\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15.])\n",
      "cls loss 674.36474609375  loc loss 25.194164276123047\n",
      "cls loss 867.6421508789062  loc loss 47.188140869140625\n",
      "cls loss 748.67822265625  loc loss 41.261871337890625\n",
      "cls loss 1112.184326171875  loc loss 78.41443634033203\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19.,  7.])\n",
      "cls loss 811.0338134765625  loc loss 41.41424560546875\n",
      "cls loss 1530.3607177734375  loc loss 80.25006866455078\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 1287.847412109375  loc loss 64.93006134033203\n",
      "cls loss 1010.7451171875  loc loss 66.42578125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([38., 38.,  1., 18.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1., 18., 18.,  1.])\n",
      "cls loss 754.0662231445312  loc loss 37.789852142333984\n",
      "cls loss 914.42041015625  loc loss 32.9306640625\n",
      "cls loss 1101.97119140625  loc loss 89.671630859375\n",
      "cls loss 953.0626831054688  loc loss 54.82795333862305\n",
      "cls loss 1028.6031494140625  loc loss 44.931114196777344\n",
      "cls loss 640.9544677734375  loc loss 38.68508529663086\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.])\n",
      "cls loss 465.50909423828125  loc loss 20.918590545654297\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([32.])\n",
      "cls loss 907.0934448242188  loc loss 38.90447235107422\n",
      "cls loss 830.6070556640625  loc loss 41.64275360107422\n",
      "cls loss 921.7427978515625  loc loss 73.82574462890625\n",
      "cls loss 982.2156982421875  loc loss 50.08531188964844\n",
      "cls loss 745.0958251953125  loc loss 47.017311096191406\n",
      "cls loss 1196.5477294921875  loc loss 60.60563659667969\n",
      "cls loss 1133.76806640625  loc loss 76.53146362304688\n",
      "cls loss 969.9776611328125  loc loss 63.79095458984375\n",
      "cls loss 942.2745361328125  loc loss 45.34490203857422\n",
      "cls loss 1331.16015625  loc loss 76.6346664428711\n",
      "cls loss 905.9638671875  loc loss 35.960636138916016\n",
      "cls loss 1254.483154296875  loc loss 89.20368194580078\n",
      "cls loss 965.5250854492188  loc loss 52.23442077636719\n",
      "cls loss 758.088623046875  loc loss 51.805084228515625\n",
      "cls loss 795.08984375  loc loss 32.2283935546875\n",
      "cls loss 694.96533203125  loc loss 39.552101135253906\n",
      "cls loss 1003.3796997070312  loc loss 60.9310188293457\n",
      "cls loss 1016.9288940429688  loc loss 67.90621185302734\n",
      "cls loss 615.5773315429688  loc loss 34.64119338989258\n",
      "cls loss 1143.361328125  loc loss 66.69560241699219\n",
      "cls loss 1353.7843017578125  loc loss 73.75802612304688\n",
      "cls loss 574.4981689453125  loc loss 28.255151748657227\n",
      "cls loss 1258.22314453125  loc loss 77.59019470214844\n",
      "cls loss 815.8287963867188  loc loss 61.696250915527344\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 1126.7742919921875  loc loss 81.15730285644531\n",
      "cls loss 670.78857421875  loc loss 23.64443016052246\n",
      "cls loss 887.4765625  loc loss 47.497344970703125\n",
      "cls loss 955.5974731445312  loc loss 52.44473648071289\n",
      "cls loss 663.82568359375  loc loss 43.05685806274414\n",
      "cls loss 540.3671264648438  loc loss 21.865774154663086\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 9., 9., 1., 9., 9., 9., 9., 1., 9.])\n",
      "cls loss 1544.617431640625  loc loss 120.57096862792969\n",
      "cls loss 941.65625  loc loss 48.50331115722656\n",
      "cls loss 1296.8408203125  loc loss 95.3428726196289\n",
      "cls loss 644.552001953125  loc loss 36.27846145629883\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 42., 42.])\n",
      "cls loss 1018.3040771484375  loc loss 67.34778594970703\n",
      "cls loss 1102.69677734375  loc loss 67.42379760742188\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  2.,  1.,  1.,  1., 38.,\n",
      "         1.,  1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 38., 38., 38.,  1., 38., 38., 38.,  1.,  1., 38.,  1.,\n",
      "         1.])\n",
      "cls loss 810.2847900390625  loc loss 38.334938049316406\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  8.,  8.])\n",
      "cls loss 1510.727294921875  loc loss 84.78265380859375\n",
      "cls loss 1378.5806884765625  loc loss 88.06462860107422\n",
      "cls loss 642.9586791992188  loc loss 31.745758056640625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([4., 1., 1., 4.])\n",
      "cls loss 939.514892578125  loc loss 52.95413589477539\n",
      "cls loss 1062.122314453125  loc loss 56.28038024902344\n",
      "cls loss 604.66357421875  loc loss 21.324787139892578\n",
      "cls loss 845.0857543945312  loc loss 33.12925338745117\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([51.,  1.])\n",
      "cls loss 644.812744140625  loc loss 19.151660919189453\n",
      "cls loss 698.7862548828125  loc loss 34.89379119873047\n",
      "cls loss 1023.3372802734375  loc loss 59.007347106933594\n",
      "cls loss 1181.408203125  loc loss 84.2144775390625\n",
      "cls loss 1542.601318359375  loc loss 86.89276885986328\n",
      "cls loss 1893.968505859375  loc loss 115.17680358886719\n",
      "cls loss 1044.89892578125  loc loss 47.854827880859375\n",
      "cls loss 1024.1007080078125  loc loss 73.848388671875\n",
      "cls loss 1200.454833984375  loc loss 80.5954818725586\n",
      "cls loss 845.6506958007812  loc loss 45.477474212646484\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  3.,  1.,  1.,  1.,  3.,  1.,  1.,\n",
      "         1.,  1.,  1.])\n",
      "cls loss 937.435546875  loc loss 50.224830627441406\n",
      "cls loss 1070.456787109375  loc loss 53.66575622558594\n",
      "cls loss 940.8922729492188  loc loss 50.076045989990234\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "cls loss 790.259765625  loc loss 44.87716293334961\n",
      "cls loss 513.3399047851562  loc loss 33.698402404785156\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3.])\n",
      "cls loss 689.3267822265625  loc loss 22.97464370727539\n",
      "cls loss 885.9276123046875  loc loss 51.682533264160156\n",
      "cls loss 621.7425537109375  loc loss 37.849327087402344\n",
      "cls loss 1047.62646484375  loc loss 77.5756607055664\n",
      "cls loss 900.897216796875  loc loss 32.85189437866211\n",
      "cls loss 681.7098388671875  loc loss 40.0260124206543\n",
      "cls loss 1838.101806640625  loc loss 117.88121795654297\n",
      "cls loss 989.5172119140625  loc loss 52.3366584777832\n",
      "cls loss 616.673828125  loc loss 43.86457824707031\n",
      "cls loss 802.3916015625  loc loss 39.049835205078125\n",
      "cls loss 683.9733276367188  loc loss 44.36876678466797\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 1165.716796875  loc loss 74.98589324951172\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  9., 64., 64., 64., 64., 64., 64., 64., 64., 64.,  9.,  9.,  9.,\n",
      "         9.])\n",
      "cls loss 891.6165771484375  loc loss 36.94375228881836\n",
      "cls loss 1322.47509765625  loc loss 112.4092788696289\n",
      "cls loss 826.1414184570312  loc loss 48.22188186645508\n",
      "cls loss 1056.94921875  loc loss 72.68586730957031\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.,  3.,  3.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 760.8862915039062  loc loss 42.58271789550781\n",
      "cls loss 837.462890625  loc loss 43.809844970703125\n",
      "cls loss 743.4722900390625  loc loss 57.35616683959961\n",
      "cls loss 1066.0963134765625  loc loss 49.023155212402344\n",
      "cls loss 932.7998046875  loc loss 59.69430923461914\n",
      "cls loss 779.1051025390625  loc loss 54.678810119628906\n",
      "cls loss 888.8900146484375  loc loss 53.595481872558594\n",
      "cls loss 792.7824096679688  loc loss 48.73936462402344\n",
      "cls loss 1117.201416015625  loc loss 68.22228240966797\n",
      "cls loss 842.9784545898438  loc loss 53.833648681640625\n",
      "cls loss 772.7327880859375  loc loss 33.91044998168945\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21.])\n",
      "cls loss 722.783203125  loc loss 23.51268768310547\n",
      "cls loss 760.770751953125  loc loss 58.339111328125\n",
      "cls loss 949.6943359375  loc loss 63.659812927246094\n",
      "cls loss 609.3131103515625  loc loss 35.12607955932617\n",
      "cls loss 952.8753662109375  loc loss 50.98606872558594\n",
      "cls loss 1621.46630859375  loc loss 89.00625610351562\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 42., 42.,  1.,  1.])\n",
      "cls loss 817.8375244140625  loc loss 41.62022399902344\n",
      "cls loss 586.3182983398438  loc loss 33.716880798339844\n",
      "cls loss 797.55712890625  loc loss 49.07559585571289\n",
      "cls loss 952.5992431640625  loc loss 78.50794982910156\n",
      "cls loss 873.8688354492188  loc loss 39.557777404785156\n",
      "cls loss 1069.93603515625  loc loss 64.88291931152344\n",
      "cls loss 1013.464599609375  loc loss 65.56861877441406\n",
      "cls loss 1080.5208740234375  loc loss 56.195899963378906\n",
      "cls loss 756.7186889648438  loc loss 46.562355041503906\n",
      "cls loss 654.5372314453125  loc loss 39.372711181640625\n",
      "cls loss 728.7545166015625  loc loss 24.44921112060547\n",
      "cls loss 778.94482421875  loc loss 52.257102966308594\n",
      "cls loss 980.4597778320312  loc loss 75.43962860107422\n",
      "cls loss 1040.262939453125  loc loss 45.644012451171875\n",
      "cls loss 921.7333984375  loc loss 60.37792205810547\n",
      "cls loss 1049.38525390625  loc loss 47.68107223510742\n",
      "cls loss 1392.53173828125  loc loss 81.85726165771484\n",
      "cls loss 983.5963134765625  loc loss 60.986000061035156\n",
      "cls loss 1372.319091796875  loc loss 61.36172866821289\n",
      "cls loss 871.22900390625  loc loss 29.624544143676758\n",
      "cls loss 1034.9075927734375  loc loss 51.938236236572266\n",
      "cls loss 1006.882568359375  loc loss 49.820377349853516\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 5., 5., 5., 5., 5., 5.])\n",
      "cls loss 641.21533203125  loc loss 38.64826965332031\n",
      "cls loss 731.329345703125  loc loss 46.560543060302734\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([13.])\n",
      "cls loss 629.788818359375  loc loss 26.1406307220459\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([44., 10.,  1.,  1.,  1.])\n",
      "cls loss 680.4821166992188  loc loss 28.952163696289062\n",
      "cls loss 956.8846435546875  loc loss 50.05036544799805\n",
      "cls loss 824.839111328125  loc loss 41.848289489746094\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19., 19., 19., 19., 19., 19., 19.])\n",
      "cls loss 981.2024536132812  loc loss 56.74592590332031\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([56.])\n",
      "cls loss 1900.9527587890625  loc loss 99.8248291015625\n",
      "cls loss 1018.9334716796875  loc loss 67.78627014160156\n",
      "cls loss 1430.2398681640625  loc loss 84.16928100585938\n",
      "cls loss 1220.9652099609375  loc loss 87.08576965332031\n",
      "cls loss 737.2235717773438  loc loss 45.95135498046875\n",
      "cls loss 1312.866943359375  loc loss 82.3104019165039\n",
      "cls loss 893.2618408203125  loc loss 40.49211120605469\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 36.])\n",
      "cls loss 881.1836547851562  loc loss 47.5607795715332\n",
      "cls loss 715.6268920898438  loc loss 51.494361877441406\n",
      "cls loss 875.9697265625  loc loss 41.78047561645508\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5.])\n",
      "cls loss 877.642333984375  loc loss 49.99085998535156\n",
      "cls loss 596.1818237304688  loc loss 28.5654239654541\n",
      "cls loss 1157.063232421875  loc loss 66.07157897949219\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "cls loss 1020.2609252929688  loc loss 68.74834442138672\n",
      "cls loss 1147.795654296875  loc loss 57.893470764160156\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 1020.8530883789062  loc loss 60.838375091552734\n",
      "cls loss 1248.2120361328125  loc loss 69.81137084960938\n",
      "cls loss 975.6544799804688  loc loss 71.6383285522461\n",
      "cls loss 874.681640625  loc loss 44.34849166870117\n",
      "cls loss 922.982666015625  loc loss 51.321388244628906\n",
      "cls loss 861.40478515625  loc loss 48.1234016418457\n",
      "cls loss 1188.37451171875  loc loss 68.74624633789062\n",
      "cls loss 651.3878173828125  loc loss 28.512117385864258\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 11., 15., 10., 10., 10., 10., 10.])\n",
      "cls loss 1329.358154296875  loc loss 87.22660064697266\n",
      "cls loss 758.58984375  loc loss 45.17744064331055\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3.])\n",
      "cls loss 853.247314453125  loc loss 47.12202072143555\n",
      "cls loss 703.8388671875  loc loss 38.72697067260742\n",
      "cls loss 821.6590576171875  loc loss 39.791046142578125\n",
      "cls loss 1010.0711669921875  loc loss 50.09104537963867\n",
      "cls loss 760.0069580078125  loc loss 24.250761032104492\n",
      "cls loss 1074.2890625  loc loss 40.690155029296875\n",
      "cls loss 985.2192993164062  loc loss 59.00016784667969\n",
      "cls loss 766.235595703125  loc loss 52.877418518066406\n",
      "cls loss 1560.286865234375  loc loss 122.63895416259766\n",
      "cls loss 1182.94580078125  loc loss 83.10061645507812\n",
      "cls loss 896.1300659179688  loc loss 54.27546691894531\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  9.,  9.,  9.,  6.,  6., 85., 85.,  8.,  1.,  1.,  1.,  1.,\n",
      "         6.,  6.])\n",
      "cls loss 575.6104736328125  loc loss 35.0306396484375\n",
      "cls loss 1385.116943359375  loc loss 83.1194076538086\n",
      "cls loss 1482.856689453125  loc loss 92.21381378173828\n",
      "cls loss 961.5114135742188  loc loss 65.74401092529297\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10.,  3.,  3., 10.])\n",
      "cls loss 635.73095703125  loc loss 36.539764404296875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([7.])\n",
      "cls loss 876.3658447265625  loc loss 67.86408233642578\n",
      "cls loss 847.7634887695312  loc loss 49.892730712890625\n",
      "cls loss 914.3673095703125  loc loss 56.318321228027344\n",
      "cls loss 1199.4837646484375  loc loss 83.30740356445312\n",
      "cls loss 934.3441162109375  loc loss 52.61879348754883\n",
      "cls loss 1185.5166015625  loc loss 71.94425964355469\n",
      "cls loss 1414.264892578125  loc loss 84.32914733886719\n",
      "cls loss 980.4226684570312  loc loss 54.34964370727539\n",
      "cls loss 948.8985595703125  loc loss 63.09739685058594\n",
      "cls loss 833.9475708007812  loc loss 50.92084503173828\n",
      "cls loss 1039.76416015625  loc loss 80.98959350585938\n",
      "cls loss 1092.148193359375  loc loss 54.483768463134766\n",
      "cls loss 795.8239135742188  loc loss 37.92620086669922\n",
      "cls loss 1050.6988525390625  loc loss 79.99424743652344\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([62.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([62.])\n",
      "cls loss 516.1307983398438  loc loss 25.207487106323242\n",
      "cls loss 808.7389526367188  loc loss 58.379730224609375\n",
      "cls loss 905.3955078125  loc loss 49.747703552246094\n",
      "cls loss 793.133544921875  loc loss 27.095529556274414\n",
      "cls loss 1049.904296875  loc loss 70.22695922851562\n",
      "cls loss 1121.2275390625  loc loss 60.761085510253906\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([28.])\n",
      "cls loss 1099.33251953125  loc loss 60.86306381225586\n",
      "cls loss 1056.76171875  loc loss 64.39043426513672\n",
      "cls loss 1060.44677734375  loc loss 61.54106140136719\n",
      "cls loss 1048.8975830078125  loc loss 67.12126922607422\n",
      "cls loss 1350.8232421875  loc loss 92.48296356201172\n",
      "cls loss 876.3477172851562  loc loss 45.94987487792969\n",
      "cls loss 963.822265625  loc loss 55.70610809326172\n",
      "cls loss 1043.93896484375  loc loss 70.19927978515625\n",
      "cls loss 1410.27099609375  loc loss 94.57366180419922\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([81.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 1102.2418212890625  loc loss 51.43400955200195\n",
      "cls loss 889.094970703125  loc loss 36.40923309326172\n",
      "cls loss 710.379150390625  loc loss 39.309051513671875\n",
      "cls loss 663.808837890625  loc loss 25.758275985717773\n",
      "cls loss 689.1162109375  loc loss 39.5708122253418\n",
      "cls loss 679.891845703125  loc loss 41.32835388183594\n",
      "cls loss 842.7789916992188  loc loss 45.12957000732422\n",
      "cls loss 1096.07666015625  loc loss 71.59272003173828\n",
      "cls loss 1187.482177734375  loc loss 65.11820983886719\n",
      "cls loss 2041.31640625  loc loss 132.17721557617188\n",
      "cls loss 867.7765502929688  loc loss 39.576210021972656\n",
      "cls loss 912.927978515625  loc loss 63.685691833496094\n",
      "cls loss 690.23095703125  loc loss 48.88761520385742\n",
      "cls loss 952.0087280273438  loc loss 48.24437713623047\n",
      "cls loss 855.076416015625  loc loss 45.047203063964844\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([44., 44.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 725.80859375  loc loss 35.16393280029297\n",
      "cls loss 778.94970703125  loc loss 47.25419616699219\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15.])\n",
      "cls loss 891.8310546875  loc loss 45.961082458496094\n",
      "cls loss 475.10528564453125  loc loss 23.52013397216797\n",
      "cls loss 890.87158203125  loc loss 52.3006706237793\n",
      "cls loss 597.1377563476562  loc loss 29.786895751953125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([1., 3., 3.])\n",
      "cls loss 577.038818359375  loc loss 41.83327865600586\n",
      "cls loss 616.1386108398438  loc loss 23.298667907714844\n",
      "cls loss 952.6207275390625  loc loss 45.22518539428711\n",
      "cls loss 918.2579345703125  loc loss 52.12345886230469\n",
      "cls loss 962.3311767578125  loc loss 47.192771911621094\n",
      "cls loss 893.3931884765625  loc loss 56.02123260498047\n",
      "cls loss 736.77392578125  loc loss 49.94882583618164\n",
      "cls loss 901.093017578125  loc loss 56.277381896972656\n",
      "cls loss 884.099853515625  loc loss 47.65618133544922\n",
      "cls loss 897.590087890625  loc loss 63.50196075439453\n",
      "cls loss 520.4576416015625  loc loss 34.033729553222656\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 1183.112548828125  loc loss 58.018577575683594\n",
      "cls loss 1157.00537109375  loc loss 65.58486938476562\n",
      "cls loss 1066.735107421875  loc loss 73.68949890136719\n",
      "cls loss 1002.9050903320312  loc loss 64.07239532470703\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10., 10., 10.,  1.,  1.,  1.,  1.,  1.,  1.,  8.,  8.,\n",
      "         1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10., 10., 10.,  1.,  1.,  1.,  1.,  1.,  1.,  8.,  8.,\n",
      "         1.])\n",
      "cls loss 1118.5006103515625  loc loss 57.66175079345703\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 3., 3., 3.])\n",
      "cls loss 895.2265625  loc loss 46.69534683227539\n",
      "cls loss 675.4505004882812  loc loss 30.796415328979492\n",
      "cls loss 514.7909545898438  loc loss 24.851890563964844\n",
      "cls loss 756.4979858398438  loc loss 50.98075866699219\n",
      "cls loss 688.0867919921875  loc loss 31.471065521240234\n",
      "cls loss 774.498046875  loc loss 43.00069808959961\n",
      "cls loss 901.44482421875  loc loss 45.842674255371094\n",
      "cls loss 1138.859130859375  loc loss 75.94583892822266\n",
      "cls loss 992.1090087890625  loc loss 55.47905349731445\n",
      "cls loss 856.645751953125  loc loss 53.705589294433594\n",
      "cls loss 1006.7874145507812  loc loss 62.54644012451172\n",
      "cls loss 863.3314208984375  loc loss 53.57721710205078\n",
      "cls loss 1193.5296630859375  loc loss 93.71607971191406\n",
      "cls loss 669.3211669921875  loc loss 37.27833557128906\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 1050.4361572265625  loc loss 59.222877502441406\n",
      "cls loss 506.50604248046875  loc loss 26.747095108032227\n",
      "cls loss 1128.0955810546875  loc loss 81.57792663574219\n",
      "cls loss 705.8995971679688  loc loss 37.68110656738281\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 34.])\n",
      "cls loss 1011.09033203125  loc loss 52.07565689086914\n",
      "cls loss 616.552978515625  loc loss 31.71340560913086\n",
      "cls loss 1130.6259765625  loc loss 55.97646713256836\n",
      "cls loss 479.51495361328125  loc loss 23.111454010009766\n",
      "cls loss 1172.843994140625  loc loss 56.183345794677734\n",
      "cls loss 1018.8975830078125  loc loss 57.888099670410156\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 38.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16., 16., 16.,  9.,  9.,  9., 16., 16., 16., 85.,  9.])\n",
      "cls loss 871.4481201171875  loc loss 46.377662658691406\n",
      "cls loss 857.9525146484375  loc loss 65.09244537353516\n",
      "cls loss 1383.8682861328125  loc loss 86.87632751464844\n",
      "cls loss 1653.473876953125  loc loss 117.413330078125\n",
      "cls loss 603.712646484375  loc loss 24.87120819091797\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3., 10.,  8.,  8., 10., 10., 10.,  3.,  3., 14.])\n",
      "cls loss 794.3756103515625  loc loss 31.150197982788086\n",
      "cls loss 1068.8050537109375  loc loss 57.25543212890625\n",
      "cls loss 498.7366638183594  loc loss 17.126298904418945\n",
      "cls loss 716.8551025390625  loc loss 33.539878845214844\n",
      "cls loss 992.669189453125  loc loss 59.4154167175293\n",
      "cls loss 779.5892944335938  loc loss 55.30584716796875\n",
      "cls loss 684.03125  loc loss 30.327360153198242\n",
      "cls loss 641.7122802734375  loc loss 34.07190704345703\n",
      "cls loss 857.577392578125  loc loss 51.07778549194336\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42., 42.,  1.])\n",
      "cls loss 773.2354736328125  loc loss 54.09843826293945\n",
      "cls loss 889.3626708984375  loc loss 41.05908203125\n",
      "cls loss 1002.1414794921875  loc loss 63.545475006103516\n",
      "cls loss 1105.2843017578125  loc loss 65.14906311035156\n",
      "cls loss 875.306884765625  loc loss 44.0284423828125\n",
      "cls loss 915.5670776367188  loc loss 63.223907470703125\n",
      "cls loss 662.050537109375  loc loss 36.61166763305664\n",
      "cls loss 785.0264892578125  loc loss 39.46317672729492\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20.])\n",
      "cls loss 513.2177124023438  loc loss 29.602529525756836\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([11.])\n",
      "cls loss 668.47998046875  loc loss 31.595539093017578\n",
      "cls loss 546.0926513671875  loc loss 25.6570987701416\n",
      "cls loss 960.6271362304688  loc loss 75.57093811035156\n",
      "cls loss 501.67388916015625  loc loss 22.758350372314453\n",
      "cls loss 875.8304443359375  loc loss 51.774688720703125\n",
      "cls loss 659.3441162109375  loc loss 26.601211547851562\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 35., 27.])\n",
      "cls loss 822.5067138671875  loc loss 53.661216735839844\n",
      "cls loss 916.8873291015625  loc loss 65.1767578125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 744.9718017578125  loc loss 45.82650375366211\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([42.,  1.])\n",
      "cls loss 813.4585571289062  loc loss 66.62049102783203\n",
      "cls loss 778.6644897460938  loc loss 42.955230712890625\n",
      "cls loss 958.91650390625  loc loss 50.96499252319336\n",
      "cls loss 1171.8289794921875  loc loss 65.76908874511719\n",
      "cls loss 982.2173461914062  loc loss 63.86310577392578\n",
      "cls loss 675.2890625  loc loss 45.36411666870117\n",
      "cls loss 640.3624877929688  loc loss 41.93822479248047\n",
      "cls loss 584.2659301757812  loc loss 18.652666091918945\n",
      "cls loss 751.38330078125  loc loss 40.21148681640625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 1., 1.])\n",
      "cls loss 643.0054931640625  loc loss 40.04439163208008\n",
      "cls loss 730.9606323242188  loc loss 54.236328125\n",
      "cls loss 823.2822265625  loc loss 46.942054748535156\n",
      "cls loss 758.0037841796875  loc loss 42.41279983520508\n",
      "cls loss 735.9180908203125  loc loss 47.1558837890625\n",
      "cls loss 807.1007080078125  loc loss 55.721763610839844\n",
      "cls loss 1168.495849609375  loc loss 64.6439437866211\n",
      "cls loss 993.5991821289062  loc loss 69.07327270507812\n",
      "cls loss 918.6065673828125  loc loss 50.76364517211914\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 763.693115234375  loc loss 49.34841537475586\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 1068.84814453125  loc loss 34.817626953125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([81.])\n",
      "cls loss 1037.075927734375  loc loss 64.88554382324219\n",
      "cls loss 667.37109375  loc loss 41.98160171508789\n",
      "cls loss 626.9019165039062  loc loss 28.605302810668945\n",
      "cls loss 854.0379028320312  loc loss 33.88202667236328\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3.,  1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 19.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 19.])\n",
      "cls loss 936.0113525390625  loc loss 61.02461242675781\n",
      "cls loss 655.3275146484375  loc loss 24.62019920349121\n",
      "cls loss 638.2216186523438  loc loss 30.635921478271484\n",
      "cls loss 1045.963623046875  loc loss 74.33472442626953\n",
      "cls loss 615.7070922851562  loc loss 33.46337890625\n",
      "cls loss 753.45263671875  loc loss 48.474647521972656\n",
      "cls loss 777.6473388671875  loc loss 57.23875427246094\n",
      "cls loss 670.7099609375  loc loss 42.431922912597656\n",
      "cls loss 858.890869140625  loc loss 48.184234619140625\n",
      "cls loss 912.4072265625  loc loss 61.73756408691406\n",
      "cls loss 1127.99755859375  loc loss 92.6099853515625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 81.])\n",
      "cls loss 799.166748046875  loc loss 44.892127990722656\n",
      "cls loss 811.20654296875  loc loss 37.640167236328125\n",
      "cls loss 830.6167602539062  loc loss 43.236366271972656\n",
      "cls loss 709.5049438476562  loc loss 29.182586669921875\n",
      "cls loss 639.81298828125  loc loss 32.836273193359375\n",
      "cls loss 713.24658203125  loc loss 42.42560577392578\n",
      "cls loss 564.1697387695312  loc loss 37.51845932006836\n",
      "cls loss 527.9359130859375  loc loss 30.333927154541016\n",
      "cls loss 633.4426879882812  loc loss 39.536502838134766\n",
      "cls loss 817.171630859375  loc loss 47.7421875\n",
      "cls loss 715.0274658203125  loc loss 43.90156555175781\n",
      "cls loss 784.87939453125  loc loss 44.68162155151367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 460.088623046875  loc loss 28.826169967651367\n",
      "cls loss 1396.716796875  loc loss 92.29163360595703\n",
      "cls loss 920.2939453125  loc loss 62.67556381225586\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 737.5750122070312  loc loss 43.85192108154297\n",
      "cls loss 829.133544921875  loc loss 54.24525451660156\n",
      "cls loss 749.3388671875  loc loss 34.50169372558594\n",
      "cls loss 863.6448364257812  loc loss 54.65543746948242\n",
      "cls loss 868.4232177734375  loc loss 57.44148254394531\n",
      "cls loss 805.3319091796875  loc loss 49.24049377441406\n",
      "cls loss 783.7825317382812  loc loss 36.00572967529297\n",
      "cls loss 576.4051513671875  loc loss 29.163652420043945\n",
      "cls loss 725.1719970703125  loc loss 45.8696403503418\n",
      "cls loss 817.4097290039062  loc loss 55.98063278198242\n",
      "cls loss 975.1497192382812  loc loss 41.49675750732422\n",
      "cls loss 1147.267333984375  loc loss 67.66680145263672\n",
      "cls loss 1181.106201171875  loc loss 73.13595581054688\n",
      "cls loss 916.401611328125  loc loss 46.28068161010742\n",
      "cls loss 916.8937377929688  loc loss 72.57549285888672\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1., 38., 47.,  1.,  1.,  1.,  1.,  1., 62.])\n",
      "cls loss 731.2606201171875  loc loss 37.358367919921875\n",
      "cls loss 941.0218505859375  loc loss 47.795494079589844\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 931.2249755859375  loc loss 53.4234733581543\n",
      "cls loss 1302.367431640625  loc loss 68.96742248535156\n",
      "cls loss 694.6703491210938  loc loss 35.642032623291016\n",
      "cls loss 755.967041015625  loc loss 57.856422424316406\n",
      "cls loss 741.2327880859375  loc loss 45.684078216552734\n",
      "cls loss 576.1224975585938  loc loss 20.06976890563965\n",
      "cls loss 702.8863525390625  loc loss 41.81230163574219\n",
      "cls loss 646.1673583984375  loc loss 29.424299240112305\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1., 35.])\n",
      "cls loss 701.917236328125  loc loss 35.98631286621094\n",
      "cls loss 1128.412353515625  loc loss 56.967369079589844\n",
      "cls loss 1008.0977172851562  loc loss 58.411888122558594\n",
      "cls loss 834.6202392578125  loc loss 66.01888275146484\n",
      "cls loss 717.7071533203125  loc loss 52.17521667480469\n",
      "cls loss 853.1629638671875  loc loss 62.71258544921875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 514.335205078125  loc loss 29.449052810668945\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 842.13916015625  loc loss 39.735565185546875\n",
      "cls loss 1232.2489013671875  loc loss 71.14800262451172\n",
      "cls loss 1352.8052978515625  loc loss 97.44882202148438\n",
      "cls loss 833.6246337890625  loc loss 40.60212707519531\n",
      "cls loss 663.248779296875  loc loss 36.94854736328125\n",
      "cls loss 674.137939453125  loc loss 40.45131301879883\n",
      "cls loss 685.3992919921875  loc loss 55.338199615478516\n",
      "cls loss 707.3065795898438  loc loss 29.30763053894043\n",
      "cls loss 1048.9681396484375  loc loss 75.47335815429688\n",
      "cls loss 924.283203125  loc loss 50.80450439453125\n",
      "cls loss 631.874267578125  loc loss 29.045442581176758\n",
      "cls loss 1025.33935546875  loc loss 49.08061981201172\n",
      "cls loss 1148.8572998046875  loc loss 76.26463317871094\n",
      "cls loss 984.6423950195312  loc loss 54.907310485839844\n",
      "cls loss 906.8489990234375  loc loss 42.50044631958008\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.])\n",
      "cls loss 909.7010498046875  loc loss 51.53251266479492\n",
      "cls loss 787.3237915039062  loc loss 46.17683792114258\n",
      "cls loss 1154.94970703125  loc loss 56.216331481933594\n",
      "cls loss 1253.2674560546875  loc loss 104.5284652709961\n",
      "cls loss 808.56884765625  loc loss 30.583757400512695\n",
      "cls loss 788.121826171875  loc loss 42.40747833251953\n",
      "cls loss 717.5457763671875  loc loss 37.83020782470703\n",
      "cls loss 708.947509765625  loc loss 40.45319747924805\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 21., 21., 21.])\n",
      "cls loss 782.9385986328125  loc loss 41.11345672607422\n",
      "cls loss 805.58154296875  loc loss 34.981849670410156\n",
      "cls loss 775.87255859375  loc loss 42.58903121948242\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 35.])\n",
      "cls loss 1123.077392578125  loc loss 67.78543853759766\n",
      "cls loss 425.87176513671875  loc loss 21.24014663696289\n",
      "cls loss 608.221923828125  loc loss 37.1431770324707\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 600.6429443359375  loc loss 35.60911560058594\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 38., 38.,  9., 38.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1.,  1.])\n",
      "cls loss 600.180908203125  loc loss 43.56904602050781\n",
      "cls loss 997.7792358398438  loc loss 72.37689208984375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 2.,  1., 77., 31., 10., 10.,  1.,  4., 10.])\n",
      "cls loss 656.977783203125  loc loss 32.607025146484375\n",
      "cls loss 1012.908203125  loc loss 55.6017951965332\n",
      "cls loss 1802.234375  loc loss 132.6411895751953\n",
      "cls loss 612.9866943359375  loc loss 37.610050201416016\n",
      "cls loss 829.6570434570312  loc loss 69.96854400634766\n",
      "cls loss 715.4193115234375  loc loss 36.129241943359375\n",
      "cls loss 715.4302978515625  loc loss 33.85423278808594\n",
      "cls loss 869.3140869140625  loc loss 41.85690689086914\n",
      "cls loss 938.3783569335938  loc loss 51.393898010253906\n",
      "cls loss 863.2025146484375  loc loss 51.25400161743164\n",
      "cls loss 718.2858276367188  loc loss 30.765586853027344\n",
      "cls loss 937.4280395507812  loc loss 35.315242767333984\n",
      "cls loss 1589.12744140625  loc loss 77.38001251220703\n",
      "cls loss 1181.8623046875  loc loss 74.00135803222656\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1., 42., 42., 42., 42., 42., 42.,  1.,\n",
      "         1.,  1.,  1., 42.,  1.,  1., 42.,  1.])\n",
      "cls loss 748.499267578125  loc loss 45.58468246459961\n",
      "cls loss 948.41650390625  loc loss 58.46272277832031\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.])\n",
      "cls loss 498.8375244140625  loc loss 29.4641056060791\n",
      "cls loss 888.4423828125  loc loss 62.17985153198242\n",
      "cls loss 736.0552368164062  loc loss 48.77692413330078\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([11.])\n",
      "cls loss 535.7275390625  loc loss 24.207448959350586\n",
      "cls loss 742.8980102539062  loc loss 26.103057861328125\n",
      "cls loss 712.0086059570312  loc loss 31.28705596923828\n",
      "cls loss 804.3331298828125  loc loss 50.641136169433594\n",
      "cls loss 762.9571533203125  loc loss 48.63361740112305\n",
      "cls loss 761.4768676757812  loc loss 55.64371109008789\n",
      "cls loss 1079.4239501953125  loc loss 64.54945373535156\n",
      "cls loss 646.9620361328125  loc loss 38.77236557006836\n",
      "cls loss 1105.8369140625  loc loss 84.96281433105469\n",
      "cls loss 737.36181640625  loc loss 35.3846435546875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 572.3802490234375  loc loss 36.510868072509766\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1., 38., 38., 42.])\n",
      "cls loss 716.727783203125  loc loss 53.58035659790039\n",
      "cls loss 683.6549072265625  loc loss 35.503047943115234\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 650.14599609375  loc loss 39.808406829833984\n",
      "cls loss 1254.656494140625  loc loss 85.52857971191406\n",
      "cls loss 796.10107421875  loc loss 54.855472564697266\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10.,  3.,  3.,  6.,  8.,  8.,  1.,  1.,  1., 10.])\n",
      "cls loss 784.76318359375  loc loss 43.21433639526367\n",
      "cls loss 468.78472900390625  loc loss 16.851104736328125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10.,  3.])\n",
      "cls loss 820.06591796875  loc loss 35.706302642822266\n",
      "cls loss 438.0390625  loc loss 22.795663833618164\n",
      "cls loss 803.087158203125  loc loss 59.32426452636719\n",
      "cls loss 835.7019653320312  loc loss 56.05208969116211\n",
      "cls loss 636.91357421875  loc loss 35.268646240234375\n",
      "cls loss 688.3028564453125  loc loss 23.329490661621094\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 34.])\n",
      "cls loss 1128.81982421875  loc loss 61.75324249267578\n",
      "cls loss 1210.458251953125  loc loss 85.63264465332031\n",
      "cls loss 799.1468505859375  loc loss 59.83467102050781\n",
      "cls loss 574.9627075195312  loc loss 40.566715240478516\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.,  1.])\n",
      "cls loss 746.7765502929688  loc loss 32.66542434692383\n",
      "cls loss 983.6121826171875  loc loss 76.92098236083984\n",
      "cls loss 1427.7913818359375  loc loss 98.04299926757812\n",
      "cls loss 1205.1837158203125  loc loss 68.62731170654297\n",
      "cls loss 703.5482788085938  loc loss 45.06936264038086\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 1018.723876953125  loc loss 47.74850845336914\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10.])\n",
      "cls loss 573.931884765625  loc loss 31.944265365600586\n",
      "cls loss 761.6302490234375  loc loss 39.83279037475586\n",
      "cls loss 931.0157470703125  loc loss 40.957374572753906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 606.610107421875  loc loss 31.536006927490234\n",
      "cls loss 702.0745849609375  loc loss 47.96617126464844\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21.,\n",
      "        21.])\n",
      "cls loss 937.9324951171875  loc loss 55.58320999145508\n",
      "cls loss 822.735107421875  loc loss 51.571659088134766\n",
      "cls loss 640.3751220703125  loc loss 22.00880241394043\n",
      "cls loss 1026.5491943359375  loc loss 60.57316970825195\n",
      "cls loss 762.4977416992188  loc loss 56.02642822265625\n",
      "cls loss 570.1954345703125  loc loss 36.15099334716797\n",
      "cls loss 1136.798095703125  loc loss 85.40213775634766\n",
      "cls loss 1293.409912109375  loc loss 91.40847778320312\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15., 85.])\n",
      "cls loss 1010.5880737304688  loc loss 58.34590530395508\n",
      "cls loss 815.8701782226562  loc loss 67.97864532470703\n",
      "cls loss 1065.22216796875  loc loss 61.49565124511719\n",
      "cls loss 900.0761108398438  loc loss 55.49082946777344\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 8., 8.])\n",
      "cls loss 541.2095947265625  loc loss 29.701560974121094\n",
      "cls loss 763.95458984375  loc loss 38.64501190185547\n",
      "cls loss 812.377685546875  loc loss 43.401493072509766\n",
      "cls loss 675.616943359375  loc loss 35.238712310791016\n",
      "cls loss 777.2074584960938  loc loss 43.30694580078125\n",
      "cls loss 1031.9552001953125  loc loss 50.53076171875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1., 35., 27., 27.,  1., 27.,  1.])\n",
      "cls loss 1372.0887451171875  loc loss 84.2046890258789\n",
      "cls loss 602.923583984375  loc loss 45.286354064941406\n",
      "cls loss 764.467529296875  loc loss 50.08629608154297\n",
      "cls loss 688.3204345703125  loc loss 55.06484603881836\n",
      "cls loss 752.7581787109375  loc loss 49.48713302612305\n",
      "cls loss 752.6507568359375  loc loss 52.36240768432617\n",
      "cls loss 670.6224365234375  loc loss 50.694740295410156\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  2.,  2.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  2.,  2.])\n",
      "cls loss 461.09698486328125  loc loss 19.225751876831055\n",
      "cls loss 1099.33251953125  loc loss 62.544944763183594\n",
      "cls loss 752.1187744140625  loc loss 38.20067596435547\n",
      "cls loss 1067.194091796875  loc loss 79.03970336914062\n",
      "cls loss 536.2649536132812  loc loss 32.45542526245117\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 19., 19., 19., 16.])\n",
      "cls loss 564.1309814453125  loc loss 29.193267822265625\n",
      "cls loss 523.9022827148438  loc loss 19.490747451782227\n",
      "cls loss 706.035888671875  loc loss 31.35226058959961\n",
      "cls loss 858.0192260742188  loc loss 49.939796447753906\n",
      "cls loss 450.59466552734375  loc loss 33.002105712890625\n",
      "cls loss 986.39306640625  loc loss 62.18091583251953\n",
      "cls loss 631.2911987304688  loc loss 48.413883209228516\n",
      "cls loss 763.49462890625  loc loss 46.95028305053711\n",
      "cls loss 895.4075317382812  loc loss 58.98883819580078\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 1019.2286987304688  loc loss 46.57965850830078\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 1297.2857666015625  loc loss 95.78779602050781\n",
      "cls loss 1544.177001953125  loc loss 140.50241088867188\n",
      "cls loss 723.885986328125  loc loss 52.68962478637695\n",
      "cls loss 637.9688720703125  loc loss 47.313751220703125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3.,  3.,  3.,  3.,  3., 10.])\n",
      "cls loss 444.8427734375  loc loss 18.930992126464844\n",
      "cls loss 723.6920776367188  loc loss 44.42323684692383\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 1., 1., 1., 3., 3., 3., 3.])\n",
      "cls loss 736.082763671875  loc loss 43.242889404296875\n",
      "cls loss 1132.539794921875  loc loss 88.51234436035156\n",
      "cls loss 829.1529541015625  loc loss 59.175315856933594\n",
      "cls loss 708.602294921875  loc loss 38.627525329589844\n",
      "cls loss 1009.2412109375  loc loss 70.04428100585938\n",
      "cls loss 722.2140502929688  loc loss 43.53525161743164\n",
      "cls loss 1013.3089599609375  loc loss 66.75924682617188\n",
      "cls loss 706.490478515625  loc loss 59.1065788269043\n",
      "cls loss 879.1001586914062  loc loss 47.935306549072266\n",
      "cls loss 1375.625244140625  loc loss 115.48796081542969\n",
      "cls loss 998.8785400390625  loc loss 63.45835494995117\n",
      "cls loss 686.1840209960938  loc loss 31.978803634643555\n",
      "cls loss 502.45660400390625  loc loss 20.000076293945312\n",
      "cls loss 526.8621826171875  loc loss 29.322895050048828\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3., 10., 10., 10., 10., 10., 10., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10., 10., 10., 10., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 11., 10., 10., 10., 10., 10.,  3.,  3.,  3.,  3.,  3.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 11., 10., 10., 10., 10., 10.,  3.,  3.,  3.,  3.,  3.])\n",
      "cls loss 600.23876953125  loc loss 25.660463333129883\n",
      "cls loss 670.798583984375  loc loss 29.432586669921875\n",
      "cls loss 534.6668701171875  loc loss 29.00010108947754\n",
      "cls loss 553.7591552734375  loc loss 21.725727081298828\n",
      "cls loss 591.35791015625  loc loss 42.33570098876953\n",
      "cls loss 626.2896118164062  loc loss 21.480375289916992\n",
      "cls loss 883.429443359375  loc loss 63.852420806884766\n",
      "cls loss 782.684326171875  loc loss 58.3687744140625\n",
      "cls loss 1200.8978271484375  loc loss 76.07852935791016\n",
      "cls loss 589.8289794921875  loc loss 40.763755798339844\n",
      "cls loss 1042.691162109375  loc loss 69.66702270507812\n",
      "cls loss 878.5596923828125  loc loss 60.227684020996094\n",
      "cls loss 808.8513793945312  loc loss 53.543067932128906\n",
      "cls loss 778.850830078125  loc loss 59.00932312011719\n",
      "cls loss 1044.08935546875  loc loss 72.84950256347656\n",
      "cls loss 988.5325927734375  loc loss 66.84913635253906\n",
      "cls loss 571.8659057617188  loc loss 28.489486694335938\n",
      "cls loss 893.029296875  loc loss 66.14381408691406\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 10.,  1., 18.])\n",
      "cls loss 542.2276611328125  loc loss 34.88050079345703\n",
      "cls loss 598.7808837890625  loc loss 21.32856559753418\n",
      "cls loss 1009.5626831054688  loc loss 47.33834457397461\n",
      "cls loss 1251.219482421875  loc loss 84.27500915527344\n",
      "cls loss 1072.218505859375  loc loss 51.78296661376953\n",
      "cls loss 1117.133544921875  loc loss 66.91059112548828\n",
      "cls loss 931.7318115234375  loc loss 50.46062469482422\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.,  1.,  1.])\n",
      "cls loss 1092.820068359375  loc loss 69.59095764160156\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1., 38.,  1.])\n",
      "cls loss 1020.1368408203125  loc loss 56.54290008544922\n",
      "cls loss 1283.45849609375  loc loss 90.05490112304688\n",
      "cls loss 702.9771118164062  loc loss 50.58518981933594\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 826.3536376953125  loc loss 56.10084915161133\n",
      "cls loss 866.60986328125  loc loss 48.411102294921875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3., 10.,  8.,  3., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.])\n",
      "cls loss 857.3370971679688  loc loss 54.667884826660156\n",
      "cls loss 647.74658203125  loc loss 38.8398551940918\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3.,  3., 11.,  3., 10., 10.,  3.,  3., 10.])\n",
      "cls loss 788.491455078125  loc loss 42.64222717285156\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3., 10., 10., 10.])\n",
      "cls loss 719.5451049804688  loc loss 54.425682067871094\n",
      "cls loss 665.0380249023438  loc loss 36.698123931884766\n",
      "cls loss 696.2349853515625  loc loss 52.875526428222656\n",
      "cls loss 1114.4285888671875  loc loss 71.76285552978516\n",
      "cls loss 733.8623046875  loc loss 50.5406379699707\n",
      "cls loss 499.6390380859375  loc loss 42.237525939941406\n",
      "cls loss 658.0397338867188  loc loss 44.047550201416016\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 9.,  9., 85., 85.])\n",
      "cls loss 599.8768920898438  loc loss 34.510643005371094\n",
      "cls loss 730.6378784179688  loc loss 46.0567512512207\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 1077.3865966796875  loc loss 80.9853515625\n",
      "cls loss 993.9655151367188  loc loss 52.364994049072266\n",
      "cls loss 1172.456298828125  loc loss 75.17671203613281\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10., 10., 10., 10.])\n",
      "cls loss 683.4732055664062  loc loss 42.20909881591797\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([13.])\n",
      "cls loss 1028.319091796875  loc loss 92.78478240966797\n",
      "cls loss 470.0106201171875  loc loss 21.00026512145996\n",
      "cls loss 506.16802978515625  loc loss 26.263059616088867\n",
      "cls loss 737.6630249023438  loc loss 40.5411376953125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19.,  1.,  1.,  1., 19., 19.])\n",
      "cls loss 842.4871826171875  loc loss 42.6617317199707\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 521.29052734375  loc loss 44.49565505981445\n",
      "cls loss 817.3936767578125  loc loss 59.971031188964844\n",
      "cls loss 573.9420166015625  loc loss 35.53609848022461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 885.8787231445312  loc loss 55.787391662597656\n",
      "cls loss 985.6638793945312  loc loss 68.58963775634766\n",
      "cls loss 800.8011474609375  loc loss 42.18102264404297\n",
      "cls loss 1029.902099609375  loc loss 74.53230285644531\n",
      "cls loss 555.9014282226562  loc loss 21.085121154785156\n",
      "cls loss 754.0367431640625  loc loss 49.77759552001953\n",
      "cls loss 718.2142333984375  loc loss 30.982404708862305\n",
      "cls loss 612.0030517578125  loc loss 33.89726638793945\n",
      "cls loss 843.2021484375  loc loss 60.3969612121582\n",
      "cls loss 877.6090087890625  loc loss 44.40533447265625\n",
      "cls loss 1259.905029296875  loc loss 65.9537582397461\n",
      "cls loss 726.558349609375  loc loss 48.59241485595703\n",
      "cls loss 823.500732421875  loc loss 56.13175964355469\n",
      "cls loss 1178.495361328125  loc loss 80.95196533203125\n",
      "cls loss 705.2840576171875  loc loss 54.56171798706055\n",
      "cls loss 818.2264404296875  loc loss 47.75851821899414\n",
      "cls loss 1139.7618408203125  loc loss 71.85681915283203\n",
      "cls loss 1000.5286865234375  loc loss 71.49578094482422\n",
      "cls loss 1284.212158203125  loc loss 77.6907730102539\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 5.])\n",
      "cls loss 510.77215576171875  loc loss 15.09248161315918\n",
      "cls loss 518.2744750976562  loc loss 25.38640594482422\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 13.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 6., 8., 8.])\n",
      "cls loss 503.2594909667969  loc loss 20.962167739868164\n",
      "cls loss 582.8154296875  loc loss 30.561260223388672\n",
      "cls loss 993.7392578125  loc loss 78.89775085449219\n",
      "cls loss 621.3255004882812  loc loss 22.8443603515625\n",
      "cls loss 851.0232543945312  loc loss 58.48346710205078\n",
      "cls loss 1392.76708984375  loc loss 76.06776428222656\n",
      "cls loss 836.773681640625  loc loss 51.43553924560547\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([42., 42.,  1.,  1.,  1.,  1.,  1.,  1.,  1., 42., 42.])\n",
      "cls loss 947.8787841796875  loc loss 47.583526611328125\n",
      "cls loss 1114.87451171875  loc loss 79.21578979492188\n",
      "cls loss 852.7818603515625  loc loss 62.667938232421875\n",
      "cls loss 693.616943359375  loc loss 33.43539047241211\n",
      "cls loss 874.5755615234375  loc loss 48.7794189453125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 1231.1231689453125  loc loss 68.37846374511719\n",
      "cls loss 894.064208984375  loc loss 60.780982971191406\n",
      "cls loss 616.8934936523438  loc loss 33.71759033203125\n",
      "cls loss 609.4832763671875  loc loss 27.88007164001465\n",
      "cls loss 689.7166137695312  loc loss 42.21531677246094\n",
      "cls loss 943.1456298828125  loc loss 57.18443298339844\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15.])\n",
      "cls loss 518.091064453125  loc loss 24.29660415649414\n",
      "cls loss 740.539794921875  loc loss 45.626426696777344\n",
      "cls loss 648.0618896484375  loc loss 40.22275924682617\n",
      "cls loss 1019.22802734375  loc loss 76.75086975097656\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19.,  7.])\n",
      "cls loss 688.9512329101562  loc loss 40.27446746826172\n",
      "cls loss 1372.9429931640625  loc loss 78.51861572265625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 1116.904296875  loc loss 63.31696701049805\n",
      "cls loss 891.508056640625  loc loss 64.8941650390625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([38., 38.,  1., 18.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1., 18., 18.,  1.])\n",
      "cls loss 676.127197265625  loc loss 36.59674072265625\n",
      "cls loss 763.8233032226562  loc loss 32.098388671875\n",
      "cls loss 994.35986328125  loc loss 86.81964874267578\n",
      "cls loss 845.9345703125  loc loss 53.294517517089844\n",
      "cls loss 909.2093505859375  loc loss 43.574424743652344\n",
      "cls loss 535.825927734375  loc loss 37.555992126464844\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.])\n",
      "cls loss 408.37213134765625  loc loss 19.43133544921875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([32.])\n",
      "cls loss 821.2706298828125  loc loss 37.44520568847656\n",
      "cls loss 738.4385375976562  loc loss 40.651344299316406\n",
      "cls loss 846.2523193359375  loc loss 71.31548309326172\n",
      "cls loss 868.2971801757812  loc loss 48.814517974853516\n",
      "cls loss 662.574951171875  loc loss 45.44279479980469\n",
      "cls loss 1108.119140625  loc loss 59.005470275878906\n",
      "cls loss 1051.5166015625  loc loss 74.47005462646484\n",
      "cls loss 886.967041015625  loc loss 62.00951385498047\n",
      "cls loss 946.5606689453125  loc loss 44.28525161743164\n",
      "cls loss 1263.3629150390625  loc loss 74.16414642333984\n",
      "cls loss 821.8486328125  loc loss 35.2733268737793\n",
      "cls loss 1132.0662841796875  loc loss 87.36373901367188\n",
      "cls loss 878.7730102539062  loc loss 51.058982849121094\n",
      "cls loss 675.8228759765625  loc loss 50.30791091918945\n",
      "cls loss 638.2010498046875  loc loss 30.896621704101562\n",
      "cls loss 599.312744140625  loc loss 38.688873291015625\n",
      "cls loss 914.9280395507812  loc loss 59.49618148803711\n",
      "cls loss 906.4649658203125  loc loss 65.78483581542969\n",
      "cls loss 536.28173828125  loc loss 34.05838394165039\n",
      "cls loss 1028.7431640625  loc loss 64.82440948486328\n",
      "cls loss 1198.427490234375  loc loss 71.5529556274414\n",
      "cls loss 490.18707275390625  loc loss 27.838623046875\n",
      "cls loss 1121.74462890625  loc loss 75.76820373535156\n",
      "cls loss 752.55908203125  loc loss 59.79244613647461\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 1029.6480712890625  loc loss 79.27742767333984\n",
      "cls loss 559.9828491210938  loc loss 23.01961898803711\n",
      "cls loss 780.4915771484375  loc loss 46.63933563232422\n",
      "cls loss 839.58642578125  loc loss 51.79142761230469\n",
      "cls loss 586.7432861328125  loc loss 41.26015853881836\n",
      "cls loss 455.25408935546875  loc loss 20.729795455932617\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 9., 9., 1., 9., 9., 9., 9., 1., 9.])\n",
      "cls loss 1410.5732421875  loc loss 116.84961700439453\n",
      "cls loss 840.8644409179688  loc loss 47.021209716796875\n",
      "cls loss 1203.7069091796875  loc loss 93.92579650878906\n",
      "cls loss 594.5460815429688  loc loss 34.64789581298828\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 42., 42.])\n",
      "cls loss 916.150146484375  loc loss 64.7475814819336\n",
      "cls loss 972.1129150390625  loc loss 65.1607666015625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  2.,  1.,  1.,  1., 38.,\n",
      "         1.,  1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 38., 38., 38.,  1., 38., 38., 38.,  1.,  1., 38.,  1.,\n",
      "         1.])\n",
      "cls loss 748.6921997070312  loc loss 37.199462890625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  8.,  8.])\n",
      "cls loss 1383.508056640625  loc loss 82.56945037841797\n",
      "cls loss 1291.32666015625  loc loss 84.98748016357422\n",
      "cls loss 593.935546875  loc loss 30.900489807128906\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([4., 1., 1., 4.])\n",
      "cls loss 856.4822998046875  loc loss 51.84226608276367\n",
      "cls loss 954.926025390625  loc loss 54.459381103515625\n",
      "cls loss 505.8609313964844  loc loss 20.454177856445312\n",
      "cls loss 686.112548828125  loc loss 32.28973388671875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([51.,  1.])\n",
      "cls loss 512.205078125  loc loss 18.44879913330078\n",
      "cls loss 585.3653564453125  loc loss 33.741764068603516\n",
      "cls loss 924.8248291015625  loc loss 57.041038513183594\n",
      "cls loss 1074.320556640625  loc loss 81.15565490722656\n",
      "cls loss 1389.598876953125  loc loss 84.4648208618164\n",
      "cls loss 1713.696533203125  loc loss 112.57460021972656\n",
      "cls loss 875.08544921875  loc loss 47.353511810302734\n",
      "cls loss 943.2759399414062  loc loss 71.26766967773438\n",
      "cls loss 1088.4400634765625  loc loss 77.94686889648438\n",
      "cls loss 747.0573120117188  loc loss 44.50619888305664\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  3.,  1.,  1.,  1.,  3.,  1.,  1.,\n",
      "         1.,  1.,  1.])\n",
      "cls loss 830.2377319335938  loc loss 49.210227966308594\n",
      "cls loss 971.6318359375  loc loss 51.823951721191406\n",
      "cls loss 835.9440307617188  loc loss 48.00100326538086\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "cls loss 714.5902709960938  loc loss 43.6818733215332\n",
      "cls loss 446.8085021972656  loc loss 33.158241271972656\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3.])\n",
      "cls loss 619.876708984375  loc loss 21.645137786865234\n",
      "cls loss 783.7193603515625  loc loss 50.45003890991211\n",
      "cls loss 571.3851318359375  loc loss 37.073829650878906\n",
      "cls loss 962.2119140625  loc loss 75.19000244140625\n",
      "cls loss 814.3558349609375  loc loss 31.675384521484375\n",
      "cls loss 606.8565673828125  loc loss 38.231964111328125\n",
      "cls loss 1694.6295166015625  loc loss 113.5637435913086\n",
      "cls loss 821.4710083007812  loc loss 51.07928466796875\n",
      "cls loss 541.0807495117188  loc loss 42.891029357910156\n",
      "cls loss 769.7665405273438  loc loss 38.19754409790039\n",
      "cls loss 625.140869140625  loc loss 42.970848083496094\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 1087.0621337890625  loc loss 73.21308898925781\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  9., 64., 64., 64., 64., 64., 64., 64., 64., 64.,  9.,  9.,  9.,\n",
      "         9.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 777.36962890625  loc loss 35.07807922363281\n",
      "cls loss 1247.52734375  loc loss 110.06932830810547\n",
      "cls loss 774.3413696289062  loc loss 46.99276351928711\n",
      "cls loss 955.9771728515625  loc loss 71.1491470336914\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.,  3.,  3.])\n",
      "cls loss 676.7438354492188  loc loss 40.454559326171875\n",
      "cls loss 762.5366821289062  loc loss 42.72975158691406\n",
      "cls loss 661.413818359375  loc loss 55.46731948852539\n",
      "cls loss 923.758056640625  loc loss 48.16166687011719\n",
      "cls loss 831.990478515625  loc loss 58.714263916015625\n",
      "cls loss 706.8757934570312  loc loss 53.18603515625\n",
      "cls loss 754.6320190429688  loc loss 52.20004653930664\n",
      "cls loss 741.052001953125  loc loss 47.48213195800781\n",
      "cls loss 996.3324584960938  loc loss 66.5657958984375\n",
      "cls loss 774.463134765625  loc loss 51.96946716308594\n",
      "cls loss 683.533203125  loc loss 32.27931213378906\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21.])\n",
      "cls loss 598.7852783203125  loc loss 22.710926055908203\n",
      "cls loss 668.8411865234375  loc loss 56.27812957763672\n",
      "cls loss 868.8157958984375  loc loss 62.39741516113281\n",
      "cls loss 539.123291015625  loc loss 34.0820198059082\n",
      "cls loss 840.5829467773438  loc loss 49.508846282958984\n",
      "cls loss 1486.7568359375  loc loss 86.55811309814453\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 42., 42.,  1.,  1.])\n",
      "cls loss 754.2899169921875  loc loss 40.731666564941406\n",
      "cls loss 531.0120239257812  loc loss 32.75394821166992\n",
      "cls loss 712.4982299804688  loc loss 47.46217727661133\n",
      "cls loss 882.2882080078125  loc loss 77.23958587646484\n",
      "cls loss 757.83203125  loc loss 38.78480529785156\n",
      "cls loss 960.4818115234375  loc loss 62.970619201660156\n",
      "cls loss 926.2518310546875  loc loss 63.87934112548828\n",
      "cls loss 941.2216796875  loc loss 54.39555358886719\n",
      "cls loss 692.00048828125  loc loss 45.24411392211914\n",
      "cls loss 597.1110229492188  loc loss 38.71345520019531\n",
      "cls loss 630.4971923828125  loc loss 23.918018341064453\n",
      "cls loss 690.3992919921875  loc loss 50.15065002441406\n",
      "cls loss 895.2122802734375  loc loss 74.90335083007812\n",
      "cls loss 895.4103393554688  loc loss 45.00812911987305\n",
      "cls loss 837.326171875  loc loss 58.94337844848633\n",
      "cls loss 916.6348876953125  loc loss 45.91994857788086\n",
      "cls loss 1302.2596435546875  loc loss 79.46006774902344\n",
      "cls loss 879.07958984375  loc loss 60.17127990722656\n",
      "cls loss 1150.90380859375  loc loss 59.54781723022461\n",
      "cls loss 749.3706665039062  loc loss 28.699939727783203\n",
      "cls loss 927.6056518554688  loc loss 51.10372543334961\n",
      "cls loss 901.5791625976562  loc loss 49.16677474975586\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 5., 5., 5., 5., 5., 5.])\n",
      "cls loss 563.2698364257812  loc loss 37.5969123840332\n",
      "cls loss 665.712646484375  loc loss 45.2674560546875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([13.])\n",
      "cls loss 530.2361450195312  loc loss 25.713844299316406\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([44., 10.,  1.,  1.,  1.])\n",
      "cls loss 590.7490234375  loc loss 28.21685028076172\n",
      "cls loss 874.1976318359375  loc loss 48.25278854370117\n",
      "cls loss 740.832275390625  loc loss 40.41568374633789\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19., 19., 19., 19., 19., 19., 19.])\n",
      "cls loss 900.4915771484375  loc loss 55.46766662597656\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([56.])\n",
      "cls loss 1709.184814453125  loc loss 96.46636962890625\n",
      "cls loss 897.6842651367188  loc loss 66.32282257080078\n",
      "cls loss 1272.590576171875  loc loss 82.40213012695312\n",
      "cls loss 1104.758544921875  loc loss 85.31777954101562\n",
      "cls loss 672.9319458007812  loc loss 44.99552536010742\n",
      "cls loss 1197.350830078125  loc loss 79.89134216308594\n",
      "cls loss 790.4326171875  loc loss 38.94341278076172\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 36.])\n",
      "cls loss 819.8887939453125  loc loss 46.77913284301758\n",
      "cls loss 668.8021240234375  loc loss 50.269256591796875\n",
      "cls loss 790.2630615234375  loc loss 40.6259765625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5.])\n",
      "cls loss 793.344970703125  loc loss 48.7226448059082\n",
      "cls loss 540.6473388671875  loc loss 27.686477661132812\n",
      "cls loss 1033.88037109375  loc loss 63.71630096435547\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "cls loss 936.440185546875  loc loss 67.28907775878906\n",
      "cls loss 1084.90966796875  loc loss 56.53964614868164\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 886.1453857421875  loc loss 59.05956268310547\n",
      "cls loss 1139.952392578125  loc loss 68.50572204589844\n",
      "cls loss 899.10888671875  loc loss 70.02923583984375\n",
      "cls loss 734.4747314453125  loc loss 43.05110168457031\n",
      "cls loss 828.66796875  loc loss 50.26776123046875\n",
      "cls loss 777.3980102539062  loc loss 47.329345703125\n",
      "cls loss 1090.447265625  loc loss 66.78564453125\n",
      "cls loss 575.4243774414062  loc loss 28.09516143798828\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 11., 15., 10., 10., 10., 10., 10.])\n",
      "cls loss 1224.727294921875  loc loss 85.12982940673828\n",
      "cls loss 682.0472412109375  loc loss 43.57802963256836\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3.])\n",
      "cls loss 768.111083984375  loc loss 46.32489013671875\n",
      "cls loss 642.7740478515625  loc loss 38.1879768371582\n",
      "cls loss 727.584228515625  loc loss 38.69831085205078\n",
      "cls loss 917.429443359375  loc loss 49.065521240234375\n",
      "cls loss 643.4501953125  loc loss 23.430145263671875\n",
      "cls loss 914.3151245117188  loc loss 39.84162139892578\n",
      "cls loss 874.0504760742188  loc loss 57.164825439453125\n",
      "cls loss 698.934326171875  loc loss 51.561065673828125\n",
      "cls loss 1457.6295166015625  loc loss 120.1289291381836\n",
      "cls loss 1092.84033203125  loc loss 80.88766479492188\n",
      "cls loss 810.5103759765625  loc loss 52.98312759399414\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  9.,  9.,  9.,  6.,  6., 85., 85.,  8.,  1.,  1.,  1.,  1.,\n",
      "         6.,  6.])\n",
      "cls loss 519.3629150390625  loc loss 34.17378616333008\n",
      "cls loss 1247.766357421875  loc loss 81.00033569335938\n",
      "cls loss 1364.65576171875  loc loss 89.64818572998047\n",
      "cls loss 907.134521484375  loc loss 64.69580841064453\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10.,  3.,  3., 10.])\n",
      "cls loss 577.29541015625  loc loss 35.87953186035156\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([7.])\n",
      "cls loss 817.6739501953125  loc loss 65.74018859863281\n",
      "cls loss 788.5831298828125  loc loss 48.90593719482422\n",
      "cls loss 820.4703369140625  loc loss 54.79109191894531\n",
      "cls loss 1115.585205078125  loc loss 81.33382415771484\n",
      "cls loss 844.627685546875  loc loss 51.170875549316406\n",
      "cls loss 1100.572021484375  loc loss 69.85836791992188\n",
      "cls loss 1278.919189453125  loc loss 82.05656433105469\n",
      "cls loss 908.0997314453125  loc loss 53.121551513671875\n",
      "cls loss 869.27294921875  loc loss 61.135196685791016\n",
      "cls loss 760.8948974609375  loc loss 49.659019470214844\n",
      "cls loss 952.21435546875  loc loss 78.67335510253906\n",
      "cls loss 982.399169921875  loc loss 53.44321060180664\n",
      "cls loss 714.610595703125  loc loss 37.14262008666992\n",
      "cls loss 976.240966796875  loc loss 77.19725799560547\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([62.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([62.])\n",
      "cls loss 458.66748046875  loc loss 24.720640182495117\n",
      "cls loss 739.1298828125  loc loss 56.99153137207031\n",
      "cls loss 816.5471801757812  loc loss 48.859092712402344\n",
      "cls loss 677.1419067382812  loc loss 26.27728843688965\n",
      "cls loss 957.2086181640625  loc loss 69.28799438476562\n",
      "cls loss 974.0969848632812  loc loss 59.11997985839844\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([28.])\n",
      "cls loss 997.760986328125  loc loss 59.05093765258789\n",
      "cls loss 974.03173828125  loc loss 62.016998291015625\n",
      "cls loss 944.4012451171875  loc loss 59.54795455932617\n",
      "cls loss 951.6802368164062  loc loss 65.44112396240234\n",
      "cls loss 1256.3724365234375  loc loss 90.14595031738281\n",
      "cls loss 781.18115234375  loc loss 45.357818603515625\n",
      "cls loss 880.4904174804688  loc loss 54.304866790771484\n",
      "cls loss 917.639892578125  loc loss 68.53367614746094\n",
      "cls loss 1318.536865234375  loc loss 92.04685974121094\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([81.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 989.8873291015625  loc loss 49.26576614379883\n",
      "cls loss 831.0330810546875  loc loss 35.57916259765625\n",
      "cls loss 631.1806640625  loc loss 38.03669738769531\n",
      "cls loss 591.101806640625  loc loss 25.000431060791016\n",
      "cls loss 635.3176879882812  loc loss 38.3543701171875\n",
      "cls loss 613.595947265625  loc loss 40.290443420410156\n",
      "cls loss 766.9886474609375  loc loss 44.078887939453125\n",
      "cls loss 990.8173828125  loc loss 70.05651092529297\n",
      "cls loss 1097.219482421875  loc loss 63.3833122253418\n",
      "cls loss 1892.453857421875  loc loss 129.44667053222656\n",
      "cls loss 778.3260498046875  loc loss 38.331268310546875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 833.452392578125  loc loss 61.41560745239258\n",
      "cls loss 619.462890625  loc loss 47.2347297668457\n",
      "cls loss 875.5748291015625  loc loss 46.75438690185547\n",
      "cls loss 789.2132568359375  loc loss 43.900115966796875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([44., 44.])\n",
      "cls loss 656.2374877929688  loc loss 34.2348518371582\n",
      "cls loss 718.6593017578125  loc loss 46.03764724731445\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15.])\n",
      "cls loss 826.332763671875  loc loss 45.01247787475586\n",
      "cls loss 408.90673828125  loc loss 22.48711395263672\n",
      "cls loss 814.0497436523438  loc loss 51.308998107910156\n",
      "cls loss 541.15283203125  loc loss 28.796762466430664\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([1., 3., 3.])\n",
      "cls loss 515.642333984375  loc loss 41.0608024597168\n",
      "cls loss 522.6493530273438  loc loss 21.90782928466797\n",
      "cls loss 872.0562744140625  loc loss 44.31081771850586\n",
      "cls loss 838.51611328125  loc loss 50.09734344482422\n",
      "cls loss 862.2991943359375  loc loss 46.02398681640625\n",
      "cls loss 812.4197387695312  loc loss 53.136756896972656\n",
      "cls loss 677.3570556640625  loc loss 48.12635803222656\n",
      "cls loss 812.0682983398438  loc loss 54.93958282470703\n",
      "cls loss 777.866943359375  loc loss 46.133121490478516\n",
      "cls loss 811.9996948242188  loc loss 62.0605583190918\n",
      "cls loss 476.6932373046875  loc loss 32.478515625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 1064.3028564453125  loc loss 56.89677047729492\n",
      "cls loss 1097.195068359375  loc loss 63.349021911621094\n",
      "cls loss 981.6138305664062  loc loss 71.27157592773438\n",
      "cls loss 965.5175170898438  loc loss 62.76919937133789\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10., 10., 10.,  1.,  1.,  1.,  1.,  1.,  1.,  8.,  8.,\n",
      "         1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10., 10., 10.,  1.,  1.,  1.,  1.,  1.,  1.,  8.,  8.,\n",
      "         1.])\n",
      "cls loss 1027.019775390625  loc loss 56.133819580078125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 3., 3., 3.])\n",
      "cls loss 799.047607421875  loc loss 45.63916015625\n",
      "cls loss 594.03173828125  loc loss 30.128299713134766\n",
      "cls loss 438.38311767578125  loc loss 23.98373031616211\n",
      "cls loss 684.32568359375  loc loss 49.75616455078125\n",
      "cls loss 615.038818359375  loc loss 30.70892333984375\n",
      "cls loss 723.5651245117188  loc loss 42.361209869384766\n",
      "cls loss 817.5988159179688  loc loss 44.93296813964844\n",
      "cls loss 1056.919677734375  loc loss 73.54385375976562\n",
      "cls loss 871.3123168945312  loc loss 52.95864486694336\n",
      "cls loss 789.2474365234375  loc loss 51.8804817199707\n",
      "cls loss 923.4129638671875  loc loss 60.96574401855469\n",
      "cls loss 770.722412109375  loc loss 51.97478485107422\n",
      "cls loss 1110.068115234375  loc loss 91.69676971435547\n",
      "cls loss 619.3303833007812  loc loss 36.073036193847656\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 946.2634887695312  loc loss 58.102333068847656\n",
      "cls loss 455.1937255859375  loc loss 25.38585662841797\n",
      "cls loss 1060.843994140625  loc loss 79.62403106689453\n",
      "cls loss 645.372314453125  loc loss 36.736289978027344\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 34.])\n",
      "cls loss 918.431884765625  loc loss 50.59840393066406\n",
      "cls loss 579.5654907226562  loc loss 30.996471405029297\n",
      "cls loss 1046.7042236328125  loc loss 54.67095947265625\n",
      "cls loss 437.2761535644531  loc loss 22.32660675048828\n",
      "cls loss 1093.135498046875  loc loss 55.269535064697266\n",
      "cls loss 906.1993408203125  loc loss 55.33511734008789\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 38.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16., 16., 16.,  9.,  9.,  9., 16., 16., 16., 85.,  9.])\n",
      "cls loss 797.7504272460938  loc loss 45.00337600708008\n",
      "cls loss 812.8235473632812  loc loss 63.471736907958984\n",
      "cls loss 1268.8441162109375  loc loss 85.49624633789062\n",
      "cls loss 1557.906494140625  loc loss 114.5677719116211\n",
      "cls loss 546.3235473632812  loc loss 24.33707046508789\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3., 10.,  8.,  8., 10., 10., 10.,  3.,  3., 14.])\n",
      "cls loss 700.828369140625  loc loss 30.034860610961914\n",
      "cls loss 997.0325927734375  loc loss 55.46944808959961\n",
      "cls loss 421.3443908691406  loc loss 16.80721664428711\n",
      "cls loss 641.9254760742188  loc loss 32.52842330932617\n",
      "cls loss 903.4865112304688  loc loss 57.74617004394531\n",
      "cls loss 714.2760009765625  loc loss 54.11106872558594\n",
      "cls loss 569.8742065429688  loc loss 29.050283432006836\n",
      "cls loss 576.7130126953125  loc loss 33.07758712768555\n",
      "cls loss 792.5049438476562  loc loss 50.22235870361328\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42., 42.,  1.])\n",
      "cls loss 722.9677734375  loc loss 52.66752243041992\n",
      "cls loss 763.5516357421875  loc loss 39.80242156982422\n",
      "cls loss 912.1201171875  loc loss 62.052955627441406\n",
      "cls loss 977.3701171875  loc loss 63.62806701660156\n",
      "cls loss 781.3147583007812  loc loss 42.82691192626953\n",
      "cls loss 832.6339111328125  loc loss 60.99630355834961\n",
      "cls loss 605.799072265625  loc loss 35.350887298583984\n",
      "cls loss 744.6728515625  loc loss 38.57171630859375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20.])\n",
      "cls loss 467.71533203125  loc loss 28.334177017211914\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([11.])\n",
      "cls loss 590.3623657226562  loc loss 30.44568634033203\n",
      "cls loss 472.9148254394531  loc loss 24.62831687927246\n",
      "cls loss 871.316650390625  loc loss 73.6075439453125\n",
      "cls loss 438.39520263671875  loc loss 21.954822540283203\n",
      "cls loss 800.8799438476562  loc loss 50.15966033935547\n",
      "cls loss 558.7713623046875  loc loss 25.94182586669922\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 35., 27.])\n",
      "cls loss 757.1322021484375  loc loss 51.61241149902344\n",
      "cls loss 826.7451782226562  loc loss 63.919918060302734\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 649.7511596679688  loc loss 44.458229064941406\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([42.,  1.])\n",
      "cls loss 762.6172485351562  loc loss 64.810302734375\n",
      "cls loss 701.209228515625  loc loss 42.07473373413086\n",
      "cls loss 858.529052734375  loc loss 49.325374603271484\n",
      "cls loss 1091.9708251953125  loc loss 64.45414733886719\n",
      "cls loss 917.439208984375  loc loss 62.44623565673828\n",
      "cls loss 620.865478515625  loc loss 44.49434280395508\n",
      "cls loss 575.1873168945312  loc loss 40.60682678222656\n",
      "cls loss 495.9029235839844  loc loss 18.250492095947266\n",
      "cls loss 678.6027221679688  loc loss 39.085758209228516\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 1., 1.])\n",
      "cls loss 594.8341674804688  loc loss 38.32402420043945\n",
      "cls loss 690.6962280273438  loc loss 53.03380584716797\n",
      "cls loss 764.8211669921875  loc loss 45.31853485107422\n",
      "cls loss 668.920166015625  loc loss 41.53386688232422\n",
      "cls loss 680.3477783203125  loc loss 45.83759307861328\n",
      "cls loss 749.165283203125  loc loss 54.64156723022461\n",
      "cls loss 1072.990234375  loc loss 62.63690948486328\n",
      "cls loss 936.3793334960938  loc loss 67.51599884033203\n",
      "cls loss 839.2135620117188  loc loss 49.204742431640625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 688.3955688476562  loc loss 48.01799774169922\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 941.5194091796875  loc loss 34.25312042236328\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([81.])\n",
      "cls loss 957.2689208984375  loc loss 62.85361862182617\n",
      "cls loss 599.8204345703125  loc loss 40.5427360534668\n",
      "cls loss 549.72509765625  loc loss 27.938268661499023\n",
      "cls loss 748.5279541015625  loc loss 32.58763885498047\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3.,  1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 19.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 19.])\n",
      "cls loss 864.7645874023438  loc loss 59.119937896728516\n",
      "cls loss 590.3307495117188  loc loss 23.693105697631836\n",
      "cls loss 547.29345703125  loc loss 29.81884765625\n",
      "cls loss 957.7327880859375  loc loss 72.36598205566406\n",
      "cls loss 540.1929321289062  loc loss 32.446441650390625\n",
      "cls loss 668.3621215820312  loc loss 46.84736251831055\n",
      "cls loss 720.3502197265625  loc loss 55.287296295166016\n",
      "cls loss 604.4630126953125  loc loss 41.975425720214844\n",
      "cls loss 787.9591064453125  loc loss 47.060150146484375\n",
      "cls loss 841.258544921875  loc loss 60.37030792236328\n",
      "cls loss 1048.526123046875  loc loss 90.19365692138672\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 81.])\n",
      "cls loss 729.8524169921875  loc loss 43.38438415527344\n",
      "cls loss 738.920166015625  loc loss 36.89152526855469\n",
      "cls loss 764.2070922851562  loc loss 42.302207946777344\n",
      "cls loss 613.2164916992188  loc loss 28.20824432373047\n",
      "cls loss 572.11572265625  loc loss 31.92583465576172\n",
      "cls loss 650.8139038085938  loc loss 41.22746276855469\n",
      "cls loss 514.1123657226562  loc loss 35.826751708984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 459.4467468261719  loc loss 29.215391159057617\n",
      "cls loss 573.874755859375  loc loss 38.468833923339844\n",
      "cls loss 756.2866821289062  loc loss 46.5713005065918\n",
      "cls loss 664.7060546875  loc loss 43.053524017333984\n",
      "cls loss 705.2789306640625  loc loss 44.042274475097656\n",
      "cls loss 418.8412780761719  loc loss 27.771873474121094\n",
      "cls loss 1270.079833984375  loc loss 89.3572006225586\n",
      "cls loss 836.42919921875  loc loss 60.63380813598633\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 699.2196655273438  loc loss 42.2982063293457\n",
      "cls loss 746.917724609375  loc loss 52.855796813964844\n",
      "cls loss 660.596923828125  loc loss 33.779998779296875\n",
      "cls loss 796.57861328125  loc loss 53.44072341918945\n",
      "cls loss 812.8916015625  loc loss 55.86902618408203\n",
      "cls loss 749.0022583007812  loc loss 47.66718673706055\n",
      "cls loss 690.8018798828125  loc loss 34.64338302612305\n",
      "cls loss 524.2862548828125  loc loss 28.252639770507812\n",
      "cls loss 660.0345458984375  loc loss 44.73781204223633\n",
      "cls loss 735.4827880859375  loc loss 54.43303298950195\n",
      "cls loss 865.201416015625  loc loss 40.59749221801758\n",
      "cls loss 1020.6084594726562  loc loss 67.10697937011719\n",
      "cls loss 1075.863525390625  loc loss 71.58416748046875\n",
      "cls loss 828.1197509765625  loc loss 45.16124725341797\n",
      "cls loss 860.6356811523438  loc loss 71.14539337158203\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1., 38., 47.,  1.,  1.,  1.,  1.,  1., 62.])\n",
      "cls loss 659.0953369140625  loc loss 36.78791046142578\n",
      "cls loss 850.4779052734375  loc loss 46.436927795410156\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 849.8330078125  loc loss 51.9879150390625\n",
      "cls loss 1175.16552734375  loc loss 67.32693481445312\n",
      "cls loss 649.61767578125  loc loss 34.376407623291016\n",
      "cls loss 716.2727661132812  loc loss 56.21873092651367\n",
      "cls loss 669.8748779296875  loc loss 44.600189208984375\n",
      "cls loss 517.812744140625  loc loss 19.59302520751953\n",
      "cls loss 641.9798583984375  loc loss 40.63544464111328\n",
      "cls loss 584.6885986328125  loc loss 28.73163604736328\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1., 35.])\n",
      "cls loss 624.6463623046875  loc loss 34.4644889831543\n",
      "cls loss 1013.022705078125  loc loss 54.967811584472656\n",
      "cls loss 921.8040771484375  loc loss 57.18147659301758\n",
      "cls loss 792.3363037109375  loc loss 64.6681900024414\n",
      "cls loss 662.9570922851562  loc loss 51.140357971191406\n",
      "cls loss 791.277099609375  loc loss 60.77705001831055\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 462.0216064453125  loc loss 28.742156982421875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 751.6336669921875  loc loss 37.92502212524414\n",
      "cls loss 1145.82568359375  loc loss 68.62007904052734\n",
      "cls loss 1288.091796875  loc loss 95.09396362304688\n",
      "cls loss 773.2420043945312  loc loss 39.04224395751953\n",
      "cls loss 607.1890869140625  loc loss 36.05110168457031\n",
      "cls loss 622.80517578125  loc loss 39.19416046142578\n",
      "cls loss 632.1595458984375  loc loss 54.32676696777344\n",
      "cls loss 638.81396484375  loc loss 27.977642059326172\n",
      "cls loss 963.6786499023438  loc loss 74.49888610839844\n",
      "cls loss 855.079833984375  loc loss 49.73298645019531\n",
      "cls loss 579.0806274414062  loc loss 28.62368392944336\n",
      "cls loss 934.9520263671875  loc loss 47.8415412902832\n",
      "cls loss 1084.465576171875  loc loss 74.66717529296875\n",
      "cls loss 908.499755859375  loc loss 53.483741760253906\n",
      "cls loss 887.4285888671875  loc loss 41.36721420288086\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.])\n",
      "cls loss 809.9215087890625  loc loss 50.598236083984375\n",
      "cls loss 701.2164916992188  loc loss 45.1206169128418\n",
      "cls loss 1033.0352783203125  loc loss 55.14519119262695\n",
      "cls loss 1181.616455078125  loc loss 102.01487731933594\n",
      "cls loss 696.4006958007812  loc loss 29.22164535522461\n",
      "cls loss 702.5037841796875  loc loss 41.592098236083984\n",
      "cls loss 617.774169921875  loc loss 36.587982177734375\n",
      "cls loss 652.694580078125  loc loss 39.252349853515625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 21., 21., 21.])\n",
      "cls loss 693.7657470703125  loc loss 39.86116027832031\n",
      "cls loss 710.0433349609375  loc loss 33.18629455566406\n",
      "cls loss 684.4426879882812  loc loss 41.923301696777344\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 35.])\n",
      "cls loss 1028.67431640625  loc loss 66.57389831542969\n",
      "cls loss 356.6687927246094  loc loss 19.891014099121094\n",
      "cls loss 549.21728515625  loc loss 36.344051361083984\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 528.2304077148438  loc loss 34.422096252441406\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 38., 38.,  9., 38.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1.,  1.])\n",
      "cls loss 545.3917236328125  loc loss 42.111637115478516\n",
      "cls loss 912.434814453125  loc loss 70.36027526855469\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 2.,  1., 77., 31., 10., 10.,  1.,  4., 10.])\n",
      "cls loss 571.7176513671875  loc loss 31.217266082763672\n",
      "cls loss 937.5487670898438  loc loss 54.329345703125\n",
      "cls loss 1691.0126953125  loc loss 129.05897521972656\n",
      "cls loss 577.4149169921875  loc loss 36.92276382446289\n",
      "cls loss 775.395751953125  loc loss 67.95569610595703\n",
      "cls loss 647.498291015625  loc loss 35.637298583984375\n",
      "cls loss 651.2088012695312  loc loss 32.46207046508789\n",
      "cls loss 863.4207763671875  loc loss 40.92230987548828\n",
      "cls loss 878.1539916992188  loc loss 49.92985916137695\n",
      "cls loss 808.31591796875  loc loss 50.42860794067383\n",
      "cls loss 669.4384765625  loc loss 30.097427368164062\n",
      "cls loss 909.888671875  loc loss 34.17618942260742\n",
      "cls loss 1517.5272216796875  loc loss 75.31019592285156\n",
      "cls loss 1104.5390625  loc loss 71.80547332763672\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1., 42., 42., 42., 42., 42., 42.,  1.,\n",
      "         1.,  1.,  1., 42.,  1.,  1., 42.,  1.])\n",
      "cls loss 680.0301513671875  loc loss 44.08832931518555\n",
      "cls loss 893.3092041015625  loc loss 56.9936637878418\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.])\n",
      "cls loss 460.93798828125  loc loss 28.68857192993164\n",
      "cls loss 825.64501953125  loc loss 60.323307037353516\n",
      "cls loss 676.959228515625  loc loss 47.6949348449707\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([11.])\n",
      "cls loss 456.532958984375  loc loss 23.311424255371094\n",
      "cls loss 650.0166625976562  loc loss 25.823490142822266\n",
      "cls loss 612.4132080078125  loc loss 30.581369400024414\n",
      "cls loss 748.517578125  loc loss 50.1552734375\n",
      "cls loss 695.6627197265625  loc loss 46.92704772949219\n",
      "cls loss 719.980712890625  loc loss 54.710723876953125\n",
      "cls loss 984.8895263671875  loc loss 62.579132080078125\n",
      "cls loss 566.022216796875  loc loss 37.39195251464844\n",
      "cls loss 1001.4356689453125  loc loss 82.32473754882812\n",
      "cls loss 625.3046875  loc loss 33.94757843017578\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 531.1275024414062  loc loss 35.57227325439453\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1., 38., 38., 42.])\n",
      "cls loss 676.7730712890625  loc loss 51.787696838378906\n",
      "cls loss 641.173095703125  loc loss 33.79783630371094\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 574.808837890625  loc loss 38.37100601196289\n",
      "cls loss 1175.736572265625  loc loss 83.82852935791016\n",
      "cls loss 730.682373046875  loc loss 53.15920639038086\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10.,  3.,  3.,  6.,  8.,  8.,  1.,  1.,  1., 10.])\n",
      "cls loss 721.1109619140625  loc loss 41.94194030761719\n",
      "cls loss 424.66259765625  loc loss 16.1317138671875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10.,  3.])\n",
      "cls loss 708.2667236328125  loc loss 34.55105972290039\n",
      "cls loss 418.5506591796875  loc loss 22.160533905029297\n",
      "cls loss 727.0421142578125  loc loss 57.65240478515625\n",
      "cls loss 779.9422607421875  loc loss 54.891902923583984\n",
      "cls loss 594.5213623046875  loc loss 34.766353607177734\n",
      "cls loss 619.6891479492188  loc loss 22.525440216064453\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 34.])\n",
      "cls loss 1075.388916015625  loc loss 60.39457702636719\n",
      "cls loss 1099.7427978515625  loc loss 84.90780639648438\n",
      "cls loss 744.2669677734375  loc loss 58.443809509277344\n",
      "cls loss 528.02783203125  loc loss 38.912620544433594\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.,  1.])\n",
      "cls loss 682.1456298828125  loc loss 31.862396240234375\n",
      "cls loss 924.1868286132812  loc loss 74.64311218261719\n",
      "cls loss 1341.5858154296875  loc loss 95.11306762695312\n",
      "cls loss 1130.068603515625  loc loss 66.59022521972656\n",
      "cls loss 663.14892578125  loc loss 43.70775604248047\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 956.78857421875  loc loss 46.313720703125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10.])\n",
      "cls loss 518.7528686523438  loc loss 30.88434410095215\n",
      "cls loss 698.1273803710938  loc loss 38.496315002441406\n",
      "cls loss 832.0324096679688  loc loss 39.42436218261719\n",
      "cls loss 533.7930908203125  loc loss 30.542238235473633\n",
      "cls loss 633.9415893554688  loc loss 46.701419830322266\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21.,\n",
      "        21.])\n",
      "cls loss 863.3258056640625  loc loss 53.57276916503906\n",
      "cls loss 752.5081787109375  loc loss 50.47233581542969\n",
      "cls loss 551.3125610351562  loc loss 21.293859481811523\n",
      "cls loss 942.8944702148438  loc loss 59.36029052734375\n",
      "cls loss 709.6151123046875  loc loss 54.286216735839844\n",
      "cls loss 537.7083129882812  loc loss 35.108558654785156\n",
      "cls loss 1072.150146484375  loc loss 83.20489501953125\n",
      "cls loss 1220.5191650390625  loc loss 89.12471771240234\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15., 85.])\n",
      "cls loss 910.06640625  loc loss 56.348175048828125\n",
      "cls loss 768.5491333007812  loc loss 66.24374389648438\n",
      "cls loss 986.055908203125  loc loss 60.39057159423828\n",
      "cls loss 813.966552734375  loc loss 53.44118118286133\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 8., 8.])\n",
      "cls loss 476.84454345703125  loc loss 27.865846633911133\n",
      "cls loss 653.208251953125  loc loss 37.562931060791016\n",
      "cls loss 727.600341796875  loc loss 41.86589050292969\n",
      "cls loss 601.4473876953125  loc loss 33.96472930908203\n",
      "cls loss 688.6022338867188  loc loss 42.10044860839844\n",
      "cls loss 947.741455078125  loc loss 49.46381378173828\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1., 35., 27., 27.,  1., 27.,  1.])\n",
      "cls loss 1268.90234375  loc loss 82.73974609375\n",
      "cls loss 557.984619140625  loc loss 43.40058135986328\n",
      "cls loss 704.6607666015625  loc loss 48.75\n",
      "cls loss 636.4730224609375  loc loss 53.58744812011719\n",
      "cls loss 684.993408203125  loc loss 48.31977081298828\n",
      "cls loss 703.9716796875  loc loss 51.51937484741211\n",
      "cls loss 623.618896484375  loc loss 49.35029220581055\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  2.,  2.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  2.,  2.])\n",
      "cls loss 423.25518798828125  loc loss 18.299007415771484\n",
      "cls loss 998.7330322265625  loc loss 60.59789276123047\n",
      "cls loss 686.6895141601562  loc loss 37.07474899291992\n",
      "cls loss 1049.6846923828125  loc loss 77.22567749023438\n",
      "cls loss 495.52294921875  loc loss 31.40428924560547\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 19., 19., 19., 16.])\n",
      "cls loss 516.27490234375  loc loss 27.823259353637695\n",
      "cls loss 450.2086181640625  loc loss 19.224994659423828\n",
      "cls loss 620.0794677734375  loc loss 30.378555297851562\n",
      "cls loss 774.297607421875  loc loss 48.401058197021484\n",
      "cls loss 406.09515380859375  loc loss 31.77384376525879\n",
      "cls loss 906.10546875  loc loss 60.63111114501953\n",
      "cls loss 596.9332275390625  loc loss 46.963104248046875\n",
      "cls loss 693.99853515625  loc loss 45.88056945800781\n",
      "cls loss 821.2593383789062  loc loss 57.84588623046875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 945.7828979492188  loc loss 45.63979721069336\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 1179.92578125  loc loss 94.64076232910156\n",
      "cls loss 1441.2672119140625  loc loss 138.33804321289062\n",
      "cls loss 678.3961791992188  loc loss 51.861846923828125\n",
      "cls loss 605.19921875  loc loss 46.203739166259766\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3.,  3.,  3.,  3.,  3., 10.])\n",
      "cls loss 407.93511962890625  loc loss 18.19519805908203\n",
      "cls loss 653.52490234375  loc loss 43.200294494628906\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 1., 1., 1., 3., 3., 3., 3.])\n",
      "cls loss 669.0244140625  loc loss 42.296966552734375\n",
      "cls loss 1068.048095703125  loc loss 85.2285385131836\n",
      "cls loss 795.343505859375  loc loss 58.768001556396484\n",
      "cls loss 664.8261108398438  loc loss 37.29708480834961\n",
      "cls loss 955.9951171875  loc loss 68.52435302734375\n",
      "cls loss 686.2724609375  loc loss 43.286991119384766\n",
      "cls loss 974.612060546875  loc loss 64.86766052246094\n",
      "cls loss 686.3637084960938  loc loss 57.36412048339844\n",
      "cls loss 776.9869995117188  loc loss 46.83074951171875\n",
      "cls loss 1310.9844970703125  loc loss 112.95146942138672\n",
      "cls loss 935.9329833984375  loc loss 61.719844818115234\n",
      "cls loss 646.7925415039062  loc loss 31.125619888305664\n",
      "cls loss 452.0106201171875  loc loss 19.43634796142578\n",
      "cls loss 481.55145263671875  loc loss 28.398250579833984\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3., 10., 10., 10., 10., 10., 10., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10., 10., 10., 10., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 11., 10., 10., 10., 10., 10.,  3.,  3.,  3.,  3.,  3.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 11., 10., 10., 10., 10., 10.,  3.,  3.,  3.,  3.,  3.])\n",
      "cls loss 477.7399597167969  loc loss 24.72344970703125\n",
      "cls loss 624.8814697265625  loc loss 28.793659210205078\n",
      "cls loss 500.73883056640625  loc loss 28.580583572387695\n",
      "cls loss 472.8648681640625  loc loss 21.104961395263672\n",
      "cls loss 546.4737548828125  loc loss 41.42512893676758\n",
      "cls loss 537.21435546875  loc loss 20.991361618041992\n",
      "cls loss 831.1761474609375  loc loss 62.036556243896484\n",
      "cls loss 722.9588012695312  loc loss 56.45547103881836\n",
      "cls loss 1124.9522705078125  loc loss 74.5752944946289\n",
      "cls loss 544.6785278320312  loc loss 39.97913360595703\n",
      "cls loss 955.0636596679688  loc loss 67.5947036743164\n",
      "cls loss 816.999267578125  loc loss 58.583465576171875\n",
      "cls loss 735.23974609375  loc loss 51.533958435058594\n",
      "cls loss 727.3068237304688  loc loss 57.41142654418945\n",
      "cls loss 988.7102661132812  loc loss 71.04469299316406\n",
      "cls loss 944.5880737304688  loc loss 64.55577087402344\n",
      "cls loss 541.3987426757812  loc loss 27.996477127075195\n",
      "cls loss 838.724609375  loc loss 65.03742218017578\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 10.,  1., 18.])\n",
      "cls loss 486.14935302734375  loc loss 33.37544250488281\n",
      "cls loss 563.2037353515625  loc loss 20.95642852783203\n",
      "cls loss 983.3359375  loc loss 45.95580291748047\n",
      "cls loss 1208.4061279296875  loc loss 82.59677124023438\n",
      "cls loss 950.4374389648438  loc loss 50.6800651550293\n",
      "cls loss 1060.5142822265625  loc loss 65.42587280273438\n",
      "cls loss 854.0673828125  loc loss 49.47482681274414\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.,  1.,  1.])\n",
      "cls loss 986.6439208984375  loc loss 67.25050354003906\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1., 38.,  1.])\n",
      "cls loss 974.185791015625  loc loss 55.03646469116211\n",
      "cls loss 1182.0352783203125  loc loss 88.35690307617188\n",
      "cls loss 615.1980590820312  loc loss 48.53482437133789\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 767.2445068359375  loc loss 54.95673370361328\n",
      "cls loss 758.6900634765625  loc loss 47.81175994873047\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3., 10.,  8.,  3., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.])\n",
      "cls loss 816.135009765625  loc loss 53.51304626464844\n",
      "cls loss 589.89697265625  loc loss 38.03460693359375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3.,  3., 11.,  3., 10., 10.,  3.,  3., 10.])\n",
      "cls loss 746.2935180664062  loc loss 40.62677764892578\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3., 10., 10., 10.])\n",
      "cls loss 664.9434204101562  loc loss 53.18320846557617\n",
      "cls loss 601.897705078125  loc loss 35.60382080078125\n",
      "cls loss 659.2131958007812  loc loss 52.1641845703125\n",
      "cls loss 1046.6624755859375  loc loss 70.27735900878906\n",
      "cls loss 681.44677734375  loc loss 49.218910217285156\n",
      "cls loss 466.95587158203125  loc loss 41.62494659423828\n",
      "cls loss 613.822509765625  loc loss 43.3661994934082\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 9.,  9., 85., 85.])\n",
      "cls loss 562.4583740234375  loc loss 33.53962707519531\n",
      "cls loss 687.6008911132812  loc loss 44.654510498046875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 1019.5105590820312  loc loss 79.53624725341797\n",
      "cls loss 926.30615234375  loc loss 50.91825485229492\n",
      "cls loss 1072.836181640625  loc loss 73.35725402832031\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10., 10., 10., 10.])\n",
      "cls loss 648.8921508789062  loc loss 40.553802490234375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([13.])\n",
      "cls loss 994.377685546875  loc loss 89.9691162109375\n",
      "cls loss 432.59942626953125  loc loss 20.762269973754883\n",
      "cls loss 475.06707763671875  loc loss 25.657047271728516\n",
      "cls loss 672.2323608398438  loc loss 39.04049301147461\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19.,  1.,  1.,  1., 19., 19.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 757.4122314453125  loc loss 42.099124908447266\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 489.78717041015625  loc loss 44.3372688293457\n",
      "cls loss 769.3494873046875  loc loss 58.36556625366211\n",
      "cls loss 529.999755859375  loc loss 34.38688659667969\n",
      "cls loss 823.9339599609375  loc loss 54.19139099121094\n",
      "cls loss 898.60498046875  loc loss 67.13141632080078\n",
      "cls loss 743.959716796875  loc loss 40.9124641418457\n",
      "cls loss 960.0059814453125  loc loss 73.00314331054688\n",
      "cls loss 489.3408203125  loc loss 20.381229400634766\n",
      "cls loss 698.9247436523438  loc loss 48.27677917480469\n",
      "cls loss 648.411865234375  loc loss 30.035242080688477\n",
      "cls loss 567.50634765625  loc loss 33.11202621459961\n",
      "cls loss 782.5271606445312  loc loss 58.74909973144531\n",
      "cls loss 774.0146484375  loc loss 43.42943572998047\n",
      "cls loss 1115.122802734375  loc loss 64.91893768310547\n",
      "cls loss 667.0838623046875  loc loss 47.0185432434082\n",
      "cls loss 756.4606323242188  loc loss 54.71607971191406\n",
      "cls loss 1108.884765625  loc loss 78.98524475097656\n",
      "cls loss 662.8343505859375  loc loss 53.45558547973633\n",
      "cls loss 766.5302734375  loc loss 46.266841888427734\n",
      "cls loss 1049.71044921875  loc loss 70.02790832519531\n",
      "cls loss 937.3729248046875  loc loss 69.59902954101562\n",
      "cls loss 1213.9931640625  loc loss 75.18048095703125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 5.])\n",
      "cls loss 442.9440612792969  loc loss 14.322277069091797\n",
      "cls loss 478.25469970703125  loc loss 24.05316162109375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 13.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 6., 8., 8.])\n",
      "cls loss 494.797119140625  loc loss 20.188129425048828\n",
      "cls loss 530.3018798828125  loc loss 29.660537719726562\n",
      "cls loss 942.7532958984375  loc loss 77.57574462890625\n",
      "cls loss 546.00537109375  loc loss 21.924467086791992\n",
      "cls loss 776.1455078125  loc loss 56.88355255126953\n",
      "cls loss 1261.2000732421875  loc loss 74.41328430175781\n",
      "cls loss 745.6514892578125  loc loss 50.166996002197266\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([42., 42.,  1.,  1.,  1.,  1.,  1.,  1.,  1., 42., 42.])\n",
      "cls loss 835.306640625  loc loss 47.22555160522461\n",
      "cls loss 1032.4822998046875  loc loss 77.3827896118164\n",
      "cls loss 790.0704345703125  loc loss 62.11822509765625\n",
      "cls loss 625.8023681640625  loc loss 33.00202560424805\n",
      "cls loss 803.472412109375  loc loss 48.05656814575195\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 1095.9732666015625  loc loss 67.2386474609375\n",
      "cls loss 835.5830078125  loc loss 59.931358337402344\n",
      "cls loss 553.1629638671875  loc loss 33.191993713378906\n",
      "cls loss 548.3297119140625  loc loss 27.0200138092041\n",
      "cls loss 629.3232421875  loc loss 41.238311767578125\n",
      "cls loss 885.3890991210938  loc loss 56.1715087890625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15.])\n",
      "cls loss 445.09210205078125  loc loss 23.414073944091797\n",
      "cls loss 685.331298828125  loc loss 44.4714241027832\n",
      "cls loss 598.597900390625  loc loss 39.53020477294922\n",
      "cls loss 973.4033203125  loc loss 75.36992645263672\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19.,  7.])\n",
      "cls loss 633.2010498046875  loc loss 39.26184844970703\n",
      "cls loss 1284.923583984375  loc loss 76.81119537353516\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 1042.9100341796875  loc loss 61.7545166015625\n",
      "cls loss 819.338134765625  loc loss 63.42030334472656\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([38., 38.,  1., 18.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1., 18., 18.,  1.])\n",
      "cls loss 648.6571655273438  loc loss 35.64839553833008\n",
      "cls loss 695.857177734375  loc loss 31.300434112548828\n",
      "cls loss 956.568115234375  loc loss 84.62521362304688\n",
      "cls loss 807.3017578125  loc loss 51.8302116394043\n",
      "cls loss 862.2245483398438  loc loss 42.24292755126953\n",
      "cls loss 482.8261413574219  loc loss 36.642330169677734\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.])\n",
      "cls loss 384.39654541015625  loc loss 18.08783531188965\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([32.])\n",
      "cls loss 786.21923828125  loc loss 36.22420883178711\n",
      "cls loss 681.875244140625  loc loss 40.0127067565918\n",
      "cls loss 811.2392578125  loc loss 69.17345428466797\n",
      "cls loss 812.0697631835938  loc loss 47.63081359863281\n",
      "cls loss 629.387451171875  loc loss 43.953853607177734\n",
      "cls loss 1051.8388671875  loc loss 57.752708435058594\n",
      "cls loss 998.981201171875  loc loss 72.60770416259766\n",
      "cls loss 839.9089965820312  loc loss 60.16389846801758\n",
      "cls loss 894.236572265625  loc loss 43.25843811035156\n",
      "cls loss 1199.033935546875  loc loss 72.01386260986328\n",
      "cls loss 752.4249267578125  loc loss 34.74456024169922\n",
      "cls loss 1053.084716796875  loc loss 85.73968505859375\n",
      "cls loss 816.7840576171875  loc loss 49.78202819824219\n",
      "cls loss 631.016845703125  loc loss 48.93355178833008\n",
      "cls loss 547.091552734375  loc loss 29.862838745117188\n",
      "cls loss 540.8284301757812  loc loss 37.78850555419922\n",
      "cls loss 817.6629638671875  loc loss 58.08821105957031\n",
      "cls loss 841.3182373046875  loc loss 64.0498046875\n",
      "cls loss 488.5486755371094  loc loss 33.49744415283203\n",
      "cls loss 947.2047729492188  loc loss 63.166481018066406\n",
      "cls loss 1090.126953125  loc loss 69.7961196899414\n",
      "cls loss 426.3295593261719  loc loss 27.511045455932617\n",
      "cls loss 1041.968994140625  loc loss 73.87519073486328\n",
      "cls loss 717.5531005859375  loc loss 58.28855895996094\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 981.6131591796875  loc loss 77.92465209960938\n",
      "cls loss 512.679931640625  loc loss 22.4246883392334\n",
      "cls loss 734.1767578125  loc loss 45.714393615722656\n",
      "cls loss 782.6154174804688  loc loss 51.242462158203125\n",
      "cls loss 566.5999755859375  loc loss 39.750022888183594\n",
      "cls loss 428.85894775390625  loc loss 19.816791534423828\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 9., 9., 1., 9., 9., 9., 9., 1., 9.])\n",
      "cls loss 1337.158447265625  loc loss 113.85164642333984\n",
      "cls loss 810.1781005859375  loc loss 45.64921188354492\n",
      "cls loss 1167.3193359375  loc loss 92.87401580810547\n",
      "cls loss 591.9674682617188  loc loss 33.36769104003906\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 42., 42.])\n",
      "cls loss 869.4334106445312  loc loss 62.68387985229492\n",
      "cls loss 921.3568115234375  loc loss 63.12723159790039\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  2.,  1.,  1.,  1., 38.,\n",
      "         1.,  1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 38., 38., 38.,  1., 38., 38., 38.,  1.,  1., 38.,  1.,\n",
      "         1.])\n",
      "cls loss 716.7113037109375  loc loss 36.338165283203125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  8.,  8.])\n",
      "cls loss 1310.3419189453125  loc loss 80.68978881835938\n",
      "cls loss 1219.864501953125  loc loss 82.56269836425781\n",
      "cls loss 557.0989990234375  loc loss 30.063867568969727\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([4., 1., 1., 4.])\n",
      "cls loss 772.53515625  loc loss 50.666282653808594\n",
      "cls loss 867.214111328125  loc loss 52.961387634277344\n",
      "cls loss 427.9109802246094  loc loss 19.70102310180664\n",
      "cls loss 592.911865234375  loc loss 31.40760612487793\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([51.,  1.])\n",
      "cls loss 434.6020202636719  loc loss 17.858963012695312\n",
      "cls loss 517.388427734375  loc loss 32.64528274536133\n",
      "cls loss 869.6286010742188  loc loss 55.55198669433594\n",
      "cls loss 1023.6102905273438  loc loss 78.44268798828125\n",
      "cls loss 1318.3814697265625  loc loss 82.07920837402344\n",
      "cls loss 1616.41845703125  loc loss 110.08985137939453\n",
      "cls loss 770.3087158203125  loc loss 46.65910339355469\n",
      "cls loss 901.6973876953125  loc loss 69.0438461303711\n",
      "cls loss 1012.6453247070312  loc loss 75.74441528320312\n",
      "cls loss 703.6695556640625  loc loss 43.66099548339844\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  3.,  1.,  1.,  1.,  3.,  1.,  1.,\n",
      "         1.,  1.,  1.])\n",
      "cls loss 791.1663818359375  loc loss 48.17090606689453\n",
      "cls loss 936.8115234375  loc loss 50.30292510986328\n",
      "cls loss 828.489501953125  loc loss 46.321170806884766\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "cls loss 699.4063720703125  loc loss 42.55076599121094\n",
      "cls loss 426.63507080078125  loc loss 32.64529800415039\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3.])\n",
      "cls loss 600.6567993164062  loc loss 20.367753982543945\n",
      "cls loss 725.5469970703125  loc loss 48.95513916015625\n",
      "cls loss 560.1826171875  loc loss 36.45401382446289\n",
      "cls loss 941.8485107421875  loc loss 72.7965316772461\n",
      "cls loss 777.0791015625  loc loss 30.69828987121582\n",
      "cls loss 568.9329223632812  loc loss 36.72456359863281\n",
      "cls loss 1616.773193359375  loc loss 109.9822998046875\n",
      "cls loss 738.0076904296875  loc loss 49.885284423828125\n",
      "cls loss 491.2571105957031  loc loss 41.929283142089844\n",
      "cls loss 723.5457763671875  loc loss 37.47096252441406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 568.664794921875  loc loss 41.74068069458008\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 1017.8305053710938  loc loss 71.39280700683594\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  9., 64., 64., 64., 64., 64., 64., 64., 64., 64.,  9.,  9.,  9.,\n",
      "         9.])\n",
      "cls loss 674.3043212890625  loc loss 33.539310455322266\n",
      "cls loss 1182.06591796875  loc loss 107.8525390625\n",
      "cls loss 724.8986206054688  loc loss 45.85063552856445\n",
      "cls loss 901.8193359375  loc loss 69.56111907958984\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.,  3.,  3.])\n",
      "cls loss 622.625244140625  loc loss 39.03832244873047\n",
      "cls loss 704.1361083984375  loc loss 41.78300857543945\n",
      "cls loss 612.394287109375  loc loss 53.25041198730469\n",
      "cls loss 806.1875  loc loss 47.589805603027344\n",
      "cls loss 765.236083984375  loc loss 57.64369583129883\n",
      "cls loss 667.155029296875  loc loss 51.902000427246094\n",
      "cls loss 687.06689453125  loc loss 50.890960693359375\n",
      "cls loss 707.0474243164062  loc loss 46.032371520996094\n",
      "cls loss 932.6812744140625  loc loss 65.0018539428711\n",
      "cls loss 734.1069946289062  loc loss 50.29679489135742\n",
      "cls loss 632.940185546875  loc loss 30.780683517456055\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21.])\n",
      "cls loss 537.1758422851562  loc loss 22.145854949951172\n",
      "cls loss 625.7080078125  loc loss 54.53997802734375\n",
      "cls loss 823.5411376953125  loc loss 61.24810791015625\n",
      "cls loss 509.6646423339844  loc loss 33.04399108886719\n",
      "cls loss 802.3530883789062  loc loss 48.27101516723633\n",
      "cls loss 1441.894287109375  loc loss 84.4083251953125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 42., 42.,  1.,  1.])\n",
      "cls loss 748.6367797851562  loc loss 39.99274444580078\n",
      "cls loss 509.603759765625  loc loss 32.07402420043945\n",
      "cls loss 666.1521606445312  loc loss 46.26603317260742\n",
      "cls loss 851.5509643554688  loc loss 75.9255599975586\n",
      "cls loss 683.24560546875  loc loss 38.18751525878906\n",
      "cls loss 875.1558837890625  loc loss 61.455322265625\n",
      "cls loss 863.0028076171875  loc loss 62.388099670410156\n",
      "cls loss 864.6551513671875  loc loss 52.786529541015625\n",
      "cls loss 661.3807373046875  loc loss 44.1026496887207\n",
      "cls loss 565.1954956054688  loc loss 37.97520446777344\n",
      "cls loss 565.545166015625  loc loss 23.4334716796875\n",
      "cls loss 631.7279663085938  loc loss 48.278690338134766\n",
      "cls loss 850.868896484375  loc loss 74.60704040527344\n",
      "cls loss 785.0963745117188  loc loss 44.47244644165039\n",
      "cls loss 787.0872192382812  loc loss 57.40790939331055\n",
      "cls loss 836.339599609375  loc loss 44.428123474121094\n",
      "cls loss 1230.1429443359375  loc loss 77.30918884277344\n",
      "cls loss 813.585693359375  loc loss 59.39588928222656\n",
      "cls loss 1016.5552978515625  loc loss 57.6827392578125\n",
      "cls loss 667.41162109375  loc loss 27.946250915527344\n",
      "cls loss 852.4550170898438  loc loss 50.27549743652344\n",
      "cls loss 839.9320068359375  loc loss 48.60396194458008\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 5., 5., 5., 5., 5., 5.])\n",
      "cls loss 524.6423950195312  loc loss 36.606117248535156\n",
      "cls loss 626.0634765625  loc loss 44.06178665161133\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([13.])\n",
      "cls loss 478.0555725097656  loc loss 25.349538803100586\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([44., 10.,  1.,  1.,  1.])\n",
      "cls loss 527.0241088867188  loc loss 27.65638542175293\n",
      "cls loss 826.160888671875  loc loss 46.664669036865234\n",
      "cls loss 692.9649658203125  loc loss 39.19551086425781\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19., 19., 19., 19., 19., 19., 19.])\n",
      "cls loss 860.5165405273438  loc loss 54.16084671020508\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([56.])\n",
      "cls loss 1593.963623046875  loc loss 93.69465637207031\n",
      "cls loss 821.5789794921875  loc loss 64.7255859375\n",
      "cls loss 1186.1201171875  loc loss 80.90325164794922\n",
      "cls loss 1038.0831298828125  loc loss 83.65141296386719\n",
      "cls loss 642.5595703125  loc loss 44.08328628540039\n",
      "cls loss 1127.892333984375  loc loss 78.02133178710938\n",
      "cls loss 727.3837890625  loc loss 37.593807220458984\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 36.])\n",
      "cls loss 782.073486328125  loc loss 45.78761291503906\n",
      "cls loss 645.4266357421875  loc loss 49.239437103271484\n",
      "cls loss 755.56396484375  loc loss 39.74009704589844\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5.])\n",
      "cls loss 738.49609375  loc loss 47.6632080078125\n",
      "cls loss 517.1568603515625  loc loss 26.6497802734375\n",
      "cls loss 963.1004638671875  loc loss 61.624916076660156\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "cls loss 882.2532348632812  loc loss 65.50273132324219\n",
      "cls loss 1013.2647094726562  loc loss 55.3631706237793\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 812.0020141601562  loc loss 57.5804557800293\n",
      "cls loss 1047.309814453125  loc loss 67.16014099121094\n",
      "cls loss 843.545654296875  loc loss 68.65156555175781\n",
      "cls loss 646.6716918945312  loc loss 41.92873001098633\n",
      "cls loss 751.52587890625  loc loss 49.466468811035156\n",
      "cls loss 707.0484008789062  loc loss 46.55073547363281\n",
      "cls loss 1034.5120849609375  loc loss 65.1596450805664\n",
      "cls loss 522.836181640625  loc loss 27.62188720703125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 11., 15., 10., 10., 10., 10., 10.])\n",
      "cls loss 1140.794921875  loc loss 83.36527252197266\n",
      "cls loss 639.9111938476562  loc loss 42.419986724853516\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3.])\n",
      "cls loss 734.6851196289062  loc loss 45.525699615478516\n",
      "cls loss 604.2203369140625  loc loss 37.501136779785156\n",
      "cls loss 665.880859375  loc loss 37.61717987060547\n",
      "cls loss 864.9893798828125  loc loss 48.15988540649414\n",
      "cls loss 578.9103393554688  loc loss 22.80128288269043\n",
      "cls loss 820.2887573242188  loc loss 39.1147575378418\n",
      "cls loss 823.4276123046875  loc loss 55.615928649902344\n",
      "cls loss 661.5792236328125  loc loss 50.49993133544922\n",
      "cls loss 1392.219970703125  loc loss 117.46405029296875\n",
      "cls loss 1051.624755859375  loc loss 78.87998962402344\n",
      "cls loss 764.0392456054688  loc loss 51.91619873046875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  9.,  9.,  9.,  6.,  6., 85., 85.,  8.,  1.,  1.,  1.,  1.,\n",
      "         6.,  6.])\n",
      "cls loss 499.7142333984375  loc loss 33.428131103515625\n",
      "cls loss 1169.6285400390625  loc loss 79.17472839355469\n",
      "cls loss 1294.187744140625  loc loss 87.23899841308594\n",
      "cls loss 879.9602661132812  loc loss 63.82860565185547\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10.,  3.,  3., 10.])\n",
      "cls loss 547.5259399414062  loc loss 35.41639709472656\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([7.])\n",
      "cls loss 789.5316162109375  loc loss 63.88893127441406\n",
      "cls loss 760.229248046875  loc loss 48.210052490234375\n",
      "cls loss 756.5537109375  loc loss 53.58429718017578\n",
      "cls loss 1038.06884765625  loc loss 79.56661987304688\n",
      "cls loss 795.262451171875  loc loss 49.865570068359375\n",
      "cls loss 1055.253173828125  loc loss 68.0212173461914\n",
      "cls loss 1198.69580078125  loc loss 80.06523132324219\n",
      "cls loss 848.3609619140625  loc loss 51.99049758911133\n",
      "cls loss 818.45556640625  loc loss 59.02056884765625\n",
      "cls loss 715.5015869140625  loc loss 48.70957946777344\n",
      "cls loss 894.1189575195312  loc loss 76.68843078613281\n",
      "cls loss 877.9456787109375  loc loss 52.45305633544922\n",
      "cls loss 657.4173583984375  loc loss 36.42913818359375\n",
      "cls loss 916.260986328125  loc loss 74.895751953125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([62.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([62.])\n",
      "cls loss 417.6502990722656  loc loss 24.18946647644043\n",
      "cls loss 698.08935546875  loc loss 55.628814697265625\n",
      "cls loss 750.46435546875  loc loss 48.03665542602539\n",
      "cls loss 596.5154418945312  loc loss 25.507221221923828\n",
      "cls loss 902.1126098632812  loc loss 68.38778686523438\n",
      "cls loss 888.0218505859375  loc loss 57.765586853027344\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([28.])\n",
      "cls loss 938.6864013671875  loc loss 57.59174728393555\n",
      "cls loss 920.12890625  loc loss 59.84815216064453\n",
      "cls loss 867.0916137695312  loc loss 57.85139083862305\n",
      "cls loss 897.41357421875  loc loss 63.9195671081543\n",
      "cls loss 1193.8270263671875  loc loss 88.09600830078125\n",
      "cls loss 724.093994140625  loc loss 44.81633758544922\n",
      "cls loss 851.3907470703125  loc loss 53.166751861572266\n",
      "cls loss 857.815673828125  loc loss 66.9957504272461\n",
      "cls loss 1298.252685546875  loc loss 90.03559112548828\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([81.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 939.6668701171875  loc loss 47.095603942871094\n",
      "cls loss 803.8223266601562  loc loss 34.73941421508789\n",
      "cls loss 595.34326171875  loc loss 36.913185119628906\n",
      "cls loss 551.5819091796875  loc loss 24.278535842895508\n",
      "cls loss 616.2020263671875  loc loss 37.093841552734375\n",
      "cls loss 575.0133666992188  loc loss 39.534034729003906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 720.5812377929688  loc loss 42.90199279785156\n",
      "cls loss 916.0283813476562  loc loss 68.70826721191406\n",
      "cls loss 1021.4345092773438  loc loss 61.95729064941406\n",
      "cls loss 1809.92333984375  loc loss 127.0008544921875\n",
      "cls loss 705.6519775390625  loc loss 37.21149826049805\n",
      "cls loss 775.4681396484375  loc loss 59.374794006347656\n",
      "cls loss 571.7000732421875  loc loss 45.44912338256836\n",
      "cls loss 822.9866943359375  loc loss 45.48257064819336\n",
      "cls loss 735.78564453125  loc loss 42.931121826171875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([44., 44.])\n",
      "cls loss 602.7042236328125  loc loss 33.50471878051758\n",
      "cls loss 670.1984252929688  loc loss 44.972740173339844\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15.])\n",
      "cls loss 784.6889038085938  loc loss 44.29472351074219\n",
      "cls loss 375.37640380859375  loc loss 21.732887268066406\n",
      "cls loss 770.006591796875  loc loss 50.399620056152344\n",
      "cls loss 502.30340576171875  loc loss 27.96206283569336\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([1., 3., 3.])\n",
      "cls loss 487.23785400390625  loc loss 40.03643035888672\n",
      "cls loss 470.9443359375  loc loss 20.66992950439453\n",
      "cls loss 816.8213500976562  loc loss 43.474849700927734\n",
      "cls loss 800.0027465820312  loc loss 48.29350280761719\n",
      "cls loss 803.98291015625  loc loss 45.10984420776367\n",
      "cls loss 765.2343139648438  loc loss 50.329185485839844\n",
      "cls loss 646.4117431640625  loc loss 46.600372314453125\n",
      "cls loss 768.8282470703125  loc loss 53.78975296020508\n",
      "cls loss 714.3685302734375  loc loss 44.51165771484375\n",
      "cls loss 768.0633544921875  loc loss 60.4882698059082\n",
      "cls loss 461.0359191894531  loc loss 31.228191375732422\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 974.859375  loc loss 55.87076187133789\n",
      "cls loss 1041.8848876953125  loc loss 61.1153564453125\n",
      "cls loss 929.3214111328125  loc loss 68.85682678222656\n",
      "cls loss 937.2464599609375  loc loss 61.68567657470703\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10., 10., 10.,  1.,  1.,  1.,  1.,  1.,  1.,  8.,  8.,\n",
      "         1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10., 10., 10.,  1.,  1.,  1.,  1.,  1.,  1.,  8.,  8.,\n",
      "         1.])\n",
      "cls loss 964.6548461914062  loc loss 54.54039764404297\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 3., 3., 3.])\n",
      "cls loss 739.6546020507812  loc loss 44.76860427856445\n",
      "cls loss 542.9830932617188  loc loss 29.48067855834961\n",
      "cls loss 396.80523681640625  loc loss 23.289880752563477\n",
      "cls loss 652.2210693359375  loc loss 48.78057098388672\n",
      "cls loss 570.4133911132812  loc loss 29.930797576904297\n",
      "cls loss 691.763671875  loc loss 41.71932601928711\n",
      "cls loss 753.9703979492188  loc loss 44.1776123046875\n",
      "cls loss 1028.4979248046875  loc loss 71.34707641601562\n",
      "cls loss 804.4012451171875  loc loss 50.51013946533203\n",
      "cls loss 749.9774169921875  loc loss 50.36916732788086\n",
      "cls loss 871.8358154296875  loc loss 59.58501434326172\n",
      "cls loss 716.1700439453125  loc loss 50.5028076171875\n",
      "cls loss 1060.20703125  loc loss 89.97974395751953\n",
      "cls loss 589.6370849609375  loc loss 35.024803161621094\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 879.6398315429688  loc loss 56.94123077392578\n",
      "cls loss 429.5057373046875  loc loss 24.25726890563965\n",
      "cls loss 1033.186279296875  loc loss 77.83695983886719\n",
      "cls loss 608.7061767578125  loc loss 35.722816467285156\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 34.])\n",
      "cls loss 867.388427734375  loc loss 49.37278747558594\n",
      "cls loss 560.5400390625  loc loss 30.25373649597168\n",
      "cls loss 992.5911865234375  loc loss 53.58183288574219\n",
      "cls loss 408.4846496582031  loc loss 21.587860107421875\n",
      "cls loss 1017.5968017578125  loc loss 54.01624298095703\n",
      "cls loss 825.0193481445312  loc loss 53.293373107910156\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 38.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16., 16., 16.,  9.,  9.,  9., 16., 16., 16., 85.,  9.])\n",
      "cls loss 742.3153076171875  loc loss 43.78285217285156\n",
      "cls loss 775.3544311523438  loc loss 62.256439208984375\n",
      "cls loss 1187.213623046875  loc loss 84.0212631225586\n",
      "cls loss 1483.80908203125  loc loss 111.97589111328125\n",
      "cls loss 506.413818359375  loc loss 23.867464065551758\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3., 10.,  8.,  8., 10., 10., 10.,  3.,  3., 14.])\n",
      "cls loss 648.290771484375  loc loss 29.187904357910156\n",
      "cls loss 944.142333984375  loc loss 54.00899124145508\n",
      "cls loss 376.74652099609375  loc loss 16.567102432250977\n",
      "cls loss 596.247802734375  loc loss 31.60326385498047\n",
      "cls loss 853.8182983398438  loc loss 56.18393325805664\n",
      "cls loss 683.582763671875  loc loss 52.978187561035156\n",
      "cls loss 507.12652587890625  loc loss 27.897676467895508\n",
      "cls loss 530.7740478515625  loc loss 32.26627731323242\n",
      "cls loss 753.3353881835938  loc loss 49.41288757324219\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42., 42.,  1.])\n",
      "cls loss 704.1182861328125  loc loss 51.337398529052734\n",
      "cls loss 700.82666015625  loc loss 38.743927001953125\n",
      "cls loss 864.3985595703125  loc loss 60.936851501464844\n",
      "cls loss 917.93017578125  loc loss 62.18935775756836\n",
      "cls loss 729.3846435546875  loc loss 41.755428314208984\n",
      "cls loss 784.6129760742188  loc loss 59.06004333496094\n",
      "cls loss 575.2940673828125  loc loss 34.246482849121094\n",
      "cls loss 709.9277954101562  loc loss 37.7040901184082\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20.])\n",
      "cls loss 441.43463134765625  loc loss 27.21791648864746\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([11.])\n",
      "cls loss 549.5750122070312  loc loss 29.530534744262695\n",
      "cls loss 438.74560546875  loc loss 23.78375816345215\n",
      "cls loss 806.240966796875  loc loss 71.69135284423828\n",
      "cls loss 400.7034606933594  loc loss 21.173532485961914\n",
      "cls loss 743.5032958984375  loc loss 48.906776428222656\n",
      "cls loss 492.0306091308594  loc loss 25.383209228515625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 35., 27.])\n",
      "cls loss 717.9357299804688  loc loss 49.783409118652344\n",
      "cls loss 775.103759765625  loc loss 62.75962448120117\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 583.8373413085938  loc loss 42.832881927490234\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([42.,  1.])\n",
      "cls loss 732.0194091796875  loc loss 63.0762939453125\n",
      "cls loss 653.7589111328125  loc loss 41.26210021972656\n",
      "cls loss 807.08154296875  loc loss 47.831298828125\n",
      "cls loss 1035.95166015625  loc loss 63.492916107177734\n",
      "cls loss 879.84521484375  loc loss 61.073978424072266\n",
      "cls loss 589.1893920898438  loc loss 43.80970001220703\n",
      "cls loss 542.9838256835938  loc loss 39.52491760253906\n",
      "cls loss 458.0665283203125  loc loss 17.829687118530273\n",
      "cls loss 637.0347900390625  loc loss 38.06208419799805\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 1., 1.])\n",
      "cls loss 578.9798583984375  loc loss 36.6418342590332\n",
      "cls loss 670.113525390625  loc loss 51.787994384765625\n",
      "cls loss 721.4830322265625  loc loss 44.00034713745117\n",
      "cls loss 624.55126953125  loc loss 40.692203521728516\n",
      "cls loss 650.1427612304688  loc loss 44.5540771484375\n",
      "cls loss 722.4490966796875  loc loss 53.524383544921875\n",
      "cls loss 1017.8140869140625  loc loss 60.69862365722656\n",
      "cls loss 895.0348510742188  loc loss 66.17304992675781\n",
      "cls loss 790.9398193359375  loc loss 47.81453323364258\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 636.9080810546875  loc loss 46.893898010253906\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 821.3446044921875  loc loss 33.813716888427734\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([81.])\n",
      "cls loss 900.54541015625  loc loss 60.788787841796875\n",
      "cls loss 560.6488037109375  loc loss 39.21908187866211\n",
      "cls loss 484.5735778808594  loc loss 27.26352882385254\n",
      "cls loss 661.0670166015625  loc loss 31.351045608520508\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3.,  1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 19.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 19.])\n",
      "cls loss 812.542236328125  loc loss 57.25733184814453\n",
      "cls loss 538.5152587890625  loc loss 22.91525650024414\n",
      "cls loss 490.1075439453125  loc loss 29.222501754760742\n",
      "cls loss 905.936767578125  loc loss 70.66505432128906\n",
      "cls loss 495.9794921875  loc loss 31.58236312866211\n",
      "cls loss 613.76025390625  loc loss 45.34986114501953\n",
      "cls loss 687.005615234375  loc loss 53.509525299072266\n",
      "cls loss 561.81982421875  loc loss 41.571773529052734\n",
      "cls loss 743.256103515625  loc loss 46.017730712890625\n",
      "cls loss 798.6491088867188  loc loss 59.10372543334961\n",
      "cls loss 996.4448852539062  loc loss 88.25116729736328\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 81.])\n",
      "cls loss 691.7613525390625  loc loss 41.94284439086914\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 700.3487548828125  loc loss 36.33540344238281\n",
      "cls loss 725.519775390625  loc loss 41.38512420654297\n",
      "cls loss 564.2737426757812  loc loss 27.340471267700195\n",
      "cls loss 534.7313842773438  loc loss 31.12235450744629\n",
      "cls loss 630.9041748046875  loc loss 40.28697967529297\n",
      "cls loss 490.5780029296875  loc loss 34.19121551513672\n",
      "cls loss 419.16986083984375  loc loss 28.141239166259766\n",
      "cls loss 539.4006958007812  loc loss 37.21430969238281\n",
      "cls loss 717.2938842773438  loc loss 45.28306579589844\n",
      "cls loss 615.6405029296875  loc loss 42.2414665222168\n",
      "cls loss 647.778564453125  loc loss 43.54230499267578\n",
      "cls loss 390.28668212890625  loc loss 26.93706703186035\n",
      "cls loss 1189.494384765625  loc loss 86.94596862792969\n",
      "cls loss 790.9558715820312  loc loss 58.71862030029297\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 673.3692016601562  loc loss 40.860626220703125\n",
      "cls loss 701.925048828125  loc loss 51.59919357299805\n",
      "cls loss 605.6319580078125  loc loss 33.135719299316406\n",
      "cls loss 751.7066040039062  loc loss 52.27570724487305\n",
      "cls loss 776.731201171875  loc loss 54.259552001953125\n",
      "cls loss 703.3031005859375  loc loss 46.25231170654297\n",
      "cls loss 644.712158203125  loc loss 33.533939361572266\n",
      "cls loss 491.47674560546875  loc loss 27.45687484741211\n",
      "cls loss 625.856201171875  loc loss 43.632537841796875\n",
      "cls loss 682.9832763671875  loc loss 52.9000129699707\n",
      "cls loss 802.311279296875  loc loss 39.88787841796875\n",
      "cls loss 955.8695678710938  loc loss 66.61729431152344\n",
      "cls loss 1024.273193359375  loc loss 70.13050842285156\n",
      "cls loss 756.4989013671875  loc loss 44.43563461303711\n",
      "cls loss 826.5838012695312  loc loss 69.79973602294922\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1., 38., 47.,  1.,  1.,  1.,  1.,  1., 62.])\n",
      "cls loss 610.181640625  loc loss 36.204620361328125\n",
      "cls loss 790.349853515625  loc loss 45.36490249633789\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 799.26611328125  loc loss 50.74327087402344\n",
      "cls loss 1086.36572265625  loc loss 65.84095001220703\n",
      "cls loss 631.584716796875  loc loss 33.379642486572266\n",
      "cls loss 693.7745361328125  loc loss 54.82102584838867\n",
      "cls loss 631.947998046875  loc loss 43.62877655029297\n",
      "cls loss 476.2636413574219  loc loss 19.113037109375\n",
      "cls loss 604.2363891601562  loc loss 39.400978088378906\n",
      "cls loss 543.8814697265625  loc loss 27.981456756591797\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1., 35.])\n",
      "cls loss 583.1943359375  loc loss 33.31303405761719\n",
      "cls loss 946.0308227539062  loc loss 53.1041259765625\n",
      "cls loss 863.6214599609375  loc loss 56.1093635559082\n",
      "cls loss 760.29541015625  loc loss 63.321205139160156\n",
      "cls loss 628.58154296875  loc loss 50.11656188964844\n",
      "cls loss 746.9223022460938  loc loss 59.009403228759766\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 431.642822265625  loc loss 28.09795379638672\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 699.5303955078125  loc loss 36.26762390136719\n",
      "cls loss 1087.786376953125  loc loss 66.40373229980469\n",
      "cls loss 1241.949462890625  loc loss 93.02462005615234\n",
      "cls loss 721.5931396484375  loc loss 37.75920104980469\n",
      "cls loss 574.1766357421875  loc loss 35.20637512207031\n",
      "cls loss 591.289794921875  loc loss 38.085731506347656\n",
      "cls loss 610.1438598632812  loc loss 53.178924560546875\n",
      "cls loss 608.359375  loc loss 26.799951553344727\n",
      "cls loss 921.64501953125  loc loss 73.5489501953125\n",
      "cls loss 804.4620971679688  loc loss 48.69301223754883\n",
      "cls loss 549.71337890625  loc loss 28.259618759155273\n",
      "cls loss 890.6167602539062  loc loss 46.76769256591797\n",
      "cls loss 1031.9107666015625  loc loss 73.06974792480469\n",
      "cls loss 853.8453369140625  loc loss 52.06242752075195\n",
      "cls loss 838.1741943359375  loc loss 40.38849639892578\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.])\n",
      "cls loss 737.584716796875  loc loss 49.758697509765625\n",
      "cls loss 634.5087280273438  loc loss 44.16693878173828\n",
      "cls loss 954.828369140625  loc loss 54.13398361206055\n",
      "cls loss 1134.066650390625  loc loss 99.73053741455078\n",
      "cls loss 622.79052734375  loc loss 28.03120994567871\n",
      "cls loss 644.9263305664062  loc loss 40.824546813964844\n",
      "cls loss 555.283447265625  loc loss 35.36748504638672\n",
      "cls loss 615.3128662109375  loc loss 38.25131607055664\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 21., 21., 21.])\n",
      "cls loss 644.2057495117188  loc loss 38.7682991027832\n",
      "cls loss 636.5925903320312  loc loss 31.585819244384766\n",
      "cls loss 628.0711059570312  loc loss 41.1982307434082\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 35.])\n",
      "cls loss 968.0155029296875  loc loss 65.31684875488281\n",
      "cls loss 323.49652099609375  loc loss 18.79161834716797\n",
      "cls loss 510.5306091308594  loc loss 35.39609146118164\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 489.75677490234375  loc loss 33.13811492919922\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 38., 38.,  9., 38.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1.,  1.])\n",
      "cls loss 517.5808715820312  loc loss 41.12688446044922\n",
      "cls loss 866.3934326171875  loc loss 68.0551986694336\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 2.,  1., 77., 31., 10., 10.,  1.,  4., 10.])\n",
      "cls loss 526.1787719726562  loc loss 29.66936683654785\n",
      "cls loss 897.0682373046875  loc loss 53.21941375732422\n",
      "cls loss 1606.142822265625  loc loss 125.38162994384766\n",
      "cls loss 564.780029296875  loc loss 36.284969329833984\n",
      "cls loss 743.4174194335938  loc loss 65.95760345458984\n",
      "cls loss 615.0618896484375  loc loss 35.189239501953125\n",
      "cls loss 624.2442016601562  loc loss 31.312591552734375\n",
      "cls loss 893.51171875  loc loss 40.087318420410156\n",
      "cls loss 854.662841796875  loc loss 48.55254364013672\n",
      "cls loss 786.2525634765625  loc loss 49.84274673461914\n",
      "cls loss 630.7911376953125  loc loss 29.488569259643555\n",
      "cls loss 866.401611328125  loc loss 33.18031311035156\n",
      "cls loss 1431.7225341796875  loc loss 73.5327377319336\n",
      "cls loss 1040.333984375  loc loss 69.6333999633789\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1., 42., 42., 42., 42., 42., 42.,  1.,\n",
      "         1.,  1.,  1., 42.,  1.,  1., 42.,  1.])\n",
      "cls loss 627.9349365234375  loc loss 42.7781867980957\n",
      "cls loss 842.4834594726562  loc loss 55.649078369140625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.])\n",
      "cls loss 424.58819580078125  loc loss 27.821306228637695\n",
      "cls loss 778.0049438476562  loc loss 58.69953918457031\n",
      "cls loss 630.509765625  loc loss 46.85791015625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([11.])\n",
      "cls loss 401.45513916015625  loc loss 22.61589241027832\n",
      "cls loss 550.0914916992188  loc loss 25.351722717285156\n",
      "cls loss 542.7431640625  loc loss 29.768783569335938\n",
      "cls loss 708.0345458984375  loc loss 49.7689323425293\n",
      "cls loss 666.20654296875  loc loss 45.37123107910156\n",
      "cls loss 694.4239501953125  loc loss 53.84642791748047\n",
      "cls loss 932.07275390625  loc loss 60.74851989746094\n",
      "cls loss 525.9274291992188  loc loss 36.227108001708984\n",
      "cls loss 939.2640380859375  loc loss 80.0484390258789\n",
      "cls loss 571.699951171875  loc loss 32.73044967651367\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 514.2429809570312  loc loss 34.90827178955078\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1., 38., 38., 42.])\n",
      "cls loss 656.0543212890625  loc loss 50.183982849121094\n",
      "cls loss 640.0113525390625  loc loss 32.45366668701172\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 541.0888671875  loc loss 37.15612030029297\n",
      "cls loss 1162.4010009765625  loc loss 82.18064880371094\n",
      "cls loss 701.9061279296875  loc loss 51.726951599121094\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10.,  3.,  3.,  6.,  8.,  8.,  1.,  1.,  1., 10.])\n",
      "cls loss 687.8568115234375  loc loss 40.68535614013672\n",
      "cls loss 410.1434631347656  loc loss 15.5010404586792\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10.,  3.])\n",
      "cls loss 659.6741333007812  loc loss 33.58870315551758\n",
      "cls loss 408.37847900390625  loc loss 21.371736526489258\n",
      "cls loss 679.70703125  loc loss 56.089691162109375\n",
      "cls loss 735.3841552734375  loc loss 53.81146240234375\n",
      "cls loss 568.1044311523438  loc loss 34.33055877685547\n",
      "cls loss 552.4321899414062  loc loss 21.840734481811523\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 34.])\n",
      "cls loss 1023.770263671875  loc loss 59.240089416503906\n",
      "cls loss 1030.4981689453125  loc loss 84.20147705078125\n",
      "cls loss 699.5960083007812  loc loss 57.123252868652344\n",
      "cls loss 501.380126953125  loc loss 37.55988693237305\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.,  1.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 614.6672973632812  loc loss 31.22114372253418\n",
      "cls loss 884.2939453125  loc loss 72.65419006347656\n",
      "cls loss 1268.585205078125  loc loss 92.58256530761719\n",
      "cls loss 1073.1162109375  loc loss 64.5833511352539\n",
      "cls loss 639.8692626953125  loc loss 42.28854751586914\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 905.727294921875  loc loss 45.15772247314453\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10.])\n",
      "cls loss 485.8885803222656  loc loss 29.794435501098633\n",
      "cls loss 667.974853515625  loc loss 37.37114715576172\n",
      "cls loss 760.5728149414062  loc loss 38.19378662109375\n",
      "cls loss 494.09246826171875  loc loss 29.641223907470703\n",
      "cls loss 598.2999267578125  loc loss 45.396820068359375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21.,\n",
      "        21.])\n",
      "cls loss 822.625  loc loss 51.638038635253906\n",
      "cls loss 713.5955810546875  loc loss 49.373531341552734\n",
      "cls loss 497.6285400390625  loc loss 20.629106521606445\n",
      "cls loss 895.6930541992188  loc loss 58.14906311035156\n",
      "cls loss 682.1766967773438  loc loss 52.591854095458984\n",
      "cls loss 525.3466186523438  loc loss 34.141014099121094\n",
      "cls loss 1027.693603515625  loc loss 80.78477478027344\n",
      "cls loss 1183.3135986328125  loc loss 86.98465728759766\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15., 85.])\n",
      "cls loss 840.4578857421875  loc loss 54.37249755859375\n",
      "cls loss 732.8812866210938  loc loss 64.54588317871094\n",
      "cls loss 909.6199951171875  loc loss 59.3272590637207\n",
      "cls loss 772.4962158203125  loc loss 51.02249526977539\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 8., 8.])\n",
      "cls loss 440.488037109375  loc loss 26.32892608642578\n",
      "cls loss 589.777099609375  loc loss 36.47193908691406\n",
      "cls loss 663.4720458984375  loc loss 40.430419921875\n",
      "cls loss 561.5115966796875  loc loss 32.63349533081055\n",
      "cls loss 626.7740478515625  loc loss 40.96152877807617\n",
      "cls loss 875.3001708984375  loc loss 48.46810531616211\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1., 35., 27., 27.,  1., 27.,  1.])\n",
      "cls loss 1198.346923828125  loc loss 80.93122100830078\n",
      "cls loss 525.7550048828125  loc loss 41.61475372314453\n",
      "cls loss 669.946533203125  loc loss 47.51830291748047\n",
      "cls loss 611.2222900390625  loc loss 52.2642822265625\n",
      "cls loss 652.4279174804688  loc loss 47.1773567199707\n",
      "cls loss 679.216552734375  loc loss 50.5418815612793\n",
      "cls loss 599.963623046875  loc loss 48.229305267333984\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  2.,  2.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  2.,  2.])\n",
      "cls loss 404.5194091796875  loc loss 17.535297393798828\n",
      "cls loss 933.0855102539062  loc loss 58.73572540283203\n",
      "cls loss 651.2117919921875  loc loss 35.94193649291992\n",
      "cls loss 1029.1087646484375  loc loss 75.5668716430664\n",
      "cls loss 468.6383056640625  loc loss 30.323490142822266\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 19., 19., 19., 16.])\n",
      "cls loss 482.24517822265625  loc loss 26.404647827148438\n",
      "cls loss 404.25732421875  loc loss 18.853404998779297\n",
      "cls loss 573.5091552734375  loc loss 29.630626678466797\n",
      "cls loss 725.0703125  loc loss 47.21470642089844\n",
      "cls loss 380.426025390625  loc loss 30.756561279296875\n",
      "cls loss 853.6867065429688  loc loss 59.315120697021484\n",
      "cls loss 575.2897338867188  loc loss 45.51123046875\n",
      "cls loss 644.273193359375  loc loss 44.882041931152344\n",
      "cls loss 776.328125  loc loss 56.895652770996094\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 886.778076171875  loc loss 44.704586029052734\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 1109.0518798828125  loc loss 93.39454650878906\n",
      "cls loss 1377.34619140625  loc loss 136.27810668945312\n",
      "cls loss 651.4994506835938  loc loss 51.09634780883789\n",
      "cls loss 590.7854614257812  loc loss 45.084754943847656\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3.,  3.,  3.,  3.,  3., 10.])\n",
      "cls loss 381.8662109375  loc loss 17.73309326171875\n",
      "cls loss 632.60693359375  loc loss 42.14624786376953\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 1., 1., 1., 3., 3., 3., 3.])\n",
      "cls loss 632.3631591796875  loc loss 41.28022003173828\n",
      "cls loss 1038.09521484375  loc loss 82.21440124511719\n",
      "cls loss 783.4567260742188  loc loss 58.351417541503906\n",
      "cls loss 649.1978759765625  loc loss 36.12750244140625\n",
      "cls loss 912.707763671875  loc loss 67.0755615234375\n",
      "cls loss 656.113037109375  loc loss 42.71798324584961\n",
      "cls loss 945.8485717773438  loc loss 63.06463623046875\n",
      "cls loss 671.95703125  loc loss 55.69232177734375\n",
      "cls loss 718.157958984375  loc loss 45.6719970703125\n",
      "cls loss 1269.88134765625  loc loss 110.43267822265625\n",
      "cls loss 886.6485595703125  loc loss 60.12672424316406\n",
      "cls loss 607.7788696289062  loc loss 30.39337921142578\n",
      "cls loss 404.3738708496094  loc loss 18.92887306213379\n",
      "cls loss 449.439208984375  loc loss 27.614959716796875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3., 10., 10., 10., 10., 10., 10., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10., 10., 10., 10., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 11., 10., 10., 10., 10., 10.,  3.,  3.,  3.,  3.,  3.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 11., 10., 10., 10., 10., 10.,  3.,  3.,  3.,  3.,  3.])\n",
      "cls loss 415.2582092285156  loc loss 23.810420989990234\n",
      "cls loss 576.5943603515625  loc loss 28.23484230041504\n",
      "cls loss 464.06640625  loc loss 28.216087341308594\n",
      "cls loss 424.5494384765625  loc loss 20.49049186706543\n",
      "cls loss 518.3203125  loc loss 40.66764831542969\n",
      "cls loss 486.4831848144531  loc loss 20.460851669311523\n",
      "cls loss 799.999755859375  loc loss 60.12353515625\n",
      "cls loss 689.331787109375  loc loss 54.756778717041016\n",
      "cls loss 1070.9434814453125  loc loss 73.01577758789062\n",
      "cls loss 516.85009765625  loc loss 39.26158142089844\n",
      "cls loss 902.1737670898438  loc loss 65.65507507324219\n",
      "cls loss 774.3558349609375  loc loss 56.91106414794922\n",
      "cls loss 695.6102294921875  loc loss 49.82746124267578\n",
      "cls loss 697.577392578125  loc loss 55.976783752441406\n",
      "cls loss 954.189697265625  loc loss 69.30158996582031\n",
      "cls loss 923.9849853515625  loc loss 62.3810920715332\n",
      "cls loss 528.14404296875  loc loss 27.472942352294922\n",
      "cls loss 815.6241455078125  loc loss 63.760093688964844\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 10.,  1., 18.])\n",
      "cls loss 462.5771484375  loc loss 31.964757919311523\n",
      "cls loss 548.4395141601562  loc loss 20.615217208862305\n",
      "cls loss 952.06640625  loc loss 44.71906280517578\n",
      "cls loss 1189.5997314453125  loc loss 80.97012329101562\n",
      "cls loss 866.349609375  loc loss 49.53976058959961\n",
      "cls loss 1016.532470703125  loc loss 64.0383529663086\n",
      "cls loss 782.4263916015625  loc loss 48.385292053222656\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.,  1.,  1.])\n",
      "cls loss 919.9172973632812  loc loss 64.94044494628906\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1., 38.,  1.])\n",
      "cls loss 922.0233154296875  loc loss 53.539031982421875\n",
      "cls loss 1111.123046875  loc loss 86.5101547241211\n",
      "cls loss 563.0346069335938  loc loss 46.603939056396484\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 731.3151245117188  loc loss 53.90895080566406\n",
      "cls loss 686.3089599609375  loc loss 47.142032623291016\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3., 10.,  8.,  3., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.])\n",
      "cls loss 787.5340576171875  loc loss 52.64311218261719\n",
      "cls loss 555.5592041015625  loc loss 37.315860748291016\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3.,  3., 11.,  3., 10., 10.,  3.,  3., 10.])\n",
      "cls loss 713.0401611328125  loc loss 38.792694091796875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3., 10., 10., 10.])\n",
      "cls loss 631.1183471679688  loc loss 51.78559112548828\n",
      "cls loss 560.5159912109375  loc loss 34.572235107421875\n",
      "cls loss 637.5372314453125  loc loss 51.565208435058594\n",
      "cls loss 1021.82275390625  loc loss 68.87393951416016\n",
      "cls loss 650.562255859375  loc loss 47.978885650634766\n",
      "cls loss 454.6651611328125  loc loss 41.16932678222656\n",
      "cls loss 588.4898681640625  loc loss 42.78910446166992\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 9.,  9., 85., 85.])\n",
      "cls loss 546.3809814453125  loc loss 32.704345703125\n",
      "cls loss 662.8790893554688  loc loss 43.287906646728516\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 998.8074951171875  loc loss 78.20417022705078\n",
      "cls loss 882.2229614257812  loc loss 49.449947357177734\n",
      "cls loss 1012.5201416015625  loc loss 71.64938354492188\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10., 10., 10., 10.])\n",
      "cls loss 635.3955078125  loc loss 39.27470016479492\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([13.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 973.4139404296875  loc loss 86.92736053466797\n",
      "cls loss 408.091064453125  loc loss 20.456256866455078\n",
      "cls loss 451.48345947265625  loc loss 25.147634506225586\n",
      "cls loss 625.0841064453125  loc loss 37.69622039794922\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19.,  1.,  1.,  1., 19., 19.])\n",
      "cls loss 691.94140625  loc loss 41.45665740966797\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 459.27301025390625  loc loss 44.1224365234375\n",
      "cls loss 735.2904052734375  loc loss 56.926979064941406\n",
      "cls loss 502.4903259277344  loc loss 33.40621566772461\n",
      "cls loss 781.1007080078125  loc loss 52.65339660644531\n",
      "cls loss 836.818115234375  loc loss 65.67833709716797\n",
      "cls loss 699.355224609375  loc loss 39.66740036010742\n",
      "cls loss 900.009521484375  loc loss 71.52275085449219\n",
      "cls loss 445.5755310058594  loc loss 19.7401065826416\n",
      "cls loss 665.2874755859375  loc loss 46.879634857177734\n",
      "cls loss 596.2965087890625  loc loss 29.218826293945312\n",
      "cls loss 538.1968994140625  loc loss 32.5480842590332\n",
      "cls loss 737.5176391601562  loc loss 57.16680145263672\n",
      "cls loss 718.0594482421875  loc loss 42.605628967285156\n",
      "cls loss 1038.171875  loc loss 63.961883544921875\n",
      "cls loss 629.11279296875  loc loss 45.65995407104492\n",
      "cls loss 725.8683471679688  loc loss 53.53340530395508\n",
      "cls loss 1065.8792724609375  loc loss 76.85731506347656\n",
      "cls loss 636.63916015625  loc loss 52.18855285644531\n",
      "cls loss 738.1681518554688  loc loss 45.02396011352539\n",
      "cls loss 979.9750366210938  loc loss 68.2367172241211\n",
      "cls loss 902.0452880859375  loc loss 67.75723266601562\n",
      "cls loss 1156.2425537109375  loc loss 72.62879180908203\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 5.])\n",
      "cls loss 402.5743103027344  loc loss 13.706865310668945\n",
      "cls loss 457.223876953125  loc loss 22.835519790649414\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 13.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 6., 8., 8.])\n",
      "cls loss 487.245361328125  loc loss 19.542905807495117\n",
      "cls loss 495.58941650390625  loc loss 28.765304565429688\n",
      "cls loss 902.30517578125  loc loss 75.2829818725586\n",
      "cls loss 485.3128662109375  loc loss 21.191265106201172\n",
      "cls loss 723.38623046875  loc loss 55.50829315185547\n",
      "cls loss 1155.8790283203125  loc loss 73.2116470336914\n",
      "cls loss 685.0963134765625  loc loss 49.24139404296875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([42., 42.,  1.,  1.,  1.,  1.,  1.,  1.,  1., 42., 42.])\n",
      "cls loss 761.1295776367188  loc loss 46.91144561767578\n",
      "cls loss 961.609619140625  loc loss 75.73038482666016\n",
      "cls loss 745.358154296875  loc loss 61.83595275878906\n",
      "cls loss 582.2510986328125  loc loss 32.560184478759766\n",
      "cls loss 756.5070190429688  loc loss 47.42827606201172\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 1022.7344970703125  loc loss 66.13619232177734\n",
      "cls loss 798.9158935546875  loc loss 58.99409103393555\n",
      "cls loss 518.0205078125  loc loss 32.67485427856445\n",
      "cls loss 509.22332763671875  loc loss 25.88626480102539\n",
      "cls loss 603.9777221679688  loc loss 40.39166259765625\n",
      "cls loss 846.5804443359375  loc loss 55.34111785888672\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15.])\n",
      "cls loss 415.3736572265625  loc loss 22.54228973388672\n",
      "cls loss 658.6015014648438  loc loss 43.49757766723633\n",
      "cls loss 572.006103515625  loc loss 38.88863754272461\n",
      "cls loss 949.157470703125  loc loss 73.99589538574219\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19.,  7.])\n",
      "cls loss 610.8765869140625  loc loss 38.34270477294922\n",
      "cls loss 1234.9921875  loc loss 75.21783447265625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 1004.2418212890625  loc loss 60.1560173034668\n",
      "cls loss 774.0960693359375  loc loss 61.91880798339844\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([38., 38.,  1., 18.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1., 18., 18.,  1.])\n",
      "cls loss 636.8603515625  loc loss 34.86708450317383\n",
      "cls loss 652.2835693359375  loc loss 30.478147506713867\n",
      "cls loss 944.9700927734375  loc loss 82.7466049194336\n",
      "cls loss 774.6348876953125  loc loss 50.40211868286133\n",
      "cls loss 825.2532958984375  loc loss 41.011688232421875\n",
      "cls loss 448.5126037597656  loc loss 35.68307113647461\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.])\n",
      "cls loss 361.521240234375  loc loss 16.88841438293457\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([32.])\n",
      "cls loss 743.5805053710938  loc loss 35.15407943725586\n",
      "cls loss 629.9005126953125  loc loss 39.46976852416992\n",
      "cls loss 787.8680419921875  loc loss 67.36750793457031\n",
      "cls loss 767.7716064453125  loc loss 46.55126190185547\n",
      "cls loss 605.663330078125  loc loss 42.49948501586914\n",
      "cls loss 982.91357421875  loc loss 56.68315505981445\n",
      "cls loss 962.1720581054688  loc loss 70.90406799316406\n",
      "cls loss 799.3753051757812  loc loss 58.19306945800781\n",
      "cls loss 809.7838745117188  loc loss 42.28605270385742\n",
      "cls loss 1141.879638671875  loc loss 70.02449035644531\n",
      "cls loss 698.166259765625  loc loss 34.28023910522461\n",
      "cls loss 999.208984375  loc loss 84.1828842163086\n",
      "cls loss 773.6280517578125  loc loss 48.39337921142578\n",
      "cls loss 606.724365234375  loc loss 47.64667510986328\n",
      "cls loss 504.79144287109375  loc loss 29.009851455688477\n",
      "cls loss 509.9197998046875  loc loss 36.812538146972656\n",
      "cls loss 766.7025146484375  loc loss 56.68326950073242\n",
      "cls loss 801.68896484375  loc loss 62.31953811645508\n",
      "cls loss 462.2568054199219  loc loss 33.014713287353516\n",
      "cls loss 894.0640258789062  loc loss 61.69716262817383\n",
      "cls loss 1045.9884033203125  loc loss 68.16917419433594\n",
      "cls loss 395.623779296875  loc loss 27.212594985961914\n",
      "cls loss 1002.9732666015625  loc loss 71.93523406982422\n",
      "cls loss 702.4703979492188  loc loss 56.904075622558594\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 953.1044921875  loc loss 76.75157928466797\n",
      "cls loss 493.601806640625  loc loss 21.803890228271484\n",
      "cls loss 721.5283813476562  loc loss 44.735477447509766\n",
      "cls loss 754.5313110351562  loc loss 50.696937561035156\n",
      "cls loss 565.102294921875  loc loss 38.36619567871094\n",
      "cls loss 414.0040283203125  loc loss 19.052165985107422\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 9., 9., 1., 9., 9., 9., 9., 1., 9.])\n",
      "cls loss 1296.4761962890625  loc loss 111.07274627685547\n",
      "cls loss 795.841064453125  loc loss 44.25547790527344\n",
      "cls loss 1140.229736328125  loc loss 91.83203125\n",
      "cls loss 571.0150146484375  loc loss 32.38856506347656\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 42., 42.])\n",
      "cls loss 830.2142944335938  loc loss 60.96881866455078\n",
      "cls loss 872.1279907226562  loc loss 61.42490005493164\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  2.,  1.,  1.,  1., 38.,\n",
      "         1.,  1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 38., 38., 38.,  1., 38., 38., 38.,  1.,  1., 38.,  1.,\n",
      "         1.])\n",
      "cls loss 648.5551147460938  loc loss 35.61150360107422\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  8.,  8.])\n",
      "cls loss 1211.7850341796875  loc loss 79.1039047241211\n",
      "cls loss 1142.701416015625  loc loss 80.63544464111328\n",
      "cls loss 505.8072204589844  loc loss 29.212461471557617\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([4., 1., 1., 4.])\n",
      "cls loss 694.1510009765625  loc loss 49.524654388427734\n",
      "cls loss 805.590087890625  loc loss 51.68423080444336\n",
      "cls loss 384.22711181640625  loc loss 19.01667022705078\n",
      "cls loss 544.8804931640625  loc loss 30.61550521850586\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([51.,  1.])\n",
      "cls loss 397.709228515625  loc loss 17.33770751953125\n",
      "cls loss 484.87969970703125  loc loss 31.583698272705078\n",
      "cls loss 837.6243286132812  loc loss 54.173641204833984\n",
      "cls loss 987.9010009765625  loc loss 75.94956970214844\n",
      "cls loss 1267.140380859375  loc loss 79.72901153564453\n",
      "cls loss 1552.1219482421875  loc loss 107.76420593261719\n",
      "cls loss 708.0999755859375  loc loss 45.617042541503906\n",
      "cls loss 879.8861083984375  loc loss 67.09724426269531\n",
      "cls loss 969.3995361328125  loc loss 73.85649871826172\n",
      "cls loss 687.618896484375  loc loss 42.920135498046875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  3.,  1.,  1.,  1.,  3.,  1.,  1.,\n",
      "         1.,  1.,  1.])\n",
      "cls loss 783.313232421875  loc loss 46.98611068725586\n",
      "cls loss 933.7841796875  loc loss 48.87017059326172\n",
      "cls loss 847.7431640625  loc loss 44.82266616821289\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "cls loss 694.263916015625  loc loss 41.55908203125\n",
      "cls loss 414.18072509765625  loc loss 32.15165710449219\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3.])\n",
      "cls loss 557.564453125  loc loss 19.190746307373047\n",
      "cls loss 674.2722778320312  loc loss 47.43854522705078\n",
      "cls loss 539.0194091796875  loc loss 35.96308135986328\n",
      "cls loss 910.0256958007812  loc loss 70.31855773925781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 717.0924682617188  loc loss 29.885019302368164\n",
      "cls loss 528.0980224609375  loc loss 35.39482498168945\n",
      "cls loss 1543.87158203125  loc loss 106.71778106689453\n",
      "cls loss 674.44580078125  loc loss 48.85173034667969\n",
      "cls loss 453.3152770996094  loc loss 40.90040588378906\n",
      "cls loss 660.7364501953125  loc loss 36.87729263305664\n",
      "cls loss 524.4893798828125  loc loss 40.66023254394531\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 955.5646362304688  loc loss 69.67403411865234\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  9., 64., 64., 64., 64., 64., 64., 64., 64., 64.,  9.,  9.,  9.,\n",
      "         9.])\n",
      "cls loss 606.989501953125  loc loss 32.22077560424805\n",
      "cls loss 1141.91064453125  loc loss 105.5927963256836\n",
      "cls loss 693.6176147460938  loc loss 44.81496047973633\n",
      "cls loss 866.31396484375  loc loss 67.97500610351562\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.,  3.,  3.])\n",
      "cls loss 584.1583251953125  loc loss 37.91666793823242\n",
      "cls loss 675.216064453125  loc loss 40.893043518066406\n",
      "cls loss 593.6051025390625  loc loss 50.949764251708984\n",
      "cls loss 768.0347900390625  loc loss 47.08930206298828\n",
      "cls loss 739.5496826171875  loc loss 56.37948989868164\n",
      "cls loss 643.3094482421875  loc loss 50.831912994384766\n",
      "cls loss 662.1021728515625  loc loss 49.823516845703125\n",
      "cls loss 691.1215209960938  loc loss 44.609519958496094\n",
      "cls loss 908.613037109375  loc loss 63.37173843383789\n",
      "cls loss 705.4431762695312  loc loss 48.713470458984375\n",
      "cls loss 601.107177734375  loc loss 29.377084732055664\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21.])\n",
      "cls loss 500.98089599609375  loc loss 21.712181091308594\n",
      "cls loss 602.7938232421875  loc loss 52.83100509643555\n",
      "cls loss 792.4463500976562  loc loss 60.17424011230469\n",
      "cls loss 492.53607177734375  loc loss 32.12625503540039\n",
      "cls loss 773.81689453125  loc loss 47.08219528198242\n",
      "cls loss 1387.3472900390625  loc loss 82.40498352050781\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 42., 42.,  1.,  1.])\n",
      "cls loss 723.553955078125  loc loss 39.3161506652832\n",
      "cls loss 479.747314453125  loc loss 31.584632873535156\n",
      "cls loss 627.2249755859375  loc loss 45.25257110595703\n",
      "cls loss 820.1209106445312  loc loss 74.48479461669922\n",
      "cls loss 613.7242431640625  loc loss 37.602455139160156\n",
      "cls loss 803.02685546875  loc loss 60.089351654052734\n",
      "cls loss 806.5314331054688  loc loss 61.04585266113281\n",
      "cls loss 811.880615234375  loc loss 51.42790222167969\n",
      "cls loss 636.6032104492188  loc loss 42.96406936645508\n",
      "cls loss 544.7130737304688  loc loss 37.236427307128906\n",
      "cls loss 519.031494140625  loc loss 22.916536331176758\n",
      "cls loss 595.8547973632812  loc loss 46.60060501098633\n",
      "cls loss 826.2786865234375  loc loss 74.21604919433594\n",
      "cls loss 726.8309936523438  loc loss 43.98794174194336\n",
      "cls loss 756.80908203125  loc loss 55.903419494628906\n",
      "cls loss 795.734130859375  loc loss 43.09619140625\n",
      "cls loss 1186.5341796875  loc loss 75.3906021118164\n",
      "cls loss 777.4765625  loc loss 58.66800308227539\n",
      "cls loss 958.5169677734375  loc loss 55.86542510986328\n",
      "cls loss 629.579345703125  loc loss 27.319307327270508\n",
      "cls loss 814.390625  loc loss 49.45965576171875\n",
      "cls loss 793.7125244140625  loc loss 48.02604675292969\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 5., 5., 5., 5., 5., 5.])\n",
      "cls loss 501.974609375  loc loss 35.597755432128906\n",
      "cls loss 601.3658447265625  loc loss 42.745296478271484\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([13.])\n",
      "cls loss 449.71722412109375  loc loss 25.0324649810791\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([44., 10.,  1.,  1.,  1.])\n",
      "cls loss 487.10198974609375  loc loss 27.049457550048828\n",
      "cls loss 796.3834228515625  loc loss 45.24131774902344\n",
      "cls loss 657.846435546875  loc loss 38.10832977294922\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19., 19., 19., 19., 19., 19., 19.])\n",
      "cls loss 829.380859375  loc loss 52.852622985839844\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([56.])\n",
      "cls loss 1515.1822509765625  loc loss 91.15164184570312\n",
      "cls loss 771.689453125  loc loss 63.30149841308594\n",
      "cls loss 1119.255615234375  loc loss 79.5981674194336\n",
      "cls loss 992.1515502929688  loc loss 82.05294036865234\n",
      "cls loss 621.6092529296875  loc loss 43.10288619995117\n",
      "cls loss 1078.4345703125  loc loss 76.5011978149414\n",
      "cls loss 683.7511596679688  loc loss 36.482078552246094\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 36.])\n",
      "cls loss 756.078369140625  loc loss 44.74327087402344\n",
      "cls loss 631.842041015625  loc loss 48.29650115966797\n",
      "cls loss 737.6472778320312  loc loss 38.94764709472656\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5.])\n",
      "cls loss 705.8004150390625  loc loss 46.70643615722656\n",
      "cls loss 495.2259521484375  loc loss 25.620288848876953\n",
      "cls loss 930.5520629882812  loc loss 59.71308898925781\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "cls loss 850.6884765625  loc loss 63.59442138671875\n",
      "cls loss 960.697509765625  loc loss 54.26565170288086\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 771.791015625  loc loss 56.29298782348633\n",
      "cls loss 975.5364990234375  loc loss 65.80036926269531\n",
      "cls loss 802.3915405273438  loc loss 67.47119903564453\n",
      "cls loss 593.6878662109375  loc loss 40.82954406738281\n",
      "cls loss 698.010009765625  loc loss 48.73842239379883\n",
      "cls loss 656.4192504882812  loc loss 45.694496154785156\n",
      "cls loss 997.2716674804688  loc loss 63.763206481933594\n",
      "cls loss 489.21533203125  loc loss 27.10050392150879\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 11., 15., 10., 10., 10., 10., 10.])\n",
      "cls loss 1077.5703125  loc loss 81.71934509277344\n",
      "cls loss 612.0150146484375  loc loss 41.55683517456055\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3.])\n",
      "cls loss 720.4349365234375  loc loss 44.693077087402344\n",
      "cls loss 574.658203125  loc loss 36.74694061279297\n",
      "cls loss 633.53271484375  loc loss 36.418556213378906\n",
      "cls loss 834.2118530273438  loc loss 47.13515853881836\n",
      "cls loss 549.8082885742188  loc loss 22.219764709472656\n",
      "cls loss 775.24267578125  loc loss 38.55537796020508\n",
      "cls loss 787.18017578125  loc loss 54.4515380859375\n",
      "cls loss 643.614013671875  loc loss 49.636573791503906\n",
      "cls loss 1350.469482421875  loc loss 114.8014907836914\n",
      "cls loss 1025.782958984375  loc loss 76.97289276123047\n",
      "cls loss 729.977783203125  loc loss 50.93541717529297\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  9.,  9.,  9.,  6.,  6., 85., 85.,  8.,  1.,  1.,  1.,  1.,\n",
      "         6.,  6.])\n",
      "cls loss 491.50738525390625  loc loss 32.785884857177734\n",
      "cls loss 1113.182373046875  loc loss 77.51974487304688\n",
      "cls loss 1246.768798828125  loc loss 84.99449157714844\n",
      "cls loss 852.15625  loc loss 62.98509979248047\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10.,  3.,  3., 10.])\n",
      "cls loss 527.5032958984375  loc loss 35.07284927368164\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([7.])\n",
      "cls loss 754.934814453125  loc loss 62.09786605834961\n",
      "cls loss 738.141845703125  loc loss 47.6165885925293\n",
      "cls loss 708.7456665039062  loc loss 52.64215850830078\n",
      "cls loss 987.6451416015625  loc loss 77.92253875732422\n",
      "cls loss 766.4468994140625  loc loss 48.688716888427734\n",
      "cls loss 1020.2357788085938  loc loss 66.35498809814453\n",
      "cls loss 1148.621337890625  loc loss 78.14480590820312\n",
      "cls loss 807.212646484375  loc loss 50.92030715942383\n",
      "cls loss 785.3120727539062  loc loss 57.03677749633789\n",
      "cls loss 685.7726440429688  loc loss 47.97046661376953\n",
      "cls loss 862.9411010742188  loc loss 74.93030548095703\n",
      "cls loss 817.1704711914062  loc loss 51.470611572265625\n",
      "cls loss 625.457763671875  loc loss 35.827491760253906\n",
      "cls loss 879.432373046875  loc loss 72.80406951904297\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([62.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([62.])\n",
      "cls loss 393.83856201171875  loc loss 23.698780059814453\n",
      "cls loss 675.9453735351562  loc loss 54.224308013916016\n",
      "cls loss 711.2733154296875  loc loss 47.191349029541016\n",
      "cls loss 552.3477783203125  loc loss 24.668134689331055\n",
      "cls loss 869.0631103515625  loc loss 67.3790283203125\n",
      "cls loss 842.4248046875  loc loss 56.41621398925781\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([28.])\n",
      "cls loss 904.00537109375  loc loss 56.31767272949219\n",
      "cls loss 885.1723022460938  loc loss 58.08786392211914\n",
      "cls loss 816.0512084960938  loc loss 56.39030456542969\n",
      "cls loss 859.0302734375  loc loss 62.513450622558594\n",
      "cls loss 1152.5611572265625  loc loss 86.19658660888672\n",
      "cls loss 687.109619140625  loc loss 44.30149841308594\n",
      "cls loss 836.5733642578125  loc loss 52.21205139160156\n",
      "cls loss 820.129150390625  loc loss 65.45817565917969\n",
      "cls loss 1283.208251953125  loc loss 88.43357849121094\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([81.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 902.3753662109375  loc loss 44.96723937988281\n",
      "cls loss 773.4070434570312  loc loss 33.971473693847656\n",
      "cls loss 568.0865478515625  loc loss 35.86750030517578\n",
      "cls loss 515.756591796875  loc loss 23.531253814697266\n",
      "cls loss 588.5774536132812  loc loss 35.8196907043457\n",
      "cls loss 550.931396484375  loc loss 38.837276458740234\n",
      "cls loss 680.6102905273438  loc loss 41.74052810668945\n",
      "cls loss 857.326904296875  loc loss 67.47373962402344\n",
      "cls loss 962.1458740234375  loc loss 60.755680084228516\n",
      "cls loss 1747.57861328125  loc loss 124.6943130493164\n",
      "cls loss 656.3585205078125  loc loss 36.207210540771484\n",
      "cls loss 745.034423828125  loc loss 57.556556701660156\n",
      "cls loss 540.570068359375  loc loss 43.64860916137695\n",
      "cls loss 788.3294067382812  loc loss 44.3973503112793\n",
      "cls loss 702.6177978515625  loc loss 42.050052642822266\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([44., 44.])\n",
      "cls loss 573.5277709960938  loc loss 32.779869079589844\n",
      "cls loss 648.010009765625  loc loss 44.13153839111328\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15.])\n",
      "cls loss 763.937744140625  loc loss 43.60926818847656\n",
      "cls loss 363.72406005859375  loc loss 21.10953140258789\n",
      "cls loss 749.1919555664062  loc loss 49.29326629638672\n",
      "cls loss 480.1661376953125  loc loss 27.269550323486328\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([1., 3., 3.])\n",
      "cls loss 479.73101806640625  loc loss 38.844581604003906\n",
      "cls loss 443.9241943359375  loc loss 19.649818420410156\n",
      "cls loss 771.00341796875  loc loss 42.5095100402832\n",
      "cls loss 780.322265625  loc loss 46.71543884277344\n",
      "cls loss 768.6575927734375  loc loss 44.329246520996094\n",
      "cls loss 735.569091796875  loc loss 47.820823669433594\n",
      "cls loss 624.521484375  loc loss 45.205623626708984\n",
      "cls loss 740.8729858398438  loc loss 52.818607330322266\n",
      "cls loss 674.6868896484375  loc loss 42.90019226074219\n",
      "cls loss 733.104736328125  loc loss 58.77923583984375\n",
      "cls loss 446.27056884765625  loc loss 30.244705200195312\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 903.6759643554688  loc loss 54.86406707763672\n",
      "cls loss 995.0281982421875  loc loss 58.97798538208008\n",
      "cls loss 884.3450927734375  loc loss 66.61392974853516\n",
      "cls loss 888.715576171875  loc loss 60.67222595214844\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10., 10., 10.,  1.,  1.,  1.,  1.,  1.,  1.,  8.,  8.,\n",
      "         1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10., 10., 10.,  1.,  1.,  1.,  1.,  1.,  1.,  8.,  8.,\n",
      "         1.])\n",
      "cls loss 916.2515258789062  loc loss 52.82041549682617\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 3., 3., 3.])\n",
      "cls loss 698.5925903320312  loc loss 44.021812438964844\n",
      "cls loss 509.7835693359375  loc loss 28.79090118408203\n",
      "cls loss 372.30462646484375  loc loss 22.694496154785156\n",
      "cls loss 637.5032958984375  loc loss 47.87321853637695\n",
      "cls loss 546.7642822265625  loc loss 29.154678344726562\n",
      "cls loss 667.4839477539062  loc loss 41.0073356628418\n",
      "cls loss 722.7850341796875  loc loss 43.55368423461914\n",
      "cls loss 1008.5055541992188  loc loss 69.28334045410156\n",
      "cls loss 771.6443481445312  loc loss 48.17776870727539\n",
      "cls loss 724.9414672851562  loc loss 49.06193161010742\n",
      "cls loss 841.013427734375  loc loss 58.425750732421875\n",
      "cls loss 683.6685791015625  loc loss 49.08147048950195\n",
      "cls loss 1029.398193359375  loc loss 88.32823944091797\n",
      "cls loss 574.0914306640625  loc loss 34.1563835144043\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 835.8494262695312  loc loss 55.59889221191406\n",
      "cls loss 416.35986328125  loc loss 23.302818298339844\n",
      "cls loss 1025.0447998046875  loc loss 76.04241943359375\n",
      "cls loss 580.7161865234375  loc loss 34.53303527832031\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 34.])\n",
      "cls loss 838.7313232421875  loc loss 48.41309356689453\n",
      "cls loss 533.0062255859375  loc loss 29.48845100402832\n",
      "cls loss 931.8357543945312  loc loss 52.5098876953125\n",
      "cls loss 384.44378662109375  loc loss 20.915531158447266\n",
      "cls loss 938.1929321289062  loc loss 52.532958984375\n",
      "cls loss 763.1195678710938  loc loss 51.679039001464844\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 38.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16., 16., 16.,  9.,  9.,  9., 16., 16., 16., 85.,  9.])\n",
      "cls loss 700.075439453125  loc loss 42.739173889160156\n",
      "cls loss 744.0933837890625  loc loss 61.215457916259766\n",
      "cls loss 1128.446533203125  loc loss 82.2348861694336\n",
      "cls loss 1432.467529296875  loc loss 109.40489959716797\n",
      "cls loss 475.14422607421875  loc loss 23.47701644897461\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3., 10.,  8.,  8., 10., 10., 10.,  3.,  3., 14.])\n",
      "cls loss 610.5712890625  loc loss 28.44634246826172\n",
      "cls loss 902.4463500976562  loc loss 52.71612548828125\n",
      "cls loss 352.55010986328125  loc loss 16.378442764282227\n",
      "cls loss 566.0601806640625  loc loss 30.727752685546875\n",
      "cls loss 826.1279296875  loc loss 54.71106719970703\n",
      "cls loss 671.191650390625  loc loss 51.88833236694336\n",
      "cls loss 473.68096923828125  loc loss 26.875286102294922\n",
      "cls loss 504.66748046875  loc loss 31.514820098876953\n",
      "cls loss 733.4465942382812  loc loss 48.664283752441406\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42., 42.,  1.])\n",
      "cls loss 699.1672973632812  loc loss 50.15275573730469\n",
      "cls loss 673.6928100585938  loc loss 37.7777099609375\n",
      "cls loss 837.1671142578125  loc loss 60.03166580200195\n",
      "cls loss 888.382568359375  loc loss 60.83240509033203\n",
      "cls loss 695.0662841796875  loc loss 40.77325439453125\n",
      "cls loss 755.792236328125  loc loss 57.30419158935547\n",
      "cls loss 546.04248046875  loc loss 33.23594665527344\n",
      "cls loss 654.72607421875  loc loss 36.84849166870117\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20.])\n",
      "cls loss 419.0392761230469  loc loss 26.204574584960938\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([11.])\n",
      "cls loss 523.5531616210938  loc loss 28.786930084228516\n",
      "cls loss 406.9273681640625  loc loss 23.100786209106445\n",
      "cls loss 761.0419921875  loc loss 69.71134948730469\n",
      "cls loss 375.9486389160156  loc loss 20.34114646911621\n",
      "cls loss 702.9064331054688  loc loss 47.91318893432617\n",
      "cls loss 452.56427001953125  loc loss 24.929126739501953\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 35., 27.])\n",
      "cls loss 692.7601928710938  loc loss 48.19715118408203\n",
      "cls loss 739.5479736328125  loc loss 61.694419860839844\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 549.06982421875  loc loss 41.13371658325195\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([42.,  1.])\n",
      "cls loss 711.6543579101562  loc loss 61.35915756225586\n",
      "cls loss 625.14013671875  loc loss 40.4395751953125\n",
      "cls loss 783.8145751953125  loc loss 46.47178649902344\n",
      "cls loss 996.45166015625  loc loss 62.6480598449707\n",
      "cls loss 855.7819213867188  loc loss 59.71760940551758\n",
      "cls loss 566.2691040039062  loc loss 43.37308120727539\n",
      "cls loss 525.0479736328125  loc loss 38.61492919921875\n",
      "cls loss 439.8955078125  loc loss 17.43560028076172\n",
      "cls loss 616.53173828125  loc loss 37.100929260253906\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 1., 1.])\n",
      "cls loss 575.4913940429688  loc loss 35.13260269165039\n",
      "cls loss 658.7012939453125  loc loss 50.52216339111328\n",
      "cls loss 690.7689208984375  loc loss 42.921451568603516\n",
      "cls loss 590.0772705078125  loc loss 39.86831283569336\n",
      "cls loss 626.2959594726562  loc loss 43.335350036621094\n",
      "cls loss 697.9573974609375  loc loss 52.33543014526367\n",
      "cls loss 975.7257690429688  loc loss 58.926876068115234\n",
      "cls loss 854.2181396484375  loc loss 64.90475463867188\n",
      "cls loss 749.978759765625  loc loss 46.577171325683594\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 594.7431030273438  loc loss 45.83511734008789\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 727.11181640625  loc loss 33.46181869506836\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([81.])\n",
      "cls loss 854.46728515625  loc loss 58.87125778198242\n",
      "cls loss 534.877197265625  loc loss 37.95903778076172\n",
      "cls loss 439.906005859375  loc loss 26.46552276611328\n",
      "cls loss 604.30322265625  loc loss 30.237642288208008\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3.,  1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 19.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 19.])\n",
      "cls loss 778.2978515625  loc loss 55.48313903808594\n",
      "cls loss 497.1085510253906  loc loss 22.227012634277344\n",
      "cls loss 458.51251220703125  loc loss 28.76117515563965\n",
      "cls loss 873.9828491210938  loc loss 69.00443267822266\n",
      "cls loss 475.0048828125  loc loss 30.76790428161621\n",
      "cls loss 586.7601318359375  loc loss 43.883323669433594\n",
      "cls loss 670.70849609375  loc loss 51.813087463378906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 537.0904541015625  loc loss 41.136016845703125\n",
      "cls loss 717.7703857421875  loc loss 45.01274108886719\n",
      "cls loss 779.884765625  loc loss 57.91195297241211\n",
      "cls loss 966.5878295898438  loc loss 86.68232727050781\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 81.])\n",
      "cls loss 671.1829833984375  loc loss 40.613433837890625\n",
      "cls loss 688.56640625  loc loss 35.8499755859375\n",
      "cls loss 704.3252563476562  loc loss 40.51171112060547\n",
      "cls loss 534.8380126953125  loc loss 26.54974365234375\n",
      "cls loss 511.9033203125  loc loss 30.375980377197266\n",
      "cls loss 616.0961303710938  loc loss 39.504722595214844\n",
      "cls loss 472.1402587890625  loc loss 32.69953918457031\n",
      "cls loss 390.5634460449219  loc loss 27.088058471679688\n",
      "cls loss 505.0332946777344  loc loss 35.9875373840332\n",
      "cls loss 685.506103515625  loc loss 44.0037841796875\n",
      "cls loss 571.2318115234375  loc loss 41.554161071777344\n",
      "cls loss 605.0997924804688  loc loss 43.22465133666992\n",
      "cls loss 365.7552795410156  loc loss 26.297815322875977\n",
      "cls loss 1138.216796875  loc loss 84.97824096679688\n",
      "cls loss 764.0413818359375  loc loss 56.915611267089844\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 649.5977783203125  loc loss 39.5489501953125\n",
      "cls loss 679.616455078125  loc loss 50.36634826660156\n",
      "cls loss 571.8875732421875  loc loss 32.515777587890625\n",
      "cls loss 726.392578125  loc loss 51.088417053222656\n",
      "cls loss 755.0987548828125  loc loss 52.76250457763672\n",
      "cls loss 677.0867309570312  loc loss 45.03007507324219\n",
      "cls loss 624.2483520507812  loc loss 32.62732696533203\n",
      "cls loss 477.7430419921875  loc loss 26.796188354492188\n",
      "cls loss 611.4833984375  loc loss 42.52579116821289\n",
      "cls loss 655.1566162109375  loc loss 51.397377014160156\n",
      "cls loss 760.411376953125  loc loss 39.33652114868164\n",
      "cls loss 916.0874633789062  loc loss 66.08795166015625\n",
      "cls loss 990.229736328125  loc loss 68.75509643554688\n",
      "cls loss 701.3195190429688  loc loss 43.92348098754883\n",
      "cls loss 807.93994140625  loc loss 68.44038391113281\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1., 38., 47.,  1.,  1.,  1.,  1.,  1., 62.])\n",
      "cls loss 582.989501953125  loc loss 35.55372619628906\n",
      "cls loss 747.5992431640625  loc loss 44.49740982055664\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 773.1043701171875  loc loss 49.593143463134766\n",
      "cls loss 1007.08056640625  loc loss 64.50880432128906\n",
      "cls loss 612.80810546875  loc loss 32.52657699584961\n",
      "cls loss 665.521728515625  loc loss 53.59851837158203\n",
      "cls loss 609.2705078125  loc loss 42.617401123046875\n",
      "cls loss 443.5216064453125  loc loss 18.61920166015625\n",
      "cls loss 579.4744262695312  loc loss 38.21965408325195\n",
      "cls loss 514.3712158203125  loc loss 27.234397888183594\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1., 35.])\n",
      "cls loss 559.2799072265625  loc loss 32.36253356933594\n",
      "cls loss 899.8223876953125  loc loss 51.268310546875\n",
      "cls loss 819.3052978515625  loc loss 55.1416015625\n",
      "cls loss 737.4375  loc loss 62.03480529785156\n",
      "cls loss 605.528076171875  loc loss 49.09511184692383\n",
      "cls loss 719.916748046875  loc loss 57.425392150878906\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 416.67205810546875  loc loss 27.375511169433594\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 672.7393798828125  loc loss 34.76509475708008\n",
      "cls loss 1048.008544921875  loc loss 64.24181365966797\n",
      "cls loss 1209.53125  loc loss 91.20112609863281\n",
      "cls loss 682.2760620117188  loc loss 36.57465744018555\n",
      "cls loss 553.8101806640625  loc loss 34.35361862182617\n",
      "cls loss 569.5296630859375  loc loss 37.040157318115234\n",
      "cls loss 600.5263061523438  loc loss 51.90083312988281\n",
      "cls loss 600.5745239257812  loc loss 25.731590270996094\n",
      "cls loss 902.39306640625  loc loss 72.53933715820312\n",
      "cls loss 773.4835205078125  loc loss 47.70634078979492\n",
      "cls loss 524.5224609375  loc loss 27.895160675048828\n",
      "cls loss 865.4290771484375  loc loss 45.80902862548828\n",
      "cls loss 996.3216552734375  loc loss 71.5838623046875\n",
      "cls loss 806.5704345703125  loc loss 50.659812927246094\n",
      "cls loss 770.670166015625  loc loss 39.44611740112305\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.])\n",
      "cls loss 688.6094970703125  loc loss 48.89311599731445\n",
      "cls loss 586.0143432617188  loc loss 43.355899810791016\n",
      "cls loss 894.6651000976562  loc loss 53.09367370605469\n",
      "cls loss 1096.20947265625  loc loss 97.46206665039062\n",
      "cls loss 566.823486328125  loc loss 26.991121292114258\n",
      "cls loss 609.48828125  loc loss 40.137325286865234\n",
      "cls loss 520.840576171875  loc loss 34.236446380615234\n",
      "cls loss 589.1889038085938  loc loss 37.38550567626953\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 21., 21., 21.])\n",
      "cls loss 622.1603393554688  loc loss 37.78443145751953\n",
      "cls loss 591.5228271484375  loc loss 30.149578094482422\n",
      "cls loss 597.6776123046875  loc loss 40.4647331237793\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 35.])\n",
      "cls loss 929.9403076171875  loc loss 64.0290756225586\n",
      "cls loss 309.4039306640625  loc loss 17.90838050842285\n",
      "cls loss 486.45819091796875  loc loss 34.40863037109375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 467.17083740234375  loc loss 31.775671005249023\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 38., 38.,  9., 38.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1.,  1.])\n",
      "cls loss 502.5909118652344  loc loss 40.397132873535156\n",
      "cls loss 840.0751342773438  loc loss 65.76504516601562\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 2.,  1., 77., 31., 10., 10.,  1.,  4., 10.])\n",
      "cls loss 506.074462890625  loc loss 28.001235961914062\n",
      "cls loss 876.7928466796875  loc loss 52.308773040771484\n",
      "cls loss 1551.0235595703125  loc loss 121.68363952636719\n",
      "cls loss 558.4688720703125  loc loss 35.62393569946289\n",
      "cls loss 724.4012451171875  loc loss 64.03107452392578\n",
      "cls loss 588.7744140625  loc loss 34.71193313598633\n",
      "cls loss 603.8377685546875  loc loss 30.337024688720703\n",
      "cls loss 914.379638671875  loc loss 39.27352523803711\n",
      "cls loss 828.35595703125  loc loss 47.2286491394043\n",
      "cls loss 757.4783935546875  loc loss 49.3651008605957\n",
      "cls loss 591.995849609375  loc loss 28.866840362548828\n",
      "cls loss 782.7406005859375  loc loss 32.27579116821289\n",
      "cls loss 1313.7398681640625  loc loss 71.9529037475586\n",
      "cls loss 977.4058837890625  loc loss 67.55899810791016\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1., 42., 42., 42., 42., 42., 42.,  1.,\n",
      "         1.,  1.,  1., 42.,  1.,  1., 42.,  1.])\n",
      "cls loss 583.3179931640625  loc loss 41.5550422668457\n",
      "cls loss 802.8016357421875  loc loss 54.31748962402344\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.])\n",
      "cls loss 398.1639709472656  loc loss 26.97691535949707\n",
      "cls loss 749.4008178710938  loc loss 57.11312484741211\n",
      "cls loss 602.4971923828125  loc loss 46.12697219848633\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([11.])\n",
      "cls loss 377.5089111328125  loc loss 21.996593475341797\n",
      "cls loss 500.7579345703125  loc loss 24.785486221313477\n",
      "cls loss 505.3550109863281  loc loss 28.804203033447266\n",
      "cls loss 682.7716064453125  loc loss 49.36986541748047\n",
      "cls loss 650.9888916015625  loc loss 43.955657958984375\n",
      "cls loss 669.0205078125  loc loss 52.94118118286133\n",
      "cls loss 904.7965087890625  loc loss 58.92510986328125\n",
      "cls loss 509.7287292480469  loc loss 35.161251068115234\n",
      "cls loss 910.7520141601562  loc loss 77.92115783691406\n",
      "cls loss 567.244140625  loc loss 31.696557998657227\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 510.16046142578125  loc loss 34.43235778808594\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1., 38., 38., 42.])\n",
      "cls loss 660.33935546875  loc loss 48.71261978149414\n",
      "cls loss 660.7553100585938  loc loss 31.381580352783203\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 525.4849853515625  loc loss 36.043067932128906\n",
      "cls loss 1159.456298828125  loc loss 80.60057067871094\n",
      "cls loss 674.8108520507812  loc loss 50.393157958984375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10.,  3.,  3.,  6.,  8.,  8.,  1.,  1.,  1., 10.])\n",
      "cls loss 648.1788330078125  loc loss 39.37557601928711\n",
      "cls loss 387.3358154296875  loc loss 14.90265941619873\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10.,  3.])\n",
      "cls loss 610.412109375  loc loss 32.67194366455078\n",
      "cls loss 392.0552978515625  loc loss 20.370925903320312\n",
      "cls loss 637.7666015625  loc loss 54.59196472167969\n",
      "cls loss 696.8375244140625  loc loss 52.68075180053711\n",
      "cls loss 537.255859375  loc loss 33.84776306152344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 473.2985534667969  loc loss 21.21493911743164\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 34.])\n",
      "cls loss 955.748291015625  loc loss 58.17098617553711\n",
      "cls loss 987.7687377929688  loc loss 83.3076171875\n",
      "cls loss 661.542724609375  loc loss 55.82478713989258\n",
      "cls loss 486.0109558105469  loc loss 36.5176887512207\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.,  1.])\n",
      "cls loss 568.24853515625  loc loss 30.67538070678711\n",
      "cls loss 857.3563232421875  loc loss 70.85328674316406\n",
      "cls loss 1223.54248046875  loc loss 90.21078491210938\n",
      "cls loss 1041.7392578125  loc loss 62.629859924316406\n",
      "cls loss 638.339111328125  loc loss 40.758602142333984\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 887.4532470703125  loc loss 44.32362747192383\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10.])\n",
      "cls loss 483.90460205078125  loc loss 28.833141326904297\n",
      "cls loss 659.3600463867188  loc loss 36.500064849853516\n",
      "cls loss 720.564697265625  loc loss 37.189815521240234\n",
      "cls loss 475.28521728515625  loc loss 28.888051986694336\n",
      "cls loss 577.1387939453125  loc loss 44.093605041503906\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21.,\n",
      "        21.])\n",
      "cls loss 794.39306640625  loc loss 49.845523834228516\n",
      "cls loss 685.6297607421875  loc loss 48.30519485473633\n",
      "cls loss 460.73284912109375  loc loss 20.04854393005371\n",
      "cls loss 860.385498046875  loc loss 57.00482177734375\n",
      "cls loss 659.92626953125  loc loss 51.076026916503906\n",
      "cls loss 502.9918518066406  loc loss 33.252685546875\n",
      "cls loss 994.0374145507812  loc loss 78.29670715332031\n",
      "cls loss 1145.722900390625  loc loss 84.98588562011719\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15., 85.])\n",
      "cls loss 795.8961181640625  loc loss 52.473388671875\n",
      "cls loss 694.6504516601562  loc loss 62.705753326416016\n",
      "cls loss 847.8015747070312  loc loss 58.30049133300781\n",
      "cls loss 744.322998046875  loc loss 48.57893371582031\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 8., 8.])\n",
      "cls loss 421.9124450683594  loc loss 25.102672576904297\n",
      "cls loss 555.2508544921875  loc loss 35.41412353515625\n",
      "cls loss 626.7354736328125  loc loss 39.101627349853516\n",
      "cls loss 540.3714599609375  loc loss 31.315635681152344\n",
      "cls loss 596.5479736328125  loc loss 39.83026885986328\n",
      "cls loss 835.206298828125  loc loss 47.54448699951172\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1., 35., 27., 27.,  1., 27.,  1.])\n",
      "cls loss 1144.8848876953125  loc loss 78.85698699951172\n",
      "cls loss 510.07122802734375  loc loss 40.024105072021484\n",
      "cls loss 649.5506591796875  loc loss 46.4872932434082\n",
      "cls loss 596.1817626953125  loc loss 51.21491241455078\n",
      "cls loss 625.5115966796875  loc loss 45.918296813964844\n",
      "cls loss 656.5155029296875  loc loss 49.374977111816406\n",
      "cls loss 585.0546875  loc loss 47.28324508666992\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  2.,  2.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  2.,  2.])\n",
      "cls loss 392.1988525390625  loc loss 16.905454635620117\n",
      "cls loss 886.09228515625  loc loss 57.014896392822266\n",
      "cls loss 627.81103515625  loc loss 34.92658996582031\n",
      "cls loss 1006.0047607421875  loc loss 74.0327377319336\n",
      "cls loss 447.4918212890625  loc loss 29.370285034179688\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 19., 19., 19., 16.])\n",
      "cls loss 454.71026611328125  loc loss 24.95349884033203\n",
      "cls loss 374.6478271484375  loc loss 18.379364013671875\n",
      "cls loss 544.1796875  loc loss 28.901626586914062\n",
      "cls loss 693.831298828125  loc loss 46.24051284790039\n",
      "cls loss 364.01416015625  loc loss 29.798749923706055\n",
      "cls loss 815.9788818359375  loc loss 58.10808563232422\n",
      "cls loss 557.6116333007812  loc loss 44.07436752319336\n",
      "cls loss 608.6846923828125  loc loss 43.88065719604492\n",
      "cls loss 742.4580078125  loc loss 56.011497497558594\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 840.4990844726562  loc loss 43.6875114440918\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 1068.660888671875  loc loss 92.0925521850586\n",
      "cls loss 1337.27490234375  loc loss 134.2718505859375\n",
      "cls loss 635.43896484375  loc loss 50.36631774902344\n",
      "cls loss 586.15625  loc loss 43.98143768310547\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3.,  3.,  3.,  3.,  3., 10.])\n",
      "cls loss 366.7916259765625  loc loss 17.50367546081543\n",
      "cls loss 638.0262451171875  loc loss 41.12749481201172\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 1., 1., 1., 3., 3., 3., 3.])\n",
      "cls loss 613.6357421875  loc loss 40.36962890625\n",
      "cls loss 1018.8336181640625  loc loss 79.46022033691406\n",
      "cls loss 788.4190673828125  loc loss 57.75559997558594\n",
      "cls loss 647.5714721679688  loc loss 35.043113708496094\n",
      "cls loss 871.2991333007812  loc loss 65.75106048583984\n",
      "cls loss 618.4358520507812  loc loss 41.96361541748047\n",
      "cls loss 906.5336303710938  loc loss 61.34307861328125\n",
      "cls loss 651.6666870117188  loc loss 54.19927215576172\n",
      "cls loss 662.6865234375  loc loss 44.52959060668945\n",
      "cls loss 1235.465087890625  loc loss 108.03729248046875\n",
      "cls loss 840.6714477539062  loc loss 58.72714614868164\n",
      "cls loss 568.186767578125  loc loss 29.712032318115234\n",
      "cls loss 368.1631164550781  loc loss 18.43610954284668\n",
      "cls loss 426.12030029296875  loc loss 26.824678421020508\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3., 10., 10., 10., 10., 10., 10., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10., 10., 10., 10., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 11., 10., 10., 10., 10., 10.,  3.,  3.,  3.,  3.,  3.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 11., 10., 10., 10., 10., 10.,  3.,  3.,  3.,  3.,  3.])\n",
      "cls loss 385.8944396972656  loc loss 22.961851119995117\n",
      "cls loss 535.2965698242188  loc loss 27.641765594482422\n",
      "cls loss 434.053955078125  loc loss 27.89592170715332\n",
      "cls loss 399.1617431640625  loc loss 19.899892807006836\n",
      "cls loss 500.6788330078125  loc loss 39.98997497558594\n",
      "cls loss 460.1043701171875  loc loss 19.847293853759766\n",
      "cls loss 776.1153564453125  loc loss 58.14439392089844\n",
      "cls loss 668.9794921875  loc loss 53.13077926635742\n",
      "cls loss 1028.176025390625  loc loss 71.3177490234375\n",
      "cls loss 498.3682556152344  loc loss 38.5331916809082\n",
      "cls loss 874.152099609375  loc loss 63.81305694580078\n",
      "cls loss 743.7374267578125  loc loss 55.169559478759766\n",
      "cls loss 676.2030029296875  loc loss 48.38117980957031\n",
      "cls loss 684.6605224609375  loc loss 54.62714767456055\n",
      "cls loss 935.0860595703125  loc loss 67.4964370727539\n",
      "cls loss 914.9727783203125  loc loss 60.363922119140625\n",
      "cls loss 519.87548828125  loc loss 26.923254013061523\n",
      "cls loss 807.182373046875  loc loss 62.588462829589844\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 10.,  1., 18.])\n",
      "cls loss 449.69415283203125  loc loss 30.75394630432129\n",
      "cls loss 524.2734985351562  loc loss 20.290218353271484\n",
      "cls loss 901.3392333984375  loc loss 43.5128288269043\n",
      "cls loss 1154.1771240234375  loc loss 79.25348663330078\n",
      "cls loss 788.7330322265625  loc loss 48.5200309753418\n",
      "cls loss 959.58544921875  loc loss 62.654205322265625\n",
      "cls loss 711.3541259765625  loc loss 47.23085021972656\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.,  1.,  1.])\n",
      "cls loss 877.689208984375  loc loss 62.709930419921875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1., 38.,  1.])\n",
      "cls loss 861.7846069335938  loc loss 51.975425720214844\n",
      "cls loss 1061.1959228515625  loc loss 84.56243896484375\n",
      "cls loss 533.2277221679688  loc loss 44.78461456298828\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 707.4848022460938  loc loss 52.82342529296875\n",
      "cls loss 644.4559936523438  loc loss 46.26678466796875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3., 10.,  8.,  3., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.])\n",
      "cls loss 766.5874633789062  loc loss 51.654441833496094\n",
      "cls loss 534.0496215820312  loc loss 36.447601318359375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3.,  3., 11.,  3., 10., 10.,  3.,  3., 10.])\n",
      "cls loss 676.6359252929688  loc loss 36.9349365234375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3., 10., 10., 10.])\n",
      "cls loss 612.53271484375  loc loss 50.20768737792969\n",
      "cls loss 534.4112548828125  loc loss 33.501708984375\n",
      "cls loss 626.6356201171875  loc loss 50.90752029418945\n",
      "cls loss 1031.0174560546875  loc loss 67.43992614746094\n",
      "cls loss 639.3770751953125  loc loss 46.804412841796875\n",
      "cls loss 453.97381591796875  loc loss 40.67577362060547\n",
      "cls loss 576.257080078125  loc loss 42.218406677246094\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 9.,  9., 85., 85.])\n",
      "cls loss 547.096923828125  loc loss 31.855485916137695\n",
      "cls loss 644.5311279296875  loc loss 42.038787841796875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 989.6505126953125  loc loss 76.7806167602539\n",
      "cls loss 850.1920776367188  loc loss 47.852134704589844\n",
      "cls loss 968.493896484375  loc loss 69.99951171875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10., 10., 10., 10.])\n",
      "cls loss 621.3145141601562  loc loss 38.34792709350586\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([13.])\n",
      "cls loss 949.242431640625  loc loss 83.77495574951172\n",
      "cls loss 384.3870849609375  loc loss 20.11937141418457\n",
      "cls loss 426.8876953125  loc loss 24.515039443969727\n",
      "cls loss 587.012451171875  loc loss 36.27705383300781\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19.,  1.,  1.,  1., 19., 19.])\n",
      "cls loss 636.0732421875  loc loss 40.656612396240234\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 430.53485107421875  loc loss 43.32703399658203\n",
      "cls loss 712.033935546875  loc loss 55.41184997558594\n",
      "cls loss 484.4560852050781  loc loss 32.46731185913086\n",
      "cls loss 750.90234375  loc loss 51.15383529663086\n",
      "cls loss 801.7203369140625  loc loss 64.20068359375\n",
      "cls loss 669.45947265625  loc loss 38.44415283203125\n",
      "cls loss 865.9049072265625  loc loss 69.92625427246094\n",
      "cls loss 424.3207702636719  loc loss 19.163150787353516\n",
      "cls loss 644.6561279296875  loc loss 45.46721267700195\n",
      "cls loss 568.6423950195312  loc loss 28.443639755249023\n",
      "cls loss 524.833740234375  loc loss 32.00242614746094\n",
      "cls loss 703.9639892578125  loc loss 55.53225326538086\n",
      "cls loss 687.314453125  loc loss 41.79487228393555\n",
      "cls loss 997.0674438476562  loc loss 63.000450134277344\n",
      "cls loss 608.9208984375  loc loss 44.43537139892578\n",
      "cls loss 713.130126953125  loc loss 52.46398162841797\n",
      "cls loss 1039.8369140625  loc loss 74.67684936523438\n",
      "cls loss 618.783447265625  loc loss 50.9015007019043\n",
      "cls loss 715.7159423828125  loc loss 43.99909591674805\n",
      "cls loss 930.8780517578125  loc loss 66.64289093017578\n",
      "cls loss 873.6242065429688  loc loss 66.06429290771484\n",
      "cls loss 1114.337158203125  loc loss 70.17420959472656\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 5.])\n",
      "cls loss 370.38037109375  loc loss 13.230361938476562\n",
      "cls loss 439.84625244140625  loc loss 21.74207878112793\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 13.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 6., 8., 8.])\n",
      "cls loss 463.67327880859375  loc loss 19.00995635986328\n",
      "cls loss 467.3173828125  loc loss 27.944927215576172\n",
      "cls loss 868.33642578125  loc loss 71.93668365478516\n",
      "cls loss 437.675048828125  loc loss 20.531612396240234\n",
      "cls loss 689.1968994140625  loc loss 54.146018981933594\n",
      "cls loss 1084.9091796875  loc loss 72.3270492553711\n",
      "cls loss 647.8856201171875  loc loss 48.497779846191406\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([42., 42.,  1.,  1.,  1.,  1.,  1.,  1.,  1., 42., 42.])\n",
      "cls loss 713.65576171875  loc loss 46.39672088623047\n",
      "cls loss 916.0157470703125  loc loss 74.19816589355469\n",
      "cls loss 714.462890625  loc loss 61.497432708740234\n",
      "cls loss 552.5072631835938  loc loss 32.10558319091797\n",
      "cls loss 728.1607666015625  loc loss 46.84620666503906\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 984.9183349609375  loc loss 65.21031188964844\n",
      "cls loss 776.1416015625  loc loss 58.1819953918457\n",
      "cls loss 505.1160888671875  loc loss 32.13508987426758\n",
      "cls loss 485.2263488769531  loc loss 24.686670303344727\n",
      "cls loss 593.243896484375  loc loss 39.50233840942383\n",
      "cls loss 819.7730712890625  loc loss 54.590572357177734\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15.])\n",
      "cls loss 399.71234130859375  loc loss 21.774019241333008\n",
      "cls loss 642.785888671875  loc loss 42.584320068359375\n",
      "cls loss 555.5372924804688  loc loss 38.30411911010742\n",
      "cls loss 935.6831665039062  loc loss 72.63764190673828\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19.,  7.])\n",
      "cls loss 591.32275390625  loc loss 37.50526428222656\n",
      "cls loss 1191.511962890625  loc loss 73.7044677734375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 976.73095703125  loc loss 58.50794219970703\n",
      "cls loss 741.701904296875  loc loss 60.402198791503906\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([38., 38.,  1., 18.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1., 18., 18.,  1.])\n",
      "cls loss 620.113037109375  loc loss 34.09027862548828\n",
      "cls loss 618.1331787109375  loc loss 29.626781463623047\n",
      "cls loss 931.6888427734375  loc loss 80.98114776611328\n",
      "cls loss 742.4110107421875  loc loss 48.9016227722168\n",
      "cls loss 787.001708984375  loc loss 39.892452239990234\n",
      "cls loss 428.13665771484375  loc loss 34.70381546020508\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.])\n",
      "cls loss 343.24810791015625  loc loss 15.809739112854004\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([32.])\n",
      "cls loss 705.0972290039062  loc loss 34.16404724121094\n",
      "cls loss 594.122802734375  loc loss 38.9931526184082\n",
      "cls loss 770.0596923828125  loc loss 65.7696533203125\n",
      "cls loss 736.6566772460938  loc loss 45.50931167602539\n",
      "cls loss 591.4677734375  loc loss 41.080078125\n",
      "cls loss 939.0813598632812  loc loss 55.76805114746094\n",
      "cls loss 939.54736328125  loc loss 69.26717376708984\n",
      "cls loss 777.2060546875  loc loss 56.287994384765625\n",
      "cls loss 752.0956420898438  loc loss 41.25116729736328\n",
      "cls loss 1098.126220703125  loc loss 68.13892364501953\n",
      "cls loss 660.1044921875  loc loss 33.84931564331055\n",
      "cls loss 961.8228149414062  loc loss 82.7874526977539\n",
      "cls loss 741.7888793945312  loc loss 47.053592681884766\n",
      "cls loss 591.74560546875  loc loss 46.3976936340332\n",
      "cls loss 480.3388671875  loc loss 28.242868423461914\n",
      "cls loss 489.93109130859375  loc loss 35.75276565551758\n",
      "cls loss 736.1612548828125  loc loss 55.23883819580078\n",
      "cls loss 772.9872436523438  loc loss 60.66146469116211\n",
      "cls loss 446.21966552734375  loc loss 32.51615905761719\n",
      "cls loss 862.0794677734375  loc loss 60.23207473754883\n",
      "cls loss 1017.7796630859375  loc loss 66.51322174072266\n",
      "cls loss 379.5994873046875  loc loss 26.881744384765625\n",
      "cls loss 975.7621459960938  loc loss 70.06890869140625\n",
      "cls loss 692.1749267578125  loc loss 55.5728759765625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 934.0191650390625  loc loss 75.68404388427734\n",
      "cls loss 484.76593017578125  loc loss 21.178796768188477\n",
      "cls loss 716.9213256835938  loc loss 43.59369659423828\n",
      "cls loss 739.523193359375  loc loss 50.06454086303711\n",
      "cls loss 564.9439697265625  loc loss 36.99321746826172\n",
      "cls loss 399.14080810546875  loc loss 18.402877807617188\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 9., 9., 1., 9., 9., 9., 9., 1., 9.])\n",
      "cls loss 1264.656982421875  loc loss 108.61399841308594\n",
      "cls loss 777.4962768554688  loc loss 42.84938430786133\n",
      "cls loss 1107.679443359375  loc loss 90.73199462890625\n",
      "cls loss 529.3104248046875  loc loss 31.504507064819336\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 42., 42.])\n",
      "cls loss 791.4191284179688  loc loss 59.431854248046875\n",
      "cls loss 824.9353637695312  loc loss 59.94983673095703\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  2.,  1.,  1.,  1., 38.,\n",
      "         1.,  1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 38., 38., 38.,  1., 38., 38., 38.,  1.,  1., 38.,  1.,\n",
      "         1.])\n",
      "cls loss 580.2559814453125  loc loss 34.98687744140625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  8.,  8.])\n",
      "cls loss 1132.16162109375  loc loss 77.62423706054688\n",
      "cls loss 1082.812255859375  loc loss 79.03028106689453\n",
      "cls loss 465.61932373046875  loc loss 28.432491302490234\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([4., 1., 1., 4.])\n",
      "cls loss 645.7496337890625  loc loss 48.45859146118164\n",
      "cls loss 769.00244140625  loc loss 50.4825325012207\n",
      "cls loss 362.0925598144531  loc loss 18.385498046875\n",
      "cls loss 516.4111328125  loc loss 29.894428253173828\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([51.,  1.])\n",
      "cls loss 375.6844177246094  loc loss 16.825950622558594\n",
      "cls loss 464.3774719238281  loc loss 30.531147003173828\n",
      "cls loss 815.8097534179688  loc loss 52.88779830932617\n",
      "cls loss 950.013427734375  loc loss 73.54389953613281\n",
      "cls loss 1226.755126953125  loc loss 77.28087615966797\n",
      "cls loss 1507.36767578125  loc loss 105.44155883789062\n",
      "cls loss 670.2001953125  loc loss 44.34104919433594\n",
      "cls loss 871.5054321289062  loc loss 65.30485534667969\n",
      "cls loss 948.9208984375  loc loss 72.10614013671875\n",
      "cls loss 689.2562866210938  loc loss 42.26420593261719\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  3.,  1.,  1.,  1.,  3.,  1.,  1.,\n",
      "         1.,  1.,  1.])\n",
      "cls loss 790.5469360351562  loc loss 45.71744918823242\n",
      "cls loss 947.92041015625  loc loss 47.58320617675781\n",
      "cls loss 857.8182983398438  loc loss 43.49329376220703\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "cls loss 677.78759765625  loc loss 40.64537048339844\n",
      "cls loss 398.6715087890625  loc loss 31.657711029052734\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 489.1407165527344  loc loss 18.07594108581543\n",
      "cls loss 625.0986938476562  loc loss 45.939697265625\n",
      "cls loss 503.16705322265625  loc loss 35.463661193847656\n",
      "cls loss 859.689697265625  loc loss 67.76647186279297\n",
      "cls loss 651.8021850585938  loc loss 29.217449188232422\n",
      "cls loss 492.010498046875  loc loss 34.24498748779297\n",
      "cls loss 1477.73486328125  loc loss 103.68883514404297\n",
      "cls loss 629.5006103515625  loc loss 47.860862731933594\n",
      "cls loss 431.61224365234375  loc loss 39.843875885009766\n",
      "cls loss 610.542236328125  loc loss 36.38043212890625\n",
      "cls loss 498.4713439941406  loc loss 39.68476104736328\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 915.46044921875  loc loss 68.03335571289062\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  9., 64., 64., 64., 64., 64., 64., 64., 64., 64.,  9.,  9.,  9.,\n",
      "         9.])\n",
      "cls loss 563.8375244140625  loc loss 31.003576278686523\n",
      "cls loss 1127.9044189453125  loc loss 103.44699096679688\n",
      "cls loss 668.6837768554688  loc loss 43.91377258300781\n",
      "cls loss 833.7696533203125  loc loss 66.28938293457031\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.,  3.,  3.])\n",
      "cls loss 554.621826171875  loc loss 36.985267639160156\n",
      "cls loss 671.9393310546875  loc loss 40.00145721435547\n",
      "cls loss 595.7891845703125  loc loss 48.815887451171875\n",
      "cls loss 766.6051025390625  loc loss 46.54143142700195\n",
      "cls loss 731.0767822265625  loc loss 55.06709289550781\n",
      "cls loss 634.3682861328125  loc loss 49.91111755371094\n",
      "cls loss 651.0548095703125  loc loss 48.86012268066406\n",
      "cls loss 673.9742431640625  loc loss 43.278900146484375\n",
      "cls loss 880.7810668945312  loc loss 61.76140213012695\n",
      "cls loss 686.332275390625  loc loss 47.105892181396484\n",
      "cls loss 573.06689453125  loc loss 28.076114654541016\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21.])\n",
      "cls loss 462.7796325683594  loc loss 21.408126831054688\n",
      "cls loss 579.843017578125  loc loss 51.158878326416016\n",
      "cls loss 764.362060546875  loc loss 59.118438720703125\n",
      "cls loss 478.23052978515625  loc loss 31.272029876708984\n",
      "cls loss 733.3386840820312  loc loss 45.920654296875\n",
      "cls loss 1307.9169921875  loc loss 80.41004943847656\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 42., 42.,  1.,  1.])\n",
      "cls loss 671.0388793945312  loc loss 38.7065544128418\n",
      "cls loss 448.37646484375  loc loss 31.168155670166016\n",
      "cls loss 595.622314453125  loc loss 44.36811828613281\n",
      "cls loss 799.8920288085938  loc loss 72.95860290527344\n",
      "cls loss 573.0828857421875  loc loss 37.005027770996094\n",
      "cls loss 764.7769165039062  loc loss 58.89934158325195\n",
      "cls loss 770.3101196289062  loc loss 59.71565246582031\n",
      "cls loss 783.0556640625  loc loss 50.12042999267578\n",
      "cls loss 627.7139892578125  loc loss 41.80209732055664\n",
      "cls loss 534.9745483398438  loc loss 36.40361022949219\n",
      "cls loss 494.03863525390625  loc loss 22.33074378967285\n",
      "cls loss 574.2162475585938  loc loss 45.080787658691406\n",
      "cls loss 814.882080078125  loc loss 73.58134460449219\n",
      "cls loss 704.1316528320312  loc loss 43.4827766418457\n",
      "cls loss 738.4263916015625  loc loss 54.45799255371094\n",
      "cls loss 773.4304809570312  loc loss 41.901676177978516\n",
      "cls loss 1154.5596923828125  loc loss 73.58006286621094\n",
      "cls loss 752.5545043945312  loc loss 57.97602462768555\n",
      "cls loss 912.6029052734375  loc loss 54.1855354309082\n",
      "cls loss 593.7622680664062  loc loss 26.757183074951172\n",
      "cls loss 779.3768310546875  loc loss 48.6743049621582\n",
      "cls loss 733.91357421875  loc loss 47.29463577270508\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 5., 5., 5., 5., 5., 5.])\n",
      "cls loss 485.9727478027344  loc loss 34.6509895324707\n",
      "cls loss 577.6090087890625  loc loss 41.362281799316406\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([13.])\n",
      "cls loss 423.00787353515625  loc loss 24.730140686035156\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([44., 10.,  1.,  1.,  1.])\n",
      "cls loss 459.4472351074219  loc loss 26.40895652770996\n",
      "cls loss 773.820068359375  loc loss 43.965110778808594\n",
      "cls loss 627.9219360351562  loc loss 37.1950798034668\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19., 19., 19., 19., 19., 19., 19.])\n",
      "cls loss 802.3771362304688  loc loss 51.571876525878906\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([56.])\n",
      "cls loss 1449.239990234375  loc loss 88.8411865234375\n",
      "cls loss 739.8826904296875  loc loss 61.92190170288086\n",
      "cls loss 1067.457275390625  loc loss 78.41162872314453\n",
      "cls loss 964.0580444335938  loc loss 80.41439056396484\n",
      "cls loss 609.463134765625  loc loss 42.04698181152344\n",
      "cls loss 1050.464111328125  loc loss 75.15555572509766\n",
      "cls loss 660.3438720703125  loc loss 35.628562927246094\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 36.])\n",
      "cls loss 747.39404296875  loc loss 43.61756896972656\n",
      "cls loss 632.721923828125  loc loss 47.360313415527344\n",
      "cls loss 734.6231079101562  loc loss 38.27958297729492\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5.])\n",
      "cls loss 693.3624267578125  loc loss 45.83340072631836\n",
      "cls loss 471.471435546875  loc loss 24.62162208557129\n",
      "cls loss 906.6729736328125  loc loss 57.9676628112793\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "cls loss 825.615234375  loc loss 61.663734436035156\n",
      "cls loss 913.5782470703125  loc loss 53.24225616455078\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 742.9622192382812  loc loss 55.110599517822266\n",
      "cls loss 912.4727783203125  loc loss 64.56312561035156\n",
      "cls loss 764.1953125  loc loss 66.34241485595703\n",
      "cls loss 555.9178466796875  loc loss 39.76166534423828\n",
      "cls loss 662.4509887695312  loc loss 48.001163482666016\n",
      "cls loss 622.8153076171875  loc loss 44.83209991455078\n",
      "cls loss 970.7509765625  loc loss 62.51878356933594\n",
      "cls loss 466.0271911621094  loc loss 26.531517028808594\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 11., 15., 10., 10., 10., 10., 10.])\n",
      "cls loss 1033.888671875  loc loss 80.0925064086914\n",
      "cls loss 594.9735107421875  loc loss 40.82843780517578\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3.])\n",
      "cls loss 707.1815185546875  loc loss 43.818294525146484\n",
      "cls loss 555.876953125  loc loss 35.9840087890625\n",
      "cls loss 618.738525390625  loc loss 35.1773681640625\n",
      "cls loss 821.9168701171875  loc loss 46.01302719116211\n",
      "cls loss 541.37841796875  loc loss 21.726760864257812\n",
      "cls loss 768.7100219726562  loc loss 38.1544303894043\n",
      "cls loss 760.21923828125  loc loss 53.69247055053711\n",
      "cls loss 634.7425537109375  loc loss 48.79969787597656\n",
      "cls loss 1323.379638671875  loc loss 112.20159912109375\n",
      "cls loss 1000.2166748046875  loc loss 75.048583984375\n",
      "cls loss 693.85546875  loc loss 50.01195526123047\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  9.,  9.,  9.,  6.,  6., 85., 85.,  8.,  1.,  1.,  1.,  1.,\n",
      "         6.,  6.])\n",
      "cls loss 478.177001953125  loc loss 32.269187927246094\n",
      "cls loss 1062.86328125  loc loss 75.97364807128906\n",
      "cls loss 1207.438720703125  loc loss 82.87934875488281\n",
      "cls loss 820.442138671875  loc loss 62.07063674926758\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10.,  3.,  3., 10.])\n",
      "cls loss 510.9652404785156  loc loss 34.70823669433594\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([7.])\n",
      "cls loss 720.3595581054688  loc loss 60.35537338256836\n",
      "cls loss 716.5177001953125  loc loss 47.00925827026367\n",
      "cls loss 676.4488525390625  loc loss 51.88539123535156\n",
      "cls loss 964.6845703125  loc loss 76.44050598144531\n",
      "cls loss 756.2489624023438  loc loss 47.49562454223633\n",
      "cls loss 997.06005859375  loc loss 64.73728942871094\n",
      "cls loss 1122.0478515625  loc loss 76.13720703125\n",
      "cls loss 779.8427734375  loc loss 49.88169479370117\n",
      "cls loss 765.7811279296875  loc loss 55.132102966308594\n",
      "cls loss 665.0238037109375  loc loss 47.38615417480469\n",
      "cls loss 844.2596435546875  loc loss 73.38199615478516\n",
      "cls loss 777.3939208984375  loc loss 50.405513763427734\n",
      "cls loss 601.417724609375  loc loss 35.211212158203125\n",
      "cls loss 852.135986328125  loc loss 70.80679321289062\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([62.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([62.])\n",
      "cls loss 376.00946044921875  loc loss 23.220630645751953\n",
      "cls loss 659.7018432617188  loc loss 52.91346740722656\n",
      "cls loss 682.0030517578125  loc loss 46.35576629638672\n",
      "cls loss 520.5980224609375  loc loss 23.77513313293457\n",
      "cls loss 842.3278198242188  loc loss 66.17486572265625\n",
      "cls loss 811.5170288085938  loc loss 55.01525115966797\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([28.])\n",
      "cls loss 883.463134765625  loc loss 55.12902069091797\n",
      "cls loss 858.9725341796875  loc loss 56.54896926879883\n",
      "cls loss 782.0382080078125  loc loss 54.9677848815918\n",
      "cls loss 833.42236328125  loc loss 61.032501220703125\n",
      "cls loss 1124.54443359375  loc loss 84.2628173828125\n",
      "cls loss 663.686767578125  loc loss 43.80386734008789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 832.2992553710938  loc loss 51.36707305908203\n",
      "cls loss 799.4172973632812  loc loss 64.01864624023438\n",
      "cls loss 1277.0169677734375  loc loss 87.08213806152344\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([81.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 878.1197509765625  loc loss 42.82765579223633\n",
      "cls loss 738.6942749023438  loc loss 33.24102020263672\n",
      "cls loss 547.1812744140625  loc loss 34.935970306396484\n",
      "cls loss 482.7174072265625  loc loss 22.73768424987793\n",
      "cls loss 550.6447143554688  loc loss 34.600860595703125\n",
      "cls loss 533.512939453125  loc loss 38.08182144165039\n",
      "cls loss 640.0659790039062  loc loss 40.57126998901367\n",
      "cls loss 812.16650390625  loc loss 66.29235076904297\n",
      "cls loss 909.2091064453125  loc loss 59.73716735839844\n",
      "cls loss 1701.3289794921875  loc loss 122.41316986083984\n",
      "cls loss 622.4405517578125  loc loss 35.35085678100586\n",
      "cls loss 729.41650390625  loc loss 55.981658935546875\n",
      "cls loss 519.94287109375  loc loss 41.93040466308594\n",
      "cls loss 764.7050170898438  loc loss 43.44099044799805\n",
      "cls loss 685.9815673828125  loc loss 41.2405891418457\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([44., 44.])\n",
      "cls loss 566.5999755859375  loc loss 32.0488166809082\n",
      "cls loss 648.2390747070312  loc loss 43.41134262084961\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15.])\n",
      "cls loss 767.4170532226562  loc loss 42.93177795410156\n",
      "cls loss 368.7940673828125  loc loss 20.57813835144043\n",
      "cls loss 745.6395874023438  loc loss 48.06970977783203\n",
      "cls loss 468.9994812011719  loc loss 26.74231719970703\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([1., 3., 3.])\n",
      "cls loss 479.80645751953125  loc loss 37.676029205322266\n",
      "cls loss 425.8346862792969  loc loss 18.800098419189453\n",
      "cls loss 734.8709106445312  loc loss 41.53056335449219\n",
      "cls loss 759.0576171875  loc loss 45.31749725341797\n",
      "cls loss 730.492919921875  loc loss 43.52150344848633\n",
      "cls loss 700.0096435546875  loc loss 45.619651794433594\n",
      "cls loss 600.81591796875  loc loss 43.96336364746094\n",
      "cls loss 710.5296630859375  loc loss 51.92432403564453\n",
      "cls loss 630.579345703125  loc loss 41.419189453125\n",
      "cls loss 698.9461059570312  loc loss 56.985233306884766\n",
      "cls loss 428.4639892578125  loc loss 29.397457122802734\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 847.4210205078125  loc loss 53.90435791015625\n",
      "cls loss 960.8154296875  loc loss 57.014312744140625\n",
      "cls loss 851.3753662109375  loc loss 64.45742797851562\n",
      "cls loss 849.4066162109375  loc loss 59.799278259277344\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10., 10., 10.,  1.,  1.,  1.,  1.,  1.,  1.,  8.,  8.,\n",
      "         1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10., 10., 10.,  1.,  1.,  1.,  1.,  1.,  1.,  8.,  8.,\n",
      "         1.])\n",
      "cls loss 875.6705322265625  loc loss 51.030601501464844\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 3., 3., 3.])\n",
      "cls loss 674.4884033203125  loc loss 43.44733810424805\n",
      "cls loss 492.4954833984375  loc loss 28.085681915283203\n",
      "cls loss 361.19354248046875  loc loss 22.112056732177734\n",
      "cls loss 637.7516479492188  loc loss 47.068695068359375\n",
      "cls loss 538.8345336914062  loc loss 28.38982391357422\n",
      "cls loss 651.9522705078125  loc loss 40.222625732421875\n",
      "cls loss 716.8009033203125  loc loss 43.052574157714844\n",
      "cls loss 999.1041259765625  loc loss 67.34233093261719\n",
      "cls loss 756.009033203125  loc loss 45.96393966674805\n",
      "cls loss 707.8511962890625  loc loss 47.71649932861328\n",
      "cls loss 818.2168579101562  loc loss 57.33469772338867\n",
      "cls loss 659.0440673828125  loc loss 47.79136657714844\n",
      "cls loss 1006.9765625  loc loss 86.61432647705078\n",
      "cls loss 554.9443969726562  loc loss 33.379554748535156\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 803.3223266601562  loc loss 54.27262878417969\n",
      "cls loss 406.53411865234375  loc loss 22.497465133666992\n",
      "cls loss 1010.192626953125  loc loss 74.0926742553711\n",
      "cls loss 553.9052734375  loc loss 33.181663513183594\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 34.])\n",
      "cls loss 816.9342041015625  loc loss 47.502323150634766\n",
      "cls loss 495.9025573730469  loc loss 28.775222778320312\n",
      "cls loss 873.271728515625  loc loss 51.45819091796875\n",
      "cls loss 360.8592529296875  loc loss 20.30538558959961\n",
      "cls loss 873.0022583007812  loc loss 50.9641227722168\n",
      "cls loss 716.34912109375  loc loss 50.489566802978516\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 38.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16., 16., 16.,  9.,  9.,  9., 16., 16., 16., 85.,  9.])\n",
      "cls loss 667.1326904296875  loc loss 41.92247772216797\n",
      "cls loss 722.1119384765625  loc loss 60.26336669921875\n",
      "cls loss 1085.71484375  loc loss 80.54924011230469\n",
      "cls loss 1399.61865234375  loc loss 106.93302917480469\n",
      "cls loss 453.1297302246094  loc loss 23.095190048217773\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3., 10.,  8.,  8., 10., 10., 10.,  3.,  3., 14.])\n",
      "cls loss 580.2730712890625  loc loss 27.92508888244629\n",
      "cls loss 871.9765625  loc loss 51.63291931152344\n",
      "cls loss 341.0787353515625  loc loss 16.158329010009766\n",
      "cls loss 547.9569091796875  loc loss 29.867006301879883\n",
      "cls loss 818.420654296875  loc loss 53.400794982910156\n",
      "cls loss 674.6909790039062  loc loss 50.75654602050781\n",
      "cls loss 456.6810607910156  loc loss 25.967151641845703\n",
      "cls loss 491.1702880859375  loc loss 30.802623748779297\n",
      "cls loss 724.2551879882812  loc loss 47.79153060913086\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42., 42.,  1.])\n",
      "cls loss 702.903564453125  loc loss 49.08733367919922\n",
      "cls loss 663.7449951171875  loc loss 36.81749725341797\n",
      "cls loss 815.3534545898438  loc loss 59.20119094848633\n",
      "cls loss 865.114013671875  loc loss 59.51205062866211\n",
      "cls loss 661.5846557617188  loc loss 39.818443298339844\n",
      "cls loss 731.5807495117188  loc loss 55.65323257446289\n",
      "cls loss 513.2601318359375  loc loss 32.33566665649414\n",
      "cls loss 593.609375  loc loss 36.11357498168945\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20.])\n",
      "cls loss 396.83343505859375  loc loss 25.298431396484375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([11.])\n",
      "cls loss 501.9064025878906  loc loss 28.191999435424805\n",
      "cls loss 373.4184875488281  loc loss 22.477413177490234\n",
      "cls loss 729.1265258789062  loc loss 67.81954956054688\n",
      "cls loss 358.66046142578125  loc loss 19.50665283203125\n",
      "cls loss 674.9579467773438  loc loss 46.99708557128906\n",
      "cls loss 428.1399230957031  loc loss 24.532629013061523\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 35., 27.])\n",
      "cls loss 675.2315063476562  loc loss 46.86004638671875\n",
      "cls loss 711.7996215820312  loc loss 60.67573165893555\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 528.8447875976562  loc loss 39.46013259887695\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([42.,  1.])\n",
      "cls loss 694.4805908203125  loc loss 59.568119049072266\n",
      "cls loss 613.0902099609375  loc loss 39.636512756347656\n",
      "cls loss 784.6470947265625  loc loss 45.240745544433594\n",
      "cls loss 973.974609375  loc loss 61.94242858886719\n",
      "cls loss 844.921142578125  loc loss 58.36127853393555\n",
      "cls loss 551.2901000976562  loc loss 43.13949203491211\n",
      "cls loss 515.5596923828125  loc loss 37.84243392944336\n",
      "cls loss 427.78887939453125  loc loss 17.020666122436523\n",
      "cls loss 600.6909790039062  loc loss 36.24937057495117\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 1., 1.])\n",
      "cls loss 569.4007568359375  loc loss 33.803794860839844\n",
      "cls loss 642.5384521484375  loc loss 49.26194381713867\n",
      "cls loss 654.691162109375  loc loss 41.907867431640625\n",
      "cls loss 553.1442260742188  loc loss 39.03531265258789\n",
      "cls loss 604.6337890625  loc loss 42.11878967285156\n",
      "cls loss 664.8688354492188  loc loss 51.15889358520508\n",
      "cls loss 933.7578125  loc loss 57.29603576660156\n",
      "cls loss 816.1975708007812  loc loss 63.650699615478516\n",
      "cls loss 716.3677978515625  loc loss 45.5111198425293\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 564.5662841796875  loc loss 44.70677947998047\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 668.686767578125  loc loss 33.165470123291016\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([81.])\n",
      "cls loss 823.4967041015625  loc loss 57.13496398925781\n",
      "cls loss 518.3526000976562  loc loss 36.76775360107422\n",
      "cls loss 415.1699523925781  loc loss 25.67427635192871\n",
      "cls loss 571.59423828125  loc loss 29.33591651916504\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3.,  1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 19.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 19.])\n",
      "cls loss 756.41015625  loc loss 53.85742950439453\n",
      "cls loss 470.00872802734375  loc loss 21.65892791748047\n",
      "cls loss 443.64312744140625  loc loss 28.380048751831055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 849.7779541015625  loc loss 67.44429779052734\n",
      "cls loss 465.0279541015625  loc loss 29.996158599853516\n",
      "cls loss 571.047607421875  loc loss 42.48106384277344\n",
      "cls loss 663.502197265625  loc loss 50.18235397338867\n",
      "cls loss 521.8737182617188  loc loss 40.686893463134766\n",
      "cls loss 701.709228515625  loc loss 44.0440559387207\n",
      "cls loss 769.725341796875  loc loss 56.7772216796875\n",
      "cls loss 944.6934204101562  loc loss 85.4062728881836\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 81.])\n",
      "cls loss 656.7913818359375  loc loss 39.470794677734375\n",
      "cls loss 671.7601318359375  loc loss 35.33836364746094\n",
      "cls loss 681.771240234375  loc loss 39.653404235839844\n",
      "cls loss 509.10614013671875  loc loss 25.828170776367188\n",
      "cls loss 486.2821350097656  loc loss 29.652292251586914\n",
      "cls loss 593.0194702148438  loc loss 38.84629440307617\n",
      "cls loss 453.7874755859375  loc loss 31.44766616821289\n",
      "cls loss 367.4892883300781  loc loss 26.054162979125977\n",
      "cls loss 475.73785400390625  loc loss 34.75324249267578\n",
      "cls loss 658.1587524414062  loc loss 42.703495025634766\n",
      "cls loss 541.0746459960938  loc loss 40.97918701171875\n",
      "cls loss 574.541748046875  loc loss 42.99256134033203\n",
      "cls loss 346.9514465332031  loc loss 25.743146896362305\n",
      "cls loss 1104.5616455078125  loc loss 83.31884765625\n",
      "cls loss 742.9140625  loc loss 55.264129638671875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 630.024658203125  loc loss 38.32011032104492\n",
      "cls loss 668.5760498046875  loc loss 49.16675567626953\n",
      "cls loss 549.7945556640625  loc loss 31.99072265625\n",
      "cls loss 722.1937255859375  loc loss 49.94497299194336\n",
      "cls loss 742.381591796875  loc loss 51.327369689941406\n",
      "cls loss 666.8165893554688  loc loss 43.91753005981445\n",
      "cls loss 614.8560791015625  loc loss 31.887317657470703\n",
      "cls loss 470.8985595703125  loc loss 26.206714630126953\n",
      "cls loss 603.3671875  loc loss 41.448062896728516\n",
      "cls loss 637.1019897460938  loc loss 49.90059280395508\n",
      "cls loss 726.1735229492188  loc loss 38.827117919921875\n",
      "cls loss 882.9794921875  loc loss 65.56192779541016\n",
      "cls loss 953.568603515625  loc loss 67.50606536865234\n",
      "cls loss 657.02587890625  loc loss 43.560325622558594\n",
      "cls loss 791.29052734375  loc loss 67.0850830078125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1., 38., 47.,  1.,  1.,  1.,  1.,  1., 62.])\n",
      "cls loss 560.624755859375  loc loss 34.85149383544922\n",
      "cls loss 710.5498657226562  loc loss 43.66904830932617\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 746.401123046875  loc loss 48.487754821777344\n",
      "cls loss 934.7695922851562  loc loss 63.290557861328125\n",
      "cls loss 589.442626953125  loc loss 31.71725082397461\n",
      "cls loss 639.6546630859375  loc loss 52.516204833984375\n",
      "cls loss 594.8045654296875  loc loss 41.585609436035156\n",
      "cls loss 417.7420349121094  loc loss 18.129257202148438\n",
      "cls loss 565.4266357421875  loc loss 37.10749816894531\n",
      "cls loss 498.8371276855469  loc loss 26.471939086914062\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1., 35.])\n",
      "cls loss 546.6307983398438  loc loss 31.55083656311035\n",
      "cls loss 864.854736328125  loc loss 49.600257873535156\n",
      "cls loss 794.5045776367188  loc loss 54.20769500732422\n",
      "cls loss 719.988037109375  loc loss 60.733741760253906\n",
      "cls loss 594.3126831054688  loc loss 48.10005187988281\n",
      "cls loss 704.703857421875  loc loss 56.025787353515625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 412.185302734375  loc loss 26.678279876708984\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 658.0903930664062  loc loss 33.514888763427734\n",
      "cls loss 1018.03857421875  loc loss 62.19678497314453\n",
      "cls loss 1180.7347412109375  loc loss 89.61632537841797\n",
      "cls loss 649.582763671875  loc loss 35.54507064819336\n",
      "cls loss 537.095458984375  loc loss 33.514095306396484\n",
      "cls loss 549.1729736328125  loc loss 35.983943939208984\n",
      "cls loss 592.616455078125  loc loss 50.62458419799805\n",
      "cls loss 592.5880126953125  loc loss 24.825714111328125\n",
      "cls loss 887.3616333007812  loc loss 71.36616516113281\n",
      "cls loss 744.596435546875  loc loss 46.794795989990234\n",
      "cls loss 494.80279541015625  loc loss 27.486186981201172\n",
      "cls loss 834.0989990234375  loc loss 44.839996337890625\n",
      "cls loss 960.5115356445312  loc loss 70.21891021728516\n",
      "cls loss 761.384521484375  loc loss 49.34532928466797\n",
      "cls loss 709.66455078125  loc loss 38.58738708496094\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.])\n",
      "cls loss 654.5589599609375  loc loss 47.899208068847656\n",
      "cls loss 548.8601684570312  loc loss 42.63114929199219\n",
      "cls loss 847.3858642578125  loc loss 52.051490783691406\n",
      "cls loss 1068.4427490234375  loc loss 95.31620025634766\n",
      "cls loss 531.7122802734375  loc loss 26.058443069458008\n",
      "cls loss 586.7538452148438  loc loss 39.494361877441406\n",
      "cls loss 501.829345703125  loc loss 33.1406135559082\n",
      "cls loss 570.4450073242188  loc loss 36.59677505493164\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 21., 21., 21.])\n",
      "cls loss 615.8070068359375  loc loss 36.79933547973633\n",
      "cls loss 563.5648193359375  loc loss 28.901456832885742\n",
      "cls loss 582.4176025390625  loc loss 39.767723083496094\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 35.])\n",
      "cls loss 901.6253051757812  loc loss 62.61073303222656\n",
      "cls loss 302.6261291503906  loc loss 17.19791603088379\n",
      "cls loss 470.560791015625  loc loss 33.35222625732422\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 453.9747314453125  loc loss 30.387479782104492\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 38., 38.,  9., 38.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1.,  1.])\n",
      "cls loss 496.487060546875  loc loss 39.74415969848633\n",
      "cls loss 825.4866943359375  loc loss 63.52127456665039\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 2.,  1., 77., 31., 10., 10.,  1.,  4., 10.])\n",
      "cls loss 495.958251953125  loc loss 26.376575469970703\n",
      "cls loss 858.20263671875  loc loss 51.52665328979492\n",
      "cls loss 1518.40234375  loc loss 118.05339050292969\n",
      "cls loss 550.0972900390625  loc loss 34.936710357666016\n",
      "cls loss 709.1416015625  loc loss 62.17243957519531\n",
      "cls loss 557.4955444335938  loc loss 34.19261169433594\n",
      "cls loss 575.5444946289062  loc loss 29.49502944946289\n",
      "cls loss 905.3807983398438  loc loss 38.526954650878906\n",
      "cls loss 789.948486328125  loc loss 46.040626525878906\n",
      "cls loss 719.5908203125  loc loss 48.885677337646484\n",
      "cls loss 555.2642822265625  loc loss 28.282686233520508\n",
      "cls loss 700.7518920898438  loc loss 31.458086013793945\n",
      "cls loss 1217.35546875  loc loss 70.47825622558594\n",
      "cls loss 926.8811645507812  loc loss 65.645263671875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1., 42., 42., 42., 42., 42., 42.,  1.,\n",
      "         1.,  1.,  1., 42.,  1.,  1., 42.,  1.])\n",
      "cls loss 554.004638671875  loc loss 40.36119842529297\n",
      "cls loss 776.2989501953125  loc loss 52.86663055419922\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.])\n",
      "cls loss 381.10736083984375  loc loss 26.147857666015625\n",
      "cls loss 730.4049682617188  loc loss 55.68788146972656\n",
      "cls loss 586.2769775390625  loc loss 45.379093170166016\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([11.])\n",
      "cls loss 365.2420654296875  loc loss 21.459638595581055\n",
      "cls loss 480.5152893066406  loc loss 24.129093170166016\n",
      "cls loss 483.8956298828125  loc loss 27.77205467224121\n",
      "cls loss 665.833984375  loc loss 48.90773391723633\n",
      "cls loss 641.28564453125  loc loss 42.69403839111328\n",
      "cls loss 647.0034790039062  loc loss 51.967838287353516\n",
      "cls loss 897.0191650390625  loc loss 57.25601577758789\n",
      "cls loss 507.22247314453125  loc loss 34.184837341308594\n",
      "cls loss 906.2723999023438  loc loss 75.91092681884766\n",
      "cls loss 577.306396484375  loc loss 30.8447265625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 509.3741455078125  loc loss 34.01231002807617\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1., 38., 38., 42.])\n",
      "cls loss 670.1121215820312  loc loss 47.36137008666992\n",
      "cls loss 665.712158203125  loc loss 30.53512954711914\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 506.09234619140625  loc loss 35.02845001220703\n",
      "cls loss 1118.5755615234375  loc loss 79.07605743408203\n",
      "cls loss 641.4561157226562  loc loss 49.164817810058594\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10.,  3.,  3.,  6.,  8.,  8.,  1.,  1.,  1., 10.])\n",
      "cls loss 598.0250854492188  loc loss 38.05801010131836\n",
      "cls loss 355.12713623046875  loc loss 14.379995346069336\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10.,  3.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 560.003662109375  loc loss 31.77852439880371\n",
      "cls loss 372.42864990234375  loc loss 19.188308715820312\n",
      "cls loss 605.580810546875  loc loss 53.11094284057617\n",
      "cls loss 668.6349487304688  loc loss 51.537906646728516\n",
      "cls loss 513.885498046875  loc loss 33.35272979736328\n",
      "cls loss 420.9036865234375  loc loss 20.649499893188477\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 34.])\n",
      "cls loss 911.3721923828125  loc loss 57.12836837768555\n",
      "cls loss 955.6181030273438  loc loss 82.09391784667969\n",
      "cls loss 637.186279296875  loc loss 54.503326416015625\n",
      "cls loss 472.96771240234375  loc loss 35.58253479003906\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.,  1.])\n",
      "cls loss 548.7538452148438  loc loss 30.1700496673584\n",
      "cls loss 841.92138671875  loc loss 69.28662872314453\n",
      "cls loss 1211.0130615234375  loc loss 87.96055603027344\n",
      "cls loss 1037.34765625  loc loss 60.785457611083984\n",
      "cls loss 652.1590576171875  loc loss 39.15849685668945\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 881.432373046875  loc loss 43.711090087890625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10.])\n",
      "cls loss 489.7151184082031  loc loss 27.9727725982666\n",
      "cls loss 653.9888916015625  loc loss 35.749122619628906\n",
      "cls loss 681.7242431640625  loc loss 36.335289001464844\n",
      "cls loss 455.49896240234375  loc loss 28.1961612701416\n",
      "cls loss 553.5956420898438  loc loss 42.9072265625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21.,\n",
      "        21.])\n",
      "cls loss 755.61962890625  loc loss 48.305484771728516\n",
      "cls loss 641.3701171875  loc loss 47.22441101074219\n",
      "cls loss 427.5667724609375  loc loss 19.55658721923828\n",
      "cls loss 820.3792724609375  loc loss 55.92675018310547\n",
      "cls loss 637.6727294921875  loc loss 49.652156829833984\n",
      "cls loss 465.8238220214844  loc loss 32.38499069213867\n",
      "cls loss 965.8431396484375  loc loss 75.9311294555664\n",
      "cls loss 1114.2059326171875  loc loss 83.16620635986328\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15., 85.])\n",
      "cls loss 770.4017944335938  loc loss 50.83879089355469\n",
      "cls loss 675.149658203125  loc loss 60.898983001708984\n",
      "cls loss 818.4930419921875  loc loss 57.154048919677734\n",
      "cls loss 717.7653198242188  loc loss 46.12628173828125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 8., 8.])\n",
      "cls loss 422.22625732421875  loc loss 24.227169036865234\n",
      "cls loss 547.810302734375  loc loss 34.321441650390625\n",
      "cls loss 612.7850341796875  loc loss 37.87471008300781\n",
      "cls loss 536.263427734375  loc loss 30.167808532714844\n",
      "cls loss 593.46484375  loc loss 38.68769454956055\n",
      "cls loss 819.2423095703125  loc loss 46.69993591308594\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1., 35., 27., 27.,  1., 27.,  1.])\n",
      "cls loss 1105.158447265625  loc loss 76.60986328125\n",
      "cls loss 500.69256591796875  loc loss 38.66326141357422\n",
      "cls loss 625.7225952148438  loc loss 45.60127258300781\n",
      "cls loss 577.4402465820312  loc loss 50.25758743286133\n",
      "cls loss 591.45166015625  loc loss 44.449886322021484\n",
      "cls loss 612.60595703125  loc loss 47.92261505126953\n",
      "cls loss 555.1216430664062  loc loss 46.430179595947266\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  2.,  2.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  2.,  2.])\n",
      "cls loss 368.3709716796875  loc loss 16.33993148803711\n",
      "cls loss 835.55859375  loc loss 55.48814392089844\n",
      "cls loss 603.7982177734375  loc loss 33.9526481628418\n",
      "cls loss 974.2930297851562  loc loss 72.63777923583984\n",
      "cls loss 430.6919860839844  loc loss 28.45207977294922\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 19., 19., 19., 16.])\n",
      "cls loss 435.00665283203125  loc loss 23.590267181396484\n",
      "cls loss 356.8297119140625  loc loss 17.88756561279297\n",
      "cls loss 523.9542236328125  loc loss 28.23674774169922\n",
      "cls loss 672.173583984375  loc loss 45.453739166259766\n",
      "cls loss 353.61016845703125  loc loss 28.915578842163086\n",
      "cls loss 792.5655517578125  loc loss 57.01090621948242\n",
      "cls loss 545.7521362304688  loc loss 42.72856903076172\n",
      "cls loss 590.0797119140625  loc loss 42.9112548828125\n",
      "cls loss 722.0740966796875  loc loss 55.14942932128906\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 821.396728515625  loc loss 42.59941101074219\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 1048.6182861328125  loc loss 90.7169189453125\n",
      "cls loss 1307.875244140625  loc loss 132.2896270751953\n",
      "cls loss 626.1019287109375  loc loss 49.69491195678711\n",
      "cls loss 585.3314208984375  loc loss 43.01005554199219\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3.,  3.,  3.,  3.,  3., 10.])\n",
      "cls loss 356.9215087890625  loc loss 17.442663192749023\n",
      "cls loss 645.8990478515625  loc loss 40.173885345458984\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 1., 1., 1., 3., 3., 3., 3.])\n",
      "cls loss 592.5753173828125  loc loss 39.445133209228516\n",
      "cls loss 993.090087890625  loc loss 76.77836608886719\n",
      "cls loss 783.491943359375  loc loss 56.94805908203125\n",
      "cls loss 628.92333984375  loc loss 34.039947509765625\n",
      "cls loss 825.6517333984375  loc loss 64.39573669433594\n",
      "cls loss 567.9692993164062  loc loss 40.99571990966797\n",
      "cls loss 846.2487182617188  loc loss 59.750938415527344\n",
      "cls loss 626.6837158203125  loc loss 52.9351692199707\n",
      "cls loss 614.36376953125  loc loss 43.35504913330078\n",
      "cls loss 1212.423095703125  loc loss 105.82749938964844\n",
      "cls loss 806.2427978515625  loc loss 57.48396682739258\n",
      "cls loss 540.000732421875  loc loss 29.021129608154297\n",
      "cls loss 350.7251892089844  loc loss 17.968360900878906\n",
      "cls loss 413.0902099609375  loc loss 25.957103729248047\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3., 10., 10., 10., 10., 10., 10., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10., 10., 10., 10., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 11., 10., 10., 10., 10., 10.,  3.,  3.,  3.,  3.,  3.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 11., 10., 10., 10., 10., 10.,  3.,  3.,  3.,  3.,  3.])\n",
      "cls loss 376.2889404296875  loc loss 22.161922454833984\n",
      "cls loss 516.59375  loc loss 27.007667541503906\n",
      "cls loss 423.9207458496094  loc loss 27.470870971679688\n",
      "cls loss 390.98260498046875  loc loss 19.308589935302734\n",
      "cls loss 494.00946044921875  loc loss 39.36711502075195\n",
      "cls loss 453.6348571777344  loc loss 19.188159942626953\n",
      "cls loss 752.9830932617188  loc loss 56.1546630859375\n",
      "cls loss 653.9625244140625  loc loss 51.569705963134766\n",
      "cls loss 994.1569213867188  loc loss 69.6269302368164\n",
      "cls loss 486.84661865234375  loc loss 37.86421203613281\n",
      "cls loss 861.673583984375  loc loss 62.13667678833008\n",
      "cls loss 720.8447265625  loc loss 53.44633865356445\n",
      "cls loss 664.2587890625  loc loss 47.10801696777344\n",
      "cls loss 675.0625  loc loss 53.40525817871094\n",
      "cls loss 918.3130493164062  loc loss 65.78446197509766\n",
      "cls loss 897.172119140625  loc loss 58.518882751464844\n",
      "cls loss 495.32257080078125  loc loss 26.3806095123291\n",
      "cls loss 784.8019409179688  loc loss 61.45262145996094\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 10.,  1., 18.])\n",
      "cls loss 429.6666564941406  loc loss 29.647808074951172\n",
      "cls loss 488.0819091796875  loc loss 20.013019561767578\n",
      "cls loss 841.0528564453125  loc loss 42.35401916503906\n",
      "cls loss 1108.3690185546875  loc loss 77.65931701660156\n",
      "cls loss 725.0887451171875  loc loss 47.62659454345703\n",
      "cls loss 911.1768798828125  loc loss 61.10879898071289\n",
      "cls loss 661.544921875  loc loss 46.08591079711914\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.,  1.,  1.])\n",
      "cls loss 852.262451171875  loc loss 60.62941360473633\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1., 38.,  1.])\n",
      "cls loss 825.880859375  loc loss 50.37577819824219\n",
      "cls loss 1033.27099609375  loc loss 82.42313385009766\n",
      "cls loss 515.1646118164062  loc loss 43.140892028808594\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 690.2059936523438  loc loss 51.85371780395508\n",
      "cls loss 623.395751953125  loc loss 45.34541320800781\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3., 10.,  8.,  3., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.])\n",
      "cls loss 752.140380859375  loc loss 50.658451080322266\n",
      "cls loss 520.9439697265625  loc loss 35.63665008544922\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3.,  3., 11.,  3., 10., 10.,  3.,  3., 10.])\n",
      "cls loss 643.0226440429688  loc loss 35.23596954345703\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3., 10., 10., 10.])\n",
      "cls loss 604.3995361328125  loc loss 48.59697723388672\n",
      "cls loss 520.45703125  loc loss 32.45632553100586\n",
      "cls loss 627.0196533203125  loc loss 50.215396881103516\n",
      "cls loss 1048.441162109375  loc loss 65.98085021972656\n",
      "cls loss 637.7705078125  loc loss 45.67584228515625\n",
      "cls loss 454.6811828613281  loc loss 40.14111328125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 565.97998046875  loc loss 41.69053268432617\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 9.,  9., 85., 85.])\n",
      "cls loss 542.4107666015625  loc loss 31.040313720703125\n",
      "cls loss 616.1471557617188  loc loss 40.987823486328125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 968.2235107421875  loc loss 75.41486358642578\n",
      "cls loss 818.7232666015625  loc loss 46.329429626464844\n",
      "cls loss 926.5565185546875  loc loss 68.3851547241211\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10., 10., 10., 10.])\n",
      "cls loss 600.870849609375  loc loss 37.54734802246094\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([13.])\n",
      "cls loss 929.033935546875  loc loss 80.59056091308594\n",
      "cls loss 361.13055419921875  loc loss 19.756107330322266\n",
      "cls loss 407.40264892578125  loc loss 23.858362197875977\n",
      "cls loss 565.2579345703125  loc loss 34.88823699951172\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19.,  1.,  1.,  1., 19., 19.])\n",
      "cls loss 603.4588623046875  loc loss 39.74414825439453\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 415.27911376953125  loc loss 42.14607238769531\n",
      "cls loss 696.8978271484375  loc loss 53.966392517089844\n",
      "cls loss 474.8082580566406  loc loss 31.622385025024414\n",
      "cls loss 732.449462890625  loc loss 49.671382904052734\n",
      "cls loss 787.36962890625  loc loss 62.75078201293945\n",
      "cls loss 654.2537841796875  loc loss 37.271732330322266\n",
      "cls loss 852.8701171875  loc loss 68.3526840209961\n",
      "cls loss 417.5701599121094  loc loss 18.641969680786133\n",
      "cls loss 632.744384765625  loc loss 44.11217498779297\n",
      "cls loss 553.238037109375  loc loss 27.754724502563477\n",
      "cls loss 516.3680419921875  loc loss 31.372669219970703\n",
      "cls loss 678.740234375  loc loss 53.97355270385742\n",
      "cls loss 661.685791015625  loc loss 40.94441223144531\n",
      "cls loss 960.1644287109375  loc loss 61.90473937988281\n",
      "cls loss 590.6857299804688  loc loss 43.281673431396484\n",
      "cls loss 698.541259765625  loc loss 51.465118408203125\n",
      "cls loss 1006.0830078125  loc loss 72.59306335449219\n",
      "cls loss 603.9435424804688  loc loss 49.60537338256836\n",
      "cls loss 688.076171875  loc loss 43.127933502197266\n",
      "cls loss 885.9127197265625  loc loss 65.10910034179688\n",
      "cls loss 845.7251586914062  loc loss 64.48152160644531\n",
      "cls loss 1082.6534423828125  loc loss 67.78211212158203\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 5.])\n",
      "cls loss 350.5899963378906  loc loss 12.829207420349121\n",
      "cls loss 429.72283935546875  loc loss 20.737794876098633\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 13.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 6., 8., 8.])\n",
      "cls loss 445.67254638671875  loc loss 18.563505172729492\n",
      "cls loss 452.76434326171875  loc loss 27.11146354675293\n",
      "cls loss 843.859375  loc loss 68.20843505859375\n",
      "cls loss 410.71868896484375  loc loss 19.91733169555664\n",
      "cls loss 668.6423950195312  loc loss 52.8155517578125\n",
      "cls loss 1046.6339111328125  loc loss 71.59739685058594\n",
      "cls loss 624.1439208984375  loc loss 48.01555633544922\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([42., 42.,  1.,  1.,  1.,  1.,  1.,  1.,  1., 42., 42.])\n",
      "cls loss 682.4209594726562  loc loss 45.583961486816406\n",
      "cls loss 890.5457763671875  loc loss 72.57881927490234\n",
      "cls loss 693.6476440429688  loc loss 60.83688735961914\n",
      "cls loss 530.4551391601562  loc loss 31.729570388793945\n",
      "cls loss 708.9591674804688  loc loss 46.07661819458008\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 962.704833984375  loc loss 64.32064056396484\n",
      "cls loss 756.36669921875  loc loss 57.38731384277344\n",
      "cls loss 497.0581970214844  loc loss 31.615554809570312\n",
      "cls loss 463.6658020019531  loc loss 23.54153060913086\n",
      "cls loss 585.2208862304688  loc loss 38.489131927490234\n",
      "cls loss 797.4996948242188  loc loss 53.84528732299805\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15.])\n",
      "cls loss 385.7669982910156  loc loss 21.085512161254883\n",
      "cls loss 623.34521484375  loc loss 41.73057174682617\n",
      "cls loss 541.51318359375  loc loss 37.627193450927734\n",
      "cls loss 925.8845825195312  loc loss 71.14967346191406\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19.,  7.])\n",
      "cls loss 569.1427001953125  loc loss 36.74147033691406\n",
      "cls loss 1149.3427734375  loc loss 72.30608367919922\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 953.8914794921875  loc loss 56.6939697265625\n",
      "cls loss 716.9764404296875  loc loss 58.90739059448242\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([38., 38.,  1., 18.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1., 18., 18.,  1.])\n",
      "cls loss 603.1485595703125  loc loss 33.293128967285156\n",
      "cls loss 590.3262939453125  loc loss 28.856103897094727\n",
      "cls loss 917.666748046875  loc loss 79.2799072265625\n",
      "cls loss 720.1075439453125  loc loss 47.47785186767578\n",
      "cls loss 758.756591796875  loc loss 38.93254089355469\n",
      "cls loss 414.3067932128906  loc loss 33.58736801147461\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.])\n",
      "cls loss 332.449462890625  loc loss 14.745685577392578\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([32.])\n",
      "cls loss 676.936767578125  loc loss 33.3540153503418\n",
      "cls loss 573.2216796875  loc loss 38.497066497802734\n",
      "cls loss 754.8961181640625  loc loss 64.19395446777344\n",
      "cls loss 719.524169921875  loc loss 44.578338623046875\n",
      "cls loss 583.4689331054688  loc loss 39.693885803222656\n",
      "cls loss 914.4017333984375  loc loss 54.870094299316406\n",
      "cls loss 922.697998046875  loc loss 67.74159240722656\n",
      "cls loss 764.4385375976562  loc loss 54.48127365112305\n",
      "cls loss 702.8367309570312  loc loss 40.14815139770508\n",
      "cls loss 1055.1153564453125  loc loss 66.3382568359375\n",
      "cls loss 625.208740234375  loc loss 33.41239547729492\n",
      "cls loss 931.0657958984375  loc loss 81.6514663696289\n",
      "cls loss 714.3463134765625  loc loss 45.72712707519531\n",
      "cls loss 580.9095458984375  loc loss 45.17433166503906\n",
      "cls loss 463.21026611328125  loc loss 27.536575317382812\n",
      "cls loss 475.81475830078125  loc loss 34.70716857910156\n",
      "cls loss 716.5264282226562  loc loss 53.80187225341797\n",
      "cls loss 750.67529296875  loc loss 59.103416442871094\n",
      "cls loss 435.58245849609375  loc loss 32.06755447387695\n",
      "cls loss 842.6618041992188  loc loss 58.927921295166016\n",
      "cls loss 997.8011474609375  loc loss 64.88726806640625\n",
      "cls loss 371.7349548339844  loc loss 26.48945426940918\n",
      "cls loss 957.15966796875  loc loss 68.27163696289062\n",
      "cls loss 687.900146484375  loc loss 54.33519744873047\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 924.9019165039062  loc loss 74.60887145996094\n",
      "cls loss 483.5792236328125  loc loss 20.543537139892578\n",
      "cls loss 716.993408203125  loc loss 42.36238479614258\n",
      "cls loss 725.6737670898438  loc loss 49.27869415283203\n",
      "cls loss 558.5338134765625  loc loss 35.68758773803711\n",
      "cls loss 379.1700134277344  loc loss 17.881189346313477\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 9., 9., 1., 9., 9., 9., 9., 1., 9.])\n",
      "cls loss 1229.95166015625  loc loss 106.4210433959961\n",
      "cls loss 749.0689697265625  loc loss 41.391685485839844\n",
      "cls loss 1063.93701171875  loc loss 89.43665313720703\n",
      "cls loss 488.44757080078125  loc loss 30.733259201049805\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 42., 42.])\n",
      "cls loss 755.3316040039062  loc loss 58.03742599487305\n",
      "cls loss 787.2125244140625  loc loss 58.745521545410156\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  2.,  1.,  1.,  1., 38.,\n",
      "         1.,  1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 38., 38., 38.,  1., 38., 38., 38.,  1.,  1., 38.,  1.,\n",
      "         1.])\n",
      "cls loss 527.8504638671875  loc loss 34.42644500732422\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  8.,  8.])\n",
      "cls loss 1081.730712890625  loc loss 76.21895599365234\n",
      "cls loss 1050.276611328125  loc loss 77.70719146728516\n",
      "cls loss 444.576416015625  loc loss 27.781314849853516\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([4., 1., 1., 4.])\n",
      "cls loss 621.90771484375  loc loss 47.341182708740234\n",
      "cls loss 748.0473022460938  loc loss 49.32341003417969\n",
      "cls loss 353.5843505859375  loc loss 17.779977798461914\n",
      "cls loss 497.0550537109375  loc loss 29.256160736083984\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([51.,  1.])\n",
      "cls loss 363.46258544921875  loc loss 16.317598342895508\n",
      "cls loss 449.9700622558594  loc loss 29.528030395507812\n",
      "cls loss 800.9880981445312  loc loss 51.611541748046875\n",
      "cls loss 913.0526123046875  loc loss 71.20573425292969\n",
      "cls loss 1199.48486328125  loc loss 74.77598571777344\n",
      "cls loss 1480.718994140625  loc loss 103.16587829589844\n",
      "cls loss 644.5078125  loc loss 43.017555236816406\n",
      "cls loss 866.5718994140625  loc loss 63.72602081298828\n",
      "cls loss 930.8485717773438  loc loss 70.44567108154297\n",
      "cls loss 683.1232299804688  loc loss 41.64509963989258\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  3.,  1.,  1.,  1.,  3.,  1.,  1.,\n",
      "         1.,  1.,  1.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 779.9404296875  loc loss 44.44498825073242\n",
      "cls loss 924.3365478515625  loc loss 46.365699768066406\n",
      "cls loss 822.94384765625  loc loss 42.33572769165039\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "cls loss 649.123779296875  loc loss 39.75208282470703\n",
      "cls loss 383.9210510253906  loc loss 31.16579818725586\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3.])\n",
      "cls loss 425.67828369140625  loc loss 17.095745086669922\n",
      "cls loss 589.4730224609375  loc loss 44.529476165771484\n",
      "cls loss 476.6684875488281  loc loss 34.97876739501953\n",
      "cls loss 827.115234375  loc loss 65.1827621459961\n",
      "cls loss 608.7205810546875  loc loss 28.617202758789062\n",
      "cls loss 470.70916748046875  loc loss 33.26290512084961\n",
      "cls loss 1429.77294921875  loc loss 100.76632690429688\n",
      "cls loss 602.534912109375  loc loss 46.902645111083984\n",
      "cls loss 421.19140625  loc loss 38.732208251953125\n",
      "cls loss 582.0323486328125  loc loss 35.87980270385742\n",
      "cls loss 485.11419677734375  loc loss 38.793731689453125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 890.0098876953125  loc loss 66.49815368652344\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  9., 64., 64., 64., 64., 64., 64., 64., 64., 64.,  9.,  9.,  9.,\n",
      "         9.])\n",
      "cls loss 536.9471435546875  loc loss 29.96748161315918\n",
      "cls loss 1132.384521484375  loc loss 101.34745025634766\n",
      "cls loss 647.879638671875  loc loss 43.118125915527344\n",
      "cls loss 810.2437744140625  loc loss 64.53194427490234\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.,  3.,  3.])\n",
      "cls loss 535.3707275390625  loc loss 36.14653015136719\n",
      "cls loss 671.1572265625  loc loss 39.152339935302734\n",
      "cls loss 605.3138427734375  loc loss 46.97284698486328\n",
      "cls loss 749.9462890625  loc loss 45.93429183959961\n",
      "cls loss 709.859130859375  loc loss 53.80231857299805\n",
      "cls loss 622.888671875  loc loss 49.13905334472656\n",
      "cls loss 630.0257568359375  loc loss 48.00490951538086\n",
      "cls loss 639.218505859375  loc loss 42.076263427734375\n",
      "cls loss 835.34375  loc loss 60.15562057495117\n",
      "cls loss 671.8814086914062  loc loss 45.45967102050781\n",
      "cls loss 549.8231201171875  loc loss 26.95186996459961\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21.])\n",
      "cls loss 430.80224609375  loc loss 21.206762313842773\n",
      "cls loss 558.84765625  loc loss 49.600555419921875\n",
      "cls loss 744.677978515625  loc loss 58.09539794921875\n",
      "cls loss 469.499267578125  loc loss 30.49281120300293\n",
      "cls loss 704.0616455078125  loc loss 44.800987243652344\n",
      "cls loss 1257.057373046875  loc loss 78.32246398925781\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 42., 42.,  1.,  1.])\n",
      "cls loss 638.8867797851562  loc loss 38.13031005859375\n",
      "cls loss 435.41729736328125  loc loss 30.779056549072266\n",
      "cls loss 576.7286376953125  loc loss 43.58330154418945\n",
      "cls loss 796.1181640625  loc loss 71.4132308959961\n",
      "cls loss 554.8479614257812  loc loss 36.3748779296875\n",
      "cls loss 749.294921875  loc loss 57.82799530029297\n",
      "cls loss 747.0238037109375  loc loss 58.450958251953125\n",
      "cls loss 768.3823852539062  loc loss 48.953208923339844\n",
      "cls loss 626.313720703125  loc loss 40.67815399169922\n",
      "cls loss 531.4276733398438  loc loss 35.60661315917969\n",
      "cls loss 474.3758850097656  loc loss 21.757545471191406\n",
      "cls loss 558.5904541015625  loc loss 43.649688720703125\n",
      "cls loss 806.494873046875  loc loss 72.76695251464844\n",
      "cls loss 677.7077026367188  loc loss 42.92262649536133\n",
      "cls loss 712.9638671875  loc loss 53.08281326293945\n",
      "cls loss 744.658203125  loc loss 40.834388732910156\n",
      "cls loss 1105.015869140625  loc loss 71.94275665283203\n",
      "cls loss 726.9356079101562  loc loss 57.31072235107422\n",
      "cls loss 867.9552612304688  loc loss 52.613677978515625\n",
      "cls loss 556.094482421875  loc loss 26.237821578979492\n",
      "cls loss 747.568359375  loc loss 47.82998275756836\n",
      "cls loss 689.6324462890625  loc loss 46.47943115234375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 5., 5., 5., 5., 5., 5.])\n",
      "cls loss 475.30914306640625  loc loss 33.77729034423828\n",
      "cls loss 560.9927978515625  loc loss 39.88927459716797\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([13.])\n",
      "cls loss 404.24072265625  loc loss 24.46497917175293\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([44., 10.,  1.,  1.,  1.])\n",
      "cls loss 437.0023193359375  loc loss 25.787540435791016\n",
      "cls loss 756.1907958984375  loc loss 42.822105407714844\n",
      "cls loss 609.052978515625  loc loss 36.38630294799805\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19., 19., 19., 19., 19., 19., 19.])\n",
      "cls loss 787.3590087890625  loc loss 50.18546676635742\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([56.])\n",
      "cls loss 1407.8876953125  loc loss 86.80614471435547\n",
      "cls loss 723.7734375  loc loss 60.72174835205078\n",
      "cls loss 1035.5504150390625  loc loss 77.14691925048828\n",
      "cls loss 951.0  loc loss 78.8516845703125\n",
      "cls loss 602.03759765625  loc loss 40.896846771240234\n",
      "cls loss 1026.1429443359375  loc loss 73.92375183105469\n",
      "cls loss 641.5311889648438  loc loss 34.96211242675781\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 36.])\n",
      "cls loss 732.8675537109375  loc loss 42.48670959472656\n",
      "cls loss 619.0723266601562  loc loss 46.46036911010742\n",
      "cls loss 714.2901000976562  loc loss 37.7515983581543\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5.])\n",
      "cls loss 675.5732421875  loc loss 45.06650161743164\n",
      "cls loss 437.4328308105469  loc loss 23.75168228149414\n",
      "cls loss 877.4252319335938  loc loss 56.36873245239258\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "cls loss 799.5767822265625  loc loss 59.810081481933594\n",
      "cls loss 871.1324462890625  loc loss 52.252532958984375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 724.197998046875  loc loss 53.96532440185547\n",
      "cls loss 870.8117065429688  loc loss 63.356727600097656\n",
      "cls loss 739.421142578125  loc loss 65.23272705078125\n",
      "cls loss 533.177734375  loc loss 38.725257873535156\n",
      "cls loss 639.294921875  loc loss 47.22998809814453\n",
      "cls loss 607.09521484375  loc loss 43.96708297729492\n",
      "cls loss 952.8017578125  loc loss 61.35696792602539\n",
      "cls loss 458.9175720214844  loc loss 25.963844299316406\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 11., 15., 10., 10., 10., 10., 10.])\n",
      "cls loss 1015.0670166015625  loc loss 78.36576080322266\n",
      "cls loss 588.0907592773438  loc loss 40.19407272338867\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3.])\n",
      "cls loss 702.7553100585938  loc loss 43.004150390625\n",
      "cls loss 548.1043701171875  loc loss 35.23902893066406\n",
      "cls loss 616.406005859375  loc loss 34.04319381713867\n",
      "cls loss 814.9055786132812  loc loss 44.85010528564453\n",
      "cls loss 530.255615234375  loc loss 21.32267951965332\n",
      "cls loss 750.9156494140625  loc loss 37.84559631347656\n",
      "cls loss 731.441650390625  loc loss 53.189334869384766\n",
      "cls loss 618.7884521484375  loc loss 47.893619537353516\n",
      "cls loss 1303.38720703125  loc loss 109.67996215820312\n",
      "cls loss 965.4644775390625  loc loss 73.02455139160156\n",
      "cls loss 653.4373779296875  loc loss 49.058570861816406\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  9.,  9.,  9.,  6.,  6., 85., 85.,  8.,  1.,  1.,  1.,  1.,\n",
      "         6.,  6.])\n",
      "cls loss 457.8641357421875  loc loss 31.835309982299805\n",
      "cls loss 1021.5802612304688  loc loss 74.49287414550781\n",
      "cls loss 1174.6103515625  loc loss 81.01750183105469\n",
      "cls loss 799.2340087890625  loc loss 61.024696350097656\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10.,  3.,  3., 10.])\n",
      "cls loss 502.931884765625  loc loss 34.34079360961914\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([7.])\n",
      "cls loss 705.1937255859375  loc loss 58.61137390136719\n",
      "cls loss 714.7139892578125  loc loss 46.273826599121094\n",
      "cls loss 668.3448486328125  loc loss 51.1781005859375\n",
      "cls loss 988.572265625  loc loss 75.10762023925781\n",
      "cls loss 767.2257080078125  loc loss 46.492156982421875\n",
      "cls loss 993.0119018554688  loc loss 63.188865661621094\n",
      "cls loss 1105.267333984375  loc loss 74.1943588256836\n",
      "cls loss 753.7903442382812  loc loss 48.92051315307617\n",
      "cls loss 741.8934326171875  loc loss 53.33689880371094\n",
      "cls loss 640.1599731445312  loc loss 46.74643325805664\n",
      "cls loss 826.8636474609375  loc loss 72.05921173095703\n",
      "cls loss 741.5137329101562  loc loss 49.39219665527344\n",
      "cls loss 566.6069946289062  loc loss 34.553070068359375\n",
      "cls loss 825.507080078125  loc loss 68.92293548583984\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([62.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([62.])\n",
      "cls loss 355.76611328125  loc loss 22.79366683959961\n",
      "cls loss 646.2894897460938  loc loss 51.707523345947266\n",
      "cls loss 658.8336181640625  loc loss 45.58305740356445\n",
      "cls loss 498.62591552734375  loc loss 22.887699127197266\n",
      "cls loss 825.2757568359375  loc loss 64.85014343261719\n",
      "cls loss 793.308349609375  loc loss 53.711669921875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([28.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 875.050048828125  loc loss 54.00775909423828\n",
      "cls loss 839.2415771484375  loc loss 55.164329528808594\n",
      "cls loss 766.3372192382812  loc loss 53.682884216308594\n",
      "cls loss 821.158935546875  loc loss 59.663108825683594\n",
      "cls loss 1113.49658203125  loc loss 82.32586669921875\n",
      "cls loss 648.7701416015625  loc loss 43.26655197143555\n",
      "cls loss 836.2500610351562  loc loss 50.564212799072266\n",
      "cls loss 782.9515380859375  loc loss 62.64554214477539\n",
      "cls loss 1246.0091552734375  loc loss 85.8818359375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([81.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 843.735107421875  loc loss 40.74009323120117\n",
      "cls loss 685.6455688476562  loc loss 32.52897644042969\n",
      "cls loss 521.5711669921875  loc loss 34.126564025878906\n",
      "cls loss 452.6127014160156  loc loss 21.95932960510254\n",
      "cls loss 511.8424377441406  loc loss 33.51641845703125\n",
      "cls loss 520.126220703125  loc loss 37.283443450927734\n",
      "cls loss 607.9886474609375  loc loss 39.53101348876953\n",
      "cls loss 786.094482421875  loc loss 65.12158966064453\n",
      "cls loss 871.65966796875  loc loss 58.89080810546875\n",
      "cls loss 1664.9779052734375  loc loss 120.19246673583984\n",
      "cls loss 605.6611328125  loc loss 34.661102294921875\n",
      "cls loss 724.7369384765625  loc loss 54.67208480834961\n",
      "cls loss 507.89013671875  loc loss 40.407684326171875\n",
      "cls loss 753.1050415039062  loc loss 42.64030075073242\n",
      "cls loss 693.680419921875  loc loss 40.460716247558594\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([44., 44.])\n",
      "cls loss 583.581787109375  loc loss 31.374706268310547\n",
      "cls loss 668.4249267578125  loc loss 42.8216552734375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15.])\n",
      "cls loss 786.42333984375  loc loss 42.19596862792969\n",
      "cls loss 378.1923828125  loc loss 20.16385841369629\n",
      "cls loss 742.6029663085938  loc loss 46.75131607055664\n",
      "cls loss 447.84014892578125  loc loss 26.319957733154297\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([1., 3., 3.])\n",
      "cls loss 461.8741455078125  loc loss 36.53615951538086\n",
      "cls loss 405.17706298828125  loc loss 18.06524658203125\n",
      "cls loss 705.6134643554688  loc loss 40.5676383972168\n",
      "cls loss 727.6903076171875  loc loss 44.0930290222168\n",
      "cls loss 685.4117431640625  loc loss 42.73970031738281\n",
      "cls loss 652.7493286132812  loc loss 43.76758575439453\n",
      "cls loss 574.6646728515625  loc loss 42.84868621826172\n",
      "cls loss 681.294189453125  loc loss 51.04542541503906\n",
      "cls loss 592.016357421875  loc loss 40.125797271728516\n",
      "cls loss 676.731201171875  loc loss 55.163612365722656\n",
      "cls loss 421.1953125  loc loss 28.714609146118164\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 821.3449096679688  loc loss 52.934200286865234\n",
      "cls loss 937.5887451171875  loc loss 55.152854919433594\n",
      "cls loss 838.8109130859375  loc loss 62.39594268798828\n",
      "cls loss 842.6883544921875  loc loss 59.070655822753906\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10., 10., 10.,  1.,  1.,  1.,  1.,  1.,  1.,  8.,  8.,\n",
      "         1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10., 10., 10.,  1.,  1.,  1.,  1.,  1.,  1.,  8.,  8.,\n",
      "         1.])\n",
      "cls loss 848.5150146484375  loc loss 49.204429626464844\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 3., 3., 3.])\n",
      "cls loss 666.4482421875  loc loss 42.96870422363281\n",
      "cls loss 486.47216796875  loc loss 27.427814483642578\n",
      "cls loss 357.2878723144531  loc loss 21.517791748046875\n",
      "cls loss 642.9521484375  loc loss 46.28766632080078\n",
      "cls loss 537.0001220703125  loc loss 27.638320922851562\n",
      "cls loss 626.3111572265625  loc loss 39.449825286865234\n",
      "cls loss 697.4008178710938  loc loss 42.62062454223633\n",
      "cls loss 954.7877197265625  loc loss 65.5962142944336\n",
      "cls loss 741.2001953125  loc loss 43.868316650390625\n",
      "cls loss 692.8659057617188  loc loss 46.42984390258789\n",
      "cls loss 801.5545654296875  loc loss 56.291255950927734\n",
      "cls loss 636.5493774414062  loc loss 46.695072174072266\n",
      "cls loss 988.1845703125  loc loss 84.80982971191406\n",
      "cls loss 534.79638671875  loc loss 32.711795806884766\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 780.5091552734375  loc loss 52.928531646728516\n",
      "cls loss 400.08123779296875  loc loss 21.77580451965332\n",
      "cls loss 1001.3800048828125  loc loss 72.07498168945312\n",
      "cls loss 538.8260498046875  loc loss 31.839492797851562\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 34.])\n",
      "cls loss 810.2313842773438  loc loss 46.715721130371094\n",
      "cls loss 477.0962219238281  loc loss 28.083171844482422\n",
      "cls loss 845.2744140625  loc loss 50.534278869628906\n",
      "cls loss 343.5665588378906  loc loss 19.803712844848633\n",
      "cls loss 823.899169921875  loc loss 49.37018585205078\n",
      "cls loss 682.208251953125  loc loss 49.627662658691406\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 38.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16., 16., 16.,  9.,  9.,  9., 16., 16., 16., 85.,  9.])\n",
      "cls loss 643.0367431640625  loc loss 41.241966247558594\n",
      "cls loss 704.429931640625  loc loss 59.340274810791016\n",
      "cls loss 1051.6549072265625  loc loss 78.76603698730469\n",
      "cls loss 1376.3057861328125  loc loss 104.51689910888672\n",
      "cls loss 434.40167236328125  loc loss 22.73980712890625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3., 10.,  8.,  8., 10., 10., 10.,  3.,  3., 14.])\n",
      "cls loss 556.76123046875  loc loss 27.3233699798584\n",
      "cls loss 849.2445068359375  loc loss 50.679237365722656\n",
      "cls loss 333.7669677734375  loc loss 15.956913948059082\n",
      "cls loss 537.0771484375  loc loss 29.067991256713867\n",
      "cls loss 819.68408203125  loc loss 52.12311553955078\n",
      "cls loss 682.9205322265625  loc loss 49.70464324951172\n",
      "cls loss 446.66796875  loc loss 25.06595802307129\n",
      "cls loss 485.2457275390625  loc loss 30.157133102416992\n",
      "cls loss 716.0772705078125  loc loss 46.96350860595703\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42., 42.,  1.])\n",
      "cls loss 703.813720703125  loc loss 48.16465759277344\n",
      "cls loss 651.9994506835938  loc loss 35.935211181640625\n",
      "cls loss 790.545654296875  loc loss 58.39427185058594\n",
      "cls loss 840.4502563476562  loc loss 58.298240661621094\n",
      "cls loss 630.71826171875  loc loss 38.89288330078125\n",
      "cls loss 712.713623046875  loc loss 54.10653305053711\n",
      "cls loss 485.6019287109375  loc loss 31.53705406188965\n",
      "cls loss 548.81201171875  loc loss 35.44643783569336\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20.])\n",
      "cls loss 381.19915771484375  loc loss 24.5146541595459\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([11.])\n",
      "cls loss 485.5173034667969  loc loss 27.660425186157227\n",
      "cls loss 349.4999084472656  loc loss 21.89682388305664\n",
      "cls loss 709.867431640625  loc loss 65.94324493408203\n",
      "cls loss 348.1803894042969  loc loss 18.75751304626465\n",
      "cls loss 659.72900390625  loc loss 46.10414123535156\n",
      "cls loss 413.84423828125  loc loss 24.18698501586914\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 35., 27.])\n",
      "cls loss 661.0687866210938  loc loss 45.7470817565918\n",
      "cls loss 687.18798828125  loc loss 59.650638580322266\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 519.5303344726562  loc loss 37.88552474975586\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([42.,  1.])\n",
      "cls loss 683.664794921875  loc loss 57.68914794921875\n",
      "cls loss 616.2631225585938  loc loss 38.84366226196289\n",
      "cls loss 803.586669921875  loc loss 44.137020111083984\n",
      "cls loss 962.5912475585938  loc loss 61.337791442871094\n",
      "cls loss 835.849365234375  loc loss 57.00243377685547\n",
      "cls loss 537.701171875  loc loss 42.95928955078125\n",
      "cls loss 501.45880126953125  loc loss 37.190643310546875\n",
      "cls loss 403.20013427734375  loc loss 16.593793869018555\n",
      "cls loss 580.66259765625  loc loss 35.44322967529297\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 1., 1.])\n",
      "cls loss 546.9718017578125  loc loss 32.617271423339844\n",
      "cls loss 611.4322509765625  loc loss 47.87517547607422\n",
      "cls loss 612.1055297851562  loc loss 41.0206413269043\n",
      "cls loss 519.151123046875  loc loss 38.25601577758789\n",
      "cls loss 589.456787109375  loc loss 40.89373779296875\n",
      "cls loss 635.5919189453125  loc loss 50.011985778808594\n",
      "cls loss 900.735107421875  loc loss 55.8416748046875\n",
      "cls loss 792.092041015625  loc loss 62.36703109741211\n",
      "cls loss 699.2255859375  loc loss 44.542274475097656\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 548.7176513671875  loc loss 43.55927276611328\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 650.025390625  loc loss 32.806365966796875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([81.])\n",
      "cls loss 807.2113037109375  loc loss 55.55608367919922\n",
      "cls loss 508.14501953125  loc loss 35.687686920166016\n",
      "cls loss 408.7876281738281  loc loss 24.921947479248047\n",
      "cls loss 554.84716796875  loc loss 28.603816986083984\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3.,  1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 19.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 19.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 746.558349609375  loc loss 52.426448822021484\n",
      "cls loss 452.56158447265625  loc loss 21.176555633544922\n",
      "cls loss 436.1955261230469  loc loss 28.041259765625\n",
      "cls loss 832.7938232421875  loc loss 65.87873077392578\n",
      "cls loss 457.7872619628906  loc loss 29.273164749145508\n",
      "cls loss 550.5228271484375  loc loss 41.24955749511719\n",
      "cls loss 651.5479736328125  loc loss 48.60801315307617\n",
      "cls loss 505.83203125  loc loss 40.189430236816406\n",
      "cls loss 684.1029052734375  loc loss 43.060848236083984\n",
      "cls loss 749.67578125  loc loss 55.6444091796875\n",
      "cls loss 924.9573364257812  loc loss 84.30873107910156\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 81.])\n",
      "cls loss 645.1165771484375  loc loss 38.45291519165039\n",
      "cls loss 642.8092041015625  loc loss 34.84821701049805\n",
      "cls loss 662.74755859375  loc loss 38.79233169555664\n",
      "cls loss 489.6754150390625  loc loss 25.171958923339844\n",
      "cls loss 470.7311706542969  loc loss 29.007089614868164\n",
      "cls loss 575.6019897460938  loc loss 38.288536071777344\n",
      "cls loss 441.2117919921875  loc loss 30.475515365600586\n",
      "cls loss 351.3150939941406  loc loss 25.117717742919922\n",
      "cls loss 456.4306640625  loc loss 33.643836975097656\n",
      "cls loss 641.2662353515625  loc loss 41.508544921875\n",
      "cls loss 527.4967041015625  loc loss 40.39973831176758\n",
      "cls loss 554.912109375  loc loss 42.69746398925781\n",
      "cls loss 335.1863098144531  loc loss 25.219160079956055\n",
      "cls loss 1080.9090576171875  loc loss 81.8772201538086\n",
      "cls loss 726.4727783203125  loc loss 53.752952575683594\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 615.48779296875  loc loss 37.164615631103516\n",
      "cls loss 660.935302734375  loc loss 48.02024841308594\n",
      "cls loss 533.293701171875  loc loss 31.521303176879883\n",
      "cls loss 723.880859375  loc loss 48.91021728515625\n",
      "cls loss 733.4954223632812  loc loss 50.00200653076172\n",
      "cls loss 658.92578125  loc loss 42.99580383300781\n",
      "cls loss 601.2540893554688  loc loss 31.288677215576172\n",
      "cls loss 456.0267333984375  loc loss 25.677539825439453\n",
      "cls loss 592.4609375  loc loss 40.402095794677734\n",
      "cls loss 622.0260009765625  loc loss 48.42756271362305\n",
      "cls loss 699.2161254882812  loc loss 38.38679122924805\n",
      "cls loss 853.3191528320312  loc loss 64.94282531738281\n",
      "cls loss 923.1043701171875  loc loss 66.33564758300781\n",
      "cls loss 623.832763671875  loc loss 43.2296257019043\n",
      "cls loss 775.3533325195312  loc loss 65.7751693725586\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1., 38., 47.,  1.,  1.,  1.,  1.,  1., 62.])\n",
      "cls loss 544.02490234375  loc loss 34.1400032043457\n",
      "cls loss 685.037109375  loc loss 42.91185760498047\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 730.853271484375  loc loss 47.44610595703125\n",
      "cls loss 888.2301635742188  loc loss 62.12731170654297\n",
      "cls loss 574.6529541015625  loc loss 30.967273712158203\n",
      "cls loss 622.2534790039062  loc loss 51.55683898925781\n",
      "cls loss 585.468994140625  loc loss 40.560821533203125\n",
      "cls loss 399.0450439453125  loc loss 17.586397171020508\n",
      "cls loss 559.18505859375  loc loss 36.05791091918945\n",
      "cls loss 490.3792419433594  loc loss 25.704729080200195\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1., 35.])\n",
      "cls loss 541.5341796875  loc loss 30.78569793701172\n",
      "cls loss 839.302734375  loc loss 48.067901611328125\n",
      "cls loss 775.477294921875  loc loss 53.224449157714844\n",
      "cls loss 706.5657958984375  loc loss 59.4892578125\n",
      "cls loss 584.21826171875  loc loss 47.10017395019531\n",
      "cls loss 695.54150390625  loc loss 54.80770492553711\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 407.328125  loc loss 26.043018341064453\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 641.087158203125  loc loss 32.493343353271484\n",
      "cls loss 990.8836669921875  loc loss 60.26793670654297\n",
      "cls loss 1151.6676025390625  loc loss 88.1277847290039\n",
      "cls loss 621.8707885742188  loc loss 34.58760070800781\n",
      "cls loss 522.618408203125  loc loss 32.735755920410156\n",
      "cls loss 531.1426391601562  loc loss 34.958892822265625\n",
      "cls loss 582.5784912109375  loc loss 49.32366943359375\n",
      "cls loss 583.403076171875  loc loss 24.022239685058594\n",
      "cls loss 878.7894287109375  loc loss 70.02877807617188\n",
      "cls loss 725.7989501953125  loc loss 45.90366744995117\n",
      "cls loss 474.15106201171875  loc loss 26.942808151245117\n",
      "cls loss 804.365234375  loc loss 43.84506607055664\n",
      "cls loss 929.5982055664062  loc loss 68.91840362548828\n",
      "cls loss 729.686279296875  loc loss 48.054813385009766\n",
      "cls loss 671.975341796875  loc loss 37.66039276123047\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.])\n",
      "cls loss 632.1797485351562  loc loss 46.72560501098633\n",
      "cls loss 523.505859375  loc loss 41.955020904541016\n",
      "cls loss 811.205078125  loc loss 50.993751525878906\n",
      "cls loss 1048.69287109375  loc loss 93.1642074584961\n",
      "cls loss 506.84930419921875  loc loss 25.238271713256836\n",
      "cls loss 572.8925170898438  loc loss 38.95404815673828\n",
      "cls loss 491.2840576171875  loc loss 32.20027160644531\n",
      "cls loss 555.8523559570312  loc loss 35.88728713989258\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 21., 21., 21.])\n",
      "cls loss 611.9169921875  loc loss 35.86993408203125\n",
      "cls loss 546.7989501953125  loc loss 27.904762268066406\n",
      "cls loss 573.4576416015625  loc loss 39.20098876953125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 35.])\n",
      "cls loss 880.121826171875  loc loss 61.17167282104492\n",
      "cls loss 297.9788818359375  loc loss 16.632902145385742\n",
      "cls loss 459.87347412109375  loc loss 32.363014221191406\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 447.6087341308594  loc loss 29.075315475463867\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 38., 38.,  9., 38.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1.,  1.])\n",
      "cls loss 493.80584716796875  loc loss 39.07141876220703\n",
      "cls loss 814.865234375  loc loss 61.3963737487793\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 2.,  1., 77., 31., 10., 10.,  1.,  4., 10.])\n",
      "cls loss 484.2421875  loc loss 24.885478973388672\n",
      "cls loss 833.787841796875  loc loss 50.87446212768555\n",
      "cls loss 1498.10009765625  loc loss 114.34736633300781\n",
      "cls loss 537.7351684570312  loc loss 34.22618103027344\n",
      "cls loss 693.6282958984375  loc loss 60.420738220214844\n",
      "cls loss 530.20751953125  loc loss 33.60250473022461\n",
      "cls loss 546.8902587890625  loc loss 28.734405517578125\n",
      "cls loss 884.7461547851562  loc loss 37.78587341308594\n",
      "cls loss 754.73779296875  loc loss 44.925228118896484\n",
      "cls loss 691.5877685546875  loc loss 48.36442565917969\n",
      "cls loss 530.0243530273438  loc loss 27.684995651245117\n",
      "cls loss 650.683837890625  loc loss 30.720943450927734\n",
      "cls loss 1158.8885498046875  loc loss 69.03241729736328\n",
      "cls loss 899.213623046875  loc loss 63.79241180419922\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1., 42., 42., 42., 42., 42., 42.,  1.,\n",
      "         1.,  1.,  1., 42.,  1.,  1., 42.,  1.])\n",
      "cls loss 536.715576171875  loc loss 39.17424011230469\n",
      "cls loss 760.017578125  loc loss 51.41548156738281\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.])\n",
      "cls loss 368.7548828125  loc loss 25.332508087158203\n",
      "cls loss 717.9263305664062  loc loss 54.32316207885742\n",
      "cls loss 575.4505615234375  loc loss 44.672935485839844\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([11.])\n",
      "cls loss 358.9294738769531  loc loss 20.973468780517578\n",
      "cls loss 472.99188232421875  loc loss 23.467140197753906\n",
      "cls loss 472.4405822753906  loc loss 26.707103729248047\n",
      "cls loss 657.151123046875  loc loss 48.39847183227539\n",
      "cls loss 635.6912841796875  loc loss 41.47370147705078\n",
      "cls loss 631.3812866210938  loc loss 50.83735275268555\n",
      "cls loss 891.9796752929688  loc loss 55.63142395019531\n",
      "cls loss 503.73046875  loc loss 33.27156066894531\n",
      "cls loss 901.3211669921875  loc loss 74.07576751708984\n",
      "cls loss 567.4142456054688  loc loss 30.16042709350586\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 499.8516845703125  loc loss 33.57813262939453\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1., 38., 38., 42.])\n",
      "cls loss 657.9290161132812  loc loss 46.09114074707031\n",
      "cls loss 638.3377685546875  loc loss 29.819869995117188\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 483.5712890625  loc loss 34.105098724365234\n",
      "cls loss 1067.767822265625  loc loss 77.52794647216797\n",
      "cls loss 619.2933349609375  loc loss 48.025352478027344\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10.,  3.,  3.,  6.,  8.,  8.,  1.,  1.,  1., 10.])\n",
      "cls loss 564.0322875976562  loc loss 36.7308349609375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 333.3211669921875  loc loss 13.941156387329102\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10.,  3.])\n",
      "cls loss 530.67236328125  loc loss 30.93758773803711\n",
      "cls loss 354.1426696777344  loc loss 17.892148971557617\n",
      "cls loss 588.153564453125  loc loss 51.63689041137695\n",
      "cls loss 652.0426025390625  loc loss 50.396202087402344\n",
      "cls loss 502.4249572753906  loc loss 32.87224578857422\n",
      "cls loss 398.21893310546875  loc loss 20.105745315551758\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 34.])\n",
      "cls loss 892.7476806640625  loc loss 56.17221450805664\n",
      "cls loss 929.6324462890625  loc loss 80.65908813476562\n",
      "cls loss 623.933349609375  loc loss 53.04393768310547\n",
      "cls loss 463.09527587890625  loc loss 34.76203918457031\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.,  1.])\n",
      "cls loss 540.6669921875  loc loss 29.621809005737305\n",
      "cls loss 833.0487060546875  loc loss 67.87267303466797\n",
      "cls loss 1208.722900390625  loc loss 85.84214782714844\n",
      "cls loss 1034.734375  loc loss 59.00306701660156\n",
      "cls loss 645.44140625  loc loss 37.564186096191406\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 849.3300170898438  loc loss 43.207908630371094\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10.])\n",
      "cls loss 477.0016784667969  loc loss 27.153562545776367\n",
      "cls loss 642.3759765625  loc loss 35.022056579589844\n",
      "cls loss 642.990478515625  loc loss 35.63006591796875\n",
      "cls loss 435.1937255859375  loc loss 27.598609924316406\n",
      "cls loss 532.0562744140625  loc loss 41.814022064208984\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21.,\n",
      "        21.])\n",
      "cls loss 724.7908935546875  loc loss 47.017662048339844\n",
      "cls loss 607.913818359375  loc loss 46.01323699951172\n",
      "cls loss 406.820556640625  loc loss 19.14654541015625\n",
      "cls loss 798.2212524414062  loc loss 54.94734573364258\n",
      "cls loss 624.6234130859375  loc loss 48.308631896972656\n",
      "cls loss 445.1611328125  loc loss 31.54502296447754\n",
      "cls loss 946.6429443359375  loc loss 73.71478271484375\n",
      "cls loss 1103.100830078125  loc loss 81.57926177978516\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15., 85.])\n",
      "cls loss 759.7652587890625  loc loss 49.460426330566406\n",
      "cls loss 676.9419555664062  loc loss 59.18079376220703\n",
      "cls loss 810.76025390625  loc loss 55.96819305419922\n",
      "cls loss 697.4849243164062  loc loss 43.95088195800781\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 8., 8.])\n",
      "cls loss 429.768798828125  loc loss 23.584491729736328\n",
      "cls loss 543.9599609375  loc loss 33.357826232910156\n",
      "cls loss 601.8902587890625  loc loss 36.80927276611328\n",
      "cls loss 522.7081298828125  loc loss 29.240951538085938\n",
      "cls loss 582.9049072265625  loc loss 37.52094268798828\n",
      "cls loss 778.5052490234375  loc loss 45.9495735168457\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1., 35., 27., 27.,  1., 27.,  1.])\n",
      "cls loss 1068.1627197265625  loc loss 74.36441802978516\n",
      "cls loss 482.569091796875  loc loss 37.477027893066406\n",
      "cls loss 595.6301879882812  loc loss 44.80521774291992\n",
      "cls loss 554.6031494140625  loc loss 49.325042724609375\n",
      "cls loss 563.0076293945312  loc loss 42.880611419677734\n",
      "cls loss 572.2999877929688  loc loss 46.506622314453125\n",
      "cls loss 534.296142578125  loc loss 45.539161682128906\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  2.,  2.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  2.,  2.])\n",
      "cls loss 359.15509033203125  loc loss 15.79245662689209\n",
      "cls loss 811.540283203125  loc loss 54.107215881347656\n",
      "cls loss 593.5023193359375  loc loss 33.00761795043945\n",
      "cls loss 968.1170654296875  loc loss 71.29627990722656\n",
      "cls loss 423.68402099609375  loc loss 27.525997161865234\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 19., 19., 19., 16.])\n",
      "cls loss 427.9195251464844  loc loss 22.404691696166992\n",
      "cls loss 347.87017822265625  loc loss 17.39699363708496\n",
      "cls loss 509.92578125  loc loss 27.625896453857422\n",
      "cls loss 656.0084838867188  loc loss 44.800079345703125\n",
      "cls loss 345.74755859375  loc loss 28.03436279296875\n",
      "cls loss 774.668701171875  loc loss 56.02751922607422\n",
      "cls loss 537.5392456054688  loc loss 41.539344787597656\n",
      "cls loss 576.6385498046875  loc loss 41.934669494628906\n",
      "cls loss 706.69287109375  loc loss 54.336708068847656\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 807.8820190429688  loc loss 41.446083068847656\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 1029.521484375  loc loss 89.41466522216797\n",
      "cls loss 1283.9853515625  loc loss 130.31304931640625\n",
      "cls loss 616.143310546875  loc loss 49.00957107543945\n",
      "cls loss 579.743408203125  loc loss 42.11924362182617\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3.,  3.,  3.,  3.,  3., 10.])\n",
      "cls loss 346.4098205566406  loc loss 17.509788513183594\n",
      "cls loss 647.7600708007812  loc loss 39.16166305541992\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 1., 1., 1., 3., 3., 3., 3.])\n",
      "cls loss 570.8759155273438  loc loss 38.51750946044922\n",
      "cls loss 970.9453735351562  loc loss 74.25111389160156\n",
      "cls loss 780.2131958007812  loc loss 55.94707107543945\n",
      "cls loss 613.367431640625  loc loss 33.07499694824219\n",
      "cls loss 793.97509765625  loc loss 62.964134216308594\n",
      "cls loss 531.3994140625  loc loss 39.93576431274414\n",
      "cls loss 800.6807861328125  loc loss 58.325687408447266\n",
      "cls loss 607.6044921875  loc loss 51.88534927368164\n",
      "cls loss 581.9483642578125  loc loss 42.29997253417969\n",
      "cls loss 1194.831298828125  loc loss 103.73466491699219\n",
      "cls loss 783.7433471679688  loc loss 56.41173553466797\n",
      "cls loss 523.0963134765625  loc loss 28.367002487182617\n",
      "cls loss 342.388427734375  loc loss 17.541622161865234\n",
      "cls loss 403.47528076171875  loc loss 25.03783416748047\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3., 10., 10., 10., 10., 10., 10., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10., 10., 10., 10., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 11., 10., 10., 10., 10., 10.,  3.,  3.,  3.,  3.,  3.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 11., 10., 10., 10., 10., 10.,  3.,  3.,  3.,  3.,  3.])\n",
      "cls loss 373.81817626953125  loc loss 21.432659149169922\n",
      "cls loss 507.5863037109375  loc loss 26.38978385925293\n",
      "cls loss 418.0472412109375  loc loss 27.066471099853516\n",
      "cls loss 389.4208984375  loc loss 18.757728576660156\n",
      "cls loss 490.4534912109375  loc loss 38.76051330566406\n",
      "cls loss 450.1101989746094  loc loss 18.52533721923828\n",
      "cls loss 734.63427734375  loc loss 54.24249267578125\n",
      "cls loss 642.2174072265625  loc loss 50.107688903808594\n",
      "cls loss 969.273681640625  loc loss 67.91438293457031\n",
      "cls loss 478.56201171875  loc loss 37.20962905883789\n",
      "cls loss 850.118896484375  loc loss 60.644832611083984\n",
      "cls loss 701.9448852539062  loc loss 51.80741500854492\n",
      "cls loss 651.8530883789062  loc loss 45.97481155395508\n",
      "cls loss 663.171875  loc loss 52.24296951293945\n",
      "cls loss 899.7481689453125  loc loss 64.1355972290039\n",
      "cls loss 873.915283203125  loc loss 56.88803482055664\n",
      "cls loss 466.81549072265625  loc loss 25.828866958618164\n",
      "cls loss 759.4600830078125  loc loss 60.33728790283203\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 10.,  1., 18.])\n",
      "cls loss 411.29510498046875  loc loss 28.654390335083008\n",
      "cls loss 460.88189697265625  loc loss 19.728113174438477\n",
      "cls loss 801.6842041015625  loc loss 41.29094314575195\n",
      "cls loss 1071.998779296875  loc loss 76.05782318115234\n",
      "cls loss 690.537109375  loc loss 46.753658294677734\n",
      "cls loss 886.2706298828125  loc loss 59.38483810424805\n",
      "cls loss 634.3656005859375  loc loss 44.979835510253906\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.,  1.,  1.])\n",
      "cls loss 833.6043701171875  loc loss 58.70139694213867\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1., 38.,  1.])\n",
      "cls loss 803.8516235351562  loc loss 48.881629943847656\n",
      "cls loss 1012.579833984375  loc loss 80.25749206542969\n",
      "cls loss 502.95233154296875  loc loss 41.73098373413086\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 677.117919921875  loc loss 50.86109924316406\n",
      "cls loss 609.048828125  loc loss 44.33634948730469\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3., 10.,  8.,  3., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.])\n",
      "cls loss 739.0881958007812  loc loss 49.67192840576172\n",
      "cls loss 511.4464111328125  loc loss 34.85922622680664\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3.,  3., 11.,  3., 10., 10.,  3.,  3., 10.])\n",
      "cls loss 619.4830322265625  loc loss 33.73076629638672\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3., 10., 10., 10.])\n",
      "cls loss 596.5301513671875  loc loss 47.03777313232422\n",
      "cls loss 510.04071044921875  loc loss 31.472187042236328\n",
      "cls loss 627.8016357421875  loc loss 49.31718444824219\n",
      "cls loss 1045.638427734375  loc loss 64.48880767822266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 632.44970703125  loc loss 44.55894088745117\n",
      "cls loss 451.11224365234375  loc loss 39.65176773071289\n",
      "cls loss 554.3677368164062  loc loss 41.17171096801758\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 9.,  9., 85., 85.])\n",
      "cls loss 531.847412109375  loc loss 30.270469665527344\n",
      "cls loss 588.943603515625  loc loss 40.07575988769531\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 944.7485961914062  loc loss 74.05142974853516\n",
      "cls loss 796.5199584960938  loc loss 44.84972381591797\n",
      "cls loss 898.9166870117188  loc loss 66.80781555175781\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10., 10., 10., 10.])\n",
      "cls loss 586.687744140625  loc loss 36.87131118774414\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([13.])\n",
      "cls loss 917.6441650390625  loc loss 77.60832977294922\n",
      "cls loss 345.23931884765625  loc loss 19.347463607788086\n",
      "cls loss 396.27685546875  loc loss 23.21826934814453\n",
      "cls loss 556.39208984375  loc loss 33.63541793823242\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19.,  1.,  1.,  1., 19., 19.])\n",
      "cls loss 586.5874633789062  loc loss 38.791568756103516\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 409.76300048828125  loc loss 40.835960388183594\n",
      "cls loss 687.4089965820312  loc loss 52.642669677734375\n",
      "cls loss 470.398681640625  loc loss 30.880367279052734\n",
      "cls loss 720.0463256835938  loc loss 48.214447021484375\n",
      "cls loss 778.4044189453125  loc loss 61.289886474609375\n",
      "cls loss 640.951416015625  loc loss 36.15778732299805\n",
      "cls loss 845.3609619140625  loc loss 66.90507507324219\n",
      "cls loss 406.42572021484375  loc loss 18.152631759643555\n",
      "cls loss 619.4260864257812  loc loss 42.80063247680664\n",
      "cls loss 527.9136962890625  loc loss 27.134986877441406\n",
      "cls loss 505.3111572265625  loc loss 30.749176025390625\n",
      "cls loss 659.621826171875  loc loss 52.41506576538086\n",
      "cls loss 638.60986328125  loc loss 40.00071716308594\n",
      "cls loss 925.498779296875  loc loss 60.767555236816406\n",
      "cls loss 571.6883544921875  loc loss 42.16813278198242\n",
      "cls loss 684.2169189453125  loc loss 50.52934265136719\n",
      "cls loss 983.7015380859375  loc loss 70.66275787353516\n",
      "cls loss 591.7938232421875  loc loss 48.24193572998047\n",
      "cls loss 668.57666015625  loc loss 42.342899322509766\n",
      "cls loss 858.9378662109375  loc loss 63.72136306762695\n",
      "cls loss 830.5288696289062  loc loss 63.05796813964844\n",
      "cls loss 1062.0028076171875  loc loss 65.49739074707031\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 5.])\n",
      "cls loss 343.278076171875  loc loss 12.530335426330566\n",
      "cls loss 425.78759765625  loc loss 19.833112716674805\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 13.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 6., 8., 8.])\n",
      "cls loss 430.7536315917969  loc loss 18.16858673095703\n",
      "cls loss 445.4017333984375  loc loss 26.32036018371582\n",
      "cls loss 824.5037231445312  loc loss 64.63137817382812\n",
      "cls loss 392.23760986328125  loc loss 19.343172073364258\n",
      "cls loss 653.3964233398438  loc loss 51.56588363647461\n",
      "cls loss 1020.2372436523438  loc loss 70.87025451660156\n",
      "cls loss 607.22021484375  loc loss 47.4888801574707\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([42., 42.,  1.,  1.,  1.,  1.,  1.,  1.,  1., 42., 42.])\n",
      "cls loss 661.8109130859375  loc loss 44.50933074951172\n",
      "cls loss 873.5226440429688  loc loss 71.11447143554688\n",
      "cls loss 677.9312744140625  loc loss 59.91938018798828\n",
      "cls loss 512.3165893554688  loc loss 31.33438491821289\n",
      "cls loss 690.926025390625  loc loss 45.259666442871094\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 945.9046630859375  loc loss 63.45274353027344\n",
      "cls loss 739.188720703125  loc loss 56.49411392211914\n",
      "cls loss 488.708251953125  loc loss 31.069063186645508\n",
      "cls loss 446.9166259765625  loc loss 22.564495086669922\n",
      "cls loss 578.174560546875  loc loss 37.43433380126953\n",
      "cls loss 780.333984375  loc loss 53.09701156616211\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15.])\n",
      "cls loss 374.4076232910156  loc loss 20.491779327392578\n",
      "cls loss 605.6396484375  loc loss 40.96574401855469\n",
      "cls loss 530.2254638671875  loc loss 36.933380126953125\n",
      "cls loss 919.5985717773438  loc loss 69.63088989257812\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19.,  7.])\n",
      "cls loss 552.420654296875  loc loss 35.966156005859375\n",
      "cls loss 1117.806396484375  loc loss 70.95419311523438\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 934.5205688476562  loc loss 54.876163482666016\n",
      "cls loss 698.3258056640625  loc loss 57.477577209472656\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([38., 38.,  1., 18.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1., 18., 18.,  1.])\n",
      "cls loss 589.349365234375  loc loss 32.466773986816406\n",
      "cls loss 567.553466796875  loc loss 28.17644500732422\n",
      "cls loss 906.3961181640625  loc loss 77.67630004882812\n",
      "cls loss 705.8102416992188  loc loss 46.069488525390625\n",
      "cls loss 738.07080078125  loc loss 38.12804412841797\n",
      "cls loss 402.79327392578125  loc loss 32.46711730957031\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.])\n",
      "cls loss 324.6729431152344  loc loss 13.750801086425781\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([32.])\n",
      "cls loss 653.961669921875  loc loss 32.68772506713867\n",
      "cls loss 558.3095703125  loc loss 38.016475677490234\n",
      "cls loss 741.4315795898438  loc loss 62.63713836669922\n",
      "cls loss 708.2003173828125  loc loss 43.698402404785156\n",
      "cls loss 573.3658447265625  loc loss 38.4187126159668\n",
      "cls loss 892.0772705078125  loc loss 54.11100769042969\n",
      "cls loss 905.43115234375  loc loss 66.28352355957031\n",
      "cls loss 749.6253662109375  loc loss 52.77046203613281\n",
      "cls loss 659.9191284179688  loc loss 39.06780242919922\n",
      "cls loss 1015.4065551757812  loc loss 64.66201782226562\n",
      "cls loss 598.5777587890625  loc loss 32.943939208984375\n",
      "cls loss 909.3668823242188  loc loss 80.47591400146484\n",
      "cls loss 693.7821044921875  loc loss 44.41670227050781\n",
      "cls loss 572.8615112304688  loc loss 43.98660659790039\n",
      "cls loss 451.217529296875  loc loss 26.77473258972168\n",
      "cls loss 466.0165100097656  loc loss 33.62495040893555\n",
      "cls loss 705.015625  loc loss 52.398929595947266\n",
      "cls loss 736.2943115234375  loc loss 57.6230583190918\n",
      "cls loss 430.70562744140625  loc loss 31.611709594726562\n",
      "cls loss 830.0448608398438  loc loss 57.726478576660156\n",
      "cls loss 982.492919921875  loc loss 63.177207946777344\n",
      "cls loss 368.18328857421875  loc loss 26.089292526245117\n",
      "cls loss 943.3831787109375  loc loss 66.67704772949219\n",
      "cls loss 684.54150390625  loc loss 53.175331115722656\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 918.0560302734375  loc loss 73.43923950195312\n",
      "cls loss 478.1357727050781  loc loss 19.927236557006836\n",
      "cls loss 707.5696411132812  loc loss 41.100608825683594\n",
      "cls loss 700.2037963867188  loc loss 48.375972747802734\n",
      "cls loss 539.7470703125  loc loss 34.461334228515625\n",
      "cls loss 355.9978942871094  loc loss 17.5111141204834\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 9., 9., 1., 9., 9., 9., 9., 1., 9.])\n",
      "cls loss 1194.135009765625  loc loss 104.34646606445312\n",
      "cls loss 718.3331298828125  loc loss 39.99317169189453\n",
      "cls loss 1029.316162109375  loc loss 87.89736938476562\n",
      "cls loss 459.2718505859375  loc loss 30.06679344177246\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 42., 42.])\n",
      "cls loss 730.170654296875  loc loss 56.73180389404297\n",
      "cls loss 765.75927734375  loc loss 57.683013916015625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  2.,  1.,  1.,  1., 38.,\n",
      "         1.,  1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 38., 38., 38.,  1., 38., 38., 38.,  1.,  1., 38.,  1.,\n",
      "         1.])\n",
      "cls loss 507.24102783203125  loc loss 33.827667236328125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  8.,  8.])\n",
      "cls loss 1057.229736328125  loc loss 74.85499572753906\n",
      "cls loss 1044.556884765625  loc loss 76.57723236083984\n",
      "cls loss 436.6845703125  loc loss 27.16524887084961\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([4., 1., 1., 4.])\n",
      "cls loss 612.71923828125  loc loss 46.25882339477539\n",
      "cls loss 736.126953125  loc loss 48.15116882324219\n",
      "cls loss 350.175537109375  loc loss 17.17927360534668\n",
      "cls loss 481.7304992675781  loc loss 28.71706771850586\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([51.,  1.])\n",
      "cls loss 352.1874084472656  loc loss 15.813937187194824\n",
      "cls loss 437.7398986816406  loc loss 28.607221603393555\n",
      "cls loss 789.2352294921875  loc loss 50.27685546875\n",
      "cls loss 882.8094482421875  loc loss 69.08891296386719\n",
      "cls loss 1177.45166015625  loc loss 72.27237701416016\n",
      "cls loss 1457.399169921875  loc loss 100.81607055664062\n",
      "cls loss 622.6189575195312  loc loss 41.58128356933594\n",
      "cls loss 854.5361938476562  loc loss 62.32378005981445\n",
      "cls loss 909.0006103515625  loc loss 68.88640594482422\n",
      "cls loss 672.355712890625  loc loss 41.037044525146484\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  3.,  1.,  1.,  1.,  3.,  1.,  1.,\n",
      "         1.,  1.,  1.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 763.0775146484375  loc loss 43.1006965637207\n",
      "cls loss 898.29443359375  loc loss 45.25556182861328\n",
      "cls loss 793.394775390625  loc loss 41.322227478027344\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "cls loss 629.524169921875  loc loss 38.907230377197266\n",
      "cls loss 376.2421875  loc loss 30.678422927856445\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3.])\n",
      "cls loss 391.195068359375  loc loss 16.311803817749023\n",
      "cls loss 568.3163452148438  loc loss 43.241729736328125\n",
      "cls loss 461.83984375  loc loss 34.47393798828125\n",
      "cls loss 809.1926879882812  loc loss 62.60661315917969\n",
      "cls loss 581.9937133789062  loc loss 28.08824348449707\n",
      "cls loss 457.42462158203125  loc loss 32.41475296020508\n",
      "cls loss 1392.6463623046875  loc loss 98.001220703125\n",
      "cls loss 586.5941162109375  loc loss 45.88848114013672\n",
      "cls loss 415.62591552734375  loc loss 37.607215881347656\n",
      "cls loss 564.7020263671875  loc loss 35.380619049072266\n",
      "cls loss 475.7292785644531  loc loss 37.966087341308594\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 871.7218627929688  loc loss 65.1202621459961\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  9., 64., 64., 64., 64., 64., 64., 64., 64., 64.,  9.,  9.,  9.,\n",
      "         9.])\n",
      "cls loss 518.3790283203125  loc loss 29.057762145996094\n",
      "cls loss 1141.72802734375  loc loss 99.25479125976562\n",
      "cls loss 631.1412963867188  loc loss 42.411651611328125\n",
      "cls loss 794.47607421875  loc loss 62.729061126708984\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.,  3.,  3.])\n",
      "cls loss 525.9208984375  loc loss 35.30955505371094\n",
      "cls loss 655.4535522460938  loc loss 38.38030242919922\n",
      "cls loss 603.109375  loc loss 45.34626770019531\n",
      "cls loss 717.5576171875  loc loss 45.32905960083008\n",
      "cls loss 676.0275268554688  loc loss 52.616233825683594\n",
      "cls loss 607.27197265625  loc loss 48.350833892822266\n",
      "cls loss 607.754638671875  loc loss 47.28219985961914\n",
      "cls loss 610.9620361328125  loc loss 41.082271575927734\n",
      "cls loss 797.125732421875  loc loss 58.55510711669922\n",
      "cls loss 658.5601806640625  loc loss 43.80620193481445\n",
      "cls loss 532.5908813476562  loc loss 25.928251266479492\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21.])\n",
      "cls loss 410.0692138671875  loc loss 21.038501739501953\n",
      "cls loss 544.49169921875  loc loss 48.14476013183594\n",
      "cls loss 732.919189453125  loc loss 57.102500915527344\n",
      "cls loss 466.1442565917969  loc loss 29.77100372314453\n",
      "cls loss 690.4629516601562  loc loss 43.73833465576172\n",
      "cls loss 1233.468994140625  loc loss 76.0973129272461\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 42., 42.,  1.,  1.])\n",
      "cls loss 625.8326416015625  loc loss 37.64125061035156\n",
      "cls loss 431.83941650390625  loc loss 30.41415023803711\n",
      "cls loss 565.6070556640625  loc loss 42.9327507019043\n",
      "cls loss 793.9036865234375  loc loss 69.80429077148438\n",
      "cls loss 538.6089477539062  loc loss 35.6780891418457\n",
      "cls loss 735.084716796875  loc loss 56.890892028808594\n",
      "cls loss 726.4119262695312  loc loss 57.19160461425781\n",
      "cls loss 754.3194580078125  loc loss 47.839447021484375\n",
      "cls loss 614.1017456054688  loc loss 39.64543151855469\n",
      "cls loss 524.909423828125  loc loss 34.845977783203125\n",
      "cls loss 454.33544921875  loc loss 21.228647232055664\n",
      "cls loss 545.259033203125  loc loss 42.28219223022461\n",
      "cls loss 792.5167236328125  loc loss 71.74027252197266\n",
      "cls loss 650.3506469726562  loc loss 42.323028564453125\n",
      "cls loss 685.6886596679688  loc loss 51.769569396972656\n",
      "cls loss 719.9077758789062  loc loss 39.943946838378906\n",
      "cls loss 1066.77978515625  loc loss 70.38636016845703\n",
      "cls loss 709.8140869140625  loc loss 56.6420783996582\n",
      "cls loss 842.541015625  loc loss 51.204795837402344\n",
      "cls loss 535.8360595703125  loc loss 25.757535934448242\n",
      "cls loss 728.0313720703125  loc loss 46.95973205566406\n",
      "cls loss 665.8714599609375  loc loss 45.60872268676758\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 5., 5., 5., 5., 5., 5.])\n",
      "cls loss 467.6978454589844  loc loss 32.936893463134766\n",
      "cls loss 551.4312744140625  loc loss 38.358856201171875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([13.])\n",
      "cls loss 390.927001953125  loc loss 24.190269470214844\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([44., 10.,  1.,  1.,  1.])\n",
      "cls loss 419.0068359375  loc loss 25.248558044433594\n",
      "cls loss 742.5123291015625  loc loss 41.782928466796875\n",
      "cls loss 595.657470703125  loc loss 35.64004135131836\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19., 19., 19., 19., 19., 19., 19.])\n",
      "cls loss 773.993896484375  loc loss 48.78757095336914\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([56.])\n",
      "cls loss 1377.273681640625  loc loss 84.91069793701172\n",
      "cls loss 712.7045288085938  loc loss 59.70280456542969\n",
      "cls loss 1008.56591796875  loc loss 75.72682189941406\n",
      "cls loss 938.689208984375  loc loss 77.45811462402344\n",
      "cls loss 591.219970703125  loc loss 39.65052795410156\n",
      "cls loss 994.7239990234375  loc loss 72.76118469238281\n",
      "cls loss 621.9451904296875  loc loss 34.44468307495117\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 36.])\n",
      "cls loss 712.64501953125  loc loss 41.42921447753906\n",
      "cls loss 600.2559814453125  loc loss 45.53529739379883\n",
      "cls loss 693.4635009765625  loc loss 37.30581283569336\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5.])\n",
      "cls loss 660.0204467773438  loc loss 44.3140869140625\n",
      "cls loss 414.00140380859375  loc loss 22.952226638793945\n",
      "cls loss 856.1234741210938  loc loss 54.842918395996094\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "cls loss 782.1942138671875  loc loss 58.0002326965332\n",
      "cls loss 844.006103515625  loc loss 51.307098388671875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 710.5081787109375  loc loss 52.92832565307617\n",
      "cls loss 846.264892578125  loc loss 62.216514587402344\n",
      "cls loss 722.1243896484375  loc loss 64.25079345703125\n",
      "cls loss 517.1124267578125  loc loss 37.739444732666016\n",
      "cls loss 621.7464599609375  loc loss 46.468666076660156\n",
      "cls loss 598.8423461914062  loc loss 43.1230583190918\n",
      "cls loss 938.043701171875  loc loss 60.24266815185547\n",
      "cls loss 454.4132080078125  loc loss 25.37399673461914\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 11., 15., 10., 10., 10., 10., 10.])\n",
      "cls loss 1005.41748046875  loc loss 76.57762145996094\n",
      "cls loss 584.7050170898438  loc loss 39.60835266113281\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3.])\n",
      "cls loss 687.823974609375  loc loss 42.20933532714844\n",
      "cls loss 541.9550170898438  loc loss 34.51852798461914\n",
      "cls loss 609.744384765625  loc loss 33.03608322143555\n",
      "cls loss 798.8984375  loc loss 43.69267272949219\n",
      "cls loss 503.4804382324219  loc loss 20.961029052734375\n",
      "cls loss 712.22509765625  loc loss 37.586151123046875\n",
      "cls loss 708.2720947265625  loc loss 52.797569274902344\n",
      "cls loss 602.070068359375  loc loss 46.99017333984375\n",
      "cls loss 1287.1656494140625  loc loss 107.34315490722656\n",
      "cls loss 941.9928588867188  loc loss 71.01081085205078\n",
      "cls loss 625.80126953125  loc loss 48.09507369995117\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  9.,  9.,  9.,  6.,  6., 85., 85.,  8.,  1.,  1.,  1.,  1.,\n",
      "         6.,  6.])\n",
      "cls loss 445.3521728515625  loc loss 31.461650848388672\n",
      "cls loss 994.8342895507812  loc loss 73.09884643554688\n",
      "cls loss 1153.79833984375  loc loss 79.32191467285156\n",
      "cls loss 790.177490234375  loc loss 59.845664978027344\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10.,  3.,  3., 10.])\n",
      "cls loss 503.0849609375  loc loss 33.907371520996094\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([7.])\n",
      "cls loss 701.5311279296875  loc loss 56.8641242980957\n",
      "cls loss 725.0784912109375  loc loss 45.411277770996094\n",
      "cls loss 671.7778930664062  loc loss 50.50652313232422\n",
      "cls loss 1012.968505859375  loc loss 73.82359313964844\n",
      "cls loss 767.887451171875  loc loss 45.527374267578125\n",
      "cls loss 974.8447265625  loc loss 61.70243835449219\n",
      "cls loss 1084.63330078125  loc loss 72.26464080810547\n",
      "cls loss 718.2777099609375  loc loss 47.970218658447266\n",
      "cls loss 707.7725830078125  loc loss 51.71488571166992\n",
      "cls loss 611.6527099609375  loc loss 46.08677291870117\n",
      "cls loss 814.7344970703125  loc loss 70.81825256347656\n",
      "cls loss 714.9203491210938  loc loss 48.316280364990234\n",
      "cls loss 538.6912841796875  loc loss 33.922428131103516\n",
      "cls loss 807.108642578125  loc loss 67.1385726928711\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([62.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([62.])\n",
      "cls loss 344.7685546875  loc loss 22.403364181518555\n",
      "cls loss 638.983642578125  loc loss 50.57938003540039\n",
      "cls loss 645.0992431640625  loc loss 44.827457427978516\n",
      "cls loss 486.4612731933594  loc loss 22.084016799926758\n",
      "cls loss 817.1488037109375  loc loss 63.41286087036133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 786.692138671875  loc loss 52.39178466796875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([28.])\n",
      "cls loss 877.7448120117188  loc loss 52.903480529785156\n",
      "cls loss 827.6187744140625  loc loss 53.853111267089844\n",
      "cls loss 766.9307861328125  loc loss 52.48020553588867\n",
      "cls loss 816.5147094726562  loc loss 58.324256896972656\n",
      "cls loss 1110.0556640625  loc loss 80.43927001953125\n",
      "cls loss 633.1943359375  loc loss 42.685340881347656\n",
      "cls loss 816.3118896484375  loc loss 49.82756805419922\n",
      "cls loss 747.2589111328125  loc loss 61.280887603759766\n",
      "cls loss 1175.167236328125  loc loss 84.78661346435547\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([81.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 794.7953491210938  loc loss 38.80443572998047\n",
      "cls loss 633.0891723632812  loc loss 31.759950637817383\n",
      "cls loss 501.5256042480469  loc loss 33.383209228515625\n",
      "cls loss 433.1995849609375  loc loss 21.199642181396484\n",
      "cls loss 490.2702941894531  loc loss 32.50911331176758\n",
      "cls loss 510.86492919921875  loc loss 36.425228118896484\n",
      "cls loss 588.9034423828125  loc loss 38.580196380615234\n",
      "cls loss 770.1129760742188  loc loss 64.04466247558594\n",
      "cls loss 849.05419921875  loc loss 58.12525939941406\n",
      "cls loss 1625.11376953125  loc loss 118.01594543457031\n",
      "cls loss 605.0623779296875  loc loss 34.15520477294922\n",
      "cls loss 728.7286376953125  loc loss 53.5849494934082\n",
      "cls loss 505.67645263671875  loc loss 39.09597396850586\n",
      "cls loss 750.1212158203125  loc loss 41.892852783203125\n",
      "cls loss 713.5645141601562  loc loss 39.72587585449219\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([44., 44.])\n",
      "cls loss 598.582763671875  loc loss 30.74105453491211\n",
      "cls loss 672.5364990234375  loc loss 42.27758026123047\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15.])\n",
      "cls loss 778.7341918945312  loc loss 41.38227081298828\n",
      "cls loss 363.8275146484375  loc loss 19.79325294494629\n",
      "cls loss 714.7177124023438  loc loss 45.34222412109375\n",
      "cls loss 410.14923095703125  loc loss 25.953968048095703\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([1., 3., 3.])\n",
      "cls loss 434.0467834472656  loc loss 35.51716995239258\n",
      "cls loss 384.6109924316406  loc loss 17.488086700439453\n",
      "cls loss 683.9735107421875  loc loss 39.60289001464844\n",
      "cls loss 700.8670654296875  loc loss 42.96099853515625\n",
      "cls loss 651.69677734375  loc loss 41.928688049316406\n",
      "cls loss 621.5869750976562  loc loss 42.167049407958984\n",
      "cls loss 557.05810546875  loc loss 41.84876251220703\n",
      "cls loss 666.082763671875  loc loss 50.18634033203125\n",
      "cls loss 570.6809692382812  loc loss 39.03047561645508\n",
      "cls loss 670.858642578125  loc loss 53.417137145996094\n",
      "cls loss 429.0727233886719  loc loss 28.15821075439453\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 818.5528564453125  loc loss 51.938472747802734\n",
      "cls loss 923.5968017578125  loc loss 53.39450454711914\n",
      "cls loss 838.89599609375  loc loss 60.599327087402344\n",
      "cls loss 852.2096557617188  loc loss 58.443084716796875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10., 10., 10.,  1.,  1.,  1.,  1.,  1.,  1.,  8.,  8.,\n",
      "         1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10., 10., 10.,  1.,  1.,  1.,  1.,  1.,  1.,  8.,  8.,\n",
      "         1.])\n",
      "cls loss 828.9967041015625  loc loss 47.30766677856445\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 3., 3., 3.])\n",
      "cls loss 657.6805419921875  loc loss 42.54172897338867\n",
      "cls loss 474.50860595703125  loc loss 26.78267478942871\n",
      "cls loss 346.4200134277344  loc loss 20.918729782104492\n",
      "cls loss 629.7296142578125  loc loss 45.54484558105469\n",
      "cls loss 521.3353271484375  loc loss 26.99352264404297\n",
      "cls loss 582.143798828125  loc loss 38.646480560302734\n",
      "cls loss 654.6370239257812  loc loss 42.21495819091797\n",
      "cls loss 896.9445190429688  loc loss 63.97193145751953\n",
      "cls loss 725.0703125  loc loss 41.97635269165039\n",
      "cls loss 681.45166015625  loc loss 45.21944808959961\n",
      "cls loss 787.372802734375  loc loss 55.24974822998047\n",
      "cls loss 618.2508544921875  loc loss 45.69640350341797\n",
      "cls loss 975.3233032226562  loc loss 82.93299102783203\n",
      "cls loss 536.6217651367188  loc loss 32.02699279785156\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 770.349853515625  loc loss 51.60648727416992\n",
      "cls loss 404.5118408203125  loc loss 21.065767288208008\n",
      "cls loss 1025.641845703125  loc loss 70.10602569580078\n",
      "cls loss 538.754638671875  loc loss 30.59055519104004\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 34.])\n",
      "cls loss 812.054931640625  loc loss 46.07910919189453\n",
      "cls loss 454.171630859375  loc loss 27.44879722595215\n",
      "cls loss 800.573974609375  loc loss 49.676666259765625\n",
      "cls loss 312.5627746582031  loc loss 19.366796493530273\n",
      "cls loss 745.9054565429688  loc loss 47.83099365234375\n",
      "cls loss 652.60205078125  loc loss 48.99699401855469\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 38.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16., 16., 16.,  9.,  9.,  9., 16., 16., 16., 85.,  9.])\n",
      "cls loss 616.4480590820312  loc loss 40.64912414550781\n",
      "cls loss 687.6500244140625  loc loss 58.380313873291016\n",
      "cls loss 1023.971435546875  loc loss 76.89978790283203\n",
      "cls loss 1357.5032958984375  loc loss 102.12816619873047\n",
      "cls loss 420.7596740722656  loc loss 22.400075912475586\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3., 10.,  8.,  8., 10., 10., 10.,  3.,  3., 14.])\n",
      "cls loss 540.61572265625  loc loss 26.713726043701172\n",
      "cls loss 834.0686645507812  loc loss 49.823890686035156\n",
      "cls loss 337.52142333984375  loc loss 15.746341705322266\n",
      "cls loss 542.2061157226562  loc loss 28.34920883178711\n",
      "cls loss 863.8037109375  loc loss 50.88319396972656\n",
      "cls loss 706.46337890625  loc loss 48.72254180908203\n",
      "cls loss 447.5457763671875  loc loss 24.17027473449707\n",
      "cls loss 492.736083984375  loc loss 29.580928802490234\n",
      "cls loss 709.2117309570312  loc loss 46.16649627685547\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42., 42.,  1.])\n",
      "cls loss 685.840576171875  loc loss 47.28312683105469\n",
      "cls loss 620.3475341796875  loc loss 35.130393981933594\n",
      "cls loss 755.2015380859375  loc loss 57.566654205322266\n",
      "cls loss 809.01416015625  loc loss 57.14234161376953\n",
      "cls loss 601.13330078125  loc loss 38.079620361328125\n",
      "cls loss 697.229248046875  loc loss 52.73100662231445\n",
      "cls loss 464.38018798828125  loc loss 30.782384872436523\n",
      "cls loss 517.5429077148438  loc loss 34.8132438659668\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20.])\n",
      "cls loss 369.6907958984375  loc loss 23.84526824951172\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([11.])\n",
      "cls loss 472.2071838378906  loc loss 27.181655883789062\n",
      "cls loss 333.0744323730469  loc loss 21.33592414855957\n",
      "cls loss 696.7091064453125  loc loss 64.19617462158203\n",
      "cls loss 342.54669189453125  loc loss 18.064128875732422\n",
      "cls loss 655.8600463867188  loc loss 45.10407638549805\n",
      "cls loss 408.58392333984375  loc loss 23.895172119140625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 35., 27.])\n",
      "cls loss 655.5601806640625  loc loss 44.827266693115234\n",
      "cls loss 666.8421020507812  loc loss 58.59819030761719\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 522.9210205078125  loc loss 36.36823272705078\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([42.,  1.])\n",
      "cls loss 682.6015014648438  loc loss 55.7110595703125\n",
      "cls loss 637.6143798828125  loc loss 38.06504440307617\n",
      "cls loss 836.813720703125  loc loss 43.16497802734375\n",
      "cls loss 950.6728515625  loc loss 60.718788146972656\n",
      "cls loss 814.217529296875  loc loss 55.62539291381836\n",
      "cls loss 523.5341796875  loc loss 42.74337387084961\n",
      "cls loss 478.1573791503906  loc loss 36.69478225708008\n",
      "cls loss 356.0035400390625  loc loss 16.186450958251953\n",
      "cls loss 559.1220703125  loc loss 34.66411590576172\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 1., 1.])\n",
      "cls loss 514.845703125  loc loss 31.53180503845215\n",
      "cls loss 573.7105102539062  loc loss 46.45011520385742\n",
      "cls loss 576.573974609375  loc loss 40.14607620239258\n",
      "cls loss 492.27362060546875  loc loss 37.497467041015625\n",
      "cls loss 578.9591064453125  loc loss 39.66951370239258\n",
      "cls loss 615.8612060546875  loc loss 48.95656204223633\n",
      "cls loss 879.5585327148438  loc loss 54.5289306640625\n",
      "cls loss 782.250244140625  loc loss 61.104331970214844\n",
      "cls loss 701.7614135742188  loc loss 43.65925979614258\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 545.1981201171875  loc loss 42.37242889404297\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 658.6383056640625  loc loss 32.437381744384766\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([81.])\n",
      "cls loss 801.0233154296875  loc loss 54.07807922363281\n",
      "cls loss 502.046630859375  loc loss 34.680511474609375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 405.0733642578125  loc loss 24.227487564086914\n",
      "cls loss 541.5747680664062  loc loss 28.031551361083984\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3.,  1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 19.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 19.])\n",
      "cls loss 734.0552978515625  loc loss 51.174224853515625\n",
      "cls loss 430.7681884765625  loc loss 20.762128829956055\n",
      "cls loss 424.4071960449219  loc loss 27.666584014892578\n",
      "cls loss 819.3341674804688  loc loss 64.324951171875\n",
      "cls loss 448.29046630859375  loc loss 28.61817741394043\n",
      "cls loss 521.3434448242188  loc loss 40.12018585205078\n",
      "cls loss 628.773193359375  loc loss 47.12144088745117\n",
      "cls loss 487.2914123535156  loc loss 39.650718688964844\n",
      "cls loss 665.9669189453125  loc loss 42.142005920410156\n",
      "cls loss 729.686279296875  loc loss 54.59566879272461\n",
      "cls loss 910.097900390625  loc loss 83.20352172851562\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 81.])\n",
      "cls loss 636.66748046875  loc loss 37.56604766845703\n",
      "cls loss 626.5804443359375  loc loss 34.30923080444336\n",
      "cls loss 655.736328125  loc loss 37.969810485839844\n",
      "cls loss 481.74456787109375  loc loss 24.586101531982422\n",
      "cls loss 473.22137451171875  loc loss 28.374462127685547\n",
      "cls loss 570.6005859375  loc loss 37.765560150146484\n",
      "cls loss 434.4639587402344  loc loss 29.64906883239746\n",
      "cls loss 339.59857177734375  loc loss 24.255626678466797\n",
      "cls loss 440.6033935546875  loc loss 32.64543151855469\n",
      "cls loss 625.567626953125  loc loss 40.42741012573242\n",
      "cls loss 514.0556640625  loc loss 39.83741760253906\n",
      "cls loss 539.6759643554688  loc loss 42.332637786865234\n",
      "cls loss 322.8255615234375  loc loss 24.841798782348633\n",
      "cls loss 1061.66943359375  loc loss 80.54512023925781\n",
      "cls loss 711.6160278320312  loc loss 52.365966796875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 597.562255859375  loc loss 36.085548400878906\n",
      "cls loss 649.8181762695312  loc loss 46.89106750488281\n",
      "cls loss 520.7567749023438  loc loss 31.049217224121094\n",
      "cls loss 722.1117553710938  loc loss 47.92196273803711\n",
      "cls loss 725.8604125976562  loc loss 48.862308502197266\n",
      "cls loss 655.121337890625  loc loss 42.19165802001953\n",
      "cls loss 589.3640747070312  loc loss 30.74551773071289\n",
      "cls loss 443.4168701171875  loc loss 25.18409538269043\n",
      "cls loss 585.1881713867188  loc loss 39.42598342895508\n",
      "cls loss 609.056884765625  loc loss 46.99691390991211\n",
      "cls loss 679.9830322265625  loc loss 37.9951057434082\n",
      "cls loss 833.1692504882812  loc loss 64.33224487304688\n",
      "cls loss 900.42724609375  loc loss 65.28797912597656\n",
      "cls loss 600.3564453125  loc loss 42.97145080566406\n",
      "cls loss 761.091796875  loc loss 64.51185607910156\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1., 38., 47.,  1.,  1.,  1.,  1.,  1., 62.])\n",
      "cls loss 532.8272705078125  loc loss 33.3968505859375\n",
      "cls loss 667.9408569335938  loc loss 42.168941497802734\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 720.2978515625  loc loss 46.40802001953125\n",
      "cls loss 852.8110961914062  loc loss 61.03450012207031\n",
      "cls loss 561.9042358398438  loc loss 30.19446563720703\n",
      "cls loss 606.7293701171875  loc loss 50.7265510559082\n",
      "cls loss 577.005615234375  loc loss 39.58427810668945\n",
      "cls loss 383.93560791015625  loc loss 17.018556594848633\n",
      "cls loss 554.8524780273438  loc loss 35.07027816772461\n",
      "cls loss 481.8143005371094  loc loss 24.93001937866211\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1., 35.])\n",
      "cls loss 537.3673706054688  loc loss 30.073097229003906\n",
      "cls loss 820.003662109375  loc loss 46.684417724609375\n",
      "cls loss 760.51416015625  loc loss 52.18113708496094\n",
      "cls loss 696.0361328125  loc loss 58.2776985168457\n",
      "cls loss 574.8497924804688  loc loss 46.160030364990234\n",
      "cls loss 689.2781982421875  loc loss 53.79740905761719\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 402.442138671875  loc loss 25.406381607055664\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 624.2403564453125  loc loss 31.668399810791016\n",
      "cls loss 967.2164306640625  loc loss 58.31084060668945\n",
      "cls loss 1125.607666015625  loc loss 86.90132141113281\n",
      "cls loss 600.3841552734375  loc loss 33.732994079589844\n",
      "cls loss 510.9303283691406  loc loss 32.0482292175293\n",
      "cls loss 517.771484375  loc loss 33.925018310546875\n",
      "cls loss 572.7972412109375  loc loss 48.00273895263672\n",
      "cls loss 575.882568359375  loc loss 23.29291343688965\n",
      "cls loss 874.4031982421875  loc loss 68.6298828125\n",
      "cls loss 713.72216796875  loc loss 45.081600189208984\n",
      "cls loss 458.3787841796875  loc loss 26.32025909423828\n",
      "cls loss 777.8154296875  loc loss 42.7943229675293\n",
      "cls loss 899.5564575195312  loc loss 67.68387603759766\n",
      "cls loss 703.3006591796875  loc loss 46.82704544067383\n",
      "cls loss 644.11962890625  loc loss 36.71419143676758\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.])\n",
      "cls loss 613.314453125  loc loss 45.57276153564453\n",
      "cls loss 504.80767822265625  loc loss 41.29056930541992\n",
      "cls loss 781.69921875  loc loss 49.96759796142578\n",
      "cls loss 1031.7371826171875  loc loss 91.14083862304688\n",
      "cls loss 489.0179748535156  loc loss 24.52601432800293\n",
      "cls loss 564.353271484375  loc loss 38.462276458740234\n",
      "cls loss 485.4032897949219  loc loss 31.31351661682129\n",
      "cls loss 545.9082641601562  loc loss 35.1937255859375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 21., 21., 21.])\n",
      "cls loss 607.0853271484375  loc loss 35.062984466552734\n",
      "cls loss 539.2428588867188  loc loss 27.028640747070312\n",
      "cls loss 567.7109375  loc loss 38.640907287597656\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 35.])\n",
      "cls loss 862.343994140625  loc loss 59.62731170654297\n",
      "cls loss 293.654052734375  loc loss 16.20183753967285\n",
      "cls loss 451.62713623046875  loc loss 31.406784057617188\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 443.47564697265625  loc loss 27.728500366210938\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 38., 38.,  9., 38.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1.,  1.])\n",
      "cls loss 489.9037170410156  loc loss 38.3399658203125\n",
      "cls loss 801.729248046875  loc loss 59.547481536865234\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 2.,  1., 77., 31., 10., 10.,  1.,  4., 10.])\n",
      "cls loss 468.054443359375  loc loss 23.580707550048828\n",
      "cls loss 804.1800537109375  loc loss 50.21137619018555\n",
      "cls loss 1480.5809326171875  loc loss 110.69939422607422\n",
      "cls loss 524.20166015625  loc loss 33.49351119995117\n",
      "cls loss 679.0794677734375  loc loss 58.77961730957031\n",
      "cls loss 510.7555847167969  loc loss 32.9207649230957\n",
      "cls loss 525.5565795898438  loc loss 28.048797607421875\n",
      "cls loss 868.998046875  loc loss 37.03371810913086\n",
      "cls loss 732.950927734375  loc loss 43.887943267822266\n",
      "cls loss 673.489013671875  loc loss 47.773460388183594\n",
      "cls loss 514.0467529296875  loc loss 27.073152542114258\n",
      "cls loss 619.7418212890625  loc loss 30.077116012573242\n",
      "cls loss 1119.95654296875  loc loss 67.61946105957031\n",
      "cls loss 882.1640625  loc loss 61.924800872802734\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1., 42., 42., 42., 42., 42., 42.,  1.,\n",
      "         1.,  1.,  1., 42.,  1.,  1., 42.,  1.])\n",
      "cls loss 523.9367065429688  loc loss 37.997703552246094\n",
      "cls loss 746.491455078125  loc loss 50.02498245239258\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.])\n",
      "cls loss 358.0709533691406  loc loss 24.504878997802734\n",
      "cls loss 707.2604370117188  loc loss 52.98153305053711\n",
      "cls loss 566.4624633789062  loc loss 43.9005126953125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([11.])\n",
      "cls loss 353.52288818359375  loc loss 20.570701599121094\n",
      "cls loss 465.69012451171875  loc loss 22.830408096313477\n",
      "cls loss 464.51483154296875  loc loss 25.71021842956543\n",
      "cls loss 650.8854370117188  loc loss 47.802642822265625\n",
      "cls loss 630.6182861328125  loc loss 40.33422088623047\n",
      "cls loss 619.5227661132812  loc loss 49.61669158935547\n",
      "cls loss 884.546875  loc loss 54.088043212890625\n",
      "cls loss 497.68505859375  loc loss 32.450260162353516\n",
      "cls loss 891.5394897460938  loc loss 72.37908172607422\n",
      "cls loss 550.4893798828125  loc loss 29.647228240966797\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 487.2218017578125  loc loss 33.056785583496094\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1., 38., 38., 42.])\n",
      "cls loss 637.461669921875  loc loss 44.861541748046875\n",
      "cls loss 606.4193115234375  loc loss 29.22812271118164\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 466.7916259765625  loc loss 33.31678009033203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 1032.8638916015625  loc loss 76.04893493652344\n",
      "cls loss 604.858642578125  loc loss 46.93589782714844\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10.,  3.,  3.,  6.,  8.,  8.,  1.,  1.,  1., 10.])\n",
      "cls loss 544.1828002929688  loc loss 35.407615661621094\n",
      "cls loss 320.34442138671875  loc loss 13.551525115966797\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10.,  3.])\n",
      "cls loss 513.0613403320312  loc loss 30.142427444458008\n",
      "cls loss 339.16827392578125  loc loss 16.62060546875\n",
      "cls loss 575.5908813476562  loc loss 50.16143035888672\n",
      "cls loss 639.1926879882812  loc loss 49.27257537841797\n",
      "cls loss 495.71087646484375  loc loss 32.38127517700195\n",
      "cls loss 386.2012023925781  loc loss 19.595722198486328\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 34.])\n",
      "cls loss 885.2136840820312  loc loss 55.296600341796875\n",
      "cls loss 911.0855102539062  loc loss 79.19523620605469\n",
      "cls loss 614.3914794921875  loc loss 51.63203048706055\n",
      "cls loss 456.0693359375  loc loss 34.016319274902344\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.,  1.])\n",
      "cls loss 530.3687744140625  loc loss 29.099674224853516\n",
      "cls loss 823.7654418945312  loc loss 66.5858154296875\n",
      "cls loss 1197.15966796875  loc loss 83.81270599365234\n",
      "cls loss 1020.91455078125  loc loss 57.27850341796875\n",
      "cls loss 621.6917724609375  loc loss 36.104278564453125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 808.3287353515625  loc loss 42.7567024230957\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10.])\n",
      "cls loss 459.92059326171875  loc loss 26.401958465576172\n",
      "cls loss 632.6532592773438  loc loss 34.402462005615234\n",
      "cls loss 617.7855224609375  loc loss 35.03565216064453\n",
      "cls loss 422.6474914550781  loc loss 27.101715087890625\n",
      "cls loss 518.3404541015625  loc loss 40.8341064453125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21.,\n",
      "        21.])\n",
      "cls loss 706.6885986328125  loc loss 45.842777252197266\n",
      "cls loss 589.405517578125  loc loss 44.68684387207031\n",
      "cls loss 395.0295715332031  loc loss 18.761930465698242\n",
      "cls loss 785.3318481445312  loc loss 54.034854888916016\n",
      "cls loss 615.8863525390625  loc loss 47.061492919921875\n",
      "cls loss 436.928466796875  loc loss 30.726253509521484\n",
      "cls loss 930.3492431640625  loc loss 71.52352905273438\n",
      "cls loss 1100.44775390625  loc loss 80.08000946044922\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15., 85.])\n",
      "cls loss 752.7647705078125  loc loss 48.221458435058594\n",
      "cls loss 683.1948852539062  loc loss 57.415061950683594\n",
      "cls loss 797.5211181640625  loc loss 54.75139617919922\n",
      "cls loss 680.6143798828125  loc loss 42.12547302246094\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 8., 8.])\n",
      "cls loss 429.1824645996094  loc loss 23.106962203979492\n",
      "cls loss 528.0114135742188  loc loss 32.530487060546875\n",
      "cls loss 583.5574951171875  loc loss 35.85853576660156\n",
      "cls loss 498.4439697265625  loc loss 28.45368766784668\n",
      "cls loss 563.874755859375  loc loss 36.35429382324219\n",
      "cls loss 737.7728881835938  loc loss 45.242183685302734\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1., 35., 27., 27.,  1., 27.,  1.])\n",
      "cls loss 1038.587646484375  loc loss 72.1103744506836\n",
      "cls loss 467.25299072265625  loc loss 36.367149353027344\n",
      "cls loss 575.7630615234375  loc loss 44.02809143066406\n",
      "cls loss 539.2351684570312  loc loss 48.399658203125\n",
      "cls loss 543.086181640625  loc loss 41.31507110595703\n",
      "cls loss 549.3211669921875  loc loss 45.19877624511719\n",
      "cls loss 531.228759765625  loc loss 44.657230377197266\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  2.,  2.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  2.,  2.])\n",
      "cls loss 364.4871520996094  loc loss 15.255147933959961\n",
      "cls loss 805.968017578125  loc loss 52.863197326660156\n",
      "cls loss 591.091064453125  loc loss 32.07181930541992\n",
      "cls loss 968.4258422851562  loc loss 69.99978637695312\n",
      "cls loss 416.6477966308594  loc loss 26.625898361206055\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 19., 19., 19., 16.])\n",
      "cls loss 421.0730895996094  loc loss 21.376161575317383\n",
      "cls loss 336.9774475097656  loc loss 16.921411514282227\n",
      "cls loss 496.78192138671875  loc loss 27.022296905517578\n",
      "cls loss 643.9212646484375  loc loss 44.24015426635742\n",
      "cls loss 337.6763916015625  loc loss 27.261798858642578\n",
      "cls loss 757.2947998046875  loc loss 55.09890365600586\n",
      "cls loss 523.7418212890625  loc loss 40.465301513671875\n",
      "cls loss 562.3937377929688  loc loss 40.98945617675781\n",
      "cls loss 691.9281005859375  loc loss 53.5327033996582\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 791.325927734375  loc loss 40.25798797607422\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 1010.9298095703125  loc loss 88.24018859863281\n",
      "cls loss 1263.20458984375  loc loss 128.21058654785156\n",
      "cls loss 608.899169921875  loc loss 48.29414749145508\n",
      "cls loss 578.1234130859375  loc loss 41.27924346923828\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3.,  3.,  3.,  3.,  3., 10.])\n",
      "cls loss 346.9783935546875  loc loss 17.62298583984375\n",
      "cls loss 662.4440307617188  loc loss 38.14253234863281\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 1., 1., 1., 3., 3., 3., 3.])\n",
      "cls loss 563.2098388671875  loc loss 37.56853485107422\n",
      "cls loss 958.972900390625  loc loss 71.91046142578125\n",
      "cls loss 783.2816162109375  loc loss 54.833316802978516\n",
      "cls loss 600.6480102539062  loc loss 32.175048828125\n",
      "cls loss 769.993408203125  loc loss 61.41765594482422\n",
      "cls loss 502.61962890625  loc loss 38.88975524902344\n",
      "cls loss 762.4505615234375  loc loss 56.966651916503906\n",
      "cls loss 589.6821899414062  loc loss 50.99276351928711\n",
      "cls loss 555.942138671875  loc loss 41.27488708496094\n",
      "cls loss 1181.830078125  loc loss 101.83805847167969\n",
      "cls loss 765.0082397460938  loc loss 55.430023193359375\n",
      "cls loss 510.92120361328125  loc loss 27.731359481811523\n",
      "cls loss 335.9832763671875  loc loss 17.115814208984375\n",
      "cls loss 395.7588195800781  loc loss 24.091068267822266\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3., 10., 10., 10., 10., 10., 10., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10., 10., 10., 10., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 11., 10., 10., 10., 10., 10.,  3.,  3.,  3.,  3.,  3.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 11., 10., 10., 10., 10., 10.,  3.,  3.,  3.,  3.,  3.])\n",
      "cls loss 375.4758605957031  loc loss 20.76201057434082\n",
      "cls loss 503.44427490234375  loc loss 25.717639923095703\n",
      "cls loss 417.07537841796875  loc loss 26.624130249023438\n",
      "cls loss 393.6788635253906  loc loss 18.235580444335938\n",
      "cls loss 490.96112060546875  loc loss 38.13922119140625\n",
      "cls loss 449.27947998046875  loc loss 17.83828353881836\n",
      "cls loss 721.2013549804688  loc loss 52.434696197509766\n",
      "cls loss 634.4454345703125  loc loss 48.683143615722656\n",
      "cls loss 950.37353515625  loc loss 66.27389526367188\n",
      "cls loss 471.47393798828125  loc loss 36.584251403808594\n",
      "cls loss 837.58056640625  loc loss 59.29235076904297\n",
      "cls loss 684.9820556640625  loc loss 50.28156280517578\n",
      "cls loss 638.5225219726562  loc loss 44.94730758666992\n",
      "cls loss 648.476806640625  loc loss 51.13583755493164\n",
      "cls loss 880.457763671875  loc loss 62.608665466308594\n",
      "cls loss 850.6800537109375  loc loss 55.44681930541992\n",
      "cls loss 439.29901123046875  loc loss 25.280065536499023\n",
      "cls loss 734.1513671875  loc loss 59.222442626953125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 10.,  1., 18.])\n",
      "cls loss 396.10382080078125  loc loss 27.793004989624023\n",
      "cls loss 442.7466125488281  loc loss 19.457904815673828\n",
      "cls loss 779.7462768554688  loc loss 40.276458740234375\n",
      "cls loss 1046.55126953125  loc loss 74.40373229980469\n",
      "cls loss 672.570556640625  loc loss 45.988243103027344\n",
      "cls loss 878.1357421875  loc loss 57.510257720947266\n",
      "cls loss 619.9259033203125  loc loss 43.95637512207031\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.,  1.,  1.])\n",
      "cls loss 819.2157592773438  loc loss 56.971839904785156\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1., 38.,  1.])\n",
      "cls loss 786.6964111328125  loc loss 47.4544677734375\n",
      "cls loss 993.6204833984375  loc loss 77.99169158935547\n",
      "cls loss 493.20458984375  loc loss 40.52839279174805\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 666.1312866210938  loc loss 49.888343811035156\n",
      "cls loss 595.2948608398438  loc loss 43.21165084838867\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3., 10.,  8.,  3., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.])\n",
      "cls loss 724.2559814453125  loc loss 48.67061996459961\n",
      "cls loss 502.831787109375  loc loss 34.111175537109375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3.,  3., 11.,  3., 10., 10.,  3.,  3., 10.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 600.7584838867188  loc loss 32.444183349609375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3., 10., 10., 10.])\n",
      "cls loss 587.0281372070312  loc loss 45.49646759033203\n",
      "cls loss 500.65863037109375  loc loss 30.508460998535156\n",
      "cls loss 625.83740234375  loc loss 48.22814178466797\n",
      "cls loss 1034.3399658203125  loc loss 62.91132354736328\n",
      "cls loss 625.0390014648438  loc loss 43.48942184448242\n",
      "cls loss 445.3896484375  loc loss 39.0899772644043\n",
      "cls loss 545.8311767578125  loc loss 40.65979766845703\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 9.,  9., 85., 85.])\n",
      "cls loss 520.9739990234375  loc loss 29.530757904052734\n",
      "cls loss 569.4458618164062  loc loss 39.25233840942383\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 925.8125  loc loss 72.62488555908203\n",
      "cls loss 779.6907958984375  loc loss 43.472320556640625\n",
      "cls loss 881.6466064453125  loc loss 65.31786346435547\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10., 10., 10., 10.])\n",
      "cls loss 575.6719970703125  loc loss 36.22920227050781\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([13.])\n",
      "cls loss 908.0357666015625  loc loss 74.97620391845703\n",
      "cls loss 333.04193115234375  loc loss 18.92403793334961\n",
      "cls loss 389.2110290527344  loc loss 22.619970321655273\n",
      "cls loss 552.3582153320312  loc loss 32.47136688232422\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19.,  1.,  1.,  1., 19., 19.])\n",
      "cls loss 574.8798217773438  loc loss 37.88615417480469\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 406.5689392089844  loc loss 39.47278594970703\n",
      "cls loss 679.60888671875  loc loss 51.28617477416992\n",
      "cls loss 465.9723815917969  loc loss 30.146764755249023\n",
      "cls loss 708.8021240234375  loc loss 46.7303581237793\n",
      "cls loss 765.9843139648438  loc loss 59.812644958496094\n",
      "cls loss 625.8719482421875  loc loss 35.12647247314453\n",
      "cls loss 835.4502563476562  loc loss 65.51683044433594\n",
      "cls loss 391.90289306640625  loc loss 17.680274963378906\n",
      "cls loss 605.8770751953125  loc loss 41.60530090332031\n",
      "cls loss 502.8893127441406  loc loss 26.574344635009766\n",
      "cls loss 494.8825988769531  loc loss 30.11820411682129\n",
      "cls loss 644.1073608398438  loc loss 50.91994857788086\n",
      "cls loss 621.072265625  loc loss 39.01873016357422\n",
      "cls loss 899.314208984375  loc loss 59.561492919921875\n",
      "cls loss 555.6260986328125  loc loss 41.10533905029297\n",
      "cls loss 674.6597900390625  loc loss 49.625938415527344\n",
      "cls loss 974.3040771484375  loc loss 68.87423706054688\n",
      "cls loss 581.4150390625  loc loss 46.90657043457031\n",
      "cls loss 656.9553833007812  loc loss 41.611976623535156\n",
      "cls loss 842.35498046875  loc loss 62.39011001586914\n",
      "cls loss 821.7197265625  loc loss 61.75108337402344\n",
      "cls loss 1048.88623046875  loc loss 63.260799407958984\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 5.])\n",
      "cls loss 338.8291320800781  loc loss 12.275814056396484\n",
      "cls loss 421.2131042480469  loc loss 19.069196701049805\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 13.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 6., 8., 8.])\n",
      "cls loss 411.24627685546875  loc loss 17.798093795776367\n",
      "cls loss 434.40008544921875  loc loss 25.48888397216797\n",
      "cls loss 806.7225952148438  loc loss 61.55561828613281\n",
      "cls loss 375.0819091796875  loc loss 18.816368103027344\n",
      "cls loss 641.6048583984375  loc loss 50.34565734863281\n",
      "cls loss 996.2874145507812  loc loss 70.06610107421875\n",
      "cls loss 593.22216796875  loc loss 46.862789154052734\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([42., 42.,  1.,  1.,  1.,  1.,  1.,  1.,  1., 42., 42.])\n",
      "cls loss 646.4375  loc loss 43.20826721191406\n",
      "cls loss 859.2987060546875  loc loss 69.66486358642578\n",
      "cls loss 666.384521484375  loc loss 58.88959503173828\n",
      "cls loss 500.3583984375  loc loss 30.942853927612305\n",
      "cls loss 677.6048583984375  loc loss 44.33134078979492\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 933.8790283203125  loc loss 62.51442337036133\n",
      "cls loss 726.78955078125  loc loss 55.44666290283203\n",
      "cls loss 484.1235656738281  loc loss 30.476346969604492\n",
      "cls loss 434.30047607421875  loc loss 21.842443466186523\n",
      "cls loss 571.89990234375  loc loss 36.32599639892578\n",
      "cls loss 763.3348388671875  loc loss 52.36334991455078\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15.])\n",
      "cls loss 365.51934814453125  loc loss 19.96731185913086\n",
      "cls loss 591.011962890625  loc loss 40.25185775756836\n",
      "cls loss 520.9132690429688  loc loss 36.23290252685547\n",
      "cls loss 911.3785400390625  loc loss 68.1218032836914\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19.,  7.])\n",
      "cls loss 536.899658203125  loc loss 35.16735076904297\n",
      "cls loss 1090.1451416015625  loc loss 69.69975280761719\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 913.675537109375  loc loss 53.07976531982422\n",
      "cls loss 684.3487548828125  loc loss 56.17816162109375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([38., 38.,  1., 18.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1., 18., 18.,  1.])\n",
      "cls loss 574.4732666015625  loc loss 31.60548210144043\n",
      "cls loss 548.4219970703125  loc loss 27.559972763061523\n",
      "cls loss 898.6134033203125  loc loss 76.10243225097656\n",
      "cls loss 698.92626953125  loc loss 44.73456573486328\n",
      "cls loss 723.2183837890625  loc loss 37.40498352050781\n",
      "cls loss 393.24810791015625  loc loss 31.37005615234375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.])\n",
      "cls loss 320.2731018066406  loc loss 12.869125366210938\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([32.])\n",
      "cls loss 637.2738647460938  loc loss 32.13920211791992\n",
      "cls loss 547.5127563476562  loc loss 37.57291030883789\n",
      "cls loss 727.5855712890625  loc loss 60.992279052734375\n",
      "cls loss 698.05419921875  loc loss 42.89213943481445\n",
      "cls loss 560.8490600585938  loc loss 37.20551300048828\n",
      "cls loss 867.2991943359375  loc loss 53.420257568359375\n",
      "cls loss 886.6804809570312  loc loss 64.89159393310547\n",
      "cls loss 728.8746337890625  loc loss 51.27878189086914\n",
      "cls loss 622.3295288085938  loc loss 37.969261169433594\n",
      "cls loss 979.894287109375  loc loss 63.06713104248047\n",
      "cls loss 578.541015625  loc loss 32.44784164428711\n",
      "cls loss 894.5377197265625  loc loss 79.23785400390625\n",
      "cls loss 679.3046264648438  loc loss 43.11862564086914\n",
      "cls loss 565.78564453125  loc loss 42.89274978637695\n",
      "cls loss 442.28240966796875  loc loss 25.964157104492188\n",
      "cls loss 460.40167236328125  loc loss 32.611968994140625\n",
      "cls loss 699.8299560546875  loc loss 51.03324890136719\n",
      "cls loss 727.4203491210938  loc loss 56.245208740234375\n",
      "cls loss 428.98272705078125  loc loss 31.09357452392578\n",
      "cls loss 820.15087890625  loc loss 56.613189697265625\n",
      "cls loss 967.36181640625  loc loss 61.52124786376953\n",
      "cls loss 365.6221923828125  loc loss 25.70223045349121\n",
      "cls loss 928.3388061523438  loc loss 65.1875\n",
      "cls loss 675.0328369140625  loc loss 52.000762939453125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 905.5806884765625  loc loss 72.17778015136719\n",
      "cls loss 463.5467834472656  loc loss 19.28410530090332\n",
      "cls loss 686.617431640625  loc loss 39.81871032714844\n",
      "cls loss 672.5276489257812  loc loss 47.43844985961914\n",
      "cls loss 520.5105590820312  loc loss 33.32105255126953\n",
      "cls loss 338.7148742675781  loc loss 17.23259162902832\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 9., 9., 1., 9., 9., 9., 9., 1., 9.])\n",
      "cls loss 1164.6357421875  loc loss 102.37122344970703\n",
      "cls loss 695.446044921875  loc loss 38.61826705932617\n",
      "cls loss 1005.9075927734375  loc loss 86.2199935913086\n",
      "cls loss 442.00921630859375  loc loss 29.47114372253418\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 42., 42.])\n",
      "cls loss 713.582763671875  loc loss 55.49951171875\n",
      "cls loss 755.4096069335938  loc loss 56.673343658447266\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  2.,  1.,  1.,  1., 38.,\n",
      "         1.,  1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 38., 38., 38.,  1., 38., 38., 38.,  1.,  1., 38.,  1.,\n",
      "         1.])\n",
      "cls loss 500.3443603515625  loc loss 33.298728942871094\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  8.,  8.])\n",
      "cls loss 1044.6224365234375  loc loss 73.55322265625\n",
      "cls loss 1046.4254150390625  loc loss 75.60022735595703\n",
      "cls loss 432.2640380859375  loc loss 26.559032440185547\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([4., 1., 1., 4.])\n",
      "cls loss 607.1505737304688  loc loss 45.199432373046875\n",
      "cls loss 724.7579345703125  loc loss 47.098812103271484\n",
      "cls loss 344.3394775390625  loc loss 16.63762855529785\n",
      "cls loss 467.2788391113281  loc loss 28.226173400878906\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([51.,  1.])\n",
      "cls loss 339.78057861328125  loc loss 15.330995559692383\n",
      "cls loss 427.0589599609375  loc loss 27.763370513916016\n",
      "cls loss 773.7117919921875  loc loss 48.93534851074219\n",
      "cls loss 860.1455078125  loc loss 67.22866821289062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 1152.1883544921875  loc loss 69.79389953613281\n",
      "cls loss 1433.3873291015625  loc loss 98.3916244506836\n",
      "cls loss 603.85693359375  loc loss 40.26169967651367\n",
      "cls loss 843.3402709960938  loc loss 61.105613708496094\n",
      "cls loss 893.25390625  loc loss 67.38099670410156\n",
      "cls loss 673.190673828125  loc loss 40.4622802734375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  3.,  1.,  1.,  1.,  3.,  1.,  1.,\n",
      "         1.,  1.,  1.])\n",
      "cls loss 757.5385131835938  loc loss 41.73222732543945\n",
      "cls loss 890.5908203125  loc loss 44.223045349121094\n",
      "cls loss 779.240234375  loc loss 40.40099334716797\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "cls loss 616.8056640625  loc loss 38.07789611816406\n",
      "cls loss 370.754638671875  loc loss 30.16457176208496\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3.])\n",
      "cls loss 366.55865478515625  loc loss 15.664789199829102\n",
      "cls loss 553.7830810546875  loc loss 42.00947570800781\n",
      "cls loss 449.2890319824219  loc loss 34.005279541015625\n",
      "cls loss 793.046630859375  loc loss 60.16387939453125\n",
      "cls loss 560.5496215820312  loc loss 27.644411087036133\n",
      "cls loss 446.69927978515625  loc loss 31.715803146362305\n",
      "cls loss 1360.43798828125  loc loss 95.29029083251953\n",
      "cls loss 573.8475952148438  loc loss 44.87679672241211\n",
      "cls loss 410.7582702636719  loc loss 36.48292541503906\n",
      "cls loss 551.765625  loc loss 34.79238510131836\n",
      "cls loss 470.91656494140625  loc loss 37.18312454223633\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 861.0335693359375  loc loss 63.820213317871094\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  9., 64., 64., 64., 64., 64., 64., 64., 64., 64.,  9.,  9.,  9.,\n",
      "         9.])\n",
      "cls loss 506.3715515136719  loc loss 28.19702911376953\n",
      "cls loss 1156.439697265625  loc loss 97.2039794921875\n",
      "cls loss 618.31884765625  loc loss 41.74502944946289\n",
      "cls loss 781.3976440429688  loc loss 61.006404876708984\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.,  3.,  3.])\n",
      "cls loss 521.020263671875  loc loss 34.46152877807617\n",
      "cls loss 638.364501953125  loc loss 37.64448165893555\n",
      "cls loss 593.6533203125  loc loss 43.938385009765625\n",
      "cls loss 687.0533447265625  loc loss 44.68712615966797\n",
      "cls loss 642.72216796875  loc loss 51.54576873779297\n",
      "cls loss 591.078125  loc loss 47.55739212036133\n",
      "cls loss 588.3748779296875  loc loss 46.611366271972656\n",
      "cls loss 591.697998046875  loc loss 40.18037796020508\n",
      "cls loss 767.9383544921875  loc loss 57.0423583984375\n",
      "cls loss 645.0987548828125  loc loss 42.20256805419922\n",
      "cls loss 516.795166015625  loc loss 25.044811248779297\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21.])\n",
      "cls loss 396.3498840332031  loc loss 20.901580810546875\n",
      "cls loss 533.677490234375  loc loss 46.845245361328125\n",
      "cls loss 726.3104248046875  loc loss 56.1943473815918\n",
      "cls loss 467.90399169921875  loc loss 29.072525024414062\n",
      "cls loss 681.16845703125  loc loss 42.726806640625\n",
      "cls loss 1216.27001953125  loc loss 73.79590606689453\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 42., 42.,  1.,  1.])\n",
      "cls loss 617.0836181640625  loc loss 37.184326171875\n",
      "cls loss 425.815185546875  loc loss 30.024734497070312\n",
      "cls loss 555.3712158203125  loc loss 42.2928466796875\n",
      "cls loss 784.683349609375  loc loss 68.20166015625\n",
      "cls loss 521.1105346679688  loc loss 34.953365325927734\n",
      "cls loss 718.4098510742188  loc loss 56.0079231262207\n",
      "cls loss 705.9630126953125  loc loss 55.96722412109375\n",
      "cls loss 740.3555297851562  loc loss 46.76267623901367\n",
      "cls loss 598.515625  loc loss 38.67033386230469\n",
      "cls loss 518.311767578125  loc loss 34.13159942626953\n",
      "cls loss 438.589599609375  loc loss 20.712692260742188\n",
      "cls loss 535.62451171875  loc loss 40.94757080078125\n",
      "cls loss 781.711669921875  loc loss 70.53575134277344\n",
      "cls loss 634.46142578125  loc loss 41.70375061035156\n",
      "cls loss 665.1181030273438  loc loss 50.465538024902344\n",
      "cls loss 703.91845703125  loc loss 39.204322814941406\n",
      "cls loss 1041.8426513671875  loc loss 68.8519287109375\n",
      "cls loss 697.7135009765625  loc loss 55.998023986816406\n",
      "cls loss 827.486328125  loc loss 49.93837356567383\n",
      "cls loss 519.2822265625  loc loss 25.28021240234375\n",
      "cls loss 709.474365234375  loc loss 46.10750198364258\n",
      "cls loss 646.2728881835938  loc loss 44.70478820800781\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 5., 5., 5., 5., 5., 5.])\n",
      "cls loss 460.7853088378906  loc loss 32.21809387207031\n",
      "cls loss 540.813232421875  loc loss 36.9185676574707\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([13.])\n",
      "cls loss 379.09234619140625  loc loss 23.927265167236328\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([44., 10.,  1.,  1.,  1.])\n",
      "cls loss 404.9743347167969  loc loss 24.739864349365234\n",
      "cls loss 730.94580078125  loc loss 40.8125\n",
      "cls loss 584.881591796875  loc loss 34.97528839111328\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19., 19., 19., 19., 19., 19., 19.])\n",
      "cls loss 758.38916015625  loc loss 47.35149002075195\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([56.])\n",
      "cls loss 1350.430908203125  loc loss 83.22604370117188\n",
      "cls loss 702.8298950195312  loc loss 58.898704528808594\n",
      "cls loss 984.2247314453125  loc loss 74.2077407836914\n",
      "cls loss 928.05517578125  loc loss 76.17708587646484\n",
      "cls loss 582.297119140625  loc loss 38.479461669921875\n",
      "cls loss 968.7647094726562  loc loss 71.63341522216797\n",
      "cls loss 606.0437622070312  loc loss 34.0074462890625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 36.])\n",
      "cls loss 697.094482421875  loc loss 40.376461029052734\n",
      "cls loss 587.2440185546875  loc loss 44.571929931640625\n",
      "cls loss 675.4761962890625  loc loss 36.89911651611328\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5.])\n",
      "cls loss 651.197998046875  loc loss 43.62697982788086\n",
      "cls loss 399.4908447265625  loc loss 22.31667709350586\n",
      "cls loss 840.9125366210938  loc loss 53.394447326660156\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "cls loss 768.5697021484375  loc loss 56.3095703125\n",
      "cls loss 822.98486328125  loc loss 50.388275146484375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 698.6571655273438  loc loss 51.92932891845703\n",
      "cls loss 826.2559814453125  loc loss 61.08626174926758\n",
      "cls loss 705.139404296875  loc loss 63.30695343017578\n",
      "cls loss 503.8428955078125  loc loss 36.76117706298828\n",
      "cls loss 608.53125  loc loss 45.71508026123047\n",
      "cls loss 593.8226928710938  loc loss 42.2886962890625\n",
      "cls loss 924.5025634765625  loc loss 59.137657165527344\n",
      "cls loss 448.84326171875  loc loss 24.747257232666016\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 11., 15., 10., 10., 10., 10., 10.])\n",
      "cls loss 997.9537353515625  loc loss 74.7555923461914\n",
      "cls loss 581.0084838867188  loc loss 39.013427734375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3.])\n",
      "cls loss 665.9404907226562  loc loss 41.474369049072266\n",
      "cls loss 535.7574462890625  loc loss 33.80400848388672\n",
      "cls loss 599.360107421875  loc loss 32.15569305419922\n",
      "cls loss 779.7030639648438  loc loss 42.52783203125\n",
      "cls loss 478.3280334472656  loc loss 20.613798141479492\n",
      "cls loss 676.8008422851562  loc loss 37.38829040527344\n",
      "cls loss 692.876708984375  loc loss 52.47246551513672\n",
      "cls loss 588.8767700195312  loc loss 46.094024658203125\n",
      "cls loss 1273.00244140625  loc loss 105.0907211303711\n",
      "cls loss 926.9808349609375  loc loss 68.96534729003906\n",
      "cls loss 606.961181640625  loc loss 47.132266998291016\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  9.,  9.,  9.,  6.,  6., 85., 85.,  8.,  1.,  1.,  1.,  1.,\n",
      "         6.,  6.])\n",
      "cls loss 437.98309326171875  loc loss 31.1444091796875\n",
      "cls loss 975.3709106445312  loc loss 71.76084899902344\n",
      "cls loss 1140.094970703125  loc loss 77.79621887207031\n",
      "cls loss 785.95849609375  loc loss 58.69401168823242\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10.,  3.,  3., 10.])\n",
      "cls loss 506.40264892578125  loc loss 33.43144989013672\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([7.])\n",
      "cls loss 700.540283203125  loc loss 55.13740921020508\n",
      "cls loss 728.1974487304688  loc loss 44.541439056396484\n",
      "cls loss 670.1065673828125  loc loss 49.88267517089844\n",
      "cls loss 1007.784423828125  loc loss 72.68187713623047\n",
      "cls loss 747.6438598632812  loc loss 44.66548156738281\n",
      "cls loss 939.55126953125  loc loss 60.32686996459961\n",
      "cls loss 1065.037841796875  loc loss 70.34577178955078\n",
      "cls loss 687.531494140625  loc loss 47.01128387451172\n",
      "cls loss 685.0228271484375  loc loss 50.27736282348633\n",
      "cls loss 592.576171875  loc loss 45.40351867675781\n",
      "cls loss 806.726806640625  loc loss 69.6773910522461\n",
      "cls loss 696.4793701171875  loc loss 47.20973205566406\n",
      "cls loss 523.35400390625  loc loss 33.28471755981445\n",
      "cls loss 795.061279296875  loc loss 65.49714660644531\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([62.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([62.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 342.2112731933594  loc loss 21.996715545654297\n",
      "cls loss 633.5050048828125  loc loss 49.54424285888672\n",
      "cls loss 636.486083984375  loc loss 44.1113166809082\n",
      "cls loss 478.5221862792969  loc loss 21.358325958251953\n",
      "cls loss 813.7918701171875  loc loss 61.875328063964844\n",
      "cls loss 784.6263427734375  loc loss 51.153724670410156\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([28.])\n",
      "cls loss 878.999267578125  loc loss 51.83345031738281\n",
      "cls loss 818.0579833984375  loc loss 52.661170959472656\n",
      "cls loss 765.5537719726562  loc loss 51.38764190673828\n",
      "cls loss 805.6444702148438  loc loss 57.082096099853516\n",
      "cls loss 1093.34375  loc loss 78.59004974365234\n",
      "cls loss 616.3531494140625  loc loss 41.98368453979492\n",
      "cls loss 784.7783203125  loc loss 49.123531341552734\n",
      "cls loss 712.421142578125  loc loss 59.95270538330078\n",
      "cls loss 1121.857421875  loc loss 83.73421478271484\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([81.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 762.75390625  loc loss 37.05265808105469\n",
      "cls loss 603.9695434570312  loc loss 31.03972625732422\n",
      "cls loss 493.0780334472656  loc loss 32.66794204711914\n",
      "cls loss 423.09393310546875  loc loss 20.405345916748047\n",
      "cls loss 480.8261413574219  loc loss 31.653663635253906\n",
      "cls loss 503.90216064453125  loc loss 35.45441436767578\n",
      "cls loss 576.6185302734375  loc loss 37.73794937133789\n",
      "cls loss 757.408935546875  loc loss 62.96804428100586\n",
      "cls loss 834.109130859375  loc loss 57.42680358886719\n",
      "cls loss 1588.47705078125  loc loss 115.93716430664062\n",
      "cls loss 609.9813842773438  loc loss 33.749481201171875\n",
      "cls loss 735.8946533203125  loc loss 52.743160247802734\n",
      "cls loss 507.37188720703125  loc loss 37.877197265625\n",
      "cls loss 741.1246337890625  loc loss 41.24696350097656\n",
      "cls loss 709.751953125  loc loss 38.983394622802734\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([44., 44.])\n",
      "cls loss 588.6612548828125  loc loss 30.175701141357422\n",
      "cls loss 644.7900390625  loc loss 41.76796340942383\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15.])\n",
      "cls loss 742.8363037109375  loc loss 40.45332336425781\n",
      "cls loss 343.06536865234375  loc loss 19.516035079956055\n",
      "cls loss 689.486083984375  loc loss 43.990577697753906\n",
      "cls loss 384.995849609375  loc loss 25.612085342407227\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([1., 3., 3.])\n",
      "cls loss 419.66815185546875  loc loss 34.6688117980957\n",
      "cls loss 371.53656005859375  loc loss 16.993328094482422\n",
      "cls loss 664.14501953125  loc loss 38.6429557800293\n",
      "cls loss 683.411865234375  loc loss 41.90918731689453\n",
      "cls loss 631.157958984375  loc loss 41.120758056640625\n",
      "cls loss 611.2406005859375  loc loss 40.76808166503906\n",
      "cls loss 544.2620239257812  loc loss 40.949256896972656\n",
      "cls loss 660.6409912109375  loc loss 49.32695007324219\n",
      "cls loss 560.2115478515625  loc loss 38.13459396362305\n",
      "cls loss 670.1513061523438  loc loss 51.79814529418945\n",
      "cls loss 438.1878662109375  loc loss 27.703781127929688\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 808.471435546875  loc loss 50.965362548828125\n",
      "cls loss 908.947021484375  loc loss 51.736324310302734\n",
      "cls loss 828.4056396484375  loc loss 58.96928787231445\n",
      "cls loss 834.5965576171875  loc loss 57.90562057495117\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10., 10., 10.,  1.,  1.,  1.,  1.,  1.,  1.,  8.,  8.,\n",
      "         1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10., 10., 10.,  1.,  1.,  1.,  1.,  1.,  1.,  8.,  8.,\n",
      "         1.])\n",
      "cls loss 807.911865234375  loc loss 45.44013977050781\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 3., 3., 3.])\n",
      "cls loss 643.9381103515625  loc loss 42.09161376953125\n",
      "cls loss 460.7544250488281  loc loss 26.16718292236328\n",
      "cls loss 335.7659912109375  loc loss 20.299036026000977\n",
      "cls loss 616.0372314453125  loc loss 44.8416862487793\n",
      "cls loss 505.6351013183594  loc loss 26.432411193847656\n",
      "cls loss 555.403076171875  loc loss 37.84856033325195\n",
      "cls loss 631.1758422851562  loc loss 41.88018035888672\n",
      "cls loss 867.8875732421875  loc loss 62.54548645019531\n",
      "cls loss 712.8668212890625  loc loss 40.438873291015625\n",
      "cls loss 672.948974609375  loc loss 44.10893630981445\n",
      "cls loss 773.3961791992188  loc loss 54.20963668823242\n",
      "cls loss 604.6179809570312  loc loss 44.72586441040039\n",
      "cls loss 967.0181884765625  loc loss 81.03804016113281\n",
      "cls loss 540.3444213867188  loc loss 31.349170684814453\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 764.5357055664062  loc loss 50.329593658447266\n",
      "cls loss 408.09197998046875  loc loss 20.383041381835938\n",
      "cls loss 1033.4122314453125  loc loss 68.19483947753906\n",
      "cls loss 527.2403564453125  loc loss 29.462926864624023\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 34.])\n",
      "cls loss 797.2901611328125  loc loss 45.421085357666016\n",
      "cls loss 414.1346435546875  loc loss 26.799808502197266\n",
      "cls loss 747.9251098632812  loc loss 48.83222961425781\n",
      "cls loss 286.82720947265625  loc loss 18.972827911376953\n",
      "cls loss 694.8194580078125  loc loss 46.39786148071289\n",
      "cls loss 635.407958984375  loc loss 48.45705795288086\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 38.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16., 16., 16.,  9.,  9.,  9., 16., 16., 16., 85.,  9.])\n",
      "cls loss 600.7154541015625  loc loss 40.118995666503906\n",
      "cls loss 678.9757080078125  loc loss 57.40986633300781\n",
      "cls loss 1002.3609008789062  loc loss 75.11762237548828\n",
      "cls loss 1340.0367431640625  loc loss 99.78832244873047\n",
      "cls loss 414.9930114746094  loc loss 22.075490951538086\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3., 10.,  8.,  8., 10., 10., 10.,  3.,  3., 14.])\n",
      "cls loss 528.1043090820312  loc loss 26.11042594909668\n",
      "cls loss 830.1463623046875  loc loss 48.95099639892578\n",
      "cls loss 349.65618896484375  loc loss 15.516609191894531\n",
      "cls loss 557.159912109375  loc loss 27.65778350830078\n",
      "cls loss 905.8658447265625  loc loss 49.716575622558594\n",
      "cls loss 712.5961303710938  loc loss 47.689300537109375\n",
      "cls loss 438.60125732421875  loc loss 23.258134841918945\n",
      "cls loss 480.18878173828125  loc loss 29.012939453125\n",
      "cls loss 686.8824462890625  loc loss 45.33635330200195\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42., 42.,  1.])\n",
      "cls loss 641.31103515625  loc loss 46.450721740722656\n",
      "cls loss 575.91943359375  loc loss 34.33278274536133\n",
      "cls loss 726.9451904296875  loc loss 56.649478912353516\n",
      "cls loss 786.1541748046875  loc loss 56.068336486816406\n",
      "cls loss 581.2171630859375  loc loss 37.32537841796875\n",
      "cls loss 686.776123046875  loc loss 51.45466613769531\n",
      "cls loss 452.8970642089844  loc loss 30.13311004638672\n",
      "cls loss 503.34405517578125  loc loss 34.21709442138672\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20.])\n",
      "cls loss 363.74603271484375  loc loss 23.235321044921875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([11.])\n",
      "cls loss 464.68438720703125  loc loss 26.675493240356445\n",
      "cls loss 326.978759765625  loc loss 20.805253982543945\n",
      "cls loss 692.5706787109375  loc loss 62.577186584472656\n",
      "cls loss 343.3948974609375  loc loss 17.442541122436523\n",
      "cls loss 662.1636352539062  loc loss 44.07958984375\n",
      "cls loss 408.82000732421875  loc loss 23.63715362548828\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 35., 27.])\n",
      "cls loss 659.917236328125  loc loss 44.00874710083008\n",
      "cls loss 657.0594482421875  loc loss 57.40583038330078\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 527.5119018554688  loc loss 35.00275802612305\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([42.,  1.])\n",
      "cls loss 683.2816162109375  loc loss 53.784202575683594\n",
      "cls loss 639.8204956054688  loc loss 37.29149627685547\n",
      "cls loss 822.7510375976562  loc loss 42.34029006958008\n",
      "cls loss 915.3038330078125  loc loss 60.04778289794922\n",
      "cls loss 785.712158203125  loc loss 54.22071075439453\n",
      "cls loss 516.684814453125  loc loss 42.447044372558594\n",
      "cls loss 460.57318115234375  loc loss 36.266212463378906\n",
      "cls loss 321.5858154296875  loc loss 15.784429550170898\n",
      "cls loss 545.8040771484375  loc loss 33.86810302734375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 1., 1.])\n",
      "cls loss 498.0347595214844  loc loss 30.605459213256836\n",
      "cls loss 554.578125  loc loss 44.99464797973633\n",
      "cls loss 561.8609619140625  loc loss 39.31731033325195\n",
      "cls loss 477.888671875  loc loss 36.758033752441406\n",
      "cls loss 570.6903076171875  loc loss 38.46019744873047\n",
      "cls loss 607.4234008789062  loc loss 47.946075439453125\n",
      "cls loss 870.6611328125  loc loss 53.30698013305664\n",
      "cls loss 781.80517578125  loc loss 59.797245025634766\n",
      "cls loss 715.058837890625  loc loss 42.8427734375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 545.9688720703125  loc loss 41.16050720214844\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 661.4127197265625  loc loss 32.04121780395508\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([81.])\n",
      "cls loss 788.8701171875  loc loss 52.6708984375\n",
      "cls loss 490.815673828125  loc loss 33.80674362182617\n",
      "cls loss 381.9219970703125  loc loss 23.5492000579834\n",
      "cls loss 523.0396728515625  loc loss 27.57817268371582\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3.,  1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 19.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 19.])\n",
      "cls loss 710.5428466796875  loc loss 50.08778381347656\n",
      "cls loss 407.25360107421875  loc loss 20.404197692871094\n",
      "cls loss 410.0685729980469  loc loss 27.259225845336914\n",
      "cls loss 808.038818359375  loc loss 62.8056755065918\n",
      "cls loss 440.48486328125  loc loss 28.019678115844727\n",
      "cls loss 500.5484619140625  loc loss 39.12640380859375\n",
      "cls loss 614.579345703125  loc loss 45.75946807861328\n",
      "cls loss 476.6623229980469  loc loss 39.03630447387695\n",
      "cls loss 654.6699829101562  loc loss 41.289772033691406\n",
      "cls loss 727.4110107421875  loc loss 53.6077880859375\n",
      "cls loss 900.6229248046875  loc loss 82.12692260742188\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 81.])\n",
      "cls loss 634.4964599609375  loc loss 36.78889465332031\n",
      "cls loss 620.5560913085938  loc loss 33.79196548461914\n",
      "cls loss 653.1243896484375  loc loss 37.14528274536133\n",
      "cls loss 477.4154052734375  loc loss 24.05621910095215\n",
      "cls loss 469.73370361328125  loc loss 27.784770965576172\n",
      "cls loss 557.3529052734375  loc loss 37.251766204833984\n",
      "cls loss 424.82012939453125  loc loss 28.971092224121094\n",
      "cls loss 328.4859924316406  loc loss 23.477401733398438\n",
      "cls loss 424.1368103027344  loc loss 31.770774841308594\n",
      "cls loss 606.0177001953125  loc loss 39.44781494140625\n",
      "cls loss 497.1202087402344  loc loss 39.28915786743164\n",
      "cls loss 527.57666015625  loc loss 41.943260192871094\n",
      "cls loss 311.1409606933594  loc loss 24.47702407836914\n",
      "cls loss 1047.05908203125  loc loss 79.20307922363281\n",
      "cls loss 698.7450561523438  loc loss 51.15875244140625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 584.4682006835938  loc loss 35.06047821044922\n",
      "cls loss 643.248046875  loc loss 45.86546325683594\n",
      "cls loss 519.029052734375  loc loss 30.601804733276367\n",
      "cls loss 739.1372680664062  loc loss 47.07689666748047\n",
      "cls loss 726.4586181640625  loc loss 47.896366119384766\n",
      "cls loss 659.2489624023438  loc loss 41.51537322998047\n",
      "cls loss 579.1165771484375  loc loss 30.27630615234375\n",
      "cls loss 431.1266174316406  loc loss 24.71379852294922\n",
      "cls loss 574.655029296875  loc loss 38.55512619018555\n",
      "cls loss 597.1300048828125  loc loss 45.64498519897461\n",
      "cls loss 663.3451538085938  loc loss 37.645164489746094\n",
      "cls loss 810.5940551757812  loc loss 63.7213020324707\n",
      "cls loss 874.533935546875  loc loss 64.37835693359375\n",
      "cls loss 583.4832153320312  loc loss 42.75517654418945\n",
      "cls loss 742.6065673828125  loc loss 63.352882385253906\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1., 38., 47.,  1.,  1.,  1.,  1.,  1., 62.])\n",
      "cls loss 520.8233642578125  loc loss 32.66654586791992\n",
      "cls loss 656.5206298828125  loc loss 41.443214416503906\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 712.7086181640625  loc loss 45.41264724731445\n",
      "cls loss 831.4415893554688  loc loss 59.99615478515625\n",
      "cls loss 558.5296020507812  loc loss 29.470869064331055\n",
      "cls loss 599.111572265625  loc loss 49.99147033691406\n",
      "cls loss 572.8194580078125  loc loss 38.60005187988281\n",
      "cls loss 373.8780822753906  loc loss 16.478248596191406\n",
      "cls loss 554.9149780273438  loc loss 34.0876350402832\n",
      "cls loss 475.23583984375  loc loss 24.147233963012695\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1., 35.])\n",
      "cls loss 536.87060546875  loc loss 29.380077362060547\n",
      "cls loss 806.1021728515625  loc loss 45.42023468017578\n",
      "cls loss 747.12255859375  loc loss 51.14958572387695\n",
      "cls loss 685.4181518554688  loc loss 57.116844177246094\n",
      "cls loss 558.5321044921875  loc loss 45.28787612915039\n",
      "cls loss 681.1295166015625  loc loss 52.87533950805664\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 394.82568359375  loc loss 24.82569694519043\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 607.4007568359375  loc loss 30.91838264465332\n",
      "cls loss 944.3215942382812  loc loss 56.38431930541992\n",
      "cls loss 1104.19873046875  loc loss 85.71720886230469\n",
      "cls loss 582.584716796875  loc loss 32.89324188232422\n",
      "cls loss 502.9720764160156  loc loss 31.446470260620117\n",
      "cls loss 510.18145751953125  loc loss 32.96106719970703\n",
      "cls loss 566.5436401367188  loc loss 46.619972229003906\n",
      "cls loss 572.8370361328125  loc loss 22.672935485839844\n",
      "cls loss 873.038818359375  loc loss 67.12947082519531\n",
      "cls loss 707.6004638671875  loc loss 44.30176544189453\n",
      "cls loss 444.9272766113281  loc loss 25.657812118530273\n",
      "cls loss 755.3507080078125  loc loss 41.74730682373047\n",
      "cls loss 873.0487060546875  loc loss 66.52872467041016\n",
      "cls loss 680.17041015625  loc loss 45.66797637939453\n",
      "cls loss 621.7113037109375  loc loss 35.78866958618164\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.])\n",
      "cls loss 596.4880981445312  loc loss 44.39044189453125\n",
      "cls loss 490.01422119140625  loc loss 40.65530014038086\n",
      "cls loss 757.984375  loc loss 48.96159744262695\n",
      "cls loss 1017.5459594726562  loc loss 89.20343017578125\n",
      "cls loss 476.0185546875  loc loss 23.906578063964844\n",
      "cls loss 558.8898315429688  loc loss 38.0551643371582\n",
      "cls loss 482.50042724609375  loc loss 30.510080337524414\n",
      "cls loss 539.6470947265625  loc loss 34.50135040283203\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 21., 21., 21.])\n",
      "cls loss 600.8779296875  loc loss 34.36488342285156\n",
      "cls loss 539.0728149414062  loc loss 26.302078247070312\n",
      "cls loss 565.092529296875  loc loss 38.135963439941406\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 35.])\n",
      "cls loss 847.6259765625  loc loss 58.0436897277832\n",
      "cls loss 290.4534912109375  loc loss 15.820229530334473\n",
      "cls loss 444.88934326171875  loc loss 30.550901412963867\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 438.52197265625  loc loss 26.348453521728516\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 38., 38.,  9., 38.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1.,  1.])\n",
      "cls loss 483.18994140625  loc loss 37.534141540527344\n",
      "cls loss 785.5009765625  loc loss 57.86838912963867\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 2.,  1., 77., 31., 10., 10.,  1.,  4., 10.])\n",
      "cls loss 449.8691101074219  loc loss 22.479053497314453\n",
      "cls loss 776.0606689453125  loc loss 49.573028564453125\n",
      "cls loss 1466.277099609375  loc loss 107.16864013671875\n",
      "cls loss 511.54974365234375  loc loss 32.779964447021484\n",
      "cls loss 667.248779296875  loc loss 57.24378967285156\n",
      "cls loss 497.305908203125  loc loss 32.200096130371094\n",
      "cls loss 511.58074951171875  loc loss 27.4268798828125\n",
      "cls loss 858.7350463867188  loc loss 36.27936553955078\n",
      "cls loss 725.434814453125  loc loss 42.902183532714844\n",
      "cls loss 661.0155639648438  loc loss 47.10150909423828\n",
      "cls loss 504.14556884765625  loc loss 26.48457908630371\n",
      "cls loss 599.1739501953125  loc loss 29.518939971923828\n",
      "cls loss 1088.328125  loc loss 66.24842071533203\n",
      "cls loss 869.7927856445312  loc loss 60.10203552246094\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1., 42., 42., 42., 42., 42., 42.,  1.,\n",
      "         1.,  1.,  1., 42.,  1.,  1., 42.,  1.])\n",
      "cls loss 513.2796630859375  loc loss 36.86505889892578\n",
      "cls loss 733.1021728515625  loc loss 48.733577728271484\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.])\n",
      "cls loss 347.23553466796875  loc loss 23.67426872253418\n",
      "cls loss 695.1903076171875  loc loss 51.78190612792969\n",
      "cls loss 557.5829467773438  loc loss 43.07177734375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([11.])\n",
      "cls loss 347.13861083984375  loc loss 20.23371124267578\n",
      "cls loss 455.28240966796875  loc loss 22.222856521606445\n",
      "cls loss 457.2075500488281  loc loss 24.718250274658203\n",
      "cls loss 644.590576171875  loc loss 47.13198471069336\n",
      "cls loss 625.04736328125  loc loss 39.255645751953125\n",
      "cls loss 610.0214233398438  loc loss 48.31820297241211\n",
      "cls loss 878.19970703125  loc loss 52.658287048339844\n",
      "cls loss 492.76361083984375  loc loss 31.611793518066406\n",
      "cls loss 884.1397705078125  loc loss 70.74530029296875\n",
      "cls loss 537.5032958984375  loc loss 29.222442626953125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 475.5218811035156  loc loss 32.4981689453125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1., 38., 38., 42.])\n",
      "cls loss 616.9298095703125  loc loss 43.704593658447266\n",
      "cls loss 577.8764038085938  loc loss 28.708221435546875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 453.89385986328125  loc loss 32.6292724609375\n",
      "cls loss 1008.7332763671875  loc loss 74.58843994140625\n",
      "cls loss 593.9496459960938  loc loss 45.88916778564453\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10.,  3.,  3.,  6.,  8.,  8.,  1.,  1.,  1., 10.])\n",
      "cls loss 530.6456298828125  loc loss 34.0695686340332\n",
      "cls loss 311.1265869140625  loc loss 13.222827911376953\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10.,  3.])\n",
      "cls loss 500.58575439453125  loc loss 29.44028091430664\n",
      "cls loss 326.3324890136719  loc loss 15.61690902709961\n",
      "cls loss 564.3558349609375  loc loss 48.84327697753906\n",
      "cls loss 628.77587890625  loc loss 48.170654296875\n",
      "cls loss 491.1206970214844  loc loss 31.864919662475586\n",
      "cls loss 378.4615783691406  loc loss 19.112337112426758\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 34.])\n",
      "cls loss 880.9287719726562  loc loss 54.47491455078125\n",
      "cls loss 898.759033203125  loc loss 77.7142105102539\n",
      "cls loss 604.8975830078125  loc loss 50.27149200439453\n",
      "cls loss 449.76971435546875  loc loss 33.378013610839844\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.,  1.])\n",
      "cls loss 518.7515258789062  loc loss 28.580707550048828\n",
      "cls loss 811.9817504882812  loc loss 65.37217712402344\n",
      "cls loss 1179.65087890625  loc loss 81.83931732177734\n",
      "cls loss 1003.9313354492188  loc loss 55.684967041015625\n",
      "cls loss 598.8523559570312  loc loss 34.81621551513672\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 774.2356567382812  loc loss 42.327362060546875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10.])\n",
      "cls loss 447.1995849609375  loc loss 25.748811721801758\n",
      "cls loss 625.1658325195312  loc loss 33.790252685546875\n",
      "cls loss 602.0082397460938  loc loss 34.52712631225586\n",
      "cls loss 414.6598205566406  loc loss 26.6948184967041\n",
      "cls loss 509.0587463378906  loc loss 39.903656005859375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21.,\n",
      "        21.])\n",
      "cls loss 694.5848388671875  loc loss 44.82499313354492\n",
      "cls loss 576.5184936523438  loc loss 43.275150299072266\n",
      "cls loss 385.23382568359375  loc loss 18.393341064453125\n",
      "cls loss 774.51611328125  loc loss 53.13268280029297\n",
      "cls loss 608.9193115234375  loc loss 45.86993408203125\n",
      "cls loss 433.2275695800781  loc loss 29.948749542236328\n",
      "cls loss 914.8970336914062  loc loss 69.4520492553711\n",
      "cls loss 1098.028076171875  loc loss 78.68095397949219\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15., 85.])\n",
      "cls loss 743.375244140625  loc loss 47.13774871826172\n",
      "cls loss 686.8082275390625  loc loss 55.76966857910156\n",
      "cls loss 778.0188598632812  loc loss 53.540306091308594\n",
      "cls loss 664.5692138671875  loc loss 40.55966567993164\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 8., 8.])\n",
      "cls loss 422.13690185546875  loc loss 22.750431060791016\n",
      "cls loss 507.8591003417969  loc loss 31.818687438964844\n",
      "cls loss 565.3803100585938  loc loss 35.035987854003906\n",
      "cls loss 477.23956298828125  loc loss 27.795392990112305\n",
      "cls loss 547.2927856445312  loc loss 35.212860107421875\n",
      "cls loss 710.12158203125  loc loss 44.59000015258789\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1., 35., 27., 27.,  1., 27.,  1.])\n",
      "cls loss 1016.049072265625  loc loss 70.0339126586914\n",
      "cls loss 455.68896484375  loc loss 35.349586486816406\n",
      "cls loss 562.6011962890625  loc loss 43.2317008972168\n",
      "cls loss 528.05859375  loc loss 47.41246795654297\n",
      "cls loss 526.7059326171875  loc loss 39.83340072631836\n",
      "cls loss 534.9783325195312  loc loss 43.98891830444336\n",
      "cls loss 532.905517578125  loc loss 43.746517181396484\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  2.,  2.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  2.,  2.])\n",
      "cls loss 369.5753173828125  loc loss 14.7155179977417\n",
      "cls loss 803.6741943359375  loc loss 51.7436408996582\n",
      "cls loss 588.3859252929688  loc loss 31.159461975097656\n",
      "cls loss 957.41552734375  loc loss 68.76502227783203\n",
      "cls loss 406.0838317871094  loc loss 25.79486846923828\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 19., 19., 19., 16.])\n",
      "cls loss 412.1125793457031  loc loss 20.478675842285156\n",
      "cls loss 325.90966796875  loc loss 16.45825958251953\n",
      "cls loss 485.60809326171875  loc loss 26.453205108642578\n",
      "cls loss 634.930419921875  loc loss 43.67612838745117\n",
      "cls loss 330.62890625  loc loss 26.523706436157227\n",
      "cls loss 742.255859375  loc loss 54.225399017333984\n",
      "cls loss 511.77362060546875  loc loss 39.49053955078125\n",
      "cls loss 551.7611083984375  loc loss 40.04286193847656\n",
      "cls loss 680.6285400390625  loc loss 52.70591354370117\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 779.466796875  loc loss 39.03981399536133\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 995.427490234375  loc loss 87.23470306396484\n",
      "cls loss 1244.0987548828125  loc loss 126.10120391845703\n",
      "cls loss 605.416259765625  loc loss 47.57558822631836\n",
      "cls loss 579.5739135742188  loc loss 40.50818634033203\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3.,  3.,  3.,  3.,  3., 10.])\n",
      "cls loss 354.5225524902344  loc loss 17.75887107849121\n",
      "cls loss 675.641357421875  loc loss 37.16000747680664\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 1., 1., 1., 3., 3., 3., 3.])\n",
      "cls loss 556.4146118164062  loc loss 36.5723876953125\n",
      "cls loss 946.0895385742188  loc loss 69.66874694824219\n",
      "cls loss 772.801513671875  loc loss 53.63053894042969\n",
      "cls loss 578.8116455078125  loc loss 31.315799713134766\n",
      "cls loss 749.7178344726562  loc loss 59.81803512573242\n",
      "cls loss 480.1302490234375  loc loss 37.83112716674805\n",
      "cls loss 736.1647338867188  loc loss 55.7037467956543\n",
      "cls loss 576.8509521484375  loc loss 50.21609115600586\n",
      "cls loss 539.2259521484375  loc loss 40.3106575012207\n",
      "cls loss 1171.329833984375  loc loss 100.09992980957031\n",
      "cls loss 750.5162353515625  loc loss 54.61371994018555\n",
      "cls loss 505.052734375  loc loss 27.142324447631836\n",
      "cls loss 333.8380432128906  loc loss 16.73937225341797\n",
      "cls loss 390.9833984375  loc loss 23.200878143310547\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3., 10., 10., 10., 10., 10., 10., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10., 10., 10., 10., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 11., 10., 10., 10., 10., 10.,  3.,  3.,  3.,  3.,  3.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 11., 10., 10., 10., 10., 10.,  3.,  3.,  3.,  3.,  3.])\n",
      "cls loss 381.6207275390625  loc loss 20.131145477294922\n",
      "cls loss 503.6226806640625  loc loss 25.066028594970703\n",
      "cls loss 420.1666259765625  loc loss 26.254117965698242\n",
      "cls loss 399.615966796875  loc loss 17.774078369140625\n",
      "cls loss 491.94842529296875  loc loss 37.53033447265625\n",
      "cls loss 444.12457275390625  loc loss 17.156354904174805\n",
      "cls loss 710.8284912109375  loc loss 50.769447326660156\n",
      "cls loss 627.1568603515625  loc loss 47.351112365722656\n",
      "cls loss 934.1080322265625  loc loss 64.59182739257812\n",
      "cls loss 462.7361145019531  loc loss 35.977909088134766\n",
      "cls loss 821.8588256835938  loc loss 58.08049392700195\n",
      "cls loss 669.2288818359375  loc loss 48.88663864135742\n",
      "cls loss 625.2566528320312  loc loss 44.00678634643555\n",
      "cls loss 634.0841064453125  loc loss 50.05577087402344\n",
      "cls loss 863.4793701171875  loc loss 61.1977653503418\n",
      "cls loss 834.3497314453125  loc loss 54.192962646484375\n",
      "cls loss 419.830810546875  loc loss 24.75075340270996\n",
      "cls loss 716.6142578125  loc loss 58.105751037597656\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 10.,  1., 18.])\n",
      "cls loss 386.45709228515625  loc loss 27.08162498474121\n",
      "cls loss 434.60565185546875  loc loss 19.163631439208984\n",
      "cls loss 771.4254150390625  loc loss 39.32905960083008\n",
      "cls loss 1031.1707763671875  loc loss 72.7819595336914\n",
      "cls loss 661.9065551757812  loc loss 45.245338439941406\n",
      "cls loss 875.0068359375  loc loss 55.675270080566406\n",
      "cls loss 609.211669921875  loc loss 43.0333251953125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.,  1.,  1.])\n",
      "cls loss 805.379638671875  loc loss 55.386436462402344\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1., 38.,  1.])\n",
      "cls loss 769.29052734375  loc loss 46.216129302978516\n",
      "cls loss 975.14501953125  loc loss 75.85433959960938\n",
      "cls loss 485.0741882324219  loc loss 39.40523147583008\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 655.850830078125  loc loss 48.938331604003906\n",
      "cls loss 580.9525756835938  loc loss 42.0121955871582\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3., 10.,  8.,  3., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 709.3570556640625  loc loss 47.63737487792969\n",
      "cls loss 495.0438232421875  loc loss 33.364288330078125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3.,  3., 11.,  3., 10., 10.,  3.,  3., 10.])\n",
      "cls loss 586.5701904296875  loc loss 31.38848876953125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3., 10., 10., 10.])\n",
      "cls loss 579.46435546875  loc loss 44.06204605102539\n",
      "cls loss 494.25018310546875  loc loss 29.586448669433594\n",
      "cls loss 623.154296875  loc loss 47.11064147949219\n",
      "cls loss 1025.393798828125  loc loss 61.33970642089844\n",
      "cls loss 618.7554931640625  loc loss 42.4193229675293\n",
      "cls loss 440.4377746582031  loc loss 38.59778594970703\n",
      "cls loss 540.580322265625  loc loss 40.11988067626953\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 9.,  9., 85., 85.])\n",
      "cls loss 510.2162170410156  loc loss 28.796939849853516\n",
      "cls loss 554.5319213867188  loc loss 38.552730560302734\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 909.2077026367188  loc loss 71.11550903320312\n",
      "cls loss 765.3684692382812  loc loss 42.137901306152344\n",
      "cls loss 867.32861328125  loc loss 63.88357162475586\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10., 10., 10., 10.])\n",
      "cls loss 564.9017944335938  loc loss 35.63140869140625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([13.])\n",
      "cls loss 897.583740234375  loc loss 72.6731948852539\n",
      "cls loss 323.10833740234375  loc loss 18.5289306640625\n",
      "cls loss 383.15057373046875  loc loss 22.047922134399414\n",
      "cls loss 547.323974609375  loc loss 31.379228591918945\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19.,  1.,  1.,  1., 19., 19.])\n",
      "cls loss 565.8848876953125  loc loss 37.025875091552734\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 404.06884765625  loc loss 38.124664306640625\n",
      "cls loss 671.54931640625  loc loss 49.91025924682617\n",
      "cls loss 462.0226135253906  loc loss 29.427696228027344\n",
      "cls loss 697.0887451171875  loc loss 45.321956634521484\n",
      "cls loss 753.2437133789062  loc loss 58.46013259887695\n",
      "cls loss 612.066162109375  loc loss 34.1590576171875\n",
      "cls loss 825.3255004882812  loc loss 64.08187866210938\n",
      "cls loss 378.76397705078125  loc loss 17.205068588256836\n",
      "cls loss 595.868896484375  loc loss 40.450740814208984\n",
      "cls loss 485.32830810546875  loc loss 26.024084091186523\n",
      "cls loss 487.7783203125  loc loss 29.455467224121094\n",
      "cls loss 631.1683959960938  loc loss 49.345760345458984\n",
      "cls loss 607.8690795898438  loc loss 37.984764099121094\n",
      "cls loss 879.6004638671875  loc loss 58.28057098388672\n",
      "cls loss 542.1287841796875  loc loss 40.06243133544922\n",
      "cls loss 667.1024169921875  loc loss 48.69792938232422\n",
      "cls loss 969.6380615234375  loc loss 67.30205535888672\n",
      "cls loss 571.716552734375  loc loss 45.65631866455078\n",
      "cls loss 647.083984375  loc loss 40.86698532104492\n",
      "cls loss 827.9312744140625  loc loss 61.035152435302734\n",
      "cls loss 812.702392578125  loc loss 60.554813385009766\n",
      "cls loss 1038.6171875  loc loss 61.166099548339844\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 5.])\n",
      "cls loss 333.5285949707031  loc loss 12.055480003356934\n",
      "cls loss 414.22125244140625  loc loss 18.442859649658203\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 13.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 6., 8., 8.])\n",
      "cls loss 390.68695068359375  loc loss 17.462724685668945\n",
      "cls loss 420.95880126953125  loc loss 24.73438262939453\n",
      "cls loss 792.0816650390625  loc loss 59.14924240112305\n",
      "cls loss 361.49993896484375  loc loss 18.30258560180664\n",
      "cls loss 632.3663330078125  loc loss 49.21505355834961\n",
      "cls loss 979.1417846679688  loc loss 69.1706314086914\n",
      "cls loss 581.7677001953125  loc loss 46.15730667114258\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([42., 42.,  1.,  1.,  1.,  1.,  1.,  1.,  1., 42., 42.])\n",
      "cls loss 634.4576416015625  loc loss 41.73017883300781\n",
      "cls loss 847.254638671875  loc loss 68.27210235595703\n",
      "cls loss 657.8342895507812  loc loss 57.88139343261719\n",
      "cls loss 492.47393798828125  loc loss 30.53139877319336\n",
      "cls loss 667.1004638671875  loc loss 43.38353729248047\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 922.580322265625  loc loss 61.46241760253906\n",
      "cls loss 716.7666015625  loc loss 54.22060012817383\n",
      "cls loss 478.71978759765625  loc loss 29.844043731689453\n",
      "cls loss 422.68695068359375  loc loss 21.30672836303711\n",
      "cls loss 565.26708984375  loc loss 35.2392692565918\n",
      "cls loss 746.8983154296875  loc loss 51.49173355102539\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15.])\n",
      "cls loss 358.0763244628906  loc loss 19.426183700561523\n",
      "cls loss 578.5595703125  loc loss 39.563629150390625\n",
      "cls loss 513.498046875  loc loss 35.566810607910156\n",
      "cls loss 901.9607543945312  loc loss 66.66067504882812\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19.,  7.])\n",
      "cls loss 524.181396484375  loc loss 34.311973571777344\n",
      "cls loss 1066.3109130859375  loc loss 68.47327423095703\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 893.4658203125  loc loss 51.3239860534668\n",
      "cls loss 674.0093994140625  loc loss 55.01343536376953\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([38., 38.,  1., 18.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1., 18., 18.,  1.])\n",
      "cls loss 560.5003662109375  loc loss 30.747520446777344\n",
      "cls loss 532.466064453125  loc loss 27.006057739257812\n",
      "cls loss 893.3779296875  loc loss 74.55028533935547\n",
      "cls loss 696.928466796875  loc loss 43.46858215332031\n",
      "cls loss 711.779541015625  loc loss 36.69541931152344\n",
      "cls loss 385.50933837890625  loc loss 30.457489013671875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.])\n",
      "cls loss 317.52130126953125  loc loss 12.081365585327148\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([32.])\n",
      "cls loss 623.5543212890625  loc loss 31.61978530883789\n",
      "cls loss 538.6922607421875  loc loss 37.115692138671875\n",
      "cls loss 713.702392578125  loc loss 59.433197021484375\n",
      "cls loss 684.1544189453125  loc loss 42.154361724853516\n",
      "cls loss 546.5396118164062  loc loss 36.087459564208984\n",
      "cls loss 843.2432861328125  loc loss 52.75809860229492\n",
      "cls loss 870.305908203125  loc loss 63.54547119140625\n",
      "cls loss 709.3355712890625  loc loss 49.883052825927734\n",
      "cls loss 597.7945556640625  loc loss 36.88898849487305\n",
      "cls loss 949.9889526367188  loc loss 61.542633056640625\n",
      "cls loss 565.4644775390625  loc loss 31.848745346069336\n",
      "cls loss 884.31787109375  loc loss 77.76921844482422\n",
      "cls loss 668.778564453125  loc loss 41.85626983642578\n",
      "cls loss 559.1451416015625  loc loss 41.82405090332031\n",
      "cls loss 435.0547180175781  loc loss 25.146778106689453\n",
      "cls loss 457.5001220703125  loc loss 31.71219825744629\n",
      "cls loss 696.8876953125  loc loss 49.72542953491211\n",
      "cls loss 721.34716796875  loc loss 55.001068115234375\n",
      "cls loss 427.8473205566406  loc loss 30.551952362060547\n",
      "cls loss 809.37060546875  loc loss 55.51863479614258\n",
      "cls loss 951.0460205078125  loc loss 59.939239501953125\n",
      "cls loss 361.3381042480469  loc loss 25.284399032592773\n",
      "cls loss 910.9237060546875  loc loss 63.8156852722168\n",
      "cls loss 659.6441650390625  loc loss 50.93886184692383\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 890.32861328125  loc loss 70.83113861083984\n",
      "cls loss 448.88958740234375  loc loss 18.651599884033203\n",
      "cls loss 667.2662963867188  loc loss 38.59855651855469\n",
      "cls loss 652.1395874023438  loc loss 46.463905334472656\n",
      "cls loss 508.8851013183594  loc loss 32.26741027832031\n",
      "cls loss 327.7566833496094  loc loss 17.054494857788086\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 9., 9., 1., 9., 9., 9., 9., 1., 9.])\n",
      "cls loss 1140.515869140625  loc loss 100.40265655517578\n",
      "cls loss 678.0252685546875  loc loss 37.36298751831055\n",
      "cls loss 988.5390014648438  loc loss 84.48810577392578\n",
      "cls loss 429.64581298828125  loc loss 28.945812225341797\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 42., 42.])\n",
      "cls loss 701.9345092773438  loc loss 54.365379333496094\n",
      "cls loss 749.24853515625  loc loss 55.70343017578125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  2.,  1.,  1.,  1., 38.,\n",
      "         1.,  1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 38., 38., 38.,  1., 38., 38., 38.,  1.,  1., 38.,  1.,\n",
      "         1.])\n",
      "cls loss 492.4491271972656  loc loss 32.78422927856445\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  8.,  8.])\n",
      "cls loss 1033.533935546875  loc loss 72.32830810546875\n",
      "cls loss 1043.358154296875  loc loss 74.67008972167969\n",
      "cls loss 426.01654052734375  loc loss 25.980228424072266\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([4., 1., 1., 4.])\n",
      "cls loss 599.1864013671875  loc loss 44.184818267822266\n",
      "cls loss 711.9697265625  loc loss 46.17744445800781\n",
      "cls loss 336.79864501953125  loc loss 16.148929595947266\n",
      "cls loss 454.41693115234375  loc loss 27.80319595336914\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([51.,  1.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 329.53814697265625  loc loss 14.865055084228516\n",
      "cls loss 418.5834045410156  loc loss 26.980693817138672\n",
      "cls loss 759.29443359375  loc loss 47.63105010986328\n",
      "cls loss 843.7508544921875  loc loss 65.43689727783203\n",
      "cls loss 1128.8450927734375  loc loss 67.45406341552734\n",
      "cls loss 1412.71923828125  loc loss 95.96427917480469\n",
      "cls loss 590.8505859375  loc loss 39.02703094482422\n",
      "cls loss 835.8104248046875  loc loss 60.025779724121094\n",
      "cls loss 881.8477783203125  loc loss 65.94966125488281\n",
      "cls loss 675.5814208984375  loc loss 39.90039825439453\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  3.,  1.,  1.,  1.,  3.,  1.,  1.,\n",
      "         1.,  1.,  1.])\n",
      "cls loss 751.3172607421875  loc loss 40.32342529296875\n",
      "cls loss 876.778564453125  loc loss 43.257606506347656\n",
      "cls loss 763.6328125  loc loss 39.6535530090332\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "cls loss 605.1957397460938  loc loss 37.26613235473633\n",
      "cls loss 365.14501953125  loc loss 29.667816162109375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3.])\n",
      "cls loss 347.24041748046875  loc loss 15.177511215209961\n",
      "cls loss 543.2876586914062  loc loss 40.83464050292969\n",
      "cls loss 438.92449951171875  loc loss 33.56385803222656\n",
      "cls loss 780.9029541015625  loc loss 58.03377151489258\n",
      "cls loss 544.4773559570312  loc loss 27.23666763305664\n",
      "cls loss 437.880615234375  loc loss 31.095317840576172\n",
      "cls loss 1333.954833984375  loc loss 92.73063659667969\n",
      "cls loss 563.555419921875  loc loss 43.90321731567383\n",
      "cls loss 405.5068359375  loc loss 35.414398193359375\n",
      "cls loss 543.11474609375  loc loss 34.187862396240234\n",
      "cls loss 468.73681640625  loc loss 36.50579833984375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 855.9571533203125  loc loss 62.62424850463867\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  9., 64., 64., 64., 64., 64., 64., 64., 64., 64.,  9.,  9.,  9.,\n",
      "         9.])\n",
      "cls loss 498.32464599609375  loc loss 27.457324981689453\n",
      "cls loss 1167.82177734375  loc loss 95.24227905273438\n",
      "cls loss 607.5640869140625  loc loss 41.0941276550293\n",
      "cls loss 770.235107421875  loc loss 59.38990020751953\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.,  3.,  3.])\n",
      "cls loss 515.8721923828125  loc loss 33.58659744262695\n",
      "cls loss 618.5748291015625  loc loss 37.000701904296875\n",
      "cls loss 579.09716796875  loc loss 42.7437629699707\n",
      "cls loss 657.9073486328125  loc loss 43.97206497192383\n",
      "cls loss 614.8297119140625  loc loss 50.537994384765625\n",
      "cls loss 576.6636962890625  loc loss 46.72242736816406\n",
      "cls loss 573.2093505859375  loc loss 45.9624137878418\n",
      "cls loss 578.5880126953125  loc loss 39.35471725463867\n",
      "cls loss 746.6814575195312  loc loss 55.59804153442383\n",
      "cls loss 633.26806640625  loc loss 40.72538375854492\n",
      "cls loss 504.0955810546875  loc loss 24.27773094177246\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21.])\n",
      "cls loss 386.93890380859375  loc loss 20.780620574951172\n",
      "cls loss 525.3197631835938  loc loss 45.59326934814453\n",
      "cls loss 722.6445922851562  loc loss 55.294857025146484\n",
      "cls loss 470.3527526855469  loc loss 28.39211082458496\n",
      "cls loss 671.7987060546875  loc loss 41.75035095214844\n",
      "cls loss 1198.1614990234375  loc loss 71.50650024414062\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 42., 42.,  1.,  1.])\n",
      "cls loss 605.2672119140625  loc loss 36.836551666259766\n",
      "cls loss 414.78814697265625  loc loss 29.60434913635254\n",
      "cls loss 544.9056396484375  loc loss 41.75144958496094\n",
      "cls loss 770.341552734375  loc loss 66.59979248046875\n",
      "cls loss 505.25811767578125  loc loss 34.201473236083984\n",
      "cls loss 703.1834716796875  loc loss 55.1629753112793\n",
      "cls loss 688.3787841796875  loc loss 54.813804626464844\n",
      "cls loss 728.3270263671875  loc loss 45.69382858276367\n",
      "cls loss 585.835693359375  loc loss 37.75132751464844\n",
      "cls loss 513.89208984375  loc loss 33.45556640625\n",
      "cls loss 427.7627868652344  loc loss 20.170679092407227\n",
      "cls loss 528.8551025390625  loc loss 39.70439147949219\n",
      "cls loss 772.782470703125  loc loss 69.22081756591797\n",
      "cls loss 625.37158203125  loc loss 41.17134094238281\n",
      "cls loss 647.9051513671875  loc loss 49.14025115966797\n",
      "cls loss 690.77294921875  loc loss 38.59553146362305\n",
      "cls loss 1020.33935546875  loc loss 67.50160217285156\n",
      "cls loss 686.14306640625  loc loss 55.27748489379883\n",
      "cls loss 814.8087158203125  loc loss 48.77308654785156\n",
      "cls loss 501.99090576171875  loc loss 24.848356246948242\n",
      "cls loss 690.7734985351562  loc loss 45.24406051635742\n",
      "cls loss 627.5245361328125  loc loss 43.6846923828125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 5., 5., 5., 5., 5., 5.])\n",
      "cls loss 453.5965270996094  loc loss 31.543323516845703\n",
      "cls loss 529.4999389648438  loc loss 35.54643630981445\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([13.])\n",
      "cls loss 369.3106384277344  loc loss 23.647748947143555\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([44., 10.,  1.,  1.,  1.])\n",
      "cls loss 393.09503173828125  loc loss 24.305757522583008\n",
      "cls loss 720.2435302734375  loc loss 39.95310974121094\n",
      "cls loss 575.7763671875  loc loss 34.34421920776367\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19., 19., 19., 19., 19., 19., 19.])\n",
      "cls loss 742.3230590820312  loc loss 45.867164611816406\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([56.])\n",
      "cls loss 1330.13525390625  loc loss 81.60820007324219\n",
      "cls loss 695.5239868164062  loc loss 58.220115661621094\n",
      "cls loss 965.6859741210938  loc loss 72.62679290771484\n",
      "cls loss 922.1853637695312  loc loss 74.99011993408203\n",
      "cls loss 575.3636474609375  loc loss 37.351173400878906\n",
      "cls loss 948.9755859375  loc loss 70.48167419433594\n",
      "cls loss 590.3961181640625  loc loss 33.671390533447266\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 36.])\n",
      "cls loss 682.1981201171875  loc loss 39.30401611328125\n",
      "cls loss 575.3682250976562  loc loss 43.6372184753418\n",
      "cls loss 653.366943359375  loc loss 36.50498962402344\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5.])\n",
      "cls loss 644.5743408203125  loc loss 42.93685531616211\n",
      "cls loss 387.4987487792969  loc loss 21.745168685913086\n",
      "cls loss 828.2600708007812  loc loss 52.01511764526367\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "cls loss 755.654296875  loc loss 54.736515045166016\n",
      "cls loss 802.0291748046875  loc loss 49.56340026855469\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 687.65869140625  loc loss 50.94139099121094\n",
      "cls loss 810.6185913085938  loc loss 59.96364974975586\n",
      "cls loss 689.3563842773438  loc loss 62.3478889465332\n",
      "cls loss 493.539306640625  loc loss 35.82379150390625\n",
      "cls loss 598.3229370117188  loc loss 44.953582763671875\n",
      "cls loss 590.9183959960938  loc loss 41.44472885131836\n",
      "cls loss 913.902587890625  loc loss 58.00901794433594\n",
      "cls loss 443.30462646484375  loc loss 24.07717514038086\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 11., 15., 10., 10., 10., 10., 10.])\n",
      "cls loss 990.0819091796875  loc loss 72.77532958984375\n",
      "cls loss 574.9036865234375  loc loss 38.429962158203125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3.])\n",
      "cls loss 643.144775390625  loc loss 40.81711959838867\n",
      "cls loss 529.2108154296875  loc loss 33.093841552734375\n",
      "cls loss 587.7003173828125  loc loss 31.355323791503906\n",
      "cls loss 761.5150146484375  loc loss 41.35870361328125\n",
      "cls loss 457.10528564453125  loc loss 20.300106048583984\n",
      "cls loss 647.0762329101562  loc loss 37.19533920288086\n",
      "cls loss 682.0908203125  loc loss 52.093414306640625\n",
      "cls loss 577.7885131835938  loc loss 45.132076263427734\n",
      "cls loss 1261.573974609375  loc loss 102.88531494140625\n",
      "cls loss 915.8626098632812  loc loss 66.9778060913086\n",
      "cls loss 593.397216796875  loc loss 46.18107223510742\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  9.,  9.,  9.,  6.,  6., 85., 85.,  8.,  1.,  1.,  1.,  1.,\n",
      "         6.,  6.])\n",
      "cls loss 432.8558349609375  loc loss 30.831249237060547\n",
      "cls loss 961.3063354492188  loc loss 70.4782485961914\n",
      "cls loss 1130.402099609375  loc loss 76.35957336425781\n",
      "cls loss 783.2735595703125  loc loss 57.462337493896484\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10.,  3.,  3., 10.])\n",
      "cls loss 508.5380859375  loc loss 32.864620208740234\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([7.])\n",
      "cls loss 697.464111328125  loc loss 53.43169403076172\n",
      "cls loss 718.8143310546875  loc loss 43.618324279785156\n",
      "cls loss 658.9591674804688  loc loss 49.261756896972656\n",
      "cls loss 978.62353515625  loc loss 71.51605224609375\n",
      "cls loss 715.6043701171875  loc loss 43.88673400878906\n",
      "cls loss 903.2952880859375  loc loss 59.0268669128418\n",
      "cls loss 1049.474853515625  loc loss 68.55996704101562\n",
      "cls loss 665.1295776367188  loc loss 46.09228515625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 672.158935546875  loc loss 48.984249114990234\n",
      "cls loss 580.6953125  loc loss 44.64933776855469\n",
      "cls loss 798.3511352539062  loc loss 68.5051040649414\n",
      "cls loss 681.7259521484375  loc loss 46.1366081237793\n",
      "cls loss 516.736328125  loc loss 32.6489143371582\n",
      "cls loss 786.752685546875  loc loss 64.05024719238281\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([62.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([62.])\n",
      "cls loss 343.5812072753906  loc loss 21.546161651611328\n",
      "cls loss 630.1822509765625  loc loss 48.56460952758789\n",
      "cls loss 629.6387939453125  loc loss 43.384796142578125\n",
      "cls loss 470.6331481933594  loc loss 20.684520721435547\n",
      "cls loss 808.6769409179688  loc loss 60.14234924316406\n",
      "cls loss 779.3936767578125  loc loss 50.00545120239258\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([28.])\n",
      "cls loss 871.3472290039062  loc loss 50.833675384521484\n",
      "cls loss 804.865966796875  loc loss 51.50992965698242\n",
      "cls loss 756.356689453125  loc loss 50.376949310302734\n",
      "cls loss 790.1748046875  loc loss 55.877891540527344\n",
      "cls loss 1071.189697265625  loc loss 76.87171173095703\n",
      "cls loss 603.0421142578125  loc loss 41.21263122558594\n",
      "cls loss 761.6522827148438  loc loss 48.33110427856445\n",
      "cls loss 689.0137939453125  loc loss 58.67206954956055\n",
      "cls loss 1093.541015625  loc loss 82.7479019165039\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([81.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 745.4585571289062  loc loss 35.44810104370117\n",
      "cls loss 588.107421875  loc loss 30.298898696899414\n",
      "cls loss 489.3791809082031  loc loss 31.9844913482666\n",
      "cls loss 416.58416748046875  loc loss 19.61292839050293\n",
      "cls loss 473.42474365234375  loc loss 30.857511520385742\n",
      "cls loss 497.7833251953125  loc loss 34.41585922241211\n",
      "cls loss 566.8558959960938  loc loss 37.007568359375\n",
      "cls loss 746.005615234375  loc loss 61.8826904296875\n",
      "cls loss 822.13037109375  loc loss 56.80359649658203\n",
      "cls loss 1561.201171875  loc loss 113.90286254882812\n",
      "cls loss 612.36865234375  loc loss 33.4117317199707\n",
      "cls loss 737.7255859375  loc loss 52.030311584472656\n",
      "cls loss 507.3249206542969  loc loss 36.75032043457031\n",
      "cls loss 726.2946166992188  loc loss 40.65446472167969\n",
      "cls loss 692.8115234375  loc loss 38.2352180480957\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([44., 44.])\n",
      "cls loss 574.198486328125  loc loss 29.67988395690918\n",
      "cls loss 616.0914306640625  loc loss 41.35646057128906\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15.])\n",
      "cls loss 713.968017578125  loc loss 39.35576629638672\n",
      "cls loss 330.80718994140625  loc loss 19.243515014648438\n",
      "cls loss 673.75439453125  loc loss 42.76457595825195\n",
      "cls loss 371.2359313964844  loc loss 25.238140106201172\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([1., 3., 3.])\n",
      "cls loss 412.0616455078125  loc loss 33.890384674072266\n",
      "cls loss 362.46051025390625  loc loss 16.5582332611084\n",
      "cls loss 645.22412109375  loc loss 37.78572463989258\n",
      "cls loss 669.300048828125  loc loss 40.939212799072266\n",
      "cls loss 616.490966796875  loc loss 40.322750091552734\n",
      "cls loss 609.52880859375  loc loss 39.51264190673828\n",
      "cls loss 533.6471557617188  loc loss 40.14130401611328\n",
      "cls loss 656.8805541992188  loc loss 48.46598815917969\n",
      "cls loss 549.7501220703125  loc loss 37.28607940673828\n",
      "cls loss 664.6158447265625  loc loss 50.334720611572266\n",
      "cls loss 438.4324035644531  loc loss 27.314685821533203\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 789.865966796875  loc loss 49.99243927001953\n",
      "cls loss 893.5733642578125  loc loss 50.224300384521484\n",
      "cls loss 814.0322875976562  loc loss 57.53245162963867\n",
      "cls loss 807.45654296875  loc loss 57.38387680053711\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10., 10., 10.,  1.,  1.,  1.,  1.,  1.,  1.,  8.,  8.,\n",
      "         1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10., 10., 10.,  1.,  1.,  1.,  1.,  1.,  1.,  8.,  8.,\n",
      "         1.])\n",
      "cls loss 788.466796875  loc loss 43.66242599487305\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 3., 3., 3.])\n",
      "cls loss 633.7593994140625  loc loss 41.608585357666016\n",
      "cls loss 451.01373291015625  loc loss 25.608675003051758\n",
      "cls loss 330.58770751953125  loc loss 19.66897201538086\n",
      "cls loss 608.68896484375  loc loss 44.17735290527344\n",
      "cls loss 495.10321044921875  loc loss 25.94533920288086\n",
      "cls loss 540.676025390625  loc loss 37.05744934082031\n",
      "cls loss 620.0769653320312  loc loss 41.49005126953125\n",
      "cls loss 851.920654296875  loc loss 61.24858093261719\n",
      "cls loss 700.2697143554688  loc loss 39.148529052734375\n",
      "cls loss 664.587890625  loc loss 42.98141098022461\n",
      "cls loss 760.2996826171875  loc loss 53.1336669921875\n",
      "cls loss 591.1033935546875  loc loss 43.820289611816406\n",
      "cls loss 958.1135864257812  loc loss 79.07548522949219\n",
      "cls loss 532.8341064453125  loc loss 30.642662048339844\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 754.5400390625  loc loss 49.117164611816406\n",
      "cls loss 403.964599609375  loc loss 19.765024185180664\n",
      "cls loss 1013.5001220703125  loc loss 66.44941711425781\n",
      "cls loss 514.2332763671875  loc loss 28.44065284729004\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 34.])\n",
      "cls loss 781.4085693359375  loc loss 44.79072570800781\n",
      "cls loss 387.3443603515625  loc loss 26.189151763916016\n",
      "cls loss 717.1295776367188  loc loss 48.04500961303711\n",
      "cls loss 272.9858703613281  loc loss 18.637928009033203\n",
      "cls loss 668.13525390625  loc loss 44.983238220214844\n",
      "cls loss 622.8370971679688  loc loss 47.92933654785156\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 38.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16., 16., 16.,  9.,  9.,  9., 16., 16., 16., 85.,  9.])\n",
      "cls loss 591.84912109375  loc loss 39.57250213623047\n",
      "cls loss 672.6171875  loc loss 56.43452072143555\n",
      "cls loss 982.6143798828125  loc loss 73.43383026123047\n",
      "cls loss 1325.2401123046875  loc loss 97.52108764648438\n",
      "cls loss 411.6427001953125  loc loss 21.75033950805664\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3., 10.,  8.,  8., 10., 10., 10.,  3.,  3., 14.])\n",
      "cls loss 517.51708984375  loc loss 25.45476531982422\n",
      "cls loss 831.421630859375  loc loss 48.11737823486328\n",
      "cls loss 359.3514404296875  loc loss 15.278233528137207\n",
      "cls loss 566.0574951171875  loc loss 27.01718521118164\n",
      "cls loss 908.2364501953125  loc loss 48.59710693359375\n",
      "cls loss 697.2749633789062  loc loss 46.66102981567383\n",
      "cls loss 423.14581298828125  loc loss 22.412527084350586\n",
      "cls loss 459.53863525390625  loc loss 28.4410400390625\n",
      "cls loss 665.9675903320312  loc loss 44.560585021972656\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42., 42.,  1.])\n",
      "cls loss 611.4080200195312  loc loss 45.69013214111328\n",
      "cls loss 547.2916259765625  loc loss 33.56480407714844\n",
      "cls loss 711.1513671875  loc loss 55.69547653198242\n",
      "cls loss 773.3137817382812  loc loss 55.090736389160156\n",
      "cls loss 567.4122314453125  loc loss 36.67428970336914\n",
      "cls loss 676.8787841796875  loc loss 50.27217102050781\n",
      "cls loss 444.00799560546875  loc loss 29.543296813964844\n",
      "cls loss 494.56201171875  loc loss 33.59942626953125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20.])\n",
      "cls loss 360.4364013671875  loc loss 22.675640106201172\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([11.])\n",
      "cls loss 458.75164794921875  loc loss 26.15810775756836\n",
      "cls loss 324.4978942871094  loc loss 20.286344528198242\n",
      "cls loss 694.5185546875  loc loss 61.068260192871094\n",
      "cls loss 345.1722412109375  loc loss 16.855506896972656\n",
      "cls loss 667.9474487304688  loc loss 43.026702880859375\n",
      "cls loss 405.389892578125  loc loss 23.383586883544922\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 35., 27.])\n",
      "cls loss 659.2319946289062  loc loss 43.28720474243164\n",
      "cls loss 650.71728515625  loc loss 56.11316680908203\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 522.2061767578125  loc loss 33.7447509765625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([42.,  1.])\n",
      "cls loss 675.4437866210938  loc loss 51.88982391357422\n",
      "cls loss 621.8185424804688  loc loss 36.53422546386719\n",
      "cls loss 785.3101196289062  loc loss 41.653507232666016\n",
      "cls loss 880.9435424804688  loc loss 59.29133224487305\n",
      "cls loss 766.46923828125  loc loss 52.8283576965332\n",
      "cls loss 513.7080688476562  loc loss 42.030799865722656\n",
      "cls loss 450.54925537109375  loc loss 35.90141296386719\n",
      "cls loss 306.3011779785156  loc loss 15.392335891723633\n",
      "cls loss 536.6824340820312  loc loss 33.10285568237305\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 1., 1.])\n",
      "cls loss 493.3006591796875  loc loss 29.732219696044922\n",
      "cls loss 546.659912109375  loc loss 43.53896713256836\n",
      "cls loss 556.489013671875  loc loss 38.53324890136719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 471.12786865234375  loc loss 36.075584411621094\n",
      "cls loss 564.4637451171875  loc loss 37.29179000854492\n",
      "cls loss 604.9865112304688  loc loss 46.97943115234375\n",
      "cls loss 863.9674682617188  loc loss 52.19694137573242\n",
      "cls loss 774.2874755859375  loc loss 58.53094482421875\n",
      "cls loss 714.3344116210938  loc loss 42.05187225341797\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 538.4573974609375  loc loss 40.02345275878906\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 643.6182250976562  loc loss 31.63023567199707\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([81.])\n",
      "cls loss 768.6248779296875  loc loss 51.297611236572266\n",
      "cls loss 476.8236389160156  loc loss 33.008689880371094\n",
      "cls loss 356.833984375  loc loss 22.951871871948242\n",
      "cls loss 508.7041931152344  loc loss 27.228435516357422\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3.,  1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 19.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 19.])\n",
      "cls loss 692.2660522460938  loc loss 49.079376220703125\n",
      "cls loss 391.874755859375  loc loss 20.071842193603516\n",
      "cls loss 401.367431640625  loc loss 26.822437286376953\n",
      "cls loss 797.1649169921875  loc loss 61.339691162109375\n",
      "cls loss 434.0136413574219  loc loss 27.490530014038086\n",
      "cls loss 491.180908203125  loc loss 38.2844123840332\n",
      "cls loss 610.2206420898438  loc loss 44.521629333496094\n",
      "cls loss 473.3866271972656  loc loss 38.38658905029297\n",
      "cls loss 648.0377197265625  loc loss 40.473880767822266\n",
      "cls loss 733.1461181640625  loc loss 52.59743881225586\n",
      "cls loss 890.3142700195312  loc loss 81.00920104980469\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 81.])\n",
      "cls loss 631.5132446289062  loc loss 36.07811737060547\n",
      "cls loss 602.5142822265625  loc loss 33.29425811767578\n",
      "cls loss 642.1485595703125  loc loss 36.37371826171875\n",
      "cls loss 466.81134033203125  loc loss 23.554574966430664\n",
      "cls loss 450.8424072265625  loc loss 27.25717544555664\n",
      "cls loss 532.4183959960938  loc loss 36.7496337890625\n",
      "cls loss 413.2416687011719  loc loss 28.372539520263672\n",
      "cls loss 319.000244140625  loc loss 22.78451156616211\n",
      "cls loss 412.34539794921875  loc loss 30.961517333984375\n",
      "cls loss 591.9481201171875  loc loss 38.56153869628906\n",
      "cls loss 487.51727294921875  loc loss 38.74690246582031\n",
      "cls loss 518.19287109375  loc loss 41.52461242675781\n",
      "cls loss 305.5414733886719  loc loss 24.165367126464844\n",
      "cls loss 1033.5673828125  loc loss 77.80931091308594\n",
      "cls loss 689.1961669921875  loc loss 49.974822998046875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 578.9425048828125  loc loss 34.097442626953125\n",
      "cls loss 642.7288818359375  loc loss 44.852935791015625\n",
      "cls loss 524.4387817382812  loc loss 30.172889709472656\n",
      "cls loss 758.3694458007812  loc loss 46.2755012512207\n",
      "cls loss 723.0249633789062  loc loss 47.074546813964844\n",
      "cls loss 654.22119140625  loc loss 40.905887603759766\n",
      "cls loss 559.631103515625  loc loss 29.845304489135742\n",
      "cls loss 410.52716064453125  loc loss 24.25509262084961\n",
      "cls loss 559.73193359375  loc loss 37.75791549682617\n",
      "cls loss 585.6397094726562  loc loss 44.39846420288086\n",
      "cls loss 649.9349365234375  loc loss 37.24104309082031\n",
      "cls loss 790.3666381835938  loc loss 63.085060119628906\n",
      "cls loss 852.6009521484375  loc loss 63.55193328857422\n",
      "cls loss 571.9591674804688  loc loss 42.521461486816406\n",
      "cls loss 728.2132568359375  loc loss 62.236053466796875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1., 38., 47.,  1.,  1.,  1.,  1.,  1., 62.])\n",
      "cls loss 514.5716552734375  loc loss 31.88709831237793\n",
      "cls loss 653.5838012695312  loc loss 40.66221237182617\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 713.88720703125  loc loss 44.44147491455078\n",
      "cls loss 820.1954345703125  loc loss 58.985260009765625\n",
      "cls loss 561.591552734375  loc loss 28.786039352416992\n",
      "cls loss 595.9653930664062  loc loss 49.24178695678711\n",
      "cls loss 569.8495483398438  loc loss 37.677978515625\n",
      "cls loss 365.744873046875  loc loss 15.963034629821777\n",
      "cls loss 554.2330932617188  loc loss 33.20549011230469\n",
      "cls loss 464.3063049316406  loc loss 23.405677795410156\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1., 35.])\n",
      "cls loss 534.146484375  loc loss 28.7269344329834\n",
      "cls loss 790.4192504882812  loc loss 44.256317138671875\n",
      "cls loss 728.09228515625  loc loss 50.11874771118164\n",
      "cls loss 674.6303100585938  loc loss 56.01264572143555\n",
      "cls loss 538.1102294921875  loc loss 44.43902587890625\n",
      "cls loss 672.4633178710938  loc loss 52.06795120239258\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 387.74456787109375  loc loss 24.276269912719727\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 594.8480834960938  loc loss 30.255517959594727\n",
      "cls loss 928.7648315429688  loc loss 54.54964828491211\n",
      "cls loss 1089.822265625  loc loss 84.57367706298828\n",
      "cls loss 571.8800048828125  loc loss 32.09089279174805\n",
      "cls loss 499.1973571777344  loc loss 30.899547576904297\n",
      "cls loss 509.0068359375  loc loss 32.08271789550781\n",
      "cls loss 562.1575317382812  loc loss 45.21194076538086\n",
      "cls loss 567.0430297851562  loc loss 22.133407592773438\n",
      "cls loss 867.36865234375  loc loss 65.55445861816406\n",
      "cls loss 696.904052734375  loc loss 43.52403259277344\n",
      "cls loss 428.13885498046875  loc loss 25.001264572143555\n",
      "cls loss 731.1951904296875  loc loss 40.69171142578125\n",
      "cls loss 847.325439453125  loc loss 65.4281234741211\n",
      "cls loss 659.1912841796875  loc loss 44.59194564819336\n",
      "cls loss 602.341552734375  loc loss 34.84492874145508\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.])\n",
      "cls loss 581.9178466796875  loc loss 43.3341178894043\n",
      "cls loss 478.9593505859375  loc loss 40.03148651123047\n",
      "cls loss 738.885498046875  loc loss 48.00511169433594\n",
      "cls loss 1003.8169555664062  loc loss 87.37567138671875\n",
      "cls loss 467.595947265625  loc loss 23.34819793701172\n",
      "cls loss 556.2755126953125  loc loss 37.66086196899414\n",
      "cls loss 483.560546875  loc loss 29.77452278137207\n",
      "cls loss 537.1043701171875  loc loss 33.87590026855469\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 21., 21., 21.])\n",
      "cls loss 599.0205078125  loc loss 33.75492477416992\n",
      "cls loss 544.9320678710938  loc loss 25.72144317626953\n",
      "cls loss 564.68994140625  loc loss 37.622474670410156\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 35.])\n",
      "cls loss 832.1251220703125  loc loss 56.46405792236328\n",
      "cls loss 285.5126953125  loc loss 15.475064277648926\n",
      "cls loss 435.589111328125  loc loss 29.816781997680664\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 430.01025390625  loc loss 24.99768829345703\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 38., 38.,  9., 38.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1.,  1.])\n",
      "cls loss 472.6031188964844  loc loss 36.661888122558594\n",
      "cls loss 765.7147216796875  loc loss 56.373783111572266\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 2.,  1., 77., 31., 10., 10.,  1.,  4., 10.])\n",
      "cls loss 430.98626708984375  loc loss 21.58202362060547\n",
      "cls loss 750.563232421875  loc loss 48.8394775390625\n",
      "cls loss 1453.264892578125  loc loss 103.59423828125\n",
      "cls loss 500.51873779296875  loc loss 32.077030181884766\n",
      "cls loss 658.0523071289062  loc loss 55.792240142822266\n",
      "cls loss 488.09808349609375  loc loss 31.451845169067383\n",
      "cls loss 504.1955871582031  loc loss 26.83127212524414\n",
      "cls loss 862.8173828125  loc loss 35.515743255615234\n",
      "cls loss 733.4092407226562  loc loss 41.97373962402344\n",
      "cls loss 654.37109375  loc loss 46.351806640625\n",
      "cls loss 498.5986022949219  loc loss 25.915424346923828\n",
      "cls loss 583.15283203125  loc loss 28.94591522216797\n",
      "cls loss 1060.953369140625  loc loss 64.88838195800781\n",
      "cls loss 857.7679443359375  loc loss 58.37720489501953\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1., 42., 42., 42., 42., 42., 42.,  1.,\n",
      "         1.,  1.,  1., 42.,  1.,  1., 42.,  1.])\n",
      "cls loss 503.12738037109375  loc loss 35.77356719970703\n",
      "cls loss 719.7127685546875  loc loss 47.5843620300293\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.])\n",
      "cls loss 335.85565185546875  loc loss 22.852685928344727\n",
      "cls loss 682.7136840820312  loc loss 50.572471618652344\n",
      "cls loss 548.7186279296875  loc loss 42.21708679199219\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([11.])\n",
      "cls loss 339.988525390625  loc loss 19.976970672607422\n",
      "cls loss 442.664794921875  loc loss 21.690195083618164\n",
      "cls loss 450.9388122558594  loc loss 23.758987426757812\n",
      "cls loss 638.2628173828125  loc loss 46.41649627685547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 621.6250610351562  loc loss 38.21660232543945\n",
      "cls loss 604.0634155273438  loc loss 46.94332504272461\n",
      "cls loss 878.0769653320312  loc loss 51.33824920654297\n",
      "cls loss 492.54241943359375  loc loss 30.823657989501953\n",
      "cls loss 881.49072265625  loc loss 69.16231536865234\n",
      "cls loss 529.5006103515625  loc loss 28.900432586669922\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 463.0250244140625  loc loss 31.883167266845703\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1., 38., 38., 42.])\n",
      "cls loss 595.06982421875  loc loss 42.620933532714844\n",
      "cls loss 548.4613037109375  loc loss 28.259918212890625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 442.00146484375  loc loss 32.014835357666016\n",
      "cls loss 988.0187377929688  loc loss 73.13658905029297\n",
      "cls loss 585.184814453125  loc loss 44.83309555053711\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10.,  3.,  3.,  6.,  8.,  8.,  1.,  1.,  1., 10.])\n",
      "cls loss 519.4150390625  loc loss 32.792110443115234\n",
      "cls loss 303.76226806640625  loc loss 12.891505241394043\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10.,  3.])\n",
      "cls loss 490.5633850097656  loc loss 28.778993606567383\n",
      "cls loss 314.2147216796875  loc loss 14.849739074707031\n",
      "cls loss 554.6243896484375  loc loss 47.515865325927734\n",
      "cls loss 620.6976318359375  loc loss 47.14264678955078\n",
      "cls loss 488.2198181152344  loc loss 31.373868942260742\n",
      "cls loss 374.15838623046875  loc loss 18.672927856445312\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 34.])\n",
      "cls loss 878.708251953125  loc loss 53.67251205444336\n",
      "cls loss 889.7435302734375  loc loss 76.24996185302734\n",
      "cls loss 596.6027221679688  loc loss 48.95204162597656\n",
      "cls loss 443.61669921875  loc loss 32.76797866821289\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.,  1.])\n",
      "cls loss 507.59771728515625  loc loss 28.053617477416992\n",
      "cls loss 796.612060546875  loc loss 64.21014404296875\n",
      "cls loss 1159.351318359375  loc loss 79.9366455078125\n",
      "cls loss 986.1022338867188  loc loss 54.24134063720703\n",
      "cls loss 580.2952880859375  loc loss 33.68035125732422\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 746.5089721679688  loc loss 41.84004211425781\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10.])\n",
      "cls loss 436.19891357421875  loc loss 25.17669105529785\n",
      "cls loss 618.5992431640625  loc loss 33.23934555053711\n",
      "cls loss 590.6650390625  loc loss 34.06298828125\n",
      "cls loss 408.9793395996094  loc loss 26.3402042388916\n",
      "cls loss 502.563232421875  loc loss 39.0688362121582\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21.,\n",
      "        21.])\n",
      "cls loss 687.1844482421875  loc loss 43.826576232910156\n",
      "cls loss 566.9631958007812  loc loss 41.861061096191406\n",
      "cls loss 376.25482177734375  loc loss 18.018125534057617\n",
      "cls loss 763.803466796875  loc loss 52.32854080200195\n",
      "cls loss 603.1600952148438  loc loss 44.786014556884766\n",
      "cls loss 432.4588928222656  loc loss 29.213973999023438\n",
      "cls loss 900.7981567382812  loc loss 67.48554229736328\n",
      "cls loss 1092.251708984375  loc loss 77.34689331054688\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15., 85.])\n",
      "cls loss 731.1978149414062  loc loss 46.137306213378906\n",
      "cls loss 684.747802734375  loc loss 54.276180267333984\n",
      "cls loss 753.302001953125  loc loss 52.38988494873047\n",
      "cls loss 648.1796875  loc loss 39.13587951660156\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 8., 8.])\n",
      "cls loss 412.1339111328125  loc loss 22.434926986694336\n",
      "cls loss 486.85400390625  loc loss 31.161758422851562\n",
      "cls loss 550.1840209960938  loc loss 34.340057373046875\n",
      "cls loss 461.2513427734375  loc loss 27.22007179260254\n",
      "cls loss 534.219482421875  loc loss 34.17632293701172\n",
      "cls loss 691.6806640625  loc loss 43.94198226928711\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1., 35., 27., 27.,  1., 27.,  1.])\n",
      "cls loss 996.3966064453125  loc loss 68.114013671875\n",
      "cls loss 446.73193359375  loc loss 34.42819595336914\n",
      "cls loss 552.630126953125  loc loss 42.36250686645508\n",
      "cls loss 519.224853515625  loc loss 46.453704833984375\n",
      "cls loss 511.60791015625  loc loss 38.45072555541992\n",
      "cls loss 524.1665649414062  loc loss 42.89158248901367\n",
      "cls loss 533.2948608398438  loc loss 42.81235122680664\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  2.,  2.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  2.,  2.])\n",
      "cls loss 367.382568359375  loc loss 14.152036666870117\n",
      "cls loss 798.5048828125  loc loss 50.76213073730469\n",
      "cls loss 583.1077880859375  loc loss 30.282236099243164\n",
      "cls loss 934.9420166015625  loc loss 67.56614685058594\n",
      "cls loss 394.06988525390625  loc loss 25.03791046142578\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 19., 19., 19., 16.])\n",
      "cls loss 402.3580017089844  loc loss 19.727998733520508\n",
      "cls loss 316.69775390625  loc loss 16.00621223449707\n",
      "cls loss 476.73291015625  loc loss 25.912460327148438\n",
      "cls loss 627.5535278320312  loc loss 43.13946533203125\n",
      "cls loss 324.5333557128906  loc loss 25.786148071289062\n",
      "cls loss 729.3775024414062  loc loss 53.421607971191406\n",
      "cls loss 503.3594055175781  loc loss 38.58469772338867\n",
      "cls loss 544.62646484375  loc loss 39.15835952758789\n",
      "cls loss 671.615966796875  loc loss 51.838802337646484\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 771.386474609375  loc loss 37.797706604003906\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 982.5530395507812  loc loss 86.32762908935547\n",
      "cls loss 1225.557861328125  loc loss 123.9180679321289\n",
      "cls loss 605.8572387695312  loc loss 46.83760070800781\n",
      "cls loss 581.555419921875  loc loss 39.844993591308594\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3.,  3.,  3.,  3.,  3., 10.])\n",
      "cls loss 363.16943359375  loc loss 17.88096046447754\n",
      "cls loss 675.8013305664062  loc loss 36.14529800415039\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 1., 1., 1., 3., 3., 3., 3.])\n",
      "cls loss 543.451904296875  loc loss 35.61747360229492\n",
      "cls loss 926.16796875  loc loss 67.44619750976562\n",
      "cls loss 749.10546875  loc loss 52.313201904296875\n",
      "cls loss 553.078125  loc loss 30.478490829467773\n",
      "cls loss 733.380859375  loc loss 58.314537048339844\n",
      "cls loss 464.4371337890625  loc loss 36.824867248535156\n",
      "cls loss 721.0408325195312  loc loss 54.525123596191406\n",
      "cls loss 565.6492919921875  loc loss 49.53169250488281\n",
      "cls loss 529.4708251953125  loc loss 39.346866607666016\n",
      "cls loss 1157.15234375  loc loss 98.4391098022461\n",
      "cls loss 740.3645629882812  loc loss 53.836997985839844\n",
      "cls loss 504.969482421875  loc loss 26.624135971069336\n",
      "cls loss 335.5633850097656  loc loss 16.382938385009766\n",
      "cls loss 388.61651611328125  loc loss 22.319486618041992\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3., 10., 10., 10., 10., 10., 10., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10., 10., 10., 10., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 11., 10., 10., 10., 10., 10.,  3.,  3.,  3.,  3.,  3.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 11., 10., 10., 10., 10., 10.,  3.,  3.,  3.,  3.,  3.])\n",
      "cls loss 389.0122375488281  loc loss 19.551668167114258\n",
      "cls loss 501.45880126953125  loc loss 24.446441650390625\n",
      "cls loss 419.5763854980469  loc loss 25.87434959411621\n",
      "cls loss 400.50018310546875  loc loss 17.369651794433594\n",
      "cls loss 485.17462158203125  loc loss 36.95526885986328\n",
      "cls loss 429.93670654296875  loc loss 16.496383666992188\n",
      "cls loss 700.09375  loc loss 49.25923156738281\n",
      "cls loss 616.8807373046875  loc loss 46.11860656738281\n",
      "cls loss 917.963134765625  loc loss 62.98991394042969\n",
      "cls loss 453.2475280761719  loc loss 35.38082504272461\n",
      "cls loss 805.6065673828125  loc loss 56.890159606933594\n",
      "cls loss 656.7891845703125  loc loss 47.63839340209961\n",
      "cls loss 614.296630859375  loc loss 43.16986083984375\n",
      "cls loss 623.641357421875  loc loss 48.97921371459961\n",
      "cls loss 852.3311767578125  loc loss 59.88232421875\n",
      "cls loss 825.432861328125  loc loss 53.07631301879883\n",
      "cls loss 408.8132629394531  loc loss 24.230756759643555\n",
      "cls loss 706.1357421875  loc loss 57.020179748535156\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 10.,  1., 18.])\n",
      "cls loss 379.4922180175781  loc loss 26.46354103088379\n",
      "cls loss 430.61309814453125  loc loss 18.845361709594727\n",
      "cls loss 763.1375122070312  loc loss 38.47056579589844\n",
      "cls loss 1019.2431640625  loc loss 71.09761047363281\n",
      "cls loss 649.2371215820312  loc loss 44.53675842285156\n",
      "cls loss 866.5623168945312  loc loss 53.8970947265625\n",
      "cls loss 597.2161865234375  loc loss 42.2175178527832\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.,  1.,  1.])\n",
      "cls loss 790.1295166015625  loc loss 53.9644889831543\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1., 38.,  1.])\n",
      "cls loss 752.1023559570312  loc loss 45.0865478515625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 959.3170776367188  loc loss 73.77088928222656\n",
      "cls loss 478.2935791015625  loc loss 38.409645080566406\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 647.8178100585938  loc loss 47.99192428588867\n",
      "cls loss 569.571533203125  loc loss 40.808631896972656\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3., 10.,  8.,  3., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.])\n",
      "cls loss 697.3768310546875  loc loss 46.55353927612305\n",
      "cls loss 489.3382873535156  loc loss 32.705230712890625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3.,  3., 11.,  3., 10., 10.,  3.,  3., 10.])\n",
      "cls loss 576.4535522460938  loc loss 30.45328140258789\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3., 10., 10., 10.])\n",
      "cls loss 575.0472412109375  loc loss 42.69470977783203\n",
      "cls loss 491.19635009765625  loc loss 28.772157669067383\n",
      "cls loss 619.9503173828125  loc loss 45.86595153808594\n",
      "cls loss 1013.3613891601562  loc loss 59.801658630371094\n",
      "cls loss 611.8644409179688  loc loss 41.406455993652344\n",
      "cls loss 433.728271484375  loc loss 38.07036209106445\n",
      "cls loss 533.835205078125  loc loss 39.5904655456543\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 9.,  9., 85., 85.])\n",
      "cls loss 495.31597900390625  loc loss 28.104049682617188\n",
      "cls loss 541.42822265625  loc loss 37.93309020996094\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 893.841796875  loc loss 69.53759765625\n",
      "cls loss 754.3084716796875  loc loss 40.91197204589844\n",
      "cls loss 854.45458984375  loc loss 62.56681442260742\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10., 10., 10., 10.])\n",
      "cls loss 553.89794921875  loc loss 35.05142593383789\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([13.])\n",
      "cls loss 885.9039916992188  loc loss 70.6285400390625\n",
      "cls loss 315.5044860839844  loc loss 18.11758041381836\n",
      "cls loss 379.1534423828125  loc loss 21.523935317993164\n",
      "cls loss 543.2366943359375  loc loss 30.418134689331055\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19.,  1.,  1.,  1., 19., 19.])\n",
      "cls loss 560.9223022460938  loc loss 36.289188385009766\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 405.160400390625  loc loss 36.79176330566406\n",
      "cls loss 662.6115112304688  loc loss 48.638671875\n",
      "cls loss 459.2908935546875  loc loss 28.682140350341797\n",
      "cls loss 684.8277587890625  loc loss 43.912437438964844\n",
      "cls loss 739.8817138671875  loc loss 57.18402099609375\n",
      "cls loss 597.5242309570312  loc loss 33.2566032409668\n",
      "cls loss 812.631591796875  loc loss 62.739444732666016\n",
      "cls loss 364.607421875  loc loss 16.809328079223633\n",
      "cls loss 587.5203857421875  loc loss 39.424171447753906\n",
      "cls loss 471.5361328125  loc loss 25.45885467529297\n",
      "cls loss 481.4384765625  loc loss 28.815692901611328\n",
      "cls loss 620.0281982421875  loc loss 47.759403228759766\n",
      "cls loss 596.7108764648438  loc loss 36.8955078125\n",
      "cls loss 863.7994995117188  loc loss 56.99641036987305\n",
      "cls loss 530.5431518554688  loc loss 39.14996337890625\n",
      "cls loss 661.1271362304688  loc loss 47.861549377441406\n",
      "cls loss 968.93505859375  loc loss 65.87454986572266\n",
      "cls loss 563.3179321289062  loc loss 44.48432159423828\n",
      "cls loss 638.842529296875  loc loss 40.096187591552734\n",
      "cls loss 812.5560302734375  loc loss 59.739017486572266\n",
      "cls loss 803.1539306640625  loc loss 59.3630485534668\n",
      "cls loss 1027.68505859375  loc loss 59.182708740234375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 5.])\n",
      "cls loss 326.37310791015625  loc loss 11.857638359069824\n",
      "cls loss 404.8575439453125  loc loss 17.90681266784668\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 13.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 6., 8., 8.])\n",
      "cls loss 370.81561279296875  loc loss 17.124740600585938\n",
      "cls loss 406.6715087890625  loc loss 23.98353385925293\n",
      "cls loss 779.5885009765625  loc loss 57.21298599243164\n",
      "cls loss 350.308349609375  loc loss 17.850421905517578\n",
      "cls loss 623.761474609375  loc loss 48.189456939697266\n",
      "cls loss 964.490478515625  loc loss 68.23099517822266\n",
      "cls loss 571.3264770507812  loc loss 45.3934211730957\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([42., 42.,  1.,  1.,  1.,  1.,  1.,  1.,  1., 42., 42.])\n",
      "cls loss 624.787353515625  loc loss 40.32523727416992\n",
      "cls loss 835.6751708984375  loc loss 66.94667053222656\n",
      "cls loss 651.8901977539062  loc loss 56.907989501953125\n",
      "cls loss 487.1006774902344  loc loss 30.15909767150879\n",
      "cls loss 660.3626708984375  loc loss 42.42759704589844\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 911.979736328125  loc loss 60.39225387573242\n",
      "cls loss 708.590576171875  loc loss 52.96133041381836\n",
      "cls loss 472.59564208984375  loc loss 29.187490463256836\n",
      "cls loss 409.9405822753906  loc loss 20.878210067749023\n",
      "cls loss 557.4489135742188  loc loss 34.245975494384766\n",
      "cls loss 731.7855224609375  loc loss 50.512115478515625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15.])\n",
      "cls loss 350.8216247558594  loc loss 18.88071060180664\n",
      "cls loss 566.9922485351562  loc loss 38.94410705566406\n",
      "cls loss 506.7750549316406  loc loss 34.96100616455078\n",
      "cls loss 891.1248779296875  loc loss 65.31616973876953\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19.,  7.])\n",
      "cls loss 513.175537109375  loc loss 33.41242599487305\n",
      "cls loss 1044.189697265625  loc loss 67.25358581542969\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 874.4650268554688  loc loss 49.59968948364258\n",
      "cls loss 666.1636352539062  loc loss 53.98844909667969\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([38., 38.,  1., 18.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1., 18., 18.,  1.])\n",
      "cls loss 549.47314453125  loc loss 29.93071937561035\n",
      "cls loss 519.5095825195312  loc loss 26.491504669189453\n",
      "cls loss 890.5420532226562  loc loss 73.08560943603516\n",
      "cls loss 698.6602783203125  loc loss 42.297088623046875\n",
      "cls loss 702.1892700195312  loc loss 36.00870895385742\n",
      "cls loss 379.32928466796875  loc loss 29.756481170654297\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.])\n",
      "cls loss 316.23052978515625  loc loss 11.434822082519531\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([32.])\n",
      "cls loss 610.7955322265625  loc loss 31.115772247314453\n",
      "cls loss 529.5755615234375  loc loss 36.64217758178711\n",
      "cls loss 699.3941040039062  loc loss 57.865257263183594\n",
      "cls loss 665.109130859375  loc loss 41.45001220703125\n",
      "cls loss 530.4769287109375  loc loss 35.0712776184082\n",
      "cls loss 820.1422119140625  loc loss 52.12968826293945\n",
      "cls loss 855.5635986328125  loc loss 62.250308990478516\n",
      "cls loss 692.37255859375  loc loss 48.54972457885742\n",
      "cls loss 580.86572265625  loc loss 35.83677291870117\n",
      "cls loss 924.0472412109375  loc loss 60.021018981933594\n",
      "cls loss 557.5728149414062  loc loss 31.221221923828125\n",
      "cls loss 877.5693969726562  loc loss 76.1048812866211\n",
      "cls loss 661.0849609375  loc loss 40.636844635009766\n",
      "cls loss 552.3547973632812  loc loss 40.92621612548828\n",
      "cls loss 428.86273193359375  loc loss 24.28134536743164\n",
      "cls loss 456.2116394042969  loc loss 30.907926559448242\n",
      "cls loss 693.9354858398438  loc loss 48.50865173339844\n",
      "cls loss 714.1471557617188  loc loss 53.88315963745117\n",
      "cls loss 425.0086669921875  loc loss 29.990985870361328\n",
      "cls loss 796.7489013671875  loc loss 54.49298095703125\n",
      "cls loss 933.5946044921875  loc loss 58.47767639160156\n",
      "cls loss 355.57159423828125  loc loss 24.857236862182617\n",
      "cls loss 891.4832763671875  loc loss 62.48563003540039\n",
      "cls loss 642.666748046875  loc loss 49.93724060058594\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 875.1301879882812  loc loss 69.42571258544922\n",
      "cls loss 437.33038330078125  loc loss 18.027767181396484\n",
      "cls loss 653.609130859375  loc loss 37.46580505371094\n",
      "cls loss 639.3951416015625  loc loss 45.47322463989258\n",
      "cls loss 503.39874267578125  loc loss 31.32525634765625\n",
      "cls loss 320.62060546875  loc loss 16.94801139831543\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 9., 9., 1., 9., 9., 9., 9., 1., 9.])\n",
      "cls loss 1118.296875  loc loss 98.51042175292969\n",
      "cls loss 662.2540283203125  loc loss 36.29156494140625\n",
      "cls loss 973.0035400390625  loc loss 82.7545166015625\n",
      "cls loss 418.90655517578125  loc loss 28.446292877197266\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 42., 42.])\n",
      "cls loss 692.4472045898438  loc loss 53.269203186035156\n",
      "cls loss 742.7620239257812  loc loss 54.79635238647461\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  2.,  1.,  1.,  1., 38.,\n",
      "         1.,  1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 38., 38., 38.,  1., 38., 38., 38.,  1.,  1., 38.,  1.,\n",
      "         1.])\n",
      "cls loss 480.3468933105469  loc loss 32.35321044921875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  8.,  8.])\n",
      "cls loss 1021.1636352539062  loc loss 71.16727447509766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 1035.480224609375  loc loss 73.92540740966797\n",
      "cls loss 419.14678955078125  loc loss 25.39957046508789\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([4., 1., 1., 4.])\n",
      "cls loss 590.8120727539062  loc loss 43.1456184387207\n",
      "cls loss 700.3882446289062  loc loss 45.324275970458984\n",
      "cls loss 329.88031005859375  loc loss 15.729034423828125\n",
      "cls loss 443.6650695800781  loc loss 27.41348648071289\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([51.,  1.])\n",
      "cls loss 321.88360595703125  loc loss 14.437220573425293\n",
      "cls loss 411.67913818359375  loc loss 26.235570907592773\n",
      "cls loss 746.8118896484375  loc loss 46.3670768737793\n",
      "cls loss 828.8270263671875  loc loss 63.84719467163086\n",
      "cls loss 1107.8734130859375  loc loss 65.28258514404297\n",
      "cls loss 1394.4259033203125  loc loss 93.62648010253906\n",
      "cls loss 581.954833984375  loc loss 37.88750076293945\n",
      "cls loss 828.724853515625  loc loss 59.098392486572266\n",
      "cls loss 871.244873046875  loc loss 64.56258392333984\n",
      "cls loss 673.653076171875  loc loss 39.35662078857422\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  3.,  1.,  1.,  1.,  3.,  1.,  1.,\n",
      "         1.,  1.,  1.])\n",
      "cls loss 738.8563232421875  loc loss 38.93949508666992\n",
      "cls loss 853.7127685546875  loc loss 42.39447784423828\n",
      "cls loss 744.9821166992188  loc loss 38.98750686645508\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "cls loss 594.4739990234375  loc loss 36.556602478027344\n",
      "cls loss 359.4772033691406  loc loss 29.168312072753906\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3.])\n",
      "cls loss 332.36016845703125  loc loss 14.783605575561523\n",
      "cls loss 534.9190673828125  loc loss 39.76460266113281\n",
      "cls loss 430.6827392578125  loc loss 33.12097930908203\n",
      "cls loss 770.9290771484375  loc loss 56.138423919677734\n",
      "cls loss 532.4261474609375  loc loss 26.872604370117188\n",
      "cls loss 430.0083312988281  loc loss 30.582857131958008\n",
      "cls loss 1311.7935791015625  loc loss 90.40960693359375\n",
      "cls loss 556.3056640625  loc loss 42.976234436035156\n",
      "cls loss 400.67486572265625  loc loss 34.39531707763672\n",
      "cls loss 538.3916625976562  loc loss 33.51145553588867\n",
      "cls loss 467.840576171875  loc loss 35.88187026977539\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 852.989013671875  loc loss 61.496673583984375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  9., 64., 64., 64., 64., 64., 64., 64., 64., 64.,  9.,  9.,  9.,\n",
      "         9.])\n",
      "cls loss 491.906982421875  loc loss 26.7291259765625\n",
      "cls loss 1165.79248046875  loc loss 93.27973175048828\n",
      "cls loss 596.8238525390625  loc loss 40.42778396606445\n",
      "cls loss 759.921142578125  loc loss 57.930362701416016\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.,  3.,  3.])\n",
      "cls loss 508.3060607910156  loc loss 32.68436813354492\n",
      "cls loss 598.021240234375  loc loss 36.43242263793945\n",
      "cls loss 563.7398071289062  loc loss 41.702125549316406\n",
      "cls loss 633.6103515625  loc loss 43.24565124511719\n",
      "cls loss 593.7822265625  loc loss 49.587276458740234\n",
      "cls loss 565.6218872070312  loc loss 45.880104064941406\n",
      "cls loss 562.0345458984375  loc loss 45.362884521484375\n",
      "cls loss 570.3265991210938  loc loss 38.57576370239258\n",
      "cls loss 731.06201171875  loc loss 54.26290512084961\n",
      "cls loss 624.564208984375  loc loss 39.294166564941406\n",
      "cls loss 495.52764892578125  loc loss 23.623750686645508\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21.])\n",
      "cls loss 379.4073181152344  loc loss 20.61610221862793\n",
      "cls loss 517.8448486328125  loc loss 44.488197326660156\n",
      "cls loss 718.505615234375  loc loss 54.39535903930664\n",
      "cls loss 468.8017578125  loc loss 27.69291114807129\n",
      "cls loss 660.394287109375  loc loss 40.77508544921875\n",
      "cls loss 1176.072265625  loc loss 69.2646484375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 42., 42.,  1.,  1.])\n",
      "cls loss 591.1654663085938  loc loss 36.49242401123047\n",
      "cls loss 401.4573669433594  loc loss 29.163972854614258\n",
      "cls loss 535.0927124023438  loc loss 41.26538848876953\n",
      "cls loss 756.7738037109375  loc loss 65.10203552246094\n",
      "cls loss 492.7694396972656  loc loss 33.45143508911133\n",
      "cls loss 690.9483032226562  loc loss 54.31214141845703\n",
      "cls loss 673.9619140625  loc loss 53.740684509277344\n",
      "cls loss 718.6271362304688  loc loss 44.703643798828125\n",
      "cls loss 576.3614501953125  loc loss 36.94210433959961\n",
      "cls loss 511.03265380859375  loc loss 32.79791259765625\n",
      "cls loss 419.45361328125  loc loss 19.57050895690918\n",
      "cls loss 523.3533325195312  loc loss 38.52418518066406\n",
      "cls loss 764.354248046875  loc loss 67.79271697998047\n",
      "cls loss 617.77587890625  loc loss 40.63194274902344\n",
      "cls loss 631.2415161132812  loc loss 47.8746223449707\n",
      "cls loss 677.8098754882812  loc loss 38.07878494262695\n",
      "cls loss 997.5439453125  loc loss 66.26211547851562\n",
      "cls loss 674.6729125976562  loc loss 54.49629211425781\n",
      "cls loss 802.3652954101562  loc loss 47.741676330566406\n",
      "cls loss 485.64044189453125  loc loss 24.416940689086914\n",
      "cls loss 673.7296142578125  loc loss 44.420894622802734\n",
      "cls loss 611.898681640625  loc loss 42.64139938354492\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 5., 5., 5., 5., 5., 5.])\n",
      "cls loss 446.483154296875  loc loss 30.979572296142578\n",
      "cls loss 520.2550659179688  loc loss 34.29887390136719\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([13.])\n",
      "cls loss 361.7913513183594  loc loss 23.36847686767578\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([44., 10.,  1.,  1.,  1.])\n",
      "cls loss 383.7010192871094  loc loss 23.870319366455078\n",
      "cls loss 710.1005859375  loc loss 39.081642150878906\n",
      "cls loss 568.8900146484375  loc loss 33.74732971191406\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19., 19., 19., 19., 19., 19., 19.])\n",
      "cls loss 729.8197021484375  loc loss 44.3626708984375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([56.])\n",
      "cls loss 1313.953125  loc loss 80.096435546875\n",
      "cls loss 690.4051513671875  loc loss 57.644832611083984\n",
      "cls loss 949.8916015625  loc loss 71.0143051147461\n",
      "cls loss 916.15380859375  loc loss 73.83308410644531\n",
      "cls loss 567.222900390625  loc loss 36.264015197753906\n",
      "cls loss 929.2666625976562  loc loss 69.32308959960938\n",
      "cls loss 572.5413208007812  loc loss 33.34760665893555\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 36.])\n",
      "cls loss 665.00439453125  loc loss 38.29930114746094\n",
      "cls loss 563.5762329101562  loc loss 42.72909164428711\n",
      "cls loss 630.8405151367188  loc loss 36.049556732177734\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5.])\n",
      "cls loss 639.4569091796875  loc loss 42.25464630126953\n",
      "cls loss 378.69598388671875  loc loss 21.267210006713867\n",
      "cls loss 817.9749755859375  loc loss 50.64093017578125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "cls loss 744.0418701171875  loc loss 53.29174041748047\n",
      "cls loss 784.478759765625  loc loss 48.80310821533203\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 677.5519409179688  loc loss 49.96078109741211\n",
      "cls loss 800.024658203125  loc loss 58.84236526489258\n",
      "cls loss 675.9054565429688  loc loss 61.47179412841797\n",
      "cls loss 484.60894775390625  loc loss 34.952571868896484\n",
      "cls loss 590.588623046875  loc loss 44.244651794433594\n",
      "cls loss 588.6781005859375  loc loss 40.628379821777344\n",
      "cls loss 902.8193359375  loc loss 56.89717483520508\n",
      "cls loss 436.53009033203125  loc loss 23.416757583618164\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 11., 15., 10., 10., 10., 10., 10.])\n",
      "cls loss 976.8667602539062  loc loss 70.72466278076172\n",
      "cls loss 564.834716796875  loc loss 37.87471008300781\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3.])\n",
      "cls loss 623.0330810546875  loc loss 40.21051788330078\n",
      "cls loss 522.09619140625  loc loss 32.439178466796875\n",
      "cls loss 577.0748291015625  loc loss 30.702299118041992\n",
      "cls loss 747.3650512695312  loc loss 40.19721603393555\n",
      "cls loss 440.7024841308594  loc loss 19.987899780273438\n",
      "cls loss 623.2468872070312  loc loss 36.9954719543457\n",
      "cls loss 671.415771484375  loc loss 51.63720703125\n",
      "cls loss 567.5059814453125  loc loss 44.10565948486328\n",
      "cls loss 1249.963623046875  loc loss 100.759521484375\n",
      "cls loss 906.6681518554688  loc loss 65.06590270996094\n",
      "cls loss 583.2861938476562  loc loss 45.232177734375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  9.,  9.,  9.,  6.,  6., 85., 85.,  8.,  1.,  1.,  1.,  1.,\n",
      "         6.,  6.])\n",
      "cls loss 427.97052001953125  loc loss 30.438282012939453\n",
      "cls loss 948.5183715820312  loc loss 69.3124771118164\n",
      "cls loss 1120.7484130859375  loc loss 74.96836853027344\n",
      "cls loss 778.7911987304688  loc loss 56.167484283447266\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10.,  3.,  3., 10.])\n",
      "cls loss 507.89520263671875  loc loss 32.226219177246094\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([7.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 687.982421875  loc loss 51.75429153442383\n",
      "cls loss 700.9127197265625  loc loss 42.70671844482422\n",
      "cls loss 641.982666015625  loc loss 48.63481140136719\n",
      "cls loss 942.2645263671875  loc loss 70.40293884277344\n",
      "cls loss 685.3089599609375  loc loss 43.19973373413086\n",
      "cls loss 875.1149291992188  loc loss 57.824947357177734\n",
      "cls loss 1036.55078125  loc loss 66.91156005859375\n",
      "cls loss 648.169189453125  loc loss 45.208412170410156\n",
      "cls loss 664.2000732421875  loc loss 47.8427848815918\n",
      "cls loss 571.9134521484375  loc loss 43.887237548828125\n",
      "cls loss 789.221435546875  loc loss 67.34197998046875\n",
      "cls loss 669.07666015625  loc loss 45.04665756225586\n",
      "cls loss 514.2064208984375  loc loss 32.0523567199707\n",
      "cls loss 779.664794921875  loc loss 62.746177673339844\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([62.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([62.])\n",
      "cls loss 344.3439636230469  loc loss 21.06903839111328\n",
      "cls loss 626.7291259765625  loc loss 47.593746185302734\n",
      "cls loss 620.8826904296875  loc loss 42.67303466796875\n",
      "cls loss 459.8551940917969  loc loss 20.079421997070312\n",
      "cls loss 798.8196411132812  loc loss 58.449520111083984\n",
      "cls loss 768.522705078125  loc loss 48.91103744506836\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([28.])\n",
      "cls loss 857.9636840820312  loc loss 49.853240966796875\n",
      "cls loss 789.296142578125  loc loss 50.45500946044922\n",
      "cls loss 744.9146728515625  loc loss 49.46996307373047\n",
      "cls loss 776.1499633789062  loc loss 54.73670196533203\n",
      "cls loss 1052.484619140625  loc loss 75.28722381591797\n",
      "cls loss 592.6158447265625  loc loss 40.44342041015625\n",
      "cls loss 746.73583984375  loc loss 47.50750732421875\n",
      "cls loss 674.0504150390625  loc loss 57.484981536865234\n",
      "cls loss 1074.2760009765625  loc loss 81.75212860107422\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([81.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 735.1561279296875  loc loss 33.99863052368164\n",
      "cls loss 576.126953125  loc loss 29.593135833740234\n",
      "cls loss 484.9841003417969  loc loss 31.33944320678711\n",
      "cls loss 410.0386962890625  loc loss 18.82512664794922\n",
      "cls loss 464.9942321777344  loc loss 30.142494201660156\n",
      "cls loss 490.53729248046875  loc loss 33.4232177734375\n",
      "cls loss 557.668212890625  loc loss 36.30657196044922\n",
      "cls loss 734.20458984375  loc loss 60.91813278198242\n",
      "cls loss 809.37158203125  loc loss 56.21249771118164\n",
      "cls loss 1539.614501953125  loc loss 111.87278747558594\n",
      "cls loss 611.7655029296875  loc loss 33.09195327758789\n",
      "cls loss 735.2654418945312  loc loss 51.391319274902344\n",
      "cls loss 508.0684814453125  loc loss 35.69557571411133\n",
      "cls loss 713.9442138671875  loc loss 40.03412628173828\n",
      "cls loss 677.1775512695312  loc loss 37.49787139892578\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([44., 44.])\n",
      "cls loss 566.2943115234375  loc loss 29.209491729736328\n",
      "cls loss 595.314453125  loc loss 40.95903015136719\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15.])\n",
      "cls loss 695.720947265625  loc loss 38.233917236328125\n",
      "cls loss 323.10870361328125  loc loss 18.99180030822754\n",
      "cls loss 661.5938110351562  loc loss 41.57585525512695\n",
      "cls loss 361.6584167480469  loc loss 24.80392837524414\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([1., 3., 3.])\n",
      "cls loss 405.783935546875  loc loss 33.17813491821289\n",
      "cls loss 355.06787109375  loc loss 16.128826141357422\n",
      "cls loss 630.4044799804688  loc loss 36.978477478027344\n",
      "cls loss 656.4300537109375  loc loss 40.06849670410156\n",
      "cls loss 604.3538818359375  loc loss 39.5554313659668\n",
      "cls loss 606.9683837890625  loc loss 38.36808776855469\n",
      "cls loss 522.856689453125  loc loss 39.40839385986328\n",
      "cls loss 651.527587890625  loc loss 47.60719299316406\n",
      "cls loss 538.6773071289062  loc loss 36.49979019165039\n",
      "cls loss 656.2033081054688  loc loss 49.002769470214844\n",
      "cls loss 433.71533203125  loc loss 26.93301010131836\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 773.1934204101562  loc loss 49.0515251159668\n",
      "cls loss 880.91015625  loc loss 48.79956817626953\n",
      "cls loss 802.51953125  loc loss 56.303104400634766\n",
      "cls loss 787.0296630859375  loc loss 56.91619873046875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10., 10., 10.,  1.,  1.,  1.,  1.,  1.,  1.,  8.,  8.,\n",
      "         1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10., 10., 10.,  1.,  1.,  1.,  1.,  1.,  1.,  8.,  8.,\n",
      "         1.])\n",
      "cls loss 772.3543090820312  loc loss 41.931060791015625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 3., 3., 3.])\n",
      "cls loss 625.5296020507812  loc loss 40.99892044067383\n",
      "cls loss 442.81048583984375  loc loss 25.077579498291016\n",
      "cls loss 327.5865478515625  loc loss 19.027067184448242\n",
      "cls loss 600.36181640625  loc loss 43.50645446777344\n",
      "cls loss 485.1848449707031  loc loss 25.500003814697266\n",
      "cls loss 527.648193359375  loc loss 36.29880905151367\n",
      "cls loss 609.1152954101562  loc loss 41.130889892578125\n",
      "cls loss 837.3173828125  loc loss 60.02158737182617\n",
      "cls loss 687.373046875  loc loss 38.038021087646484\n",
      "cls loss 655.704345703125  loc loss 41.87379455566406\n",
      "cls loss 748.1128540039062  loc loss 52.09001159667969\n",
      "cls loss 578.2666625976562  loc loss 42.9436149597168\n",
      "cls loss 949.3385009765625  loc loss 77.15227508544922\n",
      "cls loss 523.3331298828125  loc loss 29.817012786865234\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 745.3631591796875  loc loss 47.99913787841797\n",
      "cls loss 398.77685546875  loc loss 19.140380859375\n",
      "cls loss 989.5252075195312  loc loss 64.82334899902344\n",
      "cls loss 506.0063171386719  loc loss 27.501493453979492\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 34.])\n",
      "cls loss 771.3360595703125  loc loss 44.098297119140625\n",
      "cls loss 371.6959228515625  loc loss 25.5771541595459\n",
      "cls loss 697.5904541015625  loc loss 47.32278060913086\n",
      "cls loss 263.7794189453125  loc loss 18.317798614501953\n",
      "cls loss 648.392822265625  loc loss 43.68034362792969\n",
      "cls loss 611.685791015625  loc loss 47.38687515258789\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 38.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16., 16., 16.,  9.,  9.,  9., 16., 16., 16., 85.,  9.])\n",
      "cls loss 585.316162109375  loc loss 39.021202087402344\n",
      "cls loss 666.62255859375  loc loss 55.43914794921875\n",
      "cls loss 963.9065551757812  loc loss 71.83184051513672\n",
      "cls loss 1311.872314453125  loc loss 95.23162841796875\n",
      "cls loss 408.25836181640625  loc loss 21.439014434814453\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3., 10.,  8.,  8., 10., 10., 10.,  3.,  3., 14.])\n",
      "cls loss 508.0665283203125  loc loss 24.868289947509766\n",
      "cls loss 833.541015625  loc loss 47.28095626831055\n",
      "cls loss 365.3085632324219  loc loss 15.008951187133789\n",
      "cls loss 569.20556640625  loc loss 26.440570831298828\n",
      "cls loss 886.21435546875  loc loss 47.53350830078125\n",
      "cls loss 678.5469360351562  loc loss 45.59358215332031\n",
      "cls loss 409.47174072265625  loc loss 21.623910903930664\n",
      "cls loss 443.51507568359375  loc loss 27.887306213378906\n",
      "cls loss 650.0831909179688  loc loss 43.77843475341797\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42., 42.,  1.])\n",
      "cls loss 594.3652954101562  loc loss 44.97492980957031\n",
      "cls loss 529.0224609375  loc loss 32.83456039428711\n",
      "cls loss 699.7202758789062  loc loss 54.6962890625\n",
      "cls loss 764.3187255859375  loc loss 54.142303466796875\n",
      "cls loss 557.0805053710938  loc loss 36.09409713745117\n",
      "cls loss 667.292236328125  loc loss 49.187461853027344\n",
      "cls loss 436.4600524902344  loc loss 29.05817985534668\n",
      "cls loss 486.8663330078125  loc loss 32.99213790893555\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20.])\n",
      "cls loss 358.609130859375  loc loss 22.124713897705078\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([11.])\n",
      "cls loss 453.1886901855469  loc loss 25.646072387695312\n",
      "cls loss 322.8717041015625  loc loss 19.77658462524414\n",
      "cls loss 697.21875  loc loss 59.64274597167969\n",
      "cls loss 345.2966003417969  loc loss 16.320175170898438\n",
      "cls loss 669.4246215820312  loc loss 41.87678527832031\n",
      "cls loss 398.039794921875  loc loss 23.12860107421875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 35., 27.])\n",
      "cls loss 652.2283325195312  loc loss 42.62274932861328\n",
      "cls loss 643.6008911132812  loc loss 54.79249572753906\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 512.8945922851562  loc loss 32.5826530456543\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([42.,  1.])\n",
      "cls loss 663.9928588867188  loc loss 50.184608459472656\n",
      "cls loss 601.3646240234375  loc loss 35.775596618652344\n",
      "cls loss 754.504638671875  loc loss 41.0804328918457\n",
      "cls loss 854.025634765625  loc loss 58.45123291015625\n",
      "cls loss 753.33837890625  loc loss 51.452552795410156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 509.2933349609375  loc loss 41.520896911621094\n",
      "cls loss 442.9810485839844  loc loss 35.53422546386719\n",
      "cls loss 298.2632751464844  loc loss 15.017578125\n",
      "cls loss 529.5003662109375  loc loss 32.33024978637695\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 1., 1.])\n",
      "cls loss 492.561767578125  loc loss 28.96446990966797\n",
      "cls loss 542.8565673828125  loc loss 42.207733154296875\n",
      "cls loss 554.4168090820312  loc loss 37.78196716308594\n",
      "cls loss 467.83856201171875  loc loss 35.45216369628906\n",
      "cls loss 560.3192138671875  loc loss 36.19723892211914\n",
      "cls loss 602.64306640625  loc loss 46.07427978515625\n",
      "cls loss 853.3885498046875  loc loss 51.20320129394531\n",
      "cls loss 756.1397705078125  loc loss 57.34709548950195\n",
      "cls loss 699.6118774414062  loc loss 41.324928283691406\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 526.2310791015625  loc loss 38.984596252441406\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 622.0311279296875  loc loss 31.233827590942383\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([81.])\n",
      "cls loss 750.1958618164062  loc loss 50.02143096923828\n",
      "cls loss 465.68927001953125  loc loss 32.301124572753906\n",
      "cls loss 339.91766357421875  loc loss 22.371902465820312\n",
      "cls loss 499.89349365234375  loc loss 26.96479034423828\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3.,  1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 19.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 19.])\n",
      "cls loss 678.9464111328125  loc loss 48.13876724243164\n",
      "cls loss 382.797607421875  loc loss 19.771949768066406\n",
      "cls loss 397.36285400390625  loc loss 26.345745086669922\n",
      "cls loss 785.79296875  loc loss 59.962013244628906\n",
      "cls loss 427.2254638671875  loc loss 26.978084564208984\n",
      "cls loss 488.544921875  loc loss 37.52582931518555\n",
      "cls loss 610.31494140625  loc loss 43.43153762817383\n",
      "cls loss 472.7177734375  loc loss 37.67872619628906\n",
      "cls loss 642.787841796875  loc loss 39.673301696777344\n",
      "cls loss 733.224609375  loc loss 51.633384704589844\n",
      "cls loss 873.53466796875  loc loss 79.90829467773438\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 81.])\n",
      "cls loss 624.3219604492188  loc loss 35.43388366699219\n",
      "cls loss 576.0232543945312  loc loss 32.76723098754883\n",
      "cls loss 627.6293334960938  loc loss 35.623374938964844\n",
      "cls loss 455.5193176269531  loc loss 23.0867977142334\n",
      "cls loss 432.387939453125  loc loss 26.798847198486328\n",
      "cls loss 510.2521667480469  loc loss 36.22685623168945\n",
      "cls loss 403.7774658203125  loc loss 27.85138511657715\n",
      "cls loss 311.9722900390625  loc loss 22.175161361694336\n",
      "cls loss 404.7889404296875  loc loss 30.20148468017578\n",
      "cls loss 582.0245361328125  loc loss 37.735862731933594\n",
      "cls loss 481.7308349609375  loc loss 38.20607376098633\n",
      "cls loss 509.6690673828125  loc loss 41.09505081176758\n",
      "cls loss 304.006591796875  loc loss 23.929363250732422\n",
      "cls loss 1020.744873046875  loc loss 76.48487091064453\n",
      "cls loss 682.5550537109375  loc loss 48.82274627685547\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 575.979736328125  loc loss 33.169105529785156\n",
      "cls loss 640.8209228515625  loc loss 43.93362045288086\n",
      "cls loss 526.9473876953125  loc loss 29.748504638671875\n",
      "cls loss 755.0123901367188  loc loss 45.5754280090332\n",
      "cls loss 709.8359375  loc loss 46.333702087402344\n",
      "cls loss 637.9456787109375  loc loss 40.285133361816406\n",
      "cls loss 537.8768310546875  loc loss 29.429664611816406\n",
      "cls loss 392.27264404296875  loc loss 23.81768035888672\n",
      "cls loss 549.2274169921875  loc loss 37.0495719909668\n",
      "cls loss 576.7511596679688  loc loss 43.22259521484375\n",
      "cls loss 639.112548828125  loc loss 36.8427848815918\n",
      "cls loss 776.5035400390625  loc loss 62.41887664794922\n",
      "cls loss 836.1138916015625  loc loss 62.84101104736328\n",
      "cls loss 563.5875244140625  loc loss 42.24132537841797\n",
      "cls loss 718.9205322265625  loc loss 61.181922912597656\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1., 38., 47.,  1.,  1.,  1.,  1.,  1., 62.])\n",
      "cls loss 514.170654296875  loc loss 31.097089767456055\n",
      "cls loss 654.907958984375  loc loss 39.841583251953125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 715.5397338867188  loc loss 43.50293731689453\n",
      "cls loss 808.7490844726562  loc loss 57.95804214477539\n",
      "cls loss 560.0047607421875  loc loss 28.155237197875977\n",
      "cls loss 589.9429931640625  loc loss 48.563880920410156\n",
      "cls loss 563.347412109375  loc loss 36.79582214355469\n",
      "cls loss 357.119384765625  loc loss 15.495189666748047\n",
      "cls loss 548.1326293945312  loc loss 32.3525390625\n",
      "cls loss 450.4820251464844  loc loss 22.691638946533203\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1., 35.])\n",
      "cls loss 528.32763671875  loc loss 28.148788452148438\n",
      "cls loss 772.8758544921875  loc loss 43.175636291503906\n",
      "cls loss 710.5807495117188  loc loss 49.06902313232422\n",
      "cls loss 664.393798828125  loc loss 54.97819519042969\n",
      "cls loss 523.02978515625  loc loss 43.57732009887695\n",
      "cls loss 664.8218383789062  loc loss 51.30621337890625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 383.8185729980469  loc loss 23.762928009033203\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 588.0439453125  loc loss 29.634042739868164\n",
      "cls loss 920.1385498046875  loc loss 52.8157958984375\n",
      "cls loss 1081.242431640625  loc loss 83.49235534667969\n",
      "cls loss 567.104736328125  loc loss 31.310903549194336\n",
      "cls loss 496.33251953125  loc loss 30.475231170654297\n",
      "cls loss 506.8880920410156  loc loss 31.246484756469727\n",
      "cls loss 551.962646484375  loc loss 43.78562927246094\n",
      "cls loss 548.2808227539062  loc loss 21.677440643310547\n",
      "cls loss 850.9591064453125  loc loss 63.96238708496094\n",
      "cls loss 677.9974975585938  loc loss 42.75115966796875\n",
      "cls loss 411.7398986816406  loc loss 24.427902221679688\n",
      "cls loss 708.2721557617188  loc loss 39.65724563598633\n",
      "cls loss 826.33154296875  loc loss 64.38825988769531\n",
      "cls loss 643.2809448242188  loc loss 43.572635650634766\n",
      "cls loss 590.3629150390625  loc loss 33.95781326293945\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.])\n",
      "cls loss 567.8242797851562  loc loss 42.28546905517578\n",
      "cls loss 471.1176452636719  loc loss 39.44392395019531\n",
      "cls loss 723.0628051757812  loc loss 47.18313980102539\n",
      "cls loss 990.395751953125  loc loss 85.62312316894531\n",
      "cls loss 462.7393493652344  loc loss 22.836580276489258\n",
      "cls loss 555.8355102539062  loc loss 37.247467041015625\n",
      "cls loss 486.1122741699219  loc loss 29.055461883544922\n",
      "cls loss 535.32373046875  loc loss 33.22723388671875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 21., 21., 21.])\n",
      "cls loss 594.539306640625  loc loss 33.19452667236328\n",
      "cls loss 546.779052734375  loc loss 25.242416381835938\n",
      "cls loss 559.7926025390625  loc loss 37.15355682373047\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 35.])\n",
      "cls loss 810.679931640625  loc loss 54.89214324951172\n",
      "cls loss 277.4040222167969  loc loss 15.213150024414062\n",
      "cls loss 424.1864929199219  loc loss 29.209917068481445\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 419.93707275390625  loc loss 23.77347755432129\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 38., 38.,  9., 38.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1.,  1.])\n",
      "cls loss 462.3763122558594  loc loss 35.75877380371094\n",
      "cls loss 747.9806518554688  loc loss 55.042362213134766\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 2.,  1., 77., 31., 10., 10.,  1.,  4., 10.])\n",
      "cls loss 417.2337646484375  loc loss 20.854751586914062\n",
      "cls loss 732.1444091796875  loc loss 48.073448181152344\n",
      "cls loss 1442.5189208984375  loc loss 100.1917495727539\n",
      "cls loss 492.2637939453125  loc loss 31.404346466064453\n",
      "cls loss 650.6128540039062  loc loss 54.426788330078125\n",
      "cls loss 482.17633056640625  loc loss 30.65079116821289\n",
      "cls loss 501.26239013671875  loc loss 26.256834030151367\n",
      "cls loss 864.9669189453125  loc loss 34.757442474365234\n",
      "cls loss 742.3331298828125  loc loss 41.11042785644531\n",
      "cls loss 646.877197265625  loc loss 45.56805419921875\n",
      "cls loss 491.067138671875  loc loss 25.369653701782227\n",
      "cls loss 566.1276245117188  loc loss 28.421327590942383\n",
      "cls loss 1032.722900390625  loc loss 63.58102035522461\n",
      "cls loss 842.992431640625  loc loss 56.69345474243164\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1., 42., 42., 42., 42., 42., 42.,  1.,\n",
      "         1.,  1.,  1., 42.,  1.,  1., 42.,  1.])\n",
      "cls loss 493.0041198730469  loc loss 34.737205505371094\n",
      "cls loss 708.24609375  loc loss 46.540130615234375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 325.3808288574219  loc loss 22.07278823852539\n",
      "cls loss 672.0921630859375  loc loss 49.409297943115234\n",
      "cls loss 541.9328002929688  loc loss 41.385719299316406\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([11.])\n",
      "cls loss 335.0454406738281  loc loss 19.736371994018555\n",
      "cls loss 435.47821044921875  loc loss 21.206565856933594\n",
      "cls loss 447.4398498535156  loc loss 22.892486572265625\n",
      "cls loss 634.7562866210938  loc loss 45.67319107055664\n",
      "cls loss 621.634033203125  loc loss 37.202919006347656\n",
      "cls loss 602.4203491210938  loc loss 45.63249969482422\n",
      "cls loss 883.7296752929688  loc loss 50.09518814086914\n",
      "cls loss 492.4268798828125  loc loss 30.052845001220703\n",
      "cls loss 873.7838134765625  loc loss 67.52657318115234\n",
      "cls loss 516.4833984375  loc loss 28.62630844116211\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 446.7392272949219  loc loss 31.22901725769043\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1., 38., 38., 42.])\n",
      "cls loss 569.6402587890625  loc loss 41.60807418823242\n",
      "cls loss 520.125  loc loss 27.838788986206055\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 430.77337646484375  loc loss 31.46236228942871\n",
      "cls loss 971.11279296875  loc loss 71.77901458740234\n",
      "cls loss 578.2314453125  loc loss 43.825008392333984\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10.,  3.,  3.,  6.,  8.,  8.,  1.,  1.,  1., 10.])\n",
      "cls loss 510.447021484375  loc loss 31.60991859436035\n",
      "cls loss 299.41595458984375  loc loss 12.584046363830566\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10.,  3.])\n",
      "cls loss 483.0673828125  loc loss 28.176979064941406\n",
      "cls loss 303.2062683105469  loc loss 14.254677772521973\n",
      "cls loss 548.3370361328125  loc loss 46.25625991821289\n",
      "cls loss 616.0921020507812  loc loss 46.16619873046875\n",
      "cls loss 488.00152587890625  loc loss 30.882205963134766\n",
      "cls loss 372.8844299316406  loc loss 18.242332458496094\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 34.])\n",
      "cls loss 878.3461303710938  loc loss 52.88804626464844\n",
      "cls loss 881.406494140625  loc loss 74.87474822998047\n",
      "cls loss 587.6632080078125  loc loss 47.66273880004883\n",
      "cls loss 437.0654296875  loc loss 32.20042419433594\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.,  1.])\n",
      "cls loss 494.171875  loc loss 27.530479431152344\n",
      "cls loss 775.2515869140625  loc loss 63.0792236328125\n",
      "cls loss 1134.0491943359375  loc loss 78.17446899414062\n",
      "cls loss 964.7689208984375  loc loss 52.92210388183594\n",
      "cls loss 565.18115234375  loc loss 32.7012939453125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 725.5610961914062  loc loss 41.33006286621094\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10.])\n",
      "cls loss 429.50738525390625  loc loss 24.659473419189453\n",
      "cls loss 612.861083984375  loc loss 32.71769714355469\n",
      "cls loss 583.0501098632812  loc loss 33.63945388793945\n",
      "cls loss 405.417724609375  loc loss 26.04045867919922\n",
      "cls loss 498.65985107421875  loc loss 38.23979187011719\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21.,\n",
      "        21.])\n",
      "cls loss 683.8973388671875  loc loss 42.92033767700195\n",
      "cls loss 560.4672241210938  loc loss 40.43294143676758\n",
      "cls loss 368.11376953125  loc loss 17.682815551757812\n",
      "cls loss 753.8690185546875  loc loss 51.50802993774414\n",
      "cls loss 597.8468017578125  loc loss 43.74845504760742\n",
      "cls loss 430.1961669921875  loc loss 28.50788116455078\n",
      "cls loss 886.5393676757812  loc loss 65.59268951416016\n",
      "cls loss 1078.9544677734375  loc loss 76.03976440429688\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15., 85.])\n",
      "cls loss 714.2554931640625  loc loss 45.21492004394531\n",
      "cls loss 675.6420288085938  loc loss 52.893611907958984\n",
      "cls loss 727.35302734375  loc loss 51.29746627807617\n",
      "cls loss 632.7092895507812  loc loss 37.85493469238281\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 8., 8.])\n",
      "cls loss 402.62420654296875  loc loss 22.098506927490234\n",
      "cls loss 467.506103515625  loc loss 30.54959487915039\n",
      "cls loss 539.4736938476562  loc loss 33.692222595214844\n",
      "cls loss 451.69671630859375  loc loss 26.66122817993164\n",
      "cls loss 525.1506958007812  loc loss 33.27735900878906\n",
      "cls loss 680.466552734375  loc loss 43.31541442871094\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1., 35., 27., 27.,  1., 27.,  1.])\n",
      "cls loss 978.4583740234375  loc loss 66.38648223876953\n",
      "cls loss 439.9171142578125  loc loss 33.55017852783203\n",
      "cls loss 543.91259765625  loc loss 41.48414611816406\n",
      "cls loss 511.65570068359375  loc loss 45.512107849121094\n",
      "cls loss 496.324951171875  loc loss 37.230045318603516\n",
      "cls loss 513.7320556640625  loc loss 41.91603469848633\n",
      "cls loss 525.6411743164062  loc loss 41.87199401855469\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  2.,  2.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  2.,  2.])\n",
      "cls loss 354.3055419921875  loc loss 13.611750602722168\n",
      "cls loss 786.6749267578125  loc loss 49.88502502441406\n",
      "cls loss 574.3372802734375  loc loss 29.451318740844727\n",
      "cls loss 908.3850708007812  loc loss 66.3752670288086\n",
      "cls loss 383.45965576171875  loc loss 24.335704803466797\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 19., 19., 19., 16.])\n",
      "cls loss 393.5555114746094  loc loss 19.052074432373047\n",
      "cls loss 310.1805419921875  loc loss 15.59473705291748\n",
      "cls loss 469.78204345703125  loc loss 25.403785705566406\n",
      "cls loss 618.9630126953125  loc loss 42.603187561035156\n",
      "cls loss 319.691162109375  loc loss 25.07488441467285\n",
      "cls loss 716.9058837890625  loc loss 52.6252326965332\n",
      "cls loss 498.2810363769531  loc loss 37.75366973876953\n",
      "cls loss 539.9644775390625  loc loss 38.342777252197266\n",
      "cls loss 664.5438232421875  loc loss 50.99675369262695\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 767.841552734375  loc loss 36.63138198852539\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 972.5116577148438  loc loss 85.46955108642578\n",
      "cls loss 1207.0546875  loc loss 121.73985290527344\n",
      "cls loss 606.4462280273438  loc loss 46.0183219909668\n",
      "cls loss 578.2909545898438  loc loss 39.237510681152344\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3.,  3.,  3.,  3.,  3., 10.])\n",
      "cls loss 361.8412170410156  loc loss 17.968982696533203\n",
      "cls loss 655.1286010742188  loc loss 35.180885314941406\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 1., 1., 1., 3., 3., 3., 3.])\n",
      "cls loss 522.4683837890625  loc loss 34.67489242553711\n",
      "cls loss 901.3748779296875  loc loss 65.41414642333984\n",
      "cls loss 723.5897216796875  loc loss 51.08345413208008\n",
      "cls loss 530.3521728515625  loc loss 29.664777755737305\n",
      "cls loss 719.6846923828125  loc loss 56.831687927246094\n",
      "cls loss 454.4505615234375  loc loss 35.85260009765625\n",
      "cls loss 712.2400512695312  loc loss 53.394134521484375\n",
      "cls loss 552.49169921875  loc loss 48.865272521972656\n",
      "cls loss 523.6326904296875  loc loss 38.419212341308594\n",
      "cls loss 1138.3330078125  loc loss 96.76538848876953\n",
      "cls loss 733.5299682617188  loc loss 53.15680694580078\n",
      "cls loss 506.53509521484375  loc loss 26.133054733276367\n",
      "cls loss 338.926513671875  loc loss 16.02061653137207\n",
      "cls loss 387.0299987792969  loc loss 21.51648712158203\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3., 10., 10., 10., 10., 10., 10., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10., 10., 10., 10., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 11., 10., 10., 10., 10., 10.,  3.,  3.,  3.,  3.,  3.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 11., 10., 10., 10., 10., 10.,  3.,  3.,  3.,  3.,  3.])\n",
      "cls loss 393.9678955078125  loc loss 19.03141212463379\n",
      "cls loss 491.79339599609375  loc loss 23.880481719970703\n",
      "cls loss 411.3846740722656  loc loss 25.42295265197754\n",
      "cls loss 393.27203369140625  loc loss 16.999584197998047\n",
      "cls loss 470.51287841796875  loc loss 36.39179229736328\n",
      "cls loss 409.47412109375  loc loss 15.870552062988281\n",
      "cls loss 689.01025390625  loc loss 47.89146423339844\n",
      "cls loss 604.7347412109375  loc loss 44.96249771118164\n",
      "cls loss 902.7738037109375  loc loss 61.41767501831055\n",
      "cls loss 444.5423583984375  loc loss 34.82331466674805\n",
      "cls loss 792.2508544921875  loc loss 55.75718307495117\n",
      "cls loss 647.8961181640625  loc loss 46.49639892578125\n",
      "cls loss 606.233642578125  loc loss 42.35723114013672\n",
      "cls loss 617.2445068359375  loc loss 47.87076187133789\n",
      "cls loss 847.10498046875  loc loss 58.60491943359375\n",
      "cls loss 821.572021484375  loc loss 52.02290725708008\n",
      "cls loss 402.42010498046875  loc loss 23.678607940673828\n",
      "cls loss 698.0272216796875  loc loss 55.99110412597656\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 10.,  1., 18.])\n",
      "cls loss 371.95166015625  loc loss 25.924686431884766\n",
      "cls loss 423.53564453125  loc loss 18.519697189331055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 743.591796875  loc loss 37.709373474121094\n",
      "cls loss 1004.9275512695312  loc loss 69.35289764404297\n",
      "cls loss 630.1486206054688  loc loss 43.847801208496094\n",
      "cls loss 851.30126953125  loc loss 52.217750549316406\n",
      "cls loss 585.7340087890625  loc loss 41.438262939453125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.,  1.,  1.])\n",
      "cls loss 774.58203125  loc loss 52.714412689208984\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1., 38.,  1.])\n",
      "cls loss 739.063232421875  loc loss 43.99723815917969\n",
      "cls loss 946.6793212890625  loc loss 71.8353042602539\n",
      "cls loss 473.79400634765625  loc loss 37.463706970214844\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 643.040283203125  loc loss 47.00025939941406\n",
      "cls loss 563.2984619140625  loc loss 39.641998291015625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3., 10.,  8.,  3., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.])\n",
      "cls loss 688.6123046875  loc loss 45.384010314941406\n",
      "cls loss 485.81585693359375  loc loss 32.04581069946289\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3.,  3., 11.,  3., 10., 10.,  3.,  3., 10.])\n",
      "cls loss 570.869384765625  loc loss 29.583370208740234\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3., 10., 10., 10.])\n",
      "cls loss 571.4471435546875  loc loss 41.37204360961914\n",
      "cls loss 488.31805419921875  loc loss 28.015621185302734\n",
      "cls loss 611.818359375  loc loss 44.580467224121094\n",
      "cls loss 985.689697265625  loc loss 58.39335250854492\n",
      "cls loss 600.184814453125  loc loss 40.33701705932617\n",
      "cls loss 422.79931640625  loc loss 37.50949478149414\n",
      "cls loss 524.1883544921875  loc loss 39.034400939941406\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 9.,  9., 85., 85.])\n",
      "cls loss 479.88861083984375  loc loss 27.414464950561523\n",
      "cls loss 530.8143310546875  loc loss 37.340301513671875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 880.010498046875  loc loss 67.97441864013672\n",
      "cls loss 745.3447265625  loc loss 39.79728698730469\n",
      "cls loss 842.6890869140625  loc loss 61.30059814453125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10., 10., 10., 10.])\n",
      "cls loss 543.2806396484375  loc loss 34.45458221435547\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([13.])\n",
      "cls loss 870.9849853515625  loc loss 68.78450775146484\n",
      "cls loss 310.9422302246094  loc loss 17.71932029724121\n",
      "cls loss 377.919189453125  loc loss 21.019134521484375\n",
      "cls loss 540.4674682617188  loc loss 29.583335876464844\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19.,  1.,  1.,  1., 19., 19.])\n",
      "cls loss 558.0877685546875  loc loss 35.59770202636719\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 408.43951416015625  loc loss 35.55282211303711\n",
      "cls loss 649.7587890625  loc loss 47.32875061035156\n",
      "cls loss 454.5491943359375  loc loss 27.946989059448242\n",
      "cls loss 670.8560180664062  loc loss 42.620121002197266\n",
      "cls loss 722.9837036132812  loc loss 55.9921760559082\n",
      "cls loss 581.0015869140625  loc loss 32.45646286010742\n",
      "cls loss 796.823974609375  loc loss 61.3995475769043\n",
      "cls loss 349.8760986328125  loc loss 16.442575454711914\n",
      "cls loss 579.7146606445312  loc loss 38.504703521728516\n",
      "cls loss 461.19464111328125  loc loss 24.939918518066406\n",
      "cls loss 477.232666015625  loc loss 28.160846710205078\n",
      "cls loss 610.4483642578125  loc loss 46.122833251953125\n",
      "cls loss 588.0171508789062  loc loss 35.81280517578125\n",
      "cls loss 851.289306640625  loc loss 55.761905670166016\n",
      "cls loss 521.7530517578125  loc loss 38.28998947143555\n",
      "cls loss 658.5201416015625  loc loss 47.0319709777832\n",
      "cls loss 973.36962890625  loc loss 64.55018615722656\n",
      "cls loss 556.9901123046875  loc loss 43.443260192871094\n",
      "cls loss 631.5591430664062  loc loss 39.31854248046875\n",
      "cls loss 792.382080078125  loc loss 58.50267028808594\n",
      "cls loss 790.4755859375  loc loss 58.23988342285156\n",
      "cls loss 1011.46240234375  loc loss 57.35363006591797\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 5.])\n",
      "cls loss 316.09393310546875  loc loss 11.676078796386719\n",
      "cls loss 392.6968688964844  loc loss 17.466228485107422\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 13.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 6., 8., 8.])\n",
      "cls loss 351.6935119628906  loc loss 16.809326171875\n",
      "cls loss 393.4398193359375  loc loss 23.229576110839844\n",
      "cls loss 768.9442749023438  loc loss 55.56651306152344\n",
      "cls loss 341.9254455566406  loc loss 17.439544677734375\n",
      "cls loss 614.1366577148438  loc loss 47.199337005615234\n",
      "cls loss 952.2904052734375  loc loss 67.27391052246094\n",
      "cls loss 561.989990234375  loc loss 44.628326416015625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([42., 42.,  1.,  1.,  1.,  1.,  1.,  1.,  1., 42., 42.])\n",
      "cls loss 617.6666259765625  loc loss 39.04869842529297\n",
      "cls loss 824.1162109375  loc loss 65.67799377441406\n",
      "cls loss 648.7140502929688  loc loss 55.954158782958984\n",
      "cls loss 484.55010986328125  loc loss 29.79595947265625\n",
      "cls loss 656.2723388671875  loc loss 41.413150787353516\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 899.072509765625  loc loss 59.24889373779297\n",
      "cls loss 700.9751586914062  loc loss 51.667945861816406\n",
      "cls loss 465.73370361328125  loc loss 28.504426956176758\n",
      "cls loss 396.4161376953125  loc loss 20.517822265625\n",
      "cls loss 547.9968872070312  loc loss 33.307979583740234\n",
      "cls loss 718.4149169921875  loc loss 49.43247604370117\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15.])\n",
      "cls loss 343.56884765625  loc loss 18.307098388671875\n",
      "cls loss 556.8455810546875  loc loss 38.366363525390625\n",
      "cls loss 500.7842102050781  loc loss 34.388824462890625\n",
      "cls loss 880.13916015625  loc loss 64.07350158691406\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19.,  7.])\n",
      "cls loss 504.09478759765625  loc loss 32.52471923828125\n",
      "cls loss 1023.927978515625  loc loss 65.95960235595703\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 856.7247314453125  loc loss 47.96271896362305\n",
      "cls loss 660.5303955078125  loc loss 52.99671936035156\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([38., 38.,  1., 18.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1., 18., 18.,  1.])\n",
      "cls loss 543.50830078125  loc loss 29.183773040771484\n",
      "cls loss 508.97027587890625  loc loss 25.9916934967041\n",
      "cls loss 890.0882568359375  loc loss 71.6191177368164\n",
      "cls loss 704.3409423828125  loc loss 41.21941375732422\n",
      "cls loss 692.7410888671875  loc loss 35.32353210449219\n",
      "cls loss 374.3877868652344  loc loss 29.156408309936523\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.])\n",
      "cls loss 314.73193359375  loc loss 10.92617416381836\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([32.])\n",
      "cls loss 598.0682373046875  loc loss 30.65818977355957\n",
      "cls loss 518.59375  loc loss 36.21025466918945\n",
      "cls loss 684.33935546875  loc loss 56.41155242919922\n",
      "cls loss 641.6689453125  loc loss 40.759437561035156\n",
      "cls loss 513.230224609375  loc loss 34.106021881103516\n",
      "cls loss 797.598388671875  loc loss 51.451656341552734\n",
      "cls loss 842.5106201171875  loc loss 61.02594757080078\n",
      "cls loss 678.2544555664062  loc loss 47.33912658691406\n",
      "cls loss 570.78564453125  loc loss 34.86042785644531\n",
      "cls loss 901.272705078125  loc loss 58.56825637817383\n",
      "cls loss 553.9640502929688  loc loss 30.56886863708496\n",
      "cls loss 873.7842407226562  loc loss 74.2830810546875\n",
      "cls loss 655.7647705078125  loc loss 39.50687789916992\n",
      "cls loss 546.2031860351562  loc loss 40.142822265625\n",
      "cls loss 422.9058837890625  loc loss 23.44135093688965\n",
      "cls loss 454.9686279296875  loc loss 30.2227783203125\n",
      "cls loss 687.62841796875  loc loss 47.39698028564453\n",
      "cls loss 703.8378295898438  loc loss 52.82666778564453\n",
      "cls loss 419.9957580566406  loc loss 29.40467071533203\n",
      "cls loss 782.7027587890625  loc loss 53.44406509399414\n",
      "cls loss 915.53076171875  loc loss 57.14087677001953\n",
      "cls loss 348.46435546875  loc loss 24.41110610961914\n",
      "cls loss 873.0965576171875  loc loss 61.214752197265625\n",
      "cls loss 627.2465209960938  loc loss 49.02802658081055\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 861.2799072265625  loc loss 68.06131744384766\n",
      "cls loss 429.30145263671875  loc loss 17.43952178955078\n",
      "cls loss 645.855712890625  loc loss 36.40983963012695\n",
      "cls loss 632.5390014648438  loc loss 44.4758415222168\n",
      "cls loss 501.8172912597656  loc loss 30.514728546142578\n",
      "cls loss 315.27679443359375  loc loss 16.84910011291504\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 9., 9., 1., 9., 9., 9., 9., 1., 9.])\n",
      "cls loss 1096.7615966796875  loc loss 96.54316711425781\n",
      "cls loss 647.5966796875  loc loss 35.30805206298828\n",
      "cls loss 956.9481201171875  loc loss 81.11214447021484\n",
      "cls loss 408.6471252441406  loc loss 27.999935150146484\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 42., 42.])\n",
      "cls loss 683.70458984375  loc loss 52.2413215637207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 733.8056030273438  loc loss 53.931968688964844\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  2.,  1.,  1.,  1., 38.,\n",
      "         1.,  1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 38., 38., 38.,  1., 38., 38., 38.,  1.,  1., 38.,  1.,\n",
      "         1.])\n",
      "cls loss 465.3576965332031  loc loss 31.956951141357422\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  8.,  8.])\n",
      "cls loss 1007.9002685546875  loc loss 70.01248931884766\n",
      "cls loss 1023.625  loc loss 73.19217681884766\n",
      "cls loss 412.18902587890625  loc loss 24.82838249206543\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([4., 1., 1., 4.])\n",
      "cls loss 583.280517578125  loc loss 42.18279266357422\n",
      "cls loss 690.8582763671875  loc loss 44.540252685546875\n",
      "cls loss 324.44244384765625  loc loss 15.36141300201416\n",
      "cls loss 435.2784729003906  loc loss 27.042177200317383\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([51.,  1.])\n",
      "cls loss 315.8952941894531  loc loss 14.044846534729004\n",
      "cls loss 405.65716552734375  loc loss 25.516550064086914\n",
      "cls loss 735.19677734375  loc loss 45.137569427490234\n",
      "cls loss 813.406005859375  loc loss 62.29812240600586\n",
      "cls loss 1091.0623779296875  loc loss 63.25149154663086\n",
      "cls loss 1377.2684326171875  loc loss 91.46369171142578\n",
      "cls loss 574.745361328125  loc loss 36.887611389160156\n",
      "cls loss 817.68359375  loc loss 58.24325180053711\n",
      "cls loss 858.19384765625  loc loss 63.25212097167969\n",
      "cls loss 663.4678955078125  loc loss 38.85813903808594\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  3.,  1.,  1.,  1.,  3.,  1.,  1.,\n",
      "         1.,  1.,  1.])\n",
      "cls loss 719.493408203125  loc loss 37.60258865356445\n",
      "cls loss 825.8212280273438  loc loss 41.631858825683594\n",
      "cls loss 727.4090576171875  loc loss 38.392738342285156\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "cls loss 585.5330810546875  loc loss 35.9080810546875\n",
      "cls loss 353.98724365234375  loc loss 28.723215103149414\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3.])\n",
      "cls loss 321.7992858886719  loc loss 14.488801002502441\n",
      "cls loss 527.2742309570312  loc loss 38.70682907104492\n",
      "cls loss 424.66839599609375  loc loss 32.67595291137695\n",
      "cls loss 760.2955322265625  loc loss 54.571746826171875\n",
      "cls loss 523.1904296875  loc loss 26.518701553344727\n",
      "cls loss 422.0028076171875  loc loss 30.084665298461914\n",
      "cls loss 1291.605224609375  loc loss 88.29997253417969\n",
      "cls loss 551.15087890625  loc loss 42.17439270019531\n",
      "cls loss 396.354248046875  loc loss 33.45253372192383\n",
      "cls loss 535.3201904296875  loc loss 32.82836151123047\n",
      "cls loss 466.64410400390625  loc loss 35.284034729003906\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 849.0828857421875  loc loss 60.353668212890625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  9., 64., 64., 64., 64., 64., 64., 64., 64., 64.,  9.,  9.,  9.,\n",
      "         9.])\n",
      "cls loss 485.3880615234375  loc loss 26.019554138183594\n",
      "cls loss 1146.897216796875  loc loss 91.4901123046875\n",
      "cls loss 584.6983642578125  loc loss 39.773765563964844\n",
      "cls loss 749.9117431640625  loc loss 56.61638641357422\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.,  3.,  3.])\n",
      "cls loss 499.5273742675781  loc loss 31.79034996032715\n",
      "cls loss 579.2550048828125  loc loss 35.89192581176758\n",
      "cls loss 550.7347412109375  loc loss 40.73466491699219\n",
      "cls loss 614.9876098632812  loc loss 42.52206039428711\n",
      "cls loss 578.6719970703125  loc loss 48.62687301635742\n",
      "cls loss 557.5558471679688  loc loss 45.048255920410156\n",
      "cls loss 554.1766967773438  loc loss 44.76534652709961\n",
      "cls loss 565.0455322265625  loc loss 37.79610824584961\n",
      "cls loss 718.570068359375  loc loss 52.960689544677734\n",
      "cls loss 617.9686279296875  loc loss 37.986244201660156\n",
      "cls loss 490.148681640625  loc loss 23.038427352905273\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21.])\n",
      "cls loss 372.4716796875  loc loss 20.438899993896484\n",
      "cls loss 509.14410400390625  loc loss 43.48385238647461\n",
      "cls loss 711.96435546875  loc loss 53.53507995605469\n",
      "cls loss 463.14801025390625  loc loss 27.030014038085938\n",
      "cls loss 647.5017700195312  loc loss 39.785980224609375\n",
      "cls loss 1152.50341796875  loc loss 67.11796569824219\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 42., 42.,  1.,  1.])\n",
      "cls loss 578.403564453125  loc loss 36.18968963623047\n",
      "cls loss 389.47821044921875  loc loss 28.64931297302246\n",
      "cls loss 527.0474853515625  loc loss 40.8150520324707\n",
      "cls loss 744.5616455078125  loc loss 63.59082794189453\n",
      "cls loss 483.01177978515625  loc loss 32.747684478759766\n",
      "cls loss 680.2061767578125  loc loss 53.54852294921875\n",
      "cls loss 661.9495239257812  loc loss 52.67517852783203\n",
      "cls loss 710.2783813476562  loc loss 43.746673583984375\n",
      "cls loss 567.127197265625  loc loss 36.21864318847656\n",
      "cls loss 507.77484130859375  loc loss 32.15753173828125\n",
      "cls loss 411.83197021484375  loc loss 18.970182418823242\n",
      "cls loss 517.948486328125  loc loss 37.3990478515625\n",
      "cls loss 756.4122314453125  loc loss 66.27767181396484\n",
      "cls loss 609.8895263671875  loc loss 40.081214904785156\n",
      "cls loss 615.658203125  loc loss 46.60478210449219\n",
      "cls loss 664.9249267578125  loc loss 37.65595245361328\n",
      "cls loss 975.8063354492188  loc loss 65.13349914550781\n",
      "cls loss 664.5284423828125  loc loss 53.63380432128906\n",
      "cls loss 790.5769653320312  loc loss 46.7639274597168\n",
      "cls loss 471.81878662109375  loc loss 23.974567413330078\n",
      "cls loss 659.2489624023438  loc loss 43.64210510253906\n",
      "cls loss 599.9774780273438  loc loss 41.497676849365234\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 5., 5., 5., 5., 5., 5.])\n",
      "cls loss 439.44061279296875  loc loss 30.471948623657227\n",
      "cls loss 513.0115356445312  loc loss 33.15861129760742\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([13.])\n",
      "cls loss 355.21331787109375  loc loss 23.076683044433594\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([44., 10.,  1.,  1.,  1.])\n",
      "cls loss 376.35931396484375  loc loss 23.42975425720215\n",
      "cls loss 701.31298828125  loc loss 38.23411560058594\n",
      "cls loss 563.3741455078125  loc loss 33.1705322265625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19., 19., 19., 19., 19., 19., 19.])\n",
      "cls loss 720.736572265625  loc loss 42.87617874145508\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([56.])\n",
      "cls loss 1297.403564453125  loc loss 78.7359390258789\n",
      "cls loss 686.3006591796875  loc loss 57.104801177978516\n",
      "cls loss 933.4400634765625  loc loss 69.46208190917969\n",
      "cls loss 908.1639404296875  loc loss 72.68556213378906\n",
      "cls loss 557.5494995117188  loc loss 35.24361038208008\n",
      "cls loss 910.239013671875  loc loss 68.08023071289062\n",
      "cls loss 554.840576171875  loc loss 33.03884506225586\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 36.])\n",
      "cls loss 648.502685546875  loc loss 37.37568283081055\n",
      "cls loss 553.1786499023438  loc loss 41.8830451965332\n",
      "cls loss 610.2147216796875  loc loss 35.53759765625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5.])\n",
      "cls loss 635.9434204101562  loc loss 41.575286865234375\n",
      "cls loss 372.4776916503906  loc loss 20.819873809814453\n",
      "cls loss 808.9464111328125  loc loss 49.32422637939453\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "cls loss 733.5009765625  loc loss 51.90803527832031\n",
      "cls loss 768.5515747070312  loc loss 48.07208251953125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 667.6050415039062  loc loss 48.97702407836914\n",
      "cls loss 791.7750244140625  loc loss 57.768768310546875\n",
      "cls loss 663.2628173828125  loc loss 60.6545295715332\n",
      "cls loss 475.8642272949219  loc loss 34.153350830078125\n",
      "cls loss 583.847412109375  loc loss 43.53584671020508\n",
      "cls loss 585.140380859375  loc loss 39.81977844238281\n",
      "cls loss 891.2652587890625  loc loss 55.794586181640625\n",
      "cls loss 428.08447265625  loc loss 22.789369583129883\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 11., 15., 10., 10., 10., 10., 10.])\n",
      "cls loss 960.7705078125  loc loss 68.69319915771484\n",
      "cls loss 552.4307250976562  loc loss 37.32194519042969\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3.])\n",
      "cls loss 607.4856567382812  loc loss 39.634765625\n",
      "cls loss 516.4586791992188  loc loss 31.815242767333984\n",
      "cls loss 569.5155029296875  loc loss 30.073287963867188\n",
      "cls loss 736.4879150390625  loc loss 39.13021469116211\n",
      "cls loss 428.64019775390625  loc loss 19.66924476623535\n",
      "cls loss 603.6685180664062  loc loss 36.77033996582031\n",
      "cls loss 659.3424072265625  loc loss 51.01789093017578\n",
      "cls loss 557.3531494140625  loc loss 43.09663772583008\n",
      "cls loss 1238.09521484375  loc loss 98.72455596923828\n",
      "cls loss 897.769287109375  loc loss 63.30768966674805\n",
      "cls loss 574.75830078125  loc loss 44.29619598388672\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  9.,  9.,  9.,  6.,  6., 85., 85.,  8.,  1.,  1.,  1.,  1.,\n",
      "         6.,  6.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 422.1832275390625  loc loss 30.05801010131836\n",
      "cls loss 935.8029174804688  loc loss 68.18189239501953\n",
      "cls loss 1108.92919921875  loc loss 73.64320373535156\n",
      "cls loss 771.6309814453125  loc loss 54.94428253173828\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10.,  3.,  3., 10.])\n",
      "cls loss 505.03533935546875  loc loss 31.51055145263672\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([7.])\n",
      "cls loss 673.6007690429688  loc loss 50.118316650390625\n",
      "cls loss 681.7457275390625  loc loss 41.88959503173828\n",
      "cls loss 624.118408203125  loc loss 47.984588623046875\n",
      "cls loss 906.371337890625  loc loss 69.33897399902344\n",
      "cls loss 660.6089477539062  loc loss 42.55105209350586\n",
      "cls loss 853.72607421875  loc loss 56.69157409667969\n",
      "cls loss 1024.56884765625  loc loss 65.37315368652344\n",
      "cls loss 633.067138671875  loc loss 44.367637634277344\n",
      "cls loss 657.56298828125  loc loss 46.861141204833984\n",
      "cls loss 563.7349853515625  loc loss 43.12908935546875\n",
      "cls loss 780.0758056640625  loc loss 66.19468688964844\n",
      "cls loss 657.055908203125  loc loss 43.98539733886719\n",
      "cls loss 509.779296875  loc loss 31.447526931762695\n",
      "cls loss 771.7055053710938  loc loss 61.527435302734375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([62.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([62.])\n",
      "cls loss 342.4874572753906  loc loss 20.576507568359375\n",
      "cls loss 622.005615234375  loc loss 46.69624328613281\n",
      "cls loss 611.611083984375  loc loss 41.963706970214844\n",
      "cls loss 449.135498046875  loc loss 19.503616333007812\n",
      "cls loss 787.4290771484375  loc loss 56.77727508544922\n",
      "cls loss 758.2574462890625  loc loss 47.84946823120117\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([28.])\n",
      "cls loss 846.3421020507812  loc loss 48.90026092529297\n",
      "cls loss 774.7191162109375  loc loss 49.412445068359375\n",
      "cls loss 735.751708984375  loc loss 48.59783172607422\n",
      "cls loss 764.2447509765625  loc loss 53.60026550292969\n",
      "cls loss 1037.59423828125  loc loss 73.74634552001953\n",
      "cls loss 584.2001953125  loc loss 39.69905471801758\n",
      "cls loss 734.26025390625  loc loss 46.62861633300781\n",
      "cls loss 662.015625  loc loss 56.36573791503906\n",
      "cls loss 1054.0283203125  loc loss 80.725341796875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([81.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 725.7034301757812  loc loss 32.73371124267578\n",
      "cls loss 564.536376953125  loc loss 28.926593780517578\n",
      "cls loss 478.4888000488281  loc loss 30.717561721801758\n",
      "cls loss 403.4772033691406  loc loss 18.078874588012695\n",
      "cls loss 456.11199951171875  loc loss 29.508197784423828\n",
      "cls loss 482.9771423339844  loc loss 32.42283248901367\n",
      "cls loss 549.227294921875  loc loss 35.68172073364258\n",
      "cls loss 722.4312744140625  loc loss 59.8968505859375\n",
      "cls loss 797.795166015625  loc loss 55.63259506225586\n",
      "cls loss 1520.78076171875  loc loss 109.85079956054688\n",
      "cls loss 611.7801513671875  loc loss 32.78007125854492\n",
      "cls loss 731.7392578125  loc loss 50.80370330810547\n",
      "cls loss 510.07965087890625  loc loss 34.73727035522461\n",
      "cls loss 702.6722412109375  loc loss 39.457698822021484\n",
      "cls loss 661.03173828125  loc loss 36.77037811279297\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([44., 44.])\n",
      "cls loss 560.2666015625  loc loss 28.74518394470215\n",
      "cls loss 576.7928466796875  loc loss 40.589664459228516\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15.])\n",
      "cls loss 679.7235107421875  loc loss 37.02821350097656\n",
      "cls loss 316.6061096191406  loc loss 18.738861083984375\n",
      "cls loss 650.0369873046875  loc loss 40.52515411376953\n",
      "cls loss 354.1192932128906  loc loss 24.360504150390625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([1., 3., 3.])\n",
      "cls loss 399.85125732421875  loc loss 32.54495620727539\n",
      "cls loss 348.699951171875  loc loss 15.753254890441895\n",
      "cls loss 618.9365844726562  loc loss 36.21746826171875\n",
      "cls loss 645.18359375  loc loss 39.339271545410156\n",
      "cls loss 593.10400390625  loc loss 38.88557815551758\n",
      "cls loss 603.822265625  loc loss 37.30492401123047\n",
      "cls loss 511.6768493652344  loc loss 38.68829345703125\n",
      "cls loss 645.4624633789062  loc loss 46.732666015625\n",
      "cls loss 528.4090576171875  loc loss 35.79179000854492\n",
      "cls loss 648.133544921875  loc loss 47.81676483154297\n",
      "cls loss 427.00640869140625  loc loss 26.550064086914062\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 759.985107421875  loc loss 48.17446517944336\n",
      "cls loss 869.1703491210938  loc loss 47.44879913330078\n",
      "cls loss 792.0814208984375  loc loss 55.233314514160156\n",
      "cls loss 771.7882080078125  loc loss 56.43804168701172\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10., 10., 10.,  1.,  1.,  1.,  1.,  1.,  1.,  8.,  8.,\n",
      "         1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10., 10., 10.,  1.,  1.,  1.,  1.,  1.,  1.,  8.,  8.,\n",
      "         1.])\n",
      "cls loss 758.3255615234375  loc loss 40.34651565551758\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 3., 3., 3.])\n",
      "cls loss 617.6925048828125  loc loss 40.37610626220703\n",
      "cls loss 435.03704833984375  loc loss 24.58234405517578\n",
      "cls loss 325.52789306640625  loc loss 18.414941787719727\n",
      "cls loss 590.8306274414062  loc loss 42.87083435058594\n",
      "cls loss 474.1497802734375  loc loss 25.04955291748047\n",
      "cls loss 514.498046875  loc loss 35.56229782104492\n",
      "cls loss 596.7805786132812  loc loss 40.7676887512207\n",
      "cls loss 822.5042724609375  loc loss 58.866722106933594\n",
      "cls loss 675.355224609375  loc loss 37.01047897338867\n",
      "cls loss 646.79052734375  loc loss 40.81156921386719\n",
      "cls loss 736.897216796875  loc loss 51.06443786621094\n",
      "cls loss 566.3966064453125  loc loss 42.055030822753906\n",
      "cls loss 941.7560424804688  loc loss 75.34191131591797\n",
      "cls loss 514.8636474609375  loc loss 29.008255004882812\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 737.26416015625  loc loss 46.992218017578125\n",
      "cls loss 393.49859619140625  loc loss 18.523834228515625\n",
      "cls loss 965.6219482421875  loc loss 63.237701416015625\n",
      "cls loss 499.0069274902344  loc loss 26.698457717895508\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 34.])\n",
      "cls loss 762.4857177734375  loc loss 43.39512634277344\n",
      "cls loss 360.26397705078125  loc loss 24.993288040161133\n",
      "cls loss 681.412841796875  loc loss 46.589012145996094\n",
      "cls loss 256.2529602050781  loc loss 18.04166603088379\n",
      "cls loss 632.4927978515625  loc loss 42.49958801269531\n",
      "cls loss 601.431640625  loc loss 46.795692443847656\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 38.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16., 16., 16.,  9.,  9.,  9., 16., 16., 16., 85.,  9.])\n",
      "cls loss 579.0489501953125  loc loss 38.488677978515625\n",
      "cls loss 660.112060546875  loc loss 54.43279266357422\n",
      "cls loss 945.608642578125  loc loss 70.1547622680664\n",
      "cls loss 1299.26953125  loc loss 93.0228042602539\n",
      "cls loss 404.3327941894531  loc loss 21.114477157592773\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3., 10.,  8.,  8., 10., 10., 10.,  3.,  3., 14.])\n",
      "cls loss 499.80816650390625  loc loss 24.32949447631836\n",
      "cls loss 836.2437744140625  loc loss 46.40470886230469\n",
      "cls loss 369.0459289550781  loc loss 14.711285591125488\n",
      "cls loss 569.0020751953125  loc loss 25.840103149414062\n",
      "cls loss 849.931884765625  loc loss 46.48612976074219\n",
      "cls loss 658.3314208984375  loc loss 44.55543518066406\n",
      "cls loss 396.62982177734375  loc loss 20.826698303222656\n",
      "cls loss 430.58544921875  loc loss 27.315574645996094\n",
      "cls loss 636.9969482421875  loc loss 43.02328872680664\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42., 42.,  1.])\n",
      "cls loss 583.2525634765625  loc loss 44.28602600097656\n",
      "cls loss 516.2808227539062  loc loss 32.08782958984375\n",
      "cls loss 690.0328369140625  loc loss 53.7187614440918\n",
      "cls loss 756.9307861328125  loc loss 53.2048454284668\n",
      "cls loss 548.4427490234375  loc loss 35.619693756103516\n",
      "cls loss 658.1396484375  loc loss 48.23830795288086\n",
      "cls loss 429.9842529296875  loc loss 28.623470306396484\n",
      "cls loss 478.5565185546875  loc loss 32.41504669189453\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20.])\n",
      "cls loss 357.1917419433594  loc loss 21.592435836791992\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([11.])\n",
      "cls loss 447.8236083984375  loc loss 25.15070915222168\n",
      "cls loss 320.74713134765625  loc loss 19.26247215270996\n",
      "cls loss 697.1959228515625  loc loss 58.35636520385742\n",
      "cls loss 342.6426086425781  loc loss 15.84929370880127\n",
      "cls loss 667.113037109375  loc loss 40.802528381347656\n",
      "cls loss 388.8628234863281  loc loss 22.874975204467773\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 35., 27.])\n",
      "cls loss 642.2353515625  loc loss 42.006317138671875\n",
      "cls loss 635.9237670898438  loc loss 53.50783157348633\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 502.7911071777344  loc loss 31.555419921875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([42.,  1.])\n",
      "cls loss 652.040771484375  loc loss 48.58375930786133\n",
      "cls loss 583.93115234375  loc loss 35.072120666503906\n",
      "cls loss 731.6659545898438  loc loss 40.58251953125\n",
      "cls loss 833.2299194335938  loc loss 57.58738708496094\n",
      "cls loss 742.687744140625  loc loss 50.150787353515625\n",
      "cls loss 503.7660217285156  loc loss 40.951995849609375\n",
      "cls loss 436.2226867675781  loc loss 35.11384201049805\n",
      "cls loss 292.8684997558594  loc loss 14.670296669006348\n",
      "cls loss 523.7298583984375  loc loss 31.60834503173828\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 1., 1.])\n",
      "cls loss 492.3937072753906  loc loss 28.2724552154541\n",
      "cls loss 540.8326416015625  loc loss 41.00636291503906\n",
      "cls loss 554.0744018554688  loc loss 37.05699157714844\n",
      "cls loss 466.00311279296875  loc loss 34.83074188232422\n",
      "cls loss 556.1630859375  loc loss 35.19497299194336\n",
      "cls loss 597.79541015625  loc loss 45.24200439453125\n",
      "cls loss 838.7037353515625  loc loss 50.28364944458008\n",
      "cls loss 732.38232421875  loc loss 56.225746154785156\n",
      "cls loss 678.9076538085938  loc loss 40.59636306762695\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 514.6893920898438  loc loss 37.99272537231445\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 605.4564208984375  loc loss 30.841524124145508\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([81.])\n",
      "cls loss 735.430419921875  loc loss 48.83873748779297\n",
      "cls loss 457.6252136230469  loc loss 31.682994842529297\n",
      "cls loss 329.59075927734375  loc loss 21.803165435791016\n",
      "cls loss 494.8966369628906  loc loss 26.72162628173828\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3.,  1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 19.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 19.])\n",
      "cls loss 668.1441650390625  loc loss 47.258052825927734\n",
      "cls loss 377.7541809082031  loc loss 19.50429916381836\n",
      "cls loss 395.60626220703125  loc loss 25.877944946289062\n",
      "cls loss 775.2818603515625  loc loss 58.72914123535156\n",
      "cls loss 419.50042724609375  loc loss 26.486845016479492\n",
      "cls loss 488.3407287597656  loc loss 36.80144500732422\n",
      "cls loss 610.24951171875  loc loss 42.442771911621094\n",
      "cls loss 470.3893127441406  loc loss 36.95423889160156\n",
      "cls loss 634.8385009765625  loc loss 38.96007537841797\n",
      "cls loss 722.7781982421875  loc loss 50.69214630126953\n",
      "cls loss 851.2430419921875  loc loss 78.79639434814453\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 81.])\n",
      "cls loss 615.046875  loc loss 34.821407318115234\n",
      "cls loss 550.4379272460938  loc loss 32.28364562988281\n",
      "cls loss 614.7772216796875  loc loss 34.887733459472656\n",
      "cls loss 446.7882080078125  loc loss 22.64347267150879\n",
      "cls loss 419.757568359375  loc loss 26.380809783935547\n",
      "cls loss 494.8388366699219  loc loss 35.64512634277344\n",
      "cls loss 396.173828125  loc loss 27.35845184326172\n",
      "cls loss 306.91436767578125  loc loss 21.589683532714844\n",
      "cls loss 399.5560302734375  loc loss 29.499452590942383\n",
      "cls loss 573.9393310546875  loc loss 36.97339630126953\n",
      "cls loss 476.9232177734375  loc loss 37.6879768371582\n",
      "cls loss 502.38250732421875  loc loss 40.60791015625\n",
      "cls loss 304.2213439941406  loc loss 23.626386642456055\n",
      "cls loss 1009.639892578125  loc loss 75.1474380493164\n",
      "cls loss 677.5823974609375  loc loss 47.70469665527344\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 572.1320190429688  loc loss 32.305442810058594\n",
      "cls loss 633.146484375  loc loss 43.02693176269531\n",
      "cls loss 523.318603515625  loc loss 29.31121063232422\n",
      "cls loss 733.9247436523438  loc loss 44.94170379638672\n",
      "cls loss 693.4605712890625  loc loss 45.65996551513672\n",
      "cls loss 618.6510009765625  loc loss 39.76469802856445\n",
      "cls loss 519.5306396484375  loc loss 29.03221893310547\n",
      "cls loss 378.7587890625  loc loss 23.40838623046875\n",
      "cls loss 542.3757934570312  loc loss 36.39118194580078\n",
      "cls loss 569.4790649414062  loc loss 42.19055938720703\n",
      "cls loss 628.7352294921875  loc loss 36.44797897338867\n",
      "cls loss 767.4859619140625  loc loss 61.7010498046875\n",
      "cls loss 822.7555541992188  loc loss 62.16912078857422\n",
      "cls loss 557.4564208984375  loc loss 41.939292907714844\n",
      "cls loss 714.02734375  loc loss 60.24655532836914\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1., 38., 47.,  1.,  1.,  1.,  1.,  1., 62.])\n",
      "cls loss 518.2327880859375  loc loss 30.329500198364258\n",
      "cls loss 657.893310546875  loc loss 39.06655502319336\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 712.1958618164062  loc loss 42.60635757446289\n",
      "cls loss 792.790283203125  loc loss 56.92668151855469\n",
      "cls loss 549.8529052734375  loc loss 27.53575897216797\n",
      "cls loss 580.1211547851562  loc loss 47.96376037597656\n",
      "cls loss 553.4853515625  loc loss 35.91244888305664\n",
      "cls loss 347.80560302734375  loc loss 15.020916938781738\n",
      "cls loss 538.5385131835938  loc loss 31.60405158996582\n",
      "cls loss 437.99102783203125  loc loss 22.045236587524414\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1., 35.])\n",
      "cls loss 522.2012939453125  loc loss 27.588294982910156\n",
      "cls loss 755.8125610351562  loc loss 42.17766571044922\n",
      "cls loss 697.7869873046875  loc loss 48.12015151977539\n",
      "cls loss 653.225830078125  loc loss 54.024505615234375\n",
      "cls loss 513.44091796875  loc loss 42.76750183105469\n",
      "cls loss 657.7237548828125  loc loss 50.56966781616211\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 381.9151306152344  loc loss 23.256961822509766\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 584.00390625  loc loss 29.043420791625977\n",
      "cls loss 914.7484741210938  loc loss 51.264530181884766\n",
      "cls loss 1076.2001953125  loc loss 82.2752685546875\n",
      "cls loss 563.2147827148438  loc loss 30.558269500732422\n",
      "cls loss 491.3200378417969  loc loss 30.10516929626465\n",
      "cls loss 498.667236328125  loc loss 30.433155059814453\n",
      "cls loss 536.5228271484375  loc loss 42.34751510620117\n",
      "cls loss 522.7862548828125  loc loss 21.27973175048828\n",
      "cls loss 830.4795532226562  loc loss 62.36389923095703\n",
      "cls loss 659.1537475585938  loc loss 41.99041748046875\n",
      "cls loss 398.6069030761719  loc loss 23.885311126708984\n",
      "cls loss 689.4337158203125  loc loss 38.630638122558594\n",
      "cls loss 809.4197998046875  loc loss 63.39777374267578\n",
      "cls loss 632.1485595703125  loc loss 42.66966247558594\n",
      "cls loss 584.171875  loc loss 33.07237243652344\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.])\n",
      "cls loss 553.1851806640625  loc loss 41.3433952331543\n",
      "cls loss 465.8287658691406  loc loss 38.827003479003906\n",
      "cls loss 708.2821044921875  loc loss 46.40482711791992\n",
      "cls loss 978.413818359375  loc loss 83.95831298828125\n",
      "cls loss 459.20916748046875  loc loss 22.38239097595215\n",
      "cls loss 555.4234008789062  loc loss 36.824928283691406\n",
      "cls loss 486.001953125  loc loss 28.387718200683594\n",
      "cls loss 530.5982055664062  loc loss 32.572444915771484\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 21., 21., 21.])\n",
      "cls loss 582.3726806640625  loc loss 32.68525314331055\n",
      "cls loss 540.9047241210938  loc loss 24.823089599609375\n",
      "cls loss 549.775390625  loc loss 36.697479248046875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 35.])\n",
      "cls loss 787.1015014648438  loc loss 53.32227325439453\n",
      "cls loss 268.8736572265625  loc loss 14.96038818359375\n",
      "cls loss 413.96881103515625  loc loss 28.700056076049805\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 411.82708740234375  loc loss 22.635814666748047\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 38., 38.,  9., 38.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1.,  1.])\n",
      "cls loss 454.55859375  loc loss 34.819190979003906\n",
      "cls loss 734.5643920898438  loc loss 53.834075927734375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 2.,  1., 77., 31., 10., 10.,  1.,  4., 10.])\n",
      "cls loss 408.66357421875  loc loss 20.248594284057617\n",
      "cls loss 719.5018310546875  loc loss 47.32582092285156\n",
      "cls loss 1433.1427001953125  loc loss 96.98220825195312\n",
      "cls loss 485.7022399902344  loc loss 30.782163619995117\n",
      "cls loss 643.8177490234375  loc loss 53.17527770996094\n",
      "cls loss 477.61016845703125  loc loss 29.84699821472168\n",
      "cls loss 498.8171081542969  loc loss 25.678325653076172\n",
      "cls loss 849.7943115234375  loc loss 34.02437210083008\n",
      "cls loss 740.85107421875  loc loss 40.273223876953125\n",
      "cls loss 636.0299072265625  loc loss 44.74951934814453\n",
      "cls loss 480.5093994140625  loc loss 24.839248657226562\n",
      "cls loss 548.8704223632812  loc loss 27.924877166748047\n",
      "cls loss 1005.49853515625  loc loss 62.32975769042969\n",
      "cls loss 828.0390014648438  loc loss 55.0833854675293\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1., 42., 42., 42., 42., 42., 42.,  1.,\n",
      "         1.,  1.,  1., 42.,  1.,  1., 42.,  1.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 483.1876525878906  loc loss 33.76573944091797\n",
      "cls loss 698.9151000976562  loc loss 45.606544494628906\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.])\n",
      "cls loss 316.3953857421875  loc loss 21.34255027770996\n",
      "cls loss 663.1668701171875  loc loss 48.36208724975586\n",
      "cls loss 537.03515625  loc loss 40.5629768371582\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([11.])\n",
      "cls loss 332.322998046875  loc loss 19.512466430664062\n",
      "cls loss 433.9593200683594  loc loss 20.743980407714844\n",
      "cls loss 445.77490234375  loc loss 22.1444091796875\n",
      "cls loss 633.7825927734375  loc loss 44.89560317993164\n",
      "cls loss 622.8436889648438  loc loss 36.16576385498047\n",
      "cls loss 601.479248046875  loc loss 44.422828674316406\n",
      "cls loss 884.7388916015625  loc loss 48.93581008911133\n",
      "cls loss 485.5057373046875  loc loss 29.31945037841797\n",
      "cls loss 856.91748046875  loc loss 66.05809020996094\n",
      "cls loss 497.36199951171875  loc loss 28.407119750976562\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 429.6229248046875  loc loss 30.583106994628906\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1., 38., 38., 42.])\n",
      "cls loss 546.053955078125  loc loss 40.653324127197266\n",
      "cls loss 498.1199645996094  loc loss 27.44989013671875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 420.1686096191406  loc loss 30.946975708007812\n",
      "cls loss 958.248779296875  loc loss 70.44096374511719\n",
      "cls loss 572.3595581054688  loc loss 42.737548828125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10.,  3.,  3.,  6.,  8.,  8.,  1.,  1.,  1., 10.])\n",
      "cls loss 504.24920654296875  loc loss 30.500703811645508\n",
      "cls loss 297.8016357421875  loc loss 12.293767929077148\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10.,  3.])\n",
      "cls loss 477.464599609375  loc loss 27.642377853393555\n",
      "cls loss 295.1405944824219  loc loss 13.853551864624023\n",
      "cls loss 545.8145751953125  loc loss 45.04045104980469\n",
      "cls loss 614.87451171875  loc loss 45.284297943115234\n",
      "cls loss 488.2598876953125  loc loss 30.42538833618164\n",
      "cls loss 370.6006774902344  loc loss 17.845739364624023\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 34.])\n",
      "cls loss 873.02099609375  loc loss 52.14302062988281\n",
      "cls loss 871.743408203125  loc loss 73.61868286132812\n",
      "cls loss 575.9761352539062  loc loss 46.49760055541992\n",
      "cls loss 429.236572265625  loc loss 31.743305206298828\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.,  1.])\n",
      "cls loss 480.55975341796875  loc loss 26.987239837646484\n",
      "cls loss 753.5062255859375  loc loss 61.976165771484375\n",
      "cls loss 1110.620361328125  loc loss 76.59956359863281\n",
      "cls loss 944.642822265625  loc loss 51.68555450439453\n",
      "cls loss 553.6103515625  loc loss 31.886259078979492\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 708.55908203125  loc loss 40.78181076049805\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10.])\n",
      "cls loss 425.48504638671875  loc loss 24.13176918029785\n",
      "cls loss 607.6627807617188  loc loss 32.18632888793945\n",
      "cls loss 577.901123046875  loc loss 33.288307189941406\n",
      "cls loss 403.1653747558594  loc loss 25.776611328125\n",
      "cls loss 496.83837890625  loc loss 37.44214630126953\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21.,\n",
      "        21.])\n",
      "cls loss 683.46240234375  loc loss 42.02316665649414\n",
      "cls loss 555.9185791015625  loc loss 39.03260040283203\n",
      "cls loss 360.71441650390625  loc loss 17.33626365661621\n",
      "cls loss 743.5455322265625  loc loss 50.70793533325195\n",
      "cls loss 591.0607299804688  loc loss 42.70042037963867\n",
      "cls loss 423.08367919921875  loc loss 27.792692184448242\n",
      "cls loss 871.7001953125  loc loss 63.816444396972656\n",
      "cls loss 1059.2548828125  loc loss 74.77554321289062\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15., 85.])\n",
      "cls loss 694.4371337890625  loc loss 44.32796096801758\n",
      "cls loss 663.6148681640625  loc loss 51.648956298828125\n",
      "cls loss 703.9979248046875  loc loss 50.34355926513672\n",
      "cls loss 619.588623046875  loc loss 36.73793411254883\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 8., 8.])\n",
      "cls loss 395.3485412597656  loc loss 21.73394203186035\n",
      "cls loss 450.1571044921875  loc loss 30.0330810546875\n",
      "cls loss 532.72900390625  loc loss 33.08531951904297\n",
      "cls loss 447.33172607421875  loc loss 26.13863182067871\n",
      "cls loss 519.1090698242188  loc loss 32.49721908569336\n",
      "cls loss 673.1148681640625  loc loss 42.706321716308594\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1., 35., 27., 27.,  1., 27.,  1.])\n",
      "cls loss 960.3310546875  loc loss 64.86864471435547\n",
      "cls loss 434.0030822753906  loc loss 32.69384765625\n",
      "cls loss 535.449462890625  loc loss 40.59243392944336\n",
      "cls loss 503.61181640625  loc loss 44.61249542236328\n",
      "cls loss 479.9091491699219  loc loss 36.14516830444336\n",
      "cls loss 502.14447021484375  loc loss 41.04218673706055\n",
      "cls loss 510.3558654785156  loc loss 41.01032257080078\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  2.,  2.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  2.,  2.])\n",
      "cls loss 336.75152587890625  loc loss 13.074787139892578\n",
      "cls loss 769.6280517578125  loc loss 49.06809997558594\n",
      "cls loss 562.876708984375  loc loss 28.63153076171875\n",
      "cls loss 883.628173828125  loc loss 65.20472717285156\n",
      "cls loss 374.7889404296875  loc loss 23.710813522338867\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 19., 19., 19., 16.])\n",
      "cls loss 386.38665771484375  loc loss 18.417694091796875\n",
      "cls loss 305.8934020996094  loc loss 15.191086769104004\n",
      "cls loss 463.8849792480469  loc loss 24.910778045654297\n",
      "cls loss 608.7188720703125  loc loss 42.017616271972656\n",
      "cls loss 316.1941223144531  loc loss 24.365524291992188\n",
      "cls loss 704.3280639648438  loc loss 51.88679885864258\n",
      "cls loss 494.891357421875  loc loss 36.96357727050781\n",
      "cls loss 537.9888305664062  loc loss 37.53486633300781\n",
      "cls loss 659.6451416015625  loc loss 50.1254997253418\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 767.2495727539062  loc loss 35.5419921875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 963.6414184570312  loc loss 84.59223937988281\n",
      "cls loss 1189.230224609375  loc loss 119.55940246582031\n",
      "cls loss 604.396728515625  loc loss 45.13697814941406\n",
      "cls loss 567.401611328125  loc loss 38.6077766418457\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3.,  3.,  3.,  3.,  3., 10.])\n",
      "cls loss 350.578369140625  loc loss 18.02120590209961\n",
      "cls loss 623.9661865234375  loc loss 34.2426872253418\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 1., 1., 1., 3., 3., 3., 3.])\n",
      "cls loss 499.32672119140625  loc loss 33.762691497802734\n",
      "cls loss 878.1218872070312  loc loss 63.587074279785156\n",
      "cls loss 703.8087768554688  loc loss 49.903804779052734\n",
      "cls loss 513.1132202148438  loc loss 28.89803695678711\n",
      "cls loss 707.3128051757812  loc loss 55.439510345458984\n",
      "cls loss 447.998046875  loc loss 34.964088439941406\n",
      "cls loss 706.9345703125  loc loss 52.318626403808594\n",
      "cls loss 538.7393798828125  loc loss 48.288597106933594\n",
      "cls loss 520.155517578125  loc loss 37.51327133178711\n",
      "cls loss 1118.408203125  loc loss 95.08797454833984\n",
      "cls loss 728.0726928710938  loc loss 52.53520584106445\n",
      "cls loss 504.6826477050781  loc loss 25.65011978149414\n",
      "cls loss 340.4846496582031  loc loss 15.689684867858887\n",
      "cls loss 383.93890380859375  loc loss 20.761493682861328\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3., 10., 10., 10., 10., 10., 10., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10., 10., 10., 10., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 11., 10., 10., 10., 10., 10.,  3.,  3.,  3.,  3.,  3.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 11., 10., 10., 10., 10., 10.,  3.,  3.,  3.,  3.,  3.])\n",
      "cls loss 394.021240234375  loc loss 18.542057037353516\n",
      "cls loss 475.25506591796875  loc loss 23.368057250976562\n",
      "cls loss 396.860107421875  loc loss 24.95562744140625\n",
      "cls loss 381.7542724609375  loc loss 16.688234329223633\n",
      "cls loss 452.8677978515625  loc loss 35.854068756103516\n",
      "cls loss 388.7259826660156  loc loss 15.330744743347168\n",
      "cls loss 678.2954711914062  loc loss 46.71228790283203\n",
      "cls loss 593.1058959960938  loc loss 43.9049072265625\n",
      "cls loss 888.13916015625  loc loss 59.90351486206055\n",
      "cls loss 437.0700378417969  loc loss 34.21820831298828\n",
      "cls loss 782.3135986328125  loc loss 54.66767120361328\n",
      "cls loss 642.025634765625  loc loss 45.397911071777344\n",
      "cls loss 600.1132202148438  loc loss 41.568546295166016\n",
      "cls loss 613.8544921875  loc loss 46.85038757324219\n",
      "cls loss 843.0543823242188  loc loss 57.40456008911133\n",
      "cls loss 818.3727416992188  loc loss 51.062686920166016\n",
      "cls loss 396.3415222167969  loc loss 23.15505027770996\n",
      "cls loss 688.56982421875  loc loss 54.96608352661133\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 10.,  1., 18.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 361.52728271484375  loc loss 25.426259994506836\n",
      "cls loss 411.6664123535156  loc loss 18.1921443939209\n",
      "cls loss 716.7642822265625  loc loss 37.03313446044922\n",
      "cls loss 989.0999755859375  loc loss 67.49162292480469\n",
      "cls loss 609.60888671875  loc loss 43.14213943481445\n",
      "cls loss 836.2930297851562  loc loss 50.748355865478516\n",
      "cls loss 577.57421875  loc loss 40.72435760498047\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.,  1.,  1.])\n",
      "cls loss 759.7981567382812  loc loss 51.579498291015625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1., 38.,  1.])\n",
      "cls loss 731.533203125  loc loss 42.97243118286133\n",
      "cls loss 936.3082275390625  loc loss 70.0997085571289\n",
      "cls loss 471.75665283203125  loc loss 36.62785720825195\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 640.1536254882812  loc loss 46.0654296875\n",
      "cls loss 561.6800537109375  loc loss 38.52964782714844\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3., 10.,  8.,  3., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.])\n",
      "cls loss 682.2291259765625  loc loss 44.19611740112305\n",
      "cls loss 483.61883544921875  loc loss 31.473970413208008\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3.,  3., 11.,  3., 10., 10.,  3.,  3., 10.])\n",
      "cls loss 568.4896240234375  loc loss 28.839950561523438\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3., 10., 10., 10.])\n",
      "cls loss 564.16455078125  loc loss 40.086360931396484\n",
      "cls loss 482.268798828125  loc loss 27.342506408691406\n",
      "cls loss 595.029052734375  loc loss 43.273223876953125\n",
      "cls loss 945.0570068359375  loc loss 56.96467590332031\n",
      "cls loss 583.5797119140625  loc loss 39.29634094238281\n",
      "cls loss 409.42681884765625  loc loss 36.9483757019043\n",
      "cls loss 515.31689453125  loc loss 38.441917419433594\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 9.,  9., 85., 85.])\n",
      "cls loss 467.80364990234375  loc loss 26.782562255859375\n",
      "cls loss 523.2821044921875  loc loss 36.8098258972168\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 868.1300048828125  loc loss 66.4332046508789\n",
      "cls loss 736.8748779296875  loc loss 38.77570724487305\n",
      "cls loss 832.272216796875  loc loss 60.207275390625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10., 10., 10., 10.])\n",
      "cls loss 533.4219970703125  loc loss 33.826725006103516\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([13.])\n",
      "cls loss 851.9078979492188  loc loss 67.17972564697266\n",
      "cls loss 308.03228759765625  loc loss 17.31204605102539\n",
      "cls loss 378.13372802734375  loc loss 20.57455825805664\n",
      "cls loss 534.921142578125  loc loss 28.79595947265625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19.,  1.,  1.,  1., 19., 19.])\n",
      "cls loss 551.638916015625  loc loss 34.911922454833984\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 408.19927978515625  loc loss 34.392032623291016\n",
      "cls loss 629.5799560546875  loc loss 46.07613754272461\n",
      "cls loss 444.8226013183594  loc loss 27.22063446044922\n",
      "cls loss 654.9534301757812  loc loss 41.29323959350586\n",
      "cls loss 704.66455078125  loc loss 54.883358001708984\n",
      "cls loss 566.47705078125  loc loss 31.77811622619629\n",
      "cls loss 782.657470703125  loc loss 60.152618408203125\n",
      "cls loss 338.5052795410156  loc loss 16.077747344970703\n",
      "cls loss 573.4638061523438  loc loss 37.64423370361328\n",
      "cls loss 454.5060729980469  loc loss 24.4041748046875\n",
      "cls loss 475.56488037109375  loc loss 27.528911590576172\n",
      "cls loss 603.448974609375  loc loss 44.52842712402344\n",
      "cls loss 581.3700561523438  loc loss 34.72199249267578\n",
      "cls loss 840.7568969726562  loc loss 54.53489685058594\n",
      "cls loss 516.3299560546875  loc loss 37.45945358276367\n",
      "cls loss 657.9215087890625  loc loss 46.26579284667969\n",
      "cls loss 977.0491333007812  loc loss 63.33100891113281\n",
      "cls loss 549.9884033203125  loc loss 42.47211837768555\n",
      "cls loss 622.7997436523438  loc loss 38.510887145996094\n",
      "cls loss 765.7947998046875  loc loss 57.27853775024414\n",
      "cls loss 773.8972778320312  loc loss 57.12217330932617\n",
      "cls loss 990.0406494140625  loc loss 55.70876693725586\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 5.])\n",
      "cls loss 305.38055419921875  loc loss 11.516642570495605\n",
      "cls loss 381.5352478027344  loc loss 17.105806350708008\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 13.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 6., 8., 8.])\n",
      "cls loss 336.07025146484375  loc loss 16.518932342529297\n",
      "cls loss 384.57708740234375  loc loss 22.54828643798828\n",
      "cls loss 759.3765258789062  loc loss 54.242733001708984\n",
      "cls loss 336.27935791015625  loc loss 17.08403778076172\n",
      "cls loss 601.8983154296875  loc loss 46.28551483154297\n",
      "cls loss 944.448486328125  loc loss 66.34843444824219\n",
      "cls loss 553.7899780273438  loc loss 43.843772888183594\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([42., 42.,  1.,  1.,  1.,  1.,  1.,  1.,  1., 42., 42.])\n",
      "cls loss 614.0258178710938  loc loss 37.860660552978516\n",
      "cls loss 812.8357543945312  loc loss 64.44995880126953\n",
      "cls loss 647.2847290039062  loc loss 55.0608024597168\n",
      "cls loss 481.74591064453125  loc loss 29.450584411621094\n",
      "cls loss 648.9493408203125  loc loss 40.423118591308594\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 878.345947265625  loc loss 58.06428909301758\n",
      "cls loss 689.1429443359375  loc loss 50.38704299926758\n",
      "cls loss 455.64532470703125  loc loss 27.829015731811523\n",
      "cls loss 382.3920593261719  loc loss 20.22907257080078\n",
      "cls loss 538.0610961914062  loc loss 32.42832946777344\n",
      "cls loss 706.6364135742188  loc loss 48.28297805786133\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15.])\n",
      "cls loss 337.9152526855469  loc loss 17.684106826782227\n",
      "cls loss 549.6561279296875  loc loss 37.77674865722656\n",
      "cls loss 496.508056640625  loc loss 33.87626647949219\n",
      "cls loss 873.5025634765625  loc loss 63.00237274169922\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19.,  7.])\n",
      "cls loss 498.84979248046875  loc loss 31.609378814697266\n",
      "cls loss 1006.928466796875  loc loss 64.74659729003906\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 842.4928588867188  loc loss 46.41544723510742\n",
      "cls loss 656.8853759765625  loc loss 52.06594467163086\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([38., 38.,  1., 18.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1., 18., 18.,  1.])\n",
      "cls loss 541.96630859375  loc loss 28.446260452270508\n",
      "cls loss 500.08099365234375  loc loss 25.49751853942871\n",
      "cls loss 887.227783203125  loc loss 70.20320129394531\n",
      "cls loss 706.2359619140625  loc loss 40.23918151855469\n",
      "cls loss 679.8887329101562  loc loss 34.594242095947266\n",
      "cls loss 368.8106994628906  loc loss 28.68408203125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.])\n",
      "cls loss 309.477783203125  loc loss 10.564131736755371\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([32.])\n",
      "cls loss 584.1053466796875  loc loss 30.232290267944336\n",
      "cls loss 506.34197998046875  loc loss 35.78736877441406\n",
      "cls loss 670.36474609375  loc loss 54.99026870727539\n",
      "cls loss 618.4071655273438  loc loss 40.083595275878906\n",
      "cls loss 498.2954406738281  loc loss 33.18699264526367\n",
      "cls loss 780.3626708984375  loc loss 50.74889373779297\n",
      "cls loss 832.1676635742188  loc loss 59.8824462890625\n",
      "cls loss 669.07861328125  loc loss 46.209964752197266\n",
      "cls loss 565.2991333007812  loc loss 33.94816207885742\n",
      "cls loss 881.935791015625  loc loss 57.1518440246582\n",
      "cls loss 551.7596435546875  loc loss 29.899459838867188\n",
      "cls loss 869.5068359375  loc loss 72.48582458496094\n",
      "cls loss 649.6607666015625  loc loss 38.452171325683594\n",
      "cls loss 539.6949462890625  loc loss 39.487815856933594\n",
      "cls loss 415.6530456542969  loc loss 22.65842628479004\n",
      "cls loss 452.2921447753906  loc loss 29.609270095825195\n",
      "cls loss 677.7691040039062  loc loss 46.39908218383789\n",
      "cls loss 691.3182983398438  loc loss 51.8399658203125\n",
      "cls loss 413.54681396484375  loc loss 28.806888580322266\n",
      "cls loss 768.4476928710938  loc loss 52.43285369873047\n",
      "cls loss 899.2210693359375  loc loss 55.932464599609375\n",
      "cls loss 342.13818359375  loc loss 23.926673889160156\n",
      "cls loss 857.5946044921875  loc loss 59.989646911621094\n",
      "cls loss 615.7520751953125  loc loss 48.180423736572266\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 849.0186767578125  loc loss 66.7292251586914\n",
      "cls loss 424.4315185546875  loc loss 16.903575897216797\n",
      "cls loss 642.51416015625  loc loss 35.490196228027344\n",
      "cls loss 627.501220703125  loc loss 43.504783630371094\n",
      "cls loss 500.2375793457031  loc loss 29.72833824157715\n",
      "cls loss 310.3279113769531  loc loss 16.740310668945312\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 9., 9., 1., 9., 9., 9., 9., 1., 9.])\n",
      "cls loss 1075.31884765625  loc loss 94.64436340332031\n",
      "cls loss 633.6241455078125  loc loss 34.46919250488281\n",
      "cls loss 938.8763427734375  loc loss 79.52935028076172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 398.3728332519531  loc loss 27.577211380004883\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 42., 42.])\n",
      "cls loss 675.4959716796875  loc loss 51.26012420654297\n",
      "cls loss 723.9866333007812  loc loss 53.116947174072266\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  2.,  1.,  1.,  1., 38.,\n",
      "         1.,  1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 38., 38., 38.,  1., 38., 38., 38.,  1.,  1., 38.,  1.,\n",
      "         1.])\n",
      "cls loss 452.47955322265625  loc loss 31.5880069732666\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  8.,  8.])\n",
      "cls loss 998.000732421875  loc loss 68.90403747558594\n",
      "cls loss 1015.3815307617188  loc loss 72.50613403320312\n",
      "cls loss 407.0811767578125  loc loss 24.24339485168457\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([4., 1., 1., 4.])\n",
      "cls loss 577.2096557617188  loc loss 41.2628173828125\n",
      "cls loss 682.927978515625  loc loss 43.79182815551758\n",
      "cls loss 319.2348937988281  loc loss 15.042093276977539\n",
      "cls loss 428.301025390625  loc loss 26.66366195678711\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([51.,  1.])\n",
      "cls loss 310.7706298828125  loc loss 13.666309356689453\n",
      "cls loss 400.65863037109375  loc loss 24.795787811279297\n",
      "cls loss 722.4242553710938  loc loss 43.9651985168457\n",
      "cls loss 797.88427734375  loc loss 60.84713363647461\n",
      "cls loss 1075.04296875  loc loss 61.35139083862305\n",
      "cls loss 1358.0294189453125  loc loss 89.47635650634766\n",
      "cls loss 567.9168701171875  loc loss 35.97280502319336\n",
      "cls loss 805.0203857421875  loc loss 57.44798278808594\n",
      "cls loss 846.4367065429688  loc loss 62.04765319824219\n",
      "cls loss 653.8622436523438  loc loss 38.380943298339844\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  3.,  1.,  1.,  1.,  3.,  1.,  1.,\n",
      "         1.,  1.,  1.])\n",
      "cls loss 701.932861328125  loc loss 36.39247131347656\n",
      "cls loss 801.4051513671875  loc loss 40.9413948059082\n",
      "cls loss 712.2899169921875  loc loss 37.814083099365234\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "cls loss 577.6318969726562  loc loss 35.27272033691406\n",
      "cls loss 348.7657470703125  loc loss 28.290660858154297\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3.])\n",
      "cls loss 312.7081604003906  loc loss 14.231291770935059\n",
      "cls loss 520.591796875  loc loss 37.698097229003906\n",
      "cls loss 419.2216491699219  loc loss 32.2767448425293\n",
      "cls loss 749.3897094726562  loc loss 53.13745880126953\n",
      "cls loss 515.1744384765625  loc loss 26.199905395507812\n",
      "cls loss 414.12420654296875  loc loss 29.602947235107422\n",
      "cls loss 1272.85107421875  loc loss 86.34153747558594\n",
      "cls loss 547.041748046875  loc loss 41.4500617980957\n",
      "cls loss 391.90374755859375  loc loss 32.57952117919922\n",
      "cls loss 532.1181640625  loc loss 32.12605667114258\n",
      "cls loss 465.054443359375  loc loss 34.72240447998047\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 845.4141845703125  loc loss 59.26837921142578\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  9., 64., 64., 64., 64., 64., 64., 64., 64., 64.,  9.,  9.,  9.,\n",
      "         9.])\n",
      "cls loss 480.9410400390625  loc loss 25.365127563476562\n",
      "cls loss 1121.087158203125  loc loss 89.81741333007812\n",
      "cls loss 572.0361328125  loc loss 39.1407585144043\n",
      "cls loss 740.5696411132812  loc loss 55.42532730102539\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.,  3.,  3.])\n",
      "cls loss 491.2458190917969  loc loss 30.894651412963867\n",
      "cls loss 563.11669921875  loc loss 35.367347717285156\n",
      "cls loss 538.5477294921875  loc loss 39.82244110107422\n",
      "cls loss 598.746337890625  loc loss 41.8260383605957\n",
      "cls loss 565.4046630859375  loc loss 47.67738723754883\n",
      "cls loss 550.683349609375  loc loss 44.192115783691406\n",
      "cls loss 547.3914794921875  loc loss 44.16078567504883\n",
      "cls loss 560.9097900390625  loc loss 37.07266616821289\n",
      "cls loss 707.486572265625  loc loss 51.74264144897461\n",
      "cls loss 612.1392822265625  loc loss 36.8359489440918\n",
      "cls loss 486.6636962890625  loc loss 22.491823196411133\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21.])\n",
      "cls loss 366.03497314453125  loc loss 20.237512588500977\n",
      "cls loss 499.09344482421875  loc loss 42.651885986328125\n",
      "cls loss 704.5148315429688  loc loss 52.66368103027344\n",
      "cls loss 456.1019592285156  loc loss 26.393569946289062\n",
      "cls loss 634.9110717773438  loc loss 38.84653091430664\n",
      "cls loss 1130.29736328125  loc loss 65.12559509277344\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 42., 42.,  1.,  1.])\n",
      "cls loss 567.020263671875  loc loss 35.85405731201172\n",
      "cls loss 378.98565673828125  loc loss 28.136274337768555\n",
      "cls loss 519.10205078125  loc loss 40.331390380859375\n",
      "cls loss 733.105224609375  loc loss 62.22814178466797\n",
      "cls loss 474.5414123535156  loc loss 32.051849365234375\n",
      "cls loss 669.77734375  loc loss 52.79232406616211\n",
      "cls loss 651.6204833984375  loc loss 51.6478271484375\n",
      "cls loss 702.6192626953125  loc loss 42.88890838623047\n",
      "cls loss 557.6609497070312  loc loss 35.574851989746094\n",
      "cls loss 503.2476806640625  loc loss 31.574993133544922\n",
      "cls loss 404.75140380859375  loc loss 18.365076065063477\n",
      "cls loss 511.5787353515625  loc loss 36.3018798828125\n",
      "cls loss 748.2998046875  loc loss 64.72282409667969\n",
      "cls loss 601.8137817382812  loc loss 39.54584884643555\n",
      "cls loss 601.284423828125  loc loss 45.4724235534668\n",
      "cls loss 652.5006713867188  loc loss 37.27726364135742\n",
      "cls loss 955.1085205078125  loc loss 64.086669921875\n",
      "cls loss 656.0180053710938  loc loss 52.696258544921875\n",
      "cls loss 779.41748046875  loc loss 45.876888275146484\n",
      "cls loss 460.1504821777344  loc loss 23.55426788330078\n",
      "cls loss 647.2757568359375  loc loss 42.936832427978516\n",
      "cls loss 591.165771484375  loc loss 40.304656982421875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 5., 5., 5., 5., 5., 5.])\n",
      "cls loss 432.8817138671875  loc loss 29.962732315063477\n",
      "cls loss 506.9629211425781  loc loss 32.14717483520508\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([13.])\n",
      "cls loss 349.067138671875  loc loss 22.802806854248047\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([44., 10.,  1.,  1.,  1.])\n",
      "cls loss 369.9183044433594  loc loss 22.983768463134766\n",
      "cls loss 692.828369140625  loc loss 37.3427848815918\n",
      "cls loss 558.0533447265625  loc loss 32.61605453491211\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19., 19., 19., 19., 19., 19., 19.])\n",
      "cls loss 713.044189453125  loc loss 41.422874450683594\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([56.])\n",
      "cls loss 1276.538330078125  loc loss 77.4896240234375\n",
      "cls loss 682.1141967773438  loc loss 56.57023620605469\n",
      "cls loss 916.7214965820312  loc loss 67.98302459716797\n",
      "cls loss 898.4348754882812  loc loss 71.54680633544922\n",
      "cls loss 548.6989135742188  loc loss 34.29084014892578\n",
      "cls loss 892.8753051757812  loc loss 66.83924102783203\n",
      "cls loss 539.9506225585938  loc loss 32.74528503417969\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 36.])\n",
      "cls loss 634.3222045898438  loc loss 36.520015716552734\n",
      "cls loss 545.6304931640625  loc loss 41.0246696472168\n",
      "cls loss 592.5004272460938  loc loss 34.91501998901367\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5.])\n",
      "cls loss 633.1144409179688  loc loss 40.95066833496094\n",
      "cls loss 366.9410400390625  loc loss 20.438644409179688\n",
      "cls loss 800.523681640625  loc loss 48.06772232055664\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "cls loss 722.541259765625  loc loss 50.63139343261719\n",
      "cls loss 752.7972412109375  loc loss 47.41801452636719\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 656.8489379882812  loc loss 48.032630920410156\n",
      "cls loss 783.930908203125  loc loss 56.72031021118164\n",
      "cls loss 649.8482666015625  loc loss 59.820770263671875\n",
      "cls loss 466.88311767578125  loc loss 33.4118537902832\n",
      "cls loss 577.6824951171875  loc loss 42.84199523925781\n",
      "cls loss 579.9525146484375  loc loss 39.031455993652344\n",
      "cls loss 880.30078125  loc loss 54.666343688964844\n",
      "cls loss 419.655517578125  loc loss 22.1861572265625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 11., 15., 10., 10., 10., 10., 10.])\n",
      "cls loss 944.7803344726562  loc loss 66.69405364990234\n",
      "cls loss 539.25244140625  loc loss 36.74906921386719\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3.])\n",
      "cls loss 594.9454956054688  loc loss 39.09759521484375\n",
      "cls loss 512.199951171875  loc loss 31.187767028808594\n",
      "cls loss 563.979248046875  loc loss 29.529834747314453\n",
      "cls loss 726.916259765625  loc loss 38.11092758178711\n",
      "cls loss 418.43927001953125  loc loss 19.363544464111328\n",
      "cls loss 586.0470581054688  loc loss 36.49121856689453\n",
      "cls loss 645.7531127929688  loc loss 50.28276062011719\n",
      "cls loss 547.2425537109375  loc loss 42.10116958618164\n",
      "cls loss 1226.6612548828125  loc loss 96.69127655029297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 887.8311767578125  loc loss 61.59115219116211\n",
      "cls loss 567.7069702148438  loc loss 43.40299987792969\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  9.,  9.,  9.,  6.,  6., 85., 85.,  8.,  1.,  1.,  1.,  1.,\n",
      "         6.,  6.])\n",
      "cls loss 416.1230773925781  loc loss 29.681907653808594\n",
      "cls loss 924.5293579101562  loc loss 67.10067749023438\n",
      "cls loss 1096.285888671875  loc loss 72.38594818115234\n",
      "cls loss 762.5507202148438  loc loss 53.752532958984375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10.,  3.,  3., 10.])\n",
      "cls loss 501.18890380859375  loc loss 30.757160186767578\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([7.])\n",
      "cls loss 656.601318359375  loc loss 48.521202087402344\n",
      "cls loss 664.6158447265625  loc loss 41.08677673339844\n",
      "cls loss 605.7702026367188  loc loss 47.35132598876953\n",
      "cls loss 870.827880859375  loc loss 68.26321411132812\n",
      "cls loss 639.462158203125  loc loss 41.89292907714844\n",
      "cls loss 835.454345703125  loc loss 55.6031608581543\n",
      "cls loss 1012.7852172851562  loc loss 64.00337219238281\n",
      "cls loss 617.9140014648438  loc loss 43.56476974487305\n",
      "cls loss 650.3455810546875  loc loss 46.00997543334961\n",
      "cls loss 555.263427734375  loc loss 42.32442855834961\n",
      "cls loss 770.261474609375  loc loss 65.08363342285156\n",
      "cls loss 645.221923828125  loc loss 42.95985412597656\n",
      "cls loss 504.6407470703125  loc loss 30.82090950012207\n",
      "cls loss 764.0816650390625  loc loss 60.355064392089844\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([62.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([62.])\n",
      "cls loss 339.98284912109375  loc loss 20.034229278564453\n",
      "cls loss 615.8966064453125  loc loss 45.790714263916016\n",
      "cls loss 603.2822875976562  loc loss 41.22071075439453\n",
      "cls loss 439.01837158203125  loc loss 19.010066986083984\n",
      "cls loss 774.6455078125  loc loss 55.247406005859375\n",
      "cls loss 748.6470336914062  loc loss 46.846832275390625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([28.])\n",
      "cls loss 835.6263427734375  loc loss 48.0306282043457\n",
      "cls loss 759.8628540039062  loc loss 48.416900634765625\n",
      "cls loss 726.2451171875  loc loss 47.817726135253906\n",
      "cls loss 753.1417236328125  loc loss 52.449424743652344\n",
      "cls loss 1024.0479736328125  loc loss 72.32209014892578\n",
      "cls loss 576.89501953125  loc loss 38.924537658691406\n",
      "cls loss 722.9405517578125  loc loss 45.781612396240234\n",
      "cls loss 651.0065307617188  loc loss 55.27091979980469\n",
      "cls loss 1034.68603515625  loc loss 79.67552947998047\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([81.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 716.8193359375  loc loss 31.64822769165039\n",
      "cls loss 554.6266479492188  loc loss 28.298927307128906\n",
      "cls loss 471.67706298828125  loc loss 30.110876083374023\n",
      "cls loss 397.15496826171875  loc loss 17.37363052368164\n",
      "cls loss 447.1419677734375  loc loss 28.976089477539062\n",
      "cls loss 475.503662109375  loc loss 31.47610092163086\n",
      "cls loss 541.571044921875  loc loss 35.08372497558594\n",
      "cls loss 710.7012939453125  loc loss 58.836700439453125\n",
      "cls loss 787.93798828125  loc loss 55.01161575317383\n",
      "cls loss 1502.799072265625  loc loss 107.848876953125\n",
      "cls loss 611.1221923828125  loc loss 32.46381378173828\n",
      "cls loss 726.9661865234375  loc loss 50.26641845703125\n",
      "cls loss 511.081787109375  loc loss 33.814022064208984\n",
      "cls loss 691.5221557617188  loc loss 38.815513610839844\n",
      "cls loss 644.4642944335938  loc loss 36.10780334472656\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([44., 44.])\n",
      "cls loss 553.9573974609375  loc loss 28.303436279296875\n",
      "cls loss 559.6060180664062  loc loss 40.17314910888672\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15.])\n",
      "cls loss 665.1114501953125  loc loss 35.87406921386719\n",
      "cls loss 311.47021484375  loc loss 18.507129669189453\n",
      "cls loss 639.9114990234375  loc loss 39.51698684692383\n",
      "cls loss 348.58465576171875  loc loss 23.89320945739746\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([1., 3., 3.])\n",
      "cls loss 394.9947814941406  loc loss 31.950481414794922\n",
      "cls loss 343.16534423828125  loc loss 15.379223823547363\n",
      "cls loss 609.9990234375  loc loss 35.517967224121094\n",
      "cls loss 635.6011962890625  loc loss 38.63454818725586\n",
      "cls loss 582.525390625  loc loss 38.24729537963867\n",
      "cls loss 599.683837890625  loc loss 36.309326171875\n",
      "cls loss 500.46392822265625  loc loss 37.94501495361328\n",
      "cls loss 639.1561279296875  loc loss 45.87932586669922\n",
      "cls loss 520.0477905273438  loc loss 35.12464904785156\n",
      "cls loss 638.7821044921875  loc loss 46.693973541259766\n",
      "cls loss 417.9711608886719  loc loss 26.154373168945312\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 747.53076171875  loc loss 47.3390998840332\n",
      "cls loss 858.0316772460938  loc loss 46.18753433227539\n",
      "cls loss 780.671630859375  loc loss 54.276824951171875\n",
      "cls loss 759.3966064453125  loc loss 55.98918533325195\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10., 10., 10.,  1.,  1.,  1.,  1.,  1.,  1.,  8.,  8.,\n",
      "         1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10., 10., 10.,  1.,  1.,  1.,  1.,  1.,  1.,  8.,  8.,\n",
      "         1.])\n",
      "cls loss 746.4457397460938  loc loss 38.876441955566406\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 3., 3., 3.])\n",
      "cls loss 610.0072631835938  loc loss 39.739994049072266\n",
      "cls loss 427.68072509765625  loc loss 24.10508918762207\n",
      "cls loss 324.20599365234375  loc loss 17.830881118774414\n",
      "cls loss 581.36328125  loc loss 42.3060302734375\n",
      "cls loss 462.0731201171875  loc loss 24.59414291381836\n",
      "cls loss 501.5388488769531  loc loss 34.86442184448242\n",
      "cls loss 583.4273681640625  loc loss 40.32365417480469\n",
      "cls loss 807.0146484375  loc loss 57.805599212646484\n",
      "cls loss 664.0821533203125  loc loss 36.0473747253418\n",
      "cls loss 637.9703369140625  loc loss 39.77080535888672\n",
      "cls loss 726.1541137695312  loc loss 50.0080680847168\n",
      "cls loss 553.8477783203125  loc loss 41.16986083984375\n",
      "cls loss 935.1510009765625  loc loss 73.61576080322266\n",
      "cls loss 507.20166015625  loc loss 28.188762664794922\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 729.1688232421875  loc loss 46.067378997802734\n",
      "cls loss 388.27099609375  loc loss 17.957611083984375\n",
      "cls loss 942.3961791992188  loc loss 61.734825134277344\n",
      "cls loss 491.29486083984375  loc loss 26.016862869262695\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 34.])\n",
      "cls loss 754.11083984375  loc loss 42.64350128173828\n",
      "cls loss 351.4764404296875  loc loss 24.427072525024414\n",
      "cls loss 667.2317504882812  loc loss 45.8657112121582\n",
      "cls loss 249.2509002685547  loc loss 17.797908782958984\n",
      "cls loss 618.8316040039062  loc loss 41.36641311645508\n",
      "cls loss 591.33447265625  loc loss 46.19458770751953\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 38.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16., 16., 16.,  9.,  9.,  9., 16., 16., 16., 85.,  9.])\n",
      "cls loss 572.4100341796875  loc loss 37.99559020996094\n",
      "cls loss 652.38916015625  loc loss 53.45414733886719\n",
      "cls loss 927.1188354492188  loc loss 68.50836181640625\n",
      "cls loss 1286.1397705078125  loc loss 90.86148071289062\n",
      "cls loss 400.4622497558594  loc loss 20.796756744384766\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3., 10.,  8.,  8., 10., 10., 10.,  3.,  3., 14.])\n",
      "cls loss 492.1187744140625  loc loss 23.840213775634766\n",
      "cls loss 838.6239013671875  loc loss 45.50920486450195\n",
      "cls loss 370.49554443359375  loc loss 14.409283638000488\n",
      "cls loss 564.4484252929688  loc loss 25.286968231201172\n",
      "cls loss 807.4818115234375  loc loss 45.48038864135742\n",
      "cls loss 638.8321533203125  loc loss 43.51100540161133\n",
      "cls loss 384.70819091796875  loc loss 20.150012969970703\n",
      "cls loss 419.53936767578125  loc loss 26.748783111572266\n",
      "cls loss 625.75634765625  loc loss 42.26116943359375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42., 42.,  1.])\n",
      "cls loss 575.7047119140625  loc loss 43.64548873901367\n",
      "cls loss 506.81097412109375  loc loss 31.42652702331543\n",
      "cls loss 681.332275390625  loc loss 52.779457092285156\n",
      "cls loss 750.3318481445312  loc loss 52.27903366088867\n",
      "cls loss 541.291748046875  loc loss 35.171836853027344\n",
      "cls loss 649.43212890625  loc loss 47.406776428222656\n",
      "cls loss 424.4447021484375  loc loss 28.213367462158203\n",
      "cls loss 469.20648193359375  loc loss 31.896595001220703\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20.])\n",
      "cls loss 355.80218505859375  loc loss 21.0484676361084\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([11.])\n",
      "cls loss 442.8399353027344  loc loss 24.63888931274414\n",
      "cls loss 318.1165771484375  loc loss 18.729127883911133\n",
      "cls loss 692.5996704101562  loc loss 57.09097671508789\n",
      "cls loss 337.59326171875  loc loss 15.415024757385254\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 661.4500732421875  loc loss 39.75768280029297\n",
      "cls loss 378.4773254394531  loc loss 22.623016357421875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 35., 27.])\n",
      "cls loss 630.199951171875  loc loss 41.42292022705078\n",
      "cls loss 627.8340454101562  loc loss 52.3458137512207\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 492.30908203125  loc loss 30.64624786376953\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([42.,  1.])\n",
      "cls loss 639.7962646484375  loc loss 47.10887908935547\n",
      "cls loss 569.2356567382812  loc loss 34.39510726928711\n",
      "cls loss 713.33203125  loc loss 40.11072540283203\n",
      "cls loss 815.90625  loc loss 56.654178619384766\n",
      "cls loss 733.430908203125  loc loss 48.90179443359375\n",
      "cls loss 497.5050964355469  loc loss 40.344703674316406\n",
      "cls loss 430.0875244140625  loc loss 34.67966842651367\n",
      "cls loss 289.031005859375  loc loss 14.340569496154785\n",
      "cls loss 518.2659301757812  loc loss 30.94982147216797\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 1., 1.])\n",
      "cls loss 492.3515319824219  loc loss 27.655364990234375\n",
      "cls loss 540.2811279296875  loc loss 39.94020080566406\n",
      "cls loss 554.0783081054688  loc loss 36.37757873535156\n",
      "cls loss 463.9820861816406  loc loss 34.210689544677734\n",
      "cls loss 550.130859375  loc loss 34.263919830322266\n",
      "cls loss 590.1181030273438  loc loss 44.43524932861328\n",
      "cls loss 822.5972900390625  loc loss 49.3995475769043\n",
      "cls loss 706.9027709960938  loc loss 55.154842376708984\n",
      "cls loss 657.1541748046875  loc loss 39.91145706176758\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 504.5077209472656  loc loss 37.110076904296875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 592.7758178710938  loc loss 30.434080123901367\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([81.])\n",
      "cls loss 722.8372802734375  loc loss 47.67070388793945\n",
      "cls loss 451.6926574707031  loc loss 31.111797332763672\n",
      "cls loss 322.89312744140625  loc loss 21.21906852722168\n",
      "cls loss 491.9058837890625  loc loss 26.499439239501953\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3.,  1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 19.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 19.])\n",
      "cls loss 658.68212890625  loc loss 46.48580551147461\n",
      "cls loss 375.62261962890625  loc loss 19.24090003967285\n",
      "cls loss 395.74432373046875  loc loss 25.404277801513672\n",
      "cls loss 765.390869140625  loc loss 57.57640075683594\n",
      "cls loss 411.21044921875  loc loss 26.02524185180664\n",
      "cls loss 488.6873474121094  loc loss 36.10607147216797\n",
      "cls loss 608.781982421875  loc loss 41.570037841796875\n",
      "cls loss 465.71466064453125  loc loss 36.17119598388672\n",
      "cls loss 624.6211547851562  loc loss 38.24615478515625\n",
      "cls loss 705.2265625  loc loss 49.79725646972656\n",
      "cls loss 828.0015869140625  loc loss 77.66578674316406\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 81.])\n",
      "cls loss 606.1630859375  loc loss 34.198585510253906\n",
      "cls loss 529.1358642578125  loc loss 31.768146514892578\n",
      "cls loss 604.99462890625  loc loss 34.16788864135742\n",
      "cls loss 440.622802734375  loc loss 22.24541664123535\n",
      "cls loss 411.4540100097656  loc loss 25.998632431030273\n",
      "cls loss 484.04638671875  loc loss 35.09398651123047\n",
      "cls loss 389.3901062011719  loc loss 26.882728576660156\n",
      "cls loss 303.21539306640625  loc loss 21.06865119934082\n",
      "cls loss 395.4953308105469  loc loss 28.85610008239746\n",
      "cls loss 567.245361328125  loc loss 36.23899459838867\n",
      "cls loss 472.628173828125  loc loss 37.1553955078125\n",
      "cls loss 496.29541015625  loc loss 40.02880096435547\n",
      "cls loss 304.3215026855469  loc loss 23.275226593017578\n",
      "cls loss 999.5114135742188  loc loss 73.873291015625\n",
      "cls loss 672.0245361328125  loc loss 46.65472412109375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 565.3778076171875  loc loss 31.52730369567871\n",
      "cls loss 619.92822265625  loc loss 42.1947135925293\n",
      "cls loss 513.9923095703125  loc loss 28.880626678466797\n",
      "cls loss 707.2604370117188  loc loss 44.395057678222656\n",
      "cls loss 679.1995849609375  loc loss 45.01349639892578\n",
      "cls loss 602.5739135742188  loc loss 39.273887634277344\n",
      "cls loss 506.4990539550781  loc loss 28.639421463012695\n",
      "cls loss 369.821533203125  loc loss 23.03558349609375\n",
      "cls loss 538.135009765625  loc loss 35.79082107543945\n",
      "cls loss 563.2670288085938  loc loss 41.28242492675781\n",
      "cls loss 618.457763671875  loc loss 36.063262939453125\n",
      "cls loss 761.8765869140625  loc loss 60.938419342041016\n",
      "cls loss 811.226806640625  loc loss 61.596343994140625\n",
      "cls loss 553.23828125  loc loss 41.647422790527344\n",
      "cls loss 710.836181640625  loc loss 59.36261749267578\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1., 38., 47.,  1.,  1.,  1.,  1.,  1., 62.])\n",
      "cls loss 522.3748779296875  loc loss 29.598495483398438\n",
      "cls loss 657.2294311523438  loc loss 38.30466079711914\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 699.076904296875  loc loss 41.78430938720703\n",
      "cls loss 772.199951171875  loc loss 56.000144958496094\n",
      "cls loss 534.249267578125  loc loss 26.95281219482422\n",
      "cls loss 570.5904541015625  loc loss 47.4177360534668\n",
      "cls loss 542.736328125  loc loss 35.037452697753906\n",
      "cls loss 339.6426696777344  loc loss 14.581588745117188\n",
      "cls loss 529.0641479492188  loc loss 30.92947769165039\n",
      "cls loss 429.2962646484375  loc loss 21.442296981811523\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1., 35.])\n",
      "cls loss 518.7196044921875  loc loss 27.036645889282227\n",
      "cls loss 740.0660400390625  loc loss 41.25874710083008\n",
      "cls loss 688.4573974609375  loc loss 47.22367477416992\n",
      "cls loss 640.281982421875  loc loss 53.177764892578125\n",
      "cls loss 507.12554931640625  loc loss 41.99978256225586\n",
      "cls loss 651.181884765625  loc loss 49.869529724121094\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 379.5345458984375  loc loss 22.788366317749023\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 578.337890625  loc loss 28.45728874206543\n",
      "cls loss 905.9732055664062  loc loss 49.83415603637695\n",
      "cls loss 1070.5419921875  loc loss 81.15919494628906\n",
      "cls loss 556.8579711914062  loc loss 29.807714462280273\n",
      "cls loss 483.8116149902344  loc loss 29.805519104003906\n",
      "cls loss 487.6199645996094  loc loss 29.640413284301758\n",
      "cls loss 521.689208984375  loc loss 40.877349853515625\n",
      "cls loss 500.20123291015625  loc loss 20.93968391418457\n",
      "cls loss 812.2576904296875  loc loss 60.78837585449219\n",
      "cls loss 645.4920654296875  loc loss 41.290870666503906\n",
      "cls loss 388.29095458984375  loc loss 23.408681869506836\n",
      "cls loss 673.8546142578125  loc loss 37.671722412109375\n",
      "cls loss 794.5648803710938  loc loss 62.4488639831543\n",
      "cls loss 624.1329345703125  loc loss 41.811668395996094\n",
      "cls loss 580.340087890625  loc loss 32.24958419799805\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.])\n",
      "cls loss 538.6478881835938  loc loss 40.41826248168945\n",
      "cls loss 462.15289306640625  loc loss 38.222137451171875\n",
      "cls loss 693.2271728515625  loc loss 45.73993682861328\n",
      "cls loss 967.9425659179688  loc loss 82.43802642822266\n",
      "cls loss 454.75640869140625  loc loss 21.940929412841797\n",
      "cls loss 553.1148681640625  loc loss 36.3546142578125\n",
      "cls loss 481.365234375  loc loss 27.743255615234375\n",
      "cls loss 521.7225341796875  loc loss 31.966712951660156\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 21., 21., 21.])\n",
      "cls loss 565.6265869140625  loc loss 32.20576858520508\n",
      "cls loss 530.8880615234375  loc loss 24.38640785217285\n",
      "cls loss 539.233154296875  loc loss 36.21150588989258\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 35.])\n",
      "cls loss 766.6544189453125  loc loss 51.74174880981445\n",
      "cls loss 262.3778076171875  loc loss 14.724588394165039\n",
      "cls loss 406.15496826171875  loc loss 28.25401496887207\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 406.4239501953125  loc loss 21.651981353759766\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 38., 38.,  9., 38.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1.,  1.])\n",
      "cls loss 449.0331726074219  loc loss 33.93775939941406\n",
      "cls loss 724.4465942382812  loc loss 52.666664123535156\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 2.,  1., 77., 31., 10., 10.,  1.,  4., 10.])\n",
      "cls loss 403.5916748046875  loc loss 19.789764404296875\n",
      "cls loss 710.239990234375  loc loss 46.50234603881836\n",
      "cls loss 1422.3243408203125  loc loss 94.0286865234375\n",
      "cls loss 479.305419921875  loc loss 30.210124969482422\n",
      "cls loss 636.60107421875  loc loss 51.93492889404297\n",
      "cls loss 472.6156005859375  loc loss 29.06122589111328\n",
      "cls loss 493.7251892089844  loc loss 25.159814834594727\n",
      "cls loss 816.494140625  loc loss 33.2950439453125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 728.107666015625  loc loss 39.4398078918457\n",
      "cls loss 624.021484375  loc loss 43.89773941040039\n",
      "cls loss 470.5254211425781  loc loss 24.309829711914062\n",
      "cls loss 534.6084594726562  loc loss 27.446027755737305\n",
      "cls loss 981.0146484375  loc loss 61.127967834472656\n",
      "cls loss 814.4549560546875  loc loss 53.54254913330078\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1., 42., 42., 42., 42., 42., 42.,  1.,\n",
      "         1.,  1.,  1., 42.,  1.,  1., 42.,  1.])\n",
      "cls loss 472.20904541015625  loc loss 32.846397399902344\n",
      "cls loss 690.3411865234375  loc loss 44.75335693359375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.])\n",
      "cls loss 308.6728515625  loc loss 20.679096221923828\n",
      "cls loss 655.8043212890625  loc loss 47.26951599121094\n",
      "cls loss 533.2257690429688  loc loss 39.74672317504883\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([11.])\n",
      "cls loss 330.1299743652344  loc loss 19.30104637145996\n",
      "cls loss 433.92724609375  loc loss 20.310855865478516\n",
      "cls loss 445.03546142578125  loc loss 21.45029067993164\n",
      "cls loss 633.607666015625  loc loss 44.18072509765625\n",
      "cls loss 621.52685546875  loc loss 35.24958038330078\n",
      "cls loss 595.4427490234375  loc loss 43.281028747558594\n",
      "cls loss 875.90576171875  loc loss 47.889381408691406\n",
      "cls loss 472.7000732421875  loc loss 28.62913703918457\n",
      "cls loss 837.2142333984375  loc loss 64.61869049072266\n",
      "cls loss 477.89642333984375  loc loss 28.17218780517578\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 415.1537780761719  loc loss 29.90992546081543\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1., 38., 38., 42.])\n",
      "cls loss 528.5704345703125  loc loss 39.747013092041016\n",
      "cls loss 483.0475158691406  loc loss 27.102127075195312\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 409.7353820800781  loc loss 30.511798858642578\n",
      "cls loss 948.2534790039062  loc loss 69.12223815917969\n",
      "cls loss 567.193115234375  loc loss 41.695152282714844\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10.,  3.,  3.,  6.,  8.,  8.,  1.,  1.,  1., 10.])\n",
      "cls loss 499.7373962402344  loc loss 29.49007797241211\n",
      "cls loss 297.3221435546875  loc loss 12.017742156982422\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10.,  3.])\n",
      "cls loss 471.770751953125  loc loss 27.122337341308594\n",
      "cls loss 290.90069580078125  loc loss 13.601762771606445\n",
      "cls loss 544.798828125  loc loss 43.89154815673828\n",
      "cls loss 615.093994140625  loc loss 44.43544387817383\n",
      "cls loss 485.6884765625  loc loss 29.963258743286133\n",
      "cls loss 364.19671630859375  loc loss 17.461605072021484\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 34.])\n",
      "cls loss 857.4814453125  loc loss 51.37939453125\n",
      "cls loss 859.6690063476562  loc loss 72.498291015625\n",
      "cls loss 563.228271484375  loc loss 45.36425018310547\n",
      "cls loss 420.5261535644531  loc loss 31.280010223388672\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.,  1.])\n",
      "cls loss 469.90283203125  loc loss 26.40705680847168\n",
      "cls loss 736.72607421875  loc loss 60.88025665283203\n",
      "cls loss 1095.020263671875  loc loss 75.14617919921875\n",
      "cls loss 929.0968627929688  loc loss 50.60710525512695\n",
      "cls loss 545.7937622070312  loc loss 31.15498924255371\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 694.1201171875  loc loss 40.17634201049805\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10.])\n",
      "cls loss 422.2301025390625  loc loss 23.60161590576172\n",
      "cls loss 602.1260986328125  loc loss 31.56329917907715\n",
      "cls loss 572.202392578125  loc loss 32.939083099365234\n",
      "cls loss 400.3109130859375  loc loss 25.45381736755371\n",
      "cls loss 494.553466796875  loc loss 36.64002227783203\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21.,\n",
      "        21.])\n",
      "cls loss 682.4140625  loc loss 41.15277862548828\n",
      "cls loss 550.7152709960938  loc loss 37.715087890625\n",
      "cls loss 353.68255615234375  loc loss 17.004606246948242\n",
      "cls loss 732.5366821289062  loc loss 49.9620361328125\n",
      "cls loss 583.2606201171875  loc loss 41.70646286010742\n",
      "cls loss 412.8440246582031  loc loss 27.074892044067383\n",
      "cls loss 857.8486938476562  loc loss 62.10892105102539\n",
      "cls loss 1038.6846923828125  loc loss 73.52674102783203\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15., 85.])\n",
      "cls loss 675.1373291015625  loc loss 43.4348030090332\n",
      "cls loss 654.2481689453125  loc loss 50.51579666137695\n",
      "cls loss 684.586181640625  loc loss 49.422733306884766\n",
      "cls loss 608.262939453125  loc loss 35.711097717285156\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 8., 8.])\n",
      "cls loss 390.46051025390625  loc loss 21.350343704223633\n",
      "cls loss 435.2920227050781  loc loss 29.508182525634766\n",
      "cls loss 527.6365966796875  loc loss 32.52654266357422\n",
      "cls loss 444.402587890625  loc loss 25.659387588500977\n",
      "cls loss 513.084716796875  loc loss 31.758453369140625\n",
      "cls loss 665.8890991210938  loc loss 42.10478210449219\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1., 35., 27., 27.,  1., 27.,  1.])\n",
      "cls loss 941.3190307617188  loc loss 63.46817398071289\n",
      "cls loss 427.92254638671875  loc loss 31.898178100585938\n",
      "cls loss 526.5281982421875  loc loss 39.72256851196289\n",
      "cls loss 494.1965026855469  loc loss 43.741119384765625\n",
      "cls loss 463.04608154296875  loc loss 35.21248245239258\n",
      "cls loss 489.9281005859375  loc loss 40.18207931518555\n",
      "cls loss 493.5677185058594  loc loss 40.15556335449219\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  2.,  2.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  2.,  2.])\n",
      "cls loss 321.049072265625  loc loss 12.59604549407959\n",
      "cls loss 754.1871337890625  loc loss 48.32197570800781\n",
      "cls loss 551.3648681640625  loc loss 27.812210083007812\n",
      "cls loss 864.2816162109375  loc loss 64.06690979003906\n",
      "cls loss 367.2027587890625  loc loss 23.103147506713867\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 19., 19., 19., 16.])\n",
      "cls loss 380.49420166015625  loc loss 17.868881225585938\n",
      "cls loss 302.4736022949219  loc loss 14.78244686126709\n",
      "cls loss 458.2284851074219  loc loss 24.450420379638672\n",
      "cls loss 598.6117553710938  loc loss 41.40115737915039\n",
      "cls loss 313.512451171875  loc loss 23.71453857421875\n",
      "cls loss 691.4290771484375  loc loss 51.19446563720703\n",
      "cls loss 491.24249267578125  loc loss 36.152774810791016\n",
      "cls loss 537.301513671875  loc loss 36.76303482055664\n",
      "cls loss 656.4058227539062  loc loss 49.29081726074219\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 765.8233642578125  loc loss 34.53590393066406\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 953.4951171875  loc loss 83.6764907836914\n",
      "cls loss 1171.399169921875  loc loss 117.42877197265625\n",
      "cls loss 600.2534790039062  loc loss 44.1864128112793\n",
      "cls loss 554.1116943359375  loc loss 37.99504470825195\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3.,  3.,  3.,  3.,  3., 10.])\n",
      "cls loss 336.1729736328125  loc loss 17.996829986572266\n",
      "cls loss 597.48388671875  loc loss 33.31291198730469\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 1., 1., 1., 3., 3., 3., 3.])\n",
      "cls loss 480.6850891113281  loc loss 32.90055465698242\n",
      "cls loss 859.9268798828125  loc loss 61.842041015625\n",
      "cls loss 689.923828125  loc loss 48.705631256103516\n",
      "cls loss 498.84307861328125  loc loss 28.180017471313477\n",
      "cls loss 695.8134765625  loc loss 54.077178955078125\n",
      "cls loss 443.3597717285156  loc loss 34.158775329589844\n",
      "cls loss 703.1978149414062  loc loss 51.283447265625\n",
      "cls loss 525.0208740234375  loc loss 47.71788787841797\n",
      "cls loss 517.5638427734375  loc loss 36.67386245727539\n",
      "cls loss 1099.923583984375  loc loss 93.44132995605469\n",
      "cls loss 720.7947998046875  loc loss 51.91435623168945\n",
      "cls loss 499.22113037109375  loc loss 25.19199562072754\n",
      "cls loss 338.9010009765625  loc loss 15.361808776855469\n",
      "cls loss 378.92828369140625  loc loss 20.09087562561035\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3., 10., 10., 10., 10., 10., 10., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10., 10., 10., 10., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 11., 10., 10., 10., 10., 10.,  3.,  3.,  3.,  3.,  3.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 11., 10., 10., 10., 10., 10.,  3.,  3.,  3.,  3.,  3.])\n",
      "cls loss 389.90240478515625  loc loss 18.10142707824707\n",
      "cls loss 458.8165283203125  loc loss 22.835527420043945\n",
      "cls loss 382.49114990234375  loc loss 24.46992301940918\n",
      "cls loss 371.370849609375  loc loss 16.392087936401367\n",
      "cls loss 438.19964599609375  loc loss 35.3079833984375\n",
      "cls loss 371.5037536621094  loc loss 14.822599411010742\n",
      "cls loss 667.47216796875  loc loss 45.667381286621094\n",
      "cls loss 582.4976196289062  loc loss 42.864933013916016\n",
      "cls loss 874.3695068359375  loc loss 58.43206024169922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 430.6486511230469  loc loss 33.59585952758789\n",
      "cls loss 774.17333984375  loc loss 53.597694396972656\n",
      "cls loss 637.8825073242188  loc loss 44.38376998901367\n",
      "cls loss 593.7487182617188  loc loss 40.81637954711914\n",
      "cls loss 608.986572265625  loc loss 45.80073928833008\n",
      "cls loss 834.9251098632812  loc loss 56.2275505065918\n",
      "cls loss 811.1940307617188  loc loss 50.121620178222656\n",
      "cls loss 388.9676513671875  loc loss 22.610363006591797\n",
      "cls loss 678.73828125  loc loss 53.98112487792969\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 10.,  1., 18.])\n",
      "cls loss 350.013916015625  loc loss 24.925703048706055\n",
      "cls loss 400.3351745605469  loc loss 17.839733123779297\n",
      "cls loss 694.1461181640625  loc loss 36.421913146972656\n",
      "cls loss 976.3074340820312  loc loss 65.59719848632812\n",
      "cls loss 593.6011962890625  loc loss 42.39799880981445\n",
      "cls loss 825.934814453125  loc loss 49.44255447387695\n",
      "cls loss 572.752685546875  loc loss 40.06936264038086\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.,  1.,  1.])\n",
      "cls loss 745.6578369140625  loc loss 50.46318054199219\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1., 38.,  1.])\n",
      "cls loss 726.7734985351562  loc loss 42.030029296875\n",
      "cls loss 926.7933959960938  loc loss 68.46025085449219\n",
      "cls loss 470.5845947265625  loc loss 35.78950881958008\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 637.4060668945312  loc loss 45.085636138916016\n",
      "cls loss 560.8358154296875  loc loss 37.43412780761719\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3., 10.,  8.,  3., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.])\n",
      "cls loss 675.8661499023438  loc loss 42.95778274536133\n",
      "cls loss 480.4465637207031  loc loss 30.885663986206055\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3.,  3., 11.,  3., 10., 10.,  3.,  3., 10.])\n",
      "cls loss 565.43896484375  loc loss 28.140518188476562\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3., 10., 10., 10.])\n",
      "cls loss 553.9661254882812  loc loss 38.87885284423828\n",
      "cls loss 474.08209228515625  loc loss 26.754438400268555\n",
      "cls loss 574.917236328125  loc loss 41.9929084777832\n",
      "cls loss 907.9443359375  loc loss 55.56834411621094\n",
      "cls loss 568.8170166015625  loc loss 38.274356842041016\n",
      "cls loss 397.8509216308594  loc loss 36.33163070678711\n",
      "cls loss 510.34716796875  loc loss 37.741729736328125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 9.,  9., 85., 85.])\n",
      "cls loss 459.425537109375  loc loss 26.17668342590332\n",
      "cls loss 518.0216064453125  loc loss 36.304832458496094\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 856.59912109375  loc loss 64.89167022705078\n",
      "cls loss 729.2828979492188  loc loss 37.805538177490234\n",
      "cls loss 822.5357666015625  loc loss 59.11957550048828\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10., 10., 10., 10.])\n",
      "cls loss 523.5592041015625  loc loss 33.23428726196289\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([13.])\n",
      "cls loss 831.5726318359375  loc loss 65.70189666748047\n",
      "cls loss 304.55645751953125  loc loss 16.896934509277344\n",
      "cls loss 376.4501647949219  loc loss 20.150114059448242\n",
      "cls loss 523.76025390625  loc loss 28.080751419067383\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19.,  1.,  1.,  1., 19., 19.])\n",
      "cls loss 539.1236572265625  loc loss 34.299835205078125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 401.7126770019531  loc loss 33.25065231323242\n",
      "cls loss 605.8502807617188  loc loss 44.73176956176758\n",
      "cls loss 433.778076171875  loc loss 26.493389129638672\n",
      "cls loss 640.4392700195312  loc loss 39.97887420654297\n",
      "cls loss 688.8023681640625  loc loss 53.83794403076172\n",
      "cls loss 556.1771850585938  loc loss 31.148706436157227\n",
      "cls loss 772.0833740234375  loc loss 58.94348907470703\n",
      "cls loss 331.6517333984375  loc loss 15.730024337768555\n",
      "cls loss 569.1156005859375  loc loss 36.887245178222656\n",
      "cls loss 450.9904479980469  loc loss 23.923419952392578\n",
      "cls loss 475.21392822265625  loc loss 26.916534423828125\n",
      "cls loss 599.32666015625  loc loss 43.02458953857422\n",
      "cls loss 575.031982421875  loc loss 33.65044021606445\n",
      "cls loss 829.09619140625  loc loss 53.380950927734375\n",
      "cls loss 512.4141235351562  loc loss 36.62226486206055\n",
      "cls loss 654.281005859375  loc loss 45.54875564575195\n",
      "cls loss 973.24462890625  loc loss 62.18733215332031\n",
      "cls loss 539.4383544921875  loc loss 41.56169509887695\n",
      "cls loss 612.4608764648438  loc loss 37.7075309753418\n",
      "cls loss 739.4739379882812  loc loss 56.1138916015625\n",
      "cls loss 760.8374633789062  loc loss 56.06810760498047\n",
      "cls loss 971.2052001953125  loc loss 54.25523376464844\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 5.])\n",
      "cls loss 298.04241943359375  loc loss 11.367385864257812\n",
      "cls loss 373.436279296875  loc loss 16.82317352294922\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 13.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 6., 8., 8.])\n",
      "cls loss 324.79705810546875  loc loss 16.25436782836914\n",
      "cls loss 380.19940185546875  loc loss 21.901004791259766\n",
      "cls loss 749.98681640625  loc loss 53.037254333496094\n",
      "cls loss 332.2825622558594  loc loss 16.758468627929688\n",
      "cls loss 588.4042358398438  loc loss 45.42896270751953\n",
      "cls loss 938.045654296875  loc loss 65.44293212890625\n",
      "cls loss 546.3673706054688  loc loss 43.06739807128906\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([42., 42.,  1.,  1.,  1.,  1.,  1.,  1.,  1., 42., 42.])\n",
      "cls loss 612.6965942382812  loc loss 36.82942199707031\n",
      "cls loss 800.3624877929688  loc loss 63.254119873046875\n",
      "cls loss 645.0511474609375  loc loss 54.14604187011719\n",
      "cls loss 476.28692626953125  loc loss 29.149751663208008\n",
      "cls loss 636.6670532226562  loc loss 39.42302703857422\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 854.69873046875  loc loss 56.959999084472656\n",
      "cls loss 675.9021606445312  loc loss 49.154266357421875\n",
      "cls loss 444.92608642578125  loc loss 27.160858154296875\n",
      "cls loss 371.09246826171875  loc loss 19.98735237121582\n",
      "cls loss 528.9857177734375  loc loss 31.657678604125977\n",
      "cls loss 695.7650146484375  loc loss 47.15425109863281\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15.])\n",
      "cls loss 334.3489685058594  loc loss 17.090858459472656\n",
      "cls loss 544.738037109375  loc loss 37.259788513183594\n",
      "cls loss 493.3272399902344  loc loss 33.39485549926758\n",
      "cls loss 869.427978515625  loc loss 62.07917404174805\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19.,  7.])\n",
      "cls loss 495.64031982421875  loc loss 30.680561065673828\n",
      "cls loss 992.0657958984375  loc loss 63.49729919433594\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 829.3231811523438  loc loss 45.02369689941406\n",
      "cls loss 653.775390625  loc loss 51.119503021240234\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([38., 38.,  1., 18.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1., 18., 18.,  1.])\n",
      "cls loss 540.29931640625  loc loss 27.752059936523438\n",
      "cls loss 491.55010986328125  loc loss 25.00844383239746\n",
      "cls loss 878.1746826171875  loc loss 68.83113098144531\n",
      "cls loss 699.624267578125  loc loss 39.36125946044922\n",
      "cls loss 664.086669921875  loc loss 33.838584899902344\n",
      "cls loss 362.8243408203125  loc loss 28.309661865234375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.])\n",
      "cls loss 302.1627197265625  loc loss 10.297890663146973\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([32.])\n",
      "cls loss 571.4490966796875  loc loss 29.818395614624023\n",
      "cls loss 495.232177734375  loc loss 35.342044830322266\n",
      "cls loss 656.40087890625  loc loss 53.61206817626953\n",
      "cls loss 599.9789428710938  loc loss 39.41492462158203\n",
      "cls loss 486.95513916015625  loc loss 32.32038497924805\n",
      "cls loss 771.283935546875  loc loss 50.026817321777344\n",
      "cls loss 825.5911865234375  loc loss 58.765933990478516\n",
      "cls loss 664.3816528320312  loc loss 45.184326171875\n",
      "cls loss 558.9302978515625  loc loss 33.08208465576172\n",
      "cls loss 863.63232421875  loc loss 55.81786346435547\n",
      "cls loss 546.7843627929688  loc loss 29.280344009399414\n",
      "cls loss 861.9310302734375  loc loss 70.62171173095703\n",
      "cls loss 640.4210815429688  loc loss 37.51628875732422\n",
      "cls loss 531.716796875  loc loss 38.89247131347656\n",
      "cls loss 406.4584045410156  loc loss 21.856224060058594\n",
      "cls loss 449.1494445800781  loc loss 29.040639877319336\n",
      "cls loss 668.1533813476562  loc loss 45.45159149169922\n",
      "cls loss 681.06884765625  loc loss 50.896156311035156\n",
      "cls loss 408.0879211425781  loc loss 28.18752670288086\n",
      "cls loss 755.485107421875  loc loss 51.462345123291016\n",
      "cls loss 885.583251953125  loc loss 54.83528518676758\n",
      "cls loss 337.381103515625  loc loss 23.439075469970703\n",
      "cls loss 845.1788330078125  loc loss 58.81194305419922\n",
      "cls loss 606.6953125  loc loss 47.41736602783203\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 836.44189453125  loc loss 65.49815368652344\n",
      "cls loss 419.5514221191406  loc loss 16.41015625\n",
      "cls loss 635.7691650390625  loc loss 34.65217208862305\n",
      "cls loss 618.310791015625  loc loss 42.57530975341797\n",
      "cls loss 495.0729675292969  loc loss 29.028892517089844\n",
      "cls loss 305.6040954589844  loc loss 16.566728591918945\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 9., 9., 1., 9., 9., 9., 9., 1., 9.])\n",
      "cls loss 1054.7044677734375  loc loss 92.78522491455078\n",
      "cls loss 621.240234375  loc loss 33.715694427490234\n",
      "cls loss 920.0405883789062  loc loss 78.00952911376953\n",
      "cls loss 389.0455322265625  loc loss 27.154558181762695\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 42., 42.])\n",
      "cls loss 668.09326171875  loc loss 50.341041564941406\n",
      "cls loss 715.9481201171875  loc loss 52.373233795166016\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  2.,  1.,  1.,  1., 38.,\n",
      "         1.,  1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 38., 38., 38.,  1., 38., 38., 38.,  1.,  1., 38.,  1.,\n",
      "         1.])\n",
      "cls loss 443.15911865234375  loc loss 31.23397445678711\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  8.,  8.])\n",
      "cls loss 992.8132934570312  loc loss 67.83757781982422\n",
      "cls loss 1008.5494995117188  loc loss 71.79080200195312\n",
      "cls loss 402.2259826660156  loc loss 23.689605712890625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([4., 1., 1., 4.])\n",
      "cls loss 569.4517211914062  loc loss 40.408355712890625\n",
      "cls loss 675.118408203125  loc loss 43.06059265136719\n",
      "cls loss 312.813720703125  loc loss 14.750061988830566\n",
      "cls loss 421.66436767578125  loc loss 26.304250717163086\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([51.,  1.])\n",
      "cls loss 305.8519592285156  loc loss 13.32322883605957\n",
      "cls loss 396.4971618652344  loc loss 24.150623321533203\n",
      "cls loss 708.9903564453125  loc loss 42.77815246582031\n",
      "cls loss 782.86083984375  loc loss 59.4371223449707\n",
      "cls loss 1056.84765625  loc loss 59.677574157714844\n",
      "cls loss 1334.1439208984375  loc loss 87.59005737304688\n",
      "cls loss 560.9154663085938  loc loss 35.14194107055664\n",
      "cls loss 794.953857421875  loc loss 56.6881217956543\n",
      "cls loss 838.0347290039062  loc loss 60.95713424682617\n",
      "cls loss 650.86767578125  loc loss 37.91876983642578\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  3.,  1.,  1.,  1.,  3.,  1.,  1.,\n",
      "         1.,  1.,  1.])\n",
      "cls loss 690.1314697265625  loc loss 35.233097076416016\n",
      "cls loss 782.978515625  loc loss 40.271636962890625\n",
      "cls loss 699.5550537109375  loc loss 37.21498107910156\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "cls loss 569.970703125  loc loss 34.722206115722656\n",
      "cls loss 343.0128173828125  loc loss 27.88173484802246\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3.])\n",
      "cls loss 303.5534973144531  loc loss 13.99461555480957\n",
      "cls loss 515.0587768554688  loc loss 36.7697868347168\n",
      "cls loss 413.40557861328125  loc loss 31.87969207763672\n",
      "cls loss 739.3683471679688  loc loss 51.8791389465332\n",
      "cls loss 507.62298583984375  loc loss 25.881160736083984\n",
      "cls loss 407.45330810546875  loc loss 29.126495361328125\n",
      "cls loss 1254.1876220703125  loc loss 84.53609466552734\n",
      "cls loss 542.818359375  loc loss 40.802581787109375\n",
      "cls loss 386.6634216308594  loc loss 31.789501190185547\n",
      "cls loss 529.7247314453125  loc loss 31.420856475830078\n",
      "cls loss 464.052490234375  loc loss 34.17988586425781\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 845.188720703125  loc loss 58.250343322753906\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  9., 64., 64., 64., 64., 64., 64., 64., 64., 64.,  9.,  9.,  9.,\n",
      "         9.])\n",
      "cls loss 479.536376953125  loc loss 24.7034854888916\n",
      "cls loss 1095.14208984375  loc loss 88.16559600830078\n",
      "cls loss 560.052001953125  loc loss 38.456729888916016\n",
      "cls loss 731.5189208984375  loc loss 54.31978988647461\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.,  3.,  3.])\n",
      "cls loss 483.0391540527344  loc loss 30.032001495361328\n",
      "cls loss 546.9425048828125  loc loss 34.834320068359375\n",
      "cls loss 524.723388671875  loc loss 38.94763946533203\n",
      "cls loss 581.794189453125  loc loss 41.144691467285156\n",
      "cls loss 552.4857177734375  loc loss 46.689170837402344\n",
      "cls loss 544.562255859375  loc loss 43.364501953125\n",
      "cls loss 540.3923950195312  loc loss 43.54536819458008\n",
      "cls loss 558.38720703125  loc loss 36.346343994140625\n",
      "cls loss 698.8173828125  loc loss 50.60060501098633\n",
      "cls loss 607.063232421875  loc loss 35.76202392578125\n",
      "cls loss 485.1019287109375  loc loss 22.026350021362305\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21.])\n",
      "cls loss 360.53765869140625  loc loss 20.011091232299805\n",
      "cls loss 488.93707275390625  loc loss 41.884002685546875\n",
      "cls loss 697.8751220703125  loc loss 51.80854034423828\n",
      "cls loss 449.3096923828125  loc loss 25.807186126708984\n",
      "cls loss 622.693603515625  loc loss 37.951812744140625\n",
      "cls loss 1108.120849609375  loc loss 63.21739196777344\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 42., 42.,  1.,  1.])\n",
      "cls loss 555.6390380859375  loc loss 35.47206115722656\n",
      "cls loss 368.9469909667969  loc loss 27.602622985839844\n",
      "cls loss 510.95977783203125  loc loss 39.84648895263672\n",
      "cls loss 722.5128173828125  loc loss 60.921932220458984\n",
      "cls loss 466.8410949707031  loc loss 31.38437271118164\n",
      "cls loss 661.25  loc loss 52.10708999633789\n",
      "cls loss 642.9835205078125  loc loss 50.642269134521484\n",
      "cls loss 695.552490234375  loc loss 42.05230712890625\n",
      "cls loss 548.8807373046875  loc loss 34.96971130371094\n",
      "cls loss 498.288330078125  loc loss 31.00054931640625\n",
      "cls loss 398.64459228515625  loc loss 17.79628562927246\n",
      "cls loss 504.4769287109375  loc loss 35.2901611328125\n",
      "cls loss 740.3414306640625  loc loss 63.115379333496094\n",
      "cls loss 593.6390380859375  loc loss 38.94548034667969\n",
      "cls loss 587.939208984375  loc loss 44.39651870727539\n",
      "cls loss 641.6707153320312  loc loss 36.92622375488281\n",
      "cls loss 937.2830810546875  loc loss 63.15027618408203\n",
      "cls loss 649.1234130859375  loc loss 51.708595275878906\n",
      "cls loss 768.9683837890625  loc loss 44.9998779296875\n",
      "cls loss 450.37835693359375  loc loss 23.106670379638672\n",
      "cls loss 636.88720703125  loc loss 42.208805084228516\n",
      "cls loss 584.61083984375  loc loss 39.11279296875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 5., 5., 5., 5., 5., 5.])\n",
      "cls loss 426.70208740234375  loc loss 29.455936431884766\n",
      "cls loss 501.294921875  loc loss 31.23903465270996\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([13.])\n",
      "cls loss 343.4657287597656  loc loss 22.517616271972656\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([44., 10.,  1.,  1.,  1.])\n",
      "cls loss 364.1833190917969  loc loss 22.56076431274414\n",
      "cls loss 684.3822021484375  loc loss 36.50218200683594\n",
      "cls loss 552.30078125  loc loss 32.072975158691406\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19., 19., 19., 19., 19., 19., 19.])\n",
      "cls loss 705.5201416015625  loc loss 40.05569076538086\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([56.])\n",
      "cls loss 1250.9471435546875  loc loss 76.27742004394531\n",
      "cls loss 678.5889892578125  loc loss 55.968135833740234\n",
      "cls loss 901.086669921875  loc loss 66.56245422363281\n",
      "cls loss 889.2540283203125  loc loss 70.40538787841797\n",
      "cls loss 541.5770263671875  loc loss 33.40705108642578\n",
      "cls loss 877.1109619140625  loc loss 65.56050872802734\n",
      "cls loss 527.643798828125  loc loss 32.467437744140625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 36.])\n",
      "cls loss 622.050048828125  loc loss 35.75471878051758\n",
      "cls loss 540.046630859375  loc loss 40.19194412231445\n",
      "cls loss 576.5254516601562  loc loss 34.24812316894531\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5.])\n",
      "cls loss 629.5639038085938  loc loss 40.29584503173828\n",
      "cls loss 361.21905517578125  loc loss 20.05304527282715\n",
      "cls loss 792.041259765625  loc loss 46.84703063964844\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "cls loss 711.26171875  loc loss 49.45956039428711\n",
      "cls loss 736.9324951171875  loc loss 46.75275421142578\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 645.513671875  loc loss 47.15365219116211\n",
      "cls loss 775.3492431640625  loc loss 55.71092224121094\n",
      "cls loss 636.4859619140625  loc loss 59.0428352355957\n",
      "cls loss 457.7082214355469  loc loss 32.67121887207031\n",
      "cls loss 571.12255859375  loc loss 42.066070556640625\n",
      "cls loss 572.90966796875  loc loss 38.24622344970703\n",
      "cls loss 870.261474609375  loc loss 53.5353889465332\n",
      "cls loss 411.917236328125  loc loss 21.629474639892578\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 11., 15., 10., 10., 10., 10., 10.])\n",
      "cls loss 929.941162109375  loc loss 64.72244262695312\n",
      "cls loss 526.3161010742188  loc loss 36.18946838378906\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 584.3380126953125  loc loss 38.54105758666992\n",
      "cls loss 509.1728210449219  loc loss 30.58641242980957\n",
      "cls loss 559.759033203125  loc loss 28.988618850708008\n",
      "cls loss 718.3583984375  loc loss 37.16475296020508\n",
      "cls loss 409.71490478515625  loc loss 19.051259994506836\n",
      "cls loss 570.2613525390625  loc loss 36.1766357421875\n",
      "cls loss 631.4786376953125  loc loss 49.51185989379883\n",
      "cls loss 537.2962646484375  loc loss 41.17585754394531\n",
      "cls loss 1214.77392578125  loc loss 94.74199676513672\n",
      "cls loss 877.348876953125  loc loss 60.0618896484375\n",
      "cls loss 561.4482421875  loc loss 42.49385452270508\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  9.,  9.,  9.,  6.,  6., 85., 85.,  8.,  1.,  1.,  1.,  1.,\n",
      "         6.,  6.])\n",
      "cls loss 409.5185546875  loc loss 29.344684600830078\n",
      "cls loss 914.6732177734375  loc loss 66.05709838867188\n",
      "cls loss 1082.4564208984375  loc loss 71.17253875732422\n",
      "cls loss 752.5390625  loc loss 52.56776428222656\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10.,  3.,  3., 10.])\n",
      "cls loss 496.67169189453125  loc loss 29.989639282226562\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([7.])\n",
      "cls loss 639.8688354492188  loc loss 47.03200912475586\n",
      "cls loss 650.2960815429688  loc loss 40.374046325683594\n",
      "cls loss 588.2561645507812  loc loss 46.706520080566406\n",
      "cls loss 837.9026489257812  loc loss 67.2017822265625\n",
      "cls loss 621.4556884765625  loc loss 41.28969192504883\n",
      "cls loss 819.611328125  loc loss 54.583648681640625\n",
      "cls loss 1000.4957885742188  loc loss 62.753089904785156\n",
      "cls loss 603.8839111328125  loc loss 42.74494552612305\n",
      "cls loss 642.9723510742188  loc loss 45.241943359375\n",
      "cls loss 546.8724365234375  loc loss 41.57388687133789\n",
      "cls loss 760.7969970703125  loc loss 63.980735778808594\n",
      "cls loss 633.7536010742188  loc loss 41.97500991821289\n",
      "cls loss 498.6341552734375  loc loss 30.251434326171875\n",
      "cls loss 756.1853637695312  loc loss 59.2296257019043\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([62.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([62.])\n",
      "cls loss 337.37078857421875  loc loss 19.491588592529297\n",
      "cls loss 608.8532104492188  loc loss 44.869422912597656\n",
      "cls loss 596.0269775390625  loc loss 40.461421966552734\n",
      "cls loss 429.8341064453125  loc loss 18.58596420288086\n",
      "cls loss 760.80810546875  loc loss 53.79656219482422\n",
      "cls loss 741.0699462890625  loc loss 45.9022102355957\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([28.])\n",
      "cls loss 826.173583984375  loc loss 47.15094757080078\n",
      "cls loss 745.72216796875  loc loss 47.45451736450195\n",
      "cls loss 718.061279296875  loc loss 47.08528518676758\n",
      "cls loss 743.2418823242188  loc loss 51.313167572021484\n",
      "cls loss 1012.8798828125  loc loss 70.93299865722656\n",
      "cls loss 570.1072998046875  loc loss 38.16622543334961\n",
      "cls loss 711.834716796875  loc loss 44.94065856933594\n",
      "cls loss 639.2859497070312  loc loss 54.191558837890625\n",
      "cls loss 1014.607421875  loc loss 78.68836975097656\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([81.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 706.7381591796875  loc loss 30.716236114501953\n",
      "cls loss 544.4970703125  loc loss 27.752328872680664\n",
      "cls loss 463.9935302734375  loc loss 29.530364990234375\n",
      "cls loss 390.5054931640625  loc loss 16.673768997192383\n",
      "cls loss 438.47259521484375  loc loss 28.44704818725586\n",
      "cls loss 467.8856201171875  loc loss 30.575437545776367\n",
      "cls loss 534.7974243164062  loc loss 34.518096923828125\n",
      "cls loss 699.246337890625  loc loss 57.79749298095703\n",
      "cls loss 780.34130859375  loc loss 54.341033935546875\n",
      "cls loss 1485.5303955078125  loc loss 105.85604095458984\n",
      "cls loss 609.5379638671875  loc loss 32.106910705566406\n",
      "cls loss 721.5787353515625  loc loss 49.78679275512695\n",
      "cls loss 510.1396789550781  loc loss 32.97418212890625\n",
      "cls loss 680.395263671875  loc loss 38.216880798339844\n",
      "cls loss 627.865966796875  loc loss 35.46708679199219\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([44., 44.])\n",
      "cls loss 546.641357421875  loc loss 27.8701114654541\n",
      "cls loss 544.3295288085938  loc loss 39.72984313964844\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15.])\n",
      "cls loss 651.801513671875  loc loss 34.72869873046875\n",
      "cls loss 307.3016052246094  loc loss 18.272171020507812\n",
      "cls loss 630.8485717773438  loc loss 38.64561462402344\n",
      "cls loss 344.527587890625  loc loss 23.44168472290039\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([1., 3., 3.])\n",
      "cls loss 390.6512756347656  loc loss 31.387706756591797\n",
      "cls loss 337.796630859375  loc loss 14.992776870727539\n",
      "cls loss 602.9591064453125  loc loss 34.870059967041016\n",
      "cls loss 627.7041015625  loc loss 38.01018524169922\n",
      "cls loss 572.6968383789062  loc loss 37.704322814941406\n",
      "cls loss 594.8486328125  loc loss 35.40009307861328\n",
      "cls loss 489.7974853515625  loc loss 37.25580596923828\n",
      "cls loss 632.76025390625  loc loss 45.05065155029297\n",
      "cls loss 513.3805541992188  loc loss 34.477970123291016\n",
      "cls loss 628.317138671875  loc loss 45.688018798828125\n",
      "cls loss 407.7646179199219  loc loss 25.722084045410156\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 735.93798828125  loc loss 46.52729034423828\n",
      "cls loss 847.7691040039062  loc loss 44.992401123046875\n",
      "cls loss 767.798828125  loc loss 53.42177963256836\n",
      "cls loss 748.323974609375  loc loss 55.535682678222656\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10., 10., 10.,  1.,  1.,  1.,  1.,  1.,  1.,  8.,  8.,\n",
      "         1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10., 10., 10.,  1.,  1.,  1.,  1.,  1.,  1.,  8.,  8.,\n",
      "         1.])\n",
      "cls loss 735.1436767578125  loc loss 37.49983215332031\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 3., 3., 3.])\n",
      "cls loss 603.1405029296875  loc loss 39.057228088378906\n",
      "cls loss 420.6676025390625  loc loss 23.669231414794922\n",
      "cls loss 323.027587890625  loc loss 17.301937103271484\n",
      "cls loss 572.3478393554688  loc loss 41.754180908203125\n",
      "cls loss 450.45123291015625  loc loss 24.161958694458008\n",
      "cls loss 489.6314697265625  loc loss 34.14323806762695\n",
      "cls loss 570.4733276367188  loc loss 39.805572509765625\n",
      "cls loss 791.4766845703125  loc loss 56.738162994384766\n",
      "cls loss 654.2352905273438  loc loss 35.11476135253906\n",
      "cls loss 628.8712158203125  loc loss 38.74674987792969\n",
      "cls loss 715.5960083007812  loc loss 48.96977615356445\n",
      "cls loss 541.344970703125  loc loss 40.34012985229492\n",
      "cls loss 930.017333984375  loc loss 71.9628677368164\n",
      "cls loss 500.24346923828125  loc loss 27.381088256835938\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 721.0237426757812  loc loss 45.2105827331543\n",
      "cls loss 381.860595703125  loc loss 17.355356216430664\n",
      "cls loss 920.21240234375  loc loss 60.273372650146484\n",
      "cls loss 482.6439208984375  loc loss 25.374265670776367\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 34.])\n",
      "cls loss 745.9767456054688  loc loss 41.89784240722656\n",
      "cls loss 344.8555603027344  loc loss 23.883501052856445\n",
      "cls loss 655.5425415039062  loc loss 45.164127349853516\n",
      "cls loss 242.54647827148438  loc loss 17.55409812927246\n",
      "cls loss 607.4834594726562  loc loss 40.3249626159668\n",
      "cls loss 581.6107177734375  loc loss 45.56171798706055\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 38.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16., 16., 16.,  9.,  9.,  9., 16., 16., 16., 85.,  9.])\n",
      "cls loss 565.6674194335938  loc loss 37.46748733520508\n",
      "cls loss 643.368408203125  loc loss 52.41193389892578\n",
      "cls loss 907.9947509765625  loc loss 66.97980499267578\n",
      "cls loss 1272.5029296875  loc loss 88.83552551269531\n",
      "cls loss 396.400390625  loc loss 20.491718292236328\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3., 10.,  8.,  8., 10., 10., 10.,  3.,  3., 14.])\n",
      "cls loss 485.2565612792969  loc loss 23.349693298339844\n",
      "cls loss 837.306640625  loc loss 44.610679626464844\n",
      "cls loss 369.32879638671875  loc loss 14.101309776306152\n",
      "cls loss 555.8829345703125  loc loss 24.759658813476562\n",
      "cls loss 767.0855712890625  loc loss 44.550594329833984\n",
      "cls loss 620.976806640625  loc loss 42.4815788269043\n",
      "cls loss 373.98388671875  loc loss 19.543548583984375\n",
      "cls loss 410.109619140625  loc loss 26.190074920654297\n",
      "cls loss 616.51416015625  loc loss 41.54977035522461\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42., 42.,  1.])\n",
      "cls loss 570.65380859375  loc loss 43.03131103515625\n",
      "cls loss 498.5274963378906  loc loss 30.737335205078125\n",
      "cls loss 672.387939453125  loc loss 51.83494567871094\n",
      "cls loss 743.7410888671875  loc loss 51.374385833740234\n",
      "cls loss 534.3108520507812  loc loss 34.770538330078125\n",
      "cls loss 641.2730712890625  loc loss 46.585792541503906\n",
      "cls loss 419.21539306640625  loc loss 27.84395980834961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 458.9818115234375  loc loss 31.35726547241211\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20.])\n",
      "cls loss 353.97412109375  loc loss 20.56488800048828\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([11.])\n",
      "cls loss 438.529541015625  loc loss 24.12983512878418\n",
      "cls loss 314.96484375  loc loss 18.216136932373047\n",
      "cls loss 684.323486328125  loc loss 55.89055252075195\n",
      "cls loss 330.54620361328125  loc loss 15.033614158630371\n",
      "cls loss 652.8880615234375  loc loss 38.73410415649414\n",
      "cls loss 367.8847961425781  loc loss 22.387222290039062\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 35., 27.])\n",
      "cls loss 618.4306030273438  loc loss 40.79107666015625\n",
      "cls loss 620.7000732421875  loc loss 51.1746940612793\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 481.63916015625  loc loss 29.835968017578125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([42.,  1.])\n",
      "cls loss 627.8712768554688  loc loss 45.75183868408203\n",
      "cls loss 558.375244140625  loc loss 33.691688537597656\n",
      "cls loss 701.0393676757812  loc loss 39.6783332824707\n",
      "cls loss 801.2933959960938  loc loss 55.63505172729492\n",
      "cls loss 724.711181640625  loc loss 47.70321273803711\n",
      "cls loss 491.16845703125  loc loss 39.6616096496582\n",
      "cls loss 424.8410339355469  loc loss 34.21141815185547\n",
      "cls loss 285.62750244140625  loc loss 14.031082153320312\n",
      "cls loss 511.76287841796875  loc loss 30.315166473388672\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 1., 1.])\n",
      "cls loss 490.70166015625  loc loss 27.061847686767578\n",
      "cls loss 539.014892578125  loc loss 39.01005172729492\n",
      "cls loss 551.697509765625  loc loss 35.72550964355469\n",
      "cls loss 458.89080810546875  loc loss 33.576202392578125\n",
      "cls loss 541.7884521484375  loc loss 33.42926788330078\n",
      "cls loss 580.1746826171875  loc loss 43.70768737792969\n",
      "cls loss 806.9888916015625  loc loss 48.58727264404297\n",
      "cls loss 685.373046875  loc loss 54.12820053100586\n",
      "cls loss 640.1820068359375  loc loss 39.26125717163086\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 496.92608642578125  loc loss 36.27781677246094\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 584.3486328125  loc loss 30.023834228515625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([81.])\n",
      "cls loss 712.0953369140625  loc loss 46.60424041748047\n",
      "cls loss 447.1584167480469  loc loss 30.588285446166992\n",
      "cls loss 318.06585693359375  loc loss 20.65632438659668\n",
      "cls loss 489.9417724609375  loc loss 26.259220123291016\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3.,  1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 19.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 19.])\n",
      "cls loss 649.494140625  loc loss 45.7373161315918\n",
      "cls loss 374.455810546875  loc loss 19.009904861450195\n",
      "cls loss 394.84747314453125  loc loss 24.949974060058594\n",
      "cls loss 756.0889892578125  loc loss 56.51288604736328\n",
      "cls loss 402.61224365234375  loc loss 25.611557006835938\n",
      "cls loss 485.81024169921875  loc loss 35.42450714111328\n",
      "cls loss 602.5140991210938  loc loss 40.7850456237793\n",
      "cls loss 458.96148681640625  loc loss 35.417747497558594\n",
      "cls loss 613.5963745117188  loc loss 37.5686149597168\n",
      "cls loss 688.6646118164062  loc loss 48.916847229003906\n",
      "cls loss 809.1688842773438  loc loss 76.57539367675781\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 81.])\n",
      "cls loss 599.2793579101562  loc loss 33.63505172729492\n",
      "cls loss 514.7890625  loc loss 31.249563217163086\n",
      "cls loss 597.7301025390625  loc loss 33.44111633300781\n",
      "cls loss 436.27166748046875  loc loss 21.89423370361328\n",
      "cls loss 406.5829162597656  loc loss 25.67875862121582\n",
      "cls loss 475.532958984375  loc loss 34.54264831542969\n",
      "cls loss 382.80126953125  loc loss 26.491756439208984\n",
      "cls loss 299.962646484375  loc loss 20.589279174804688\n",
      "cls loss 391.77398681640625  loc loss 28.2202091217041\n",
      "cls loss 560.602783203125  loc loss 35.55031204223633\n",
      "cls loss 467.53387451171875  loc loss 36.64071273803711\n",
      "cls loss 490.0091552734375  loc loss 39.46160125732422\n",
      "cls loss 301.7552490234375  loc loss 22.9339599609375\n",
      "cls loss 988.8944702148438  loc loss 72.65900421142578\n",
      "cls loss 663.5687255859375  loc loss 45.63230895996094\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 556.1793823242188  loc loss 30.823932647705078\n",
      "cls loss 605.33251953125  loc loss 41.37384033203125\n",
      "cls loss 504.61981201171875  loc loss 28.47125244140625\n",
      "cls loss 686.2374877929688  loc loss 43.87887954711914\n",
      "cls loss 668.5338745117188  loc loss 44.375144958496094\n",
      "cls loss 591.634033203125  loc loss 38.766151428222656\n",
      "cls loss 497.4529113769531  loc loss 28.272523880004883\n",
      "cls loss 363.1180419921875  loc loss 22.667394638061523\n",
      "cls loss 534.9039306640625  loc loss 35.152259826660156\n",
      "cls loss 557.62353515625  loc loss 40.44887924194336\n",
      "cls loss 608.5973510742188  loc loss 35.59117889404297\n",
      "cls loss 756.9378662109375  loc loss 60.03736877441406\n",
      "cls loss 798.562255859375  loc loss 61.01716232299805\n",
      "cls loss 550.283203125  loc loss 41.24776077270508\n",
      "cls loss 706.6591796875  loc loss 58.52739715576172\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1., 38., 47.,  1.,  1.,  1.,  1.,  1., 62.])\n",
      "cls loss 523.7910766601562  loc loss 28.920391082763672\n",
      "cls loss 652.7037963867188  loc loss 37.617584228515625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 682.0617065429688  loc loss 41.00010299682617\n",
      "cls loss 751.981689453125  loc loss 55.045955657958984\n",
      "cls loss 519.6318359375  loc loss 26.41286277770996\n",
      "cls loss 563.8975830078125  loc loss 46.893070220947266\n",
      "cls loss 532.6074829101562  loc loss 34.16524124145508\n",
      "cls loss 332.5875244140625  loc loss 14.165087699890137\n",
      "cls loss 520.4693603515625  loc loss 30.275226593017578\n",
      "cls loss 423.37762451171875  loc loss 20.888269424438477\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1., 35.])\n",
      "cls loss 518.13427734375  loc loss 26.54728126525879\n",
      "cls loss 725.3160400390625  loc loss 40.396888732910156\n",
      "cls loss 680.4395751953125  loc loss 46.38901901245117\n",
      "cls loss 626.8575439453125  loc loss 52.36929702758789\n",
      "cls loss 501.46051025390625  loc loss 41.25675964355469\n",
      "cls loss 644.6446533203125  loc loss 49.20627212524414\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 375.2894287109375  loc loss 22.321224212646484\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 569.3856811523438  loc loss 27.827869415283203\n",
      "cls loss 891.3572998046875  loc loss 48.54400634765625\n",
      "cls loss 1062.053466796875  loc loss 80.07907104492188\n",
      "cls loss 548.43896484375  loc loss 29.1121768951416\n",
      "cls loss 475.74871826171875  loc loss 29.53211784362793\n",
      "cls loss 478.56756591796875  loc loss 28.89955711364746\n",
      "cls loss 510.78912353515625  loc loss 39.424861907958984\n",
      "cls loss 485.0737609863281  loc loss 20.626684188842773\n",
      "cls loss 798.8179931640625  loc loss 59.339969635009766\n",
      "cls loss 637.4967041015625  loc loss 40.637298583984375\n",
      "cls loss 379.8377685546875  loc loss 23.001705169677734\n",
      "cls loss 659.9091796875  loc loss 36.754478454589844\n",
      "cls loss 780.2202758789062  loc loss 61.514068603515625\n",
      "cls loss 617.636962890625  loc loss 41.00049591064453\n",
      "cls loss 573.806396484375  loc loss 31.538774490356445\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.])\n",
      "cls loss 526.0411376953125  loc loss 39.557220458984375\n",
      "cls loss 458.5618896484375  loc loss 37.62558364868164\n",
      "cls loss 678.303466796875  loc loss 45.10182189941406\n",
      "cls loss 958.295654296875  loc loss 81.0003662109375\n",
      "cls loss 449.53143310546875  loc loss 21.55275535583496\n",
      "cls loss 550.4945068359375  loc loss 35.865718841552734\n",
      "cls loss 475.0653076171875  loc loss 27.129619598388672\n",
      "cls loss 512.202880859375  loc loss 31.362524032592773\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 21., 21., 21.])\n",
      "cls loss 552.22412109375  loc loss 31.739503860473633\n",
      "cls loss 522.4536743164062  loc loss 23.978471755981445\n",
      "cls loss 530.4866943359375  loc loss 35.69580841064453\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 35.])\n",
      "cls loss 748.072021484375  loc loss 50.13365936279297\n",
      "cls loss 257.63037109375  loc loss 14.50393009185791\n",
      "cls loss 399.9936828613281  loc loss 27.863174438476562\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 402.08758544921875  loc loss 20.781982421875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 38., 38.,  9., 38.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1.,  1.])\n",
      "cls loss 444.740478515625  loc loss 33.061790466308594\n",
      "cls loss 716.6290283203125  loc loss 51.53668975830078\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 2.,  1., 77., 31., 10., 10.,  1.,  4., 10.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 398.408935546875  loc loss 19.380863189697266\n",
      "cls loss 701.9367065429688  loc loss 45.63257598876953\n",
      "cls loss 1409.1846923828125  loc loss 91.30950927734375\n",
      "cls loss 472.7325134277344  loc loss 29.6766300201416\n",
      "cls loss 629.0587158203125  loc loss 50.72494888305664\n",
      "cls loss 467.3646240234375  loc loss 28.257286071777344\n",
      "cls loss 487.3863830566406  loc loss 24.610652923583984\n",
      "cls loss 786.2174072265625  loc loss 32.66139221191406\n",
      "cls loss 713.1665649414062  loc loss 38.616615295410156\n",
      "cls loss 611.85791015625  loc loss 43.064720153808594\n",
      "cls loss 462.07806396484375  loc loss 23.800384521484375\n",
      "cls loss 522.489990234375  loc loss 26.96299171447754\n",
      "cls loss 957.9151611328125  loc loss 59.997413635253906\n",
      "cls loss 800.465576171875  loc loss 52.115970611572266\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1., 42., 42., 42., 42., 42., 42.,  1.,\n",
      "         1.,  1.,  1., 42.,  1.,  1., 42.,  1.])\n",
      "cls loss 460.5914001464844  loc loss 31.988121032714844\n",
      "cls loss 682.130126953125  loc loss 43.93174743652344\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.])\n",
      "cls loss 301.54473876953125  loc loss 20.033832550048828\n",
      "cls loss 649.455078125  loc loss 46.21668243408203\n",
      "cls loss 529.3629150390625  loc loss 38.971351623535156\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([11.])\n",
      "cls loss 327.64373779296875  loc loss 19.088972091674805\n",
      "cls loss 432.5565185546875  loc loss 19.907052993774414\n",
      "cls loss 443.84625244140625  loc loss 20.82789421081543\n",
      "cls loss 633.17431640625  loc loss 43.47135543823242\n",
      "cls loss 617.7752685546875  loc loss 34.36456298828125\n",
      "cls loss 585.468017578125  loc loss 42.14432907104492\n",
      "cls loss 862.8201904296875  loc loss 46.925479888916016\n",
      "cls loss 460.0686950683594  loc loss 27.93467140197754\n",
      "cls loss 820.2129516601562  loc loss 63.305908203125\n",
      "cls loss 461.43768310546875  loc loss 27.90443992614746\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 403.7110595703125  loc loss 29.251056671142578\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1., 38., 38., 42.])\n",
      "cls loss 514.849365234375  loc loss 38.9130859375\n",
      "cls loss 471.9655456542969  loc loss 26.783203125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 399.4296875  loc loss 30.071224212646484\n",
      "cls loss 938.9912109375  loc loss 67.80410766601562\n",
      "cls loss 562.5916748046875  loc loss 40.68885040283203\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10.,  3.,  3.,  6.,  8.,  8.,  1.,  1.,  1., 10.])\n",
      "cls loss 495.99774169921875  loc loss 28.550376892089844\n",
      "cls loss 296.6700439453125  loc loss 11.749289512634277\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10.,  3.])\n",
      "cls loss 465.5418701171875  loc loss 26.616004943847656\n",
      "cls loss 289.6869812011719  loc loss 13.421516418457031\n",
      "cls loss 543.5869140625  loc loss 42.810672760009766\n",
      "cls loss 614.5584106445312  loc loss 43.58375930786133\n",
      "cls loss 479.9058532714844  loc loss 29.511205673217773\n",
      "cls loss 354.80303955078125  loc loss 17.115768432617188\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 34.])\n",
      "cls loss 834.536376953125  loc loss 50.582794189453125\n",
      "cls loss 845.9468994140625  loc loss 71.462890625\n",
      "cls loss 551.9937744140625  loc loss 44.35702133178711\n",
      "cls loss 412.554443359375  loc loss 30.863801956176758\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.,  1.])\n",
      "cls loss 463.4215087890625  loc loss 25.82080841064453\n",
      "cls loss 725.3828125  loc loss 59.788448333740234\n",
      "cls loss 1086.643798828125  loc loss 73.7652587890625\n",
      "cls loss 919.1905517578125  loc loss 49.57085418701172\n",
      "cls loss 540.0496215820312  loc loss 30.489477157592773\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 680.3572998046875  loc loss 39.52690124511719\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10.])\n",
      "cls loss 416.3321533203125  loc loss 23.089317321777344\n",
      "cls loss 595.0921630859375  loc loss 30.93329429626465\n",
      "cls loss 563.64501953125  loc loss 32.61410903930664\n",
      "cls loss 395.92401123046875  loc loss 25.113386154174805\n",
      "cls loss 490.3350830078125  loc loss 35.851348876953125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21.,\n",
      "        21.])\n",
      "cls loss 678.3214111328125  loc loss 40.33643341064453\n",
      "cls loss 544.1209106445312  loc loss 36.47880935668945\n",
      "cls loss 347.7340393066406  loc loss 16.712980270385742\n",
      "cls loss 722.8612670898438  loc loss 49.23688888549805\n",
      "cls loss 576.581298828125  loc loss 40.78084945678711\n",
      "cls loss 403.74237060546875  loc loss 26.378467559814453\n",
      "cls loss 845.8365478515625  loc loss 60.425941467285156\n",
      "cls loss 1021.5313720703125  loc loss 72.2410659790039\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15., 85.])\n",
      "cls loss 658.2432250976562  loc loss 42.64773941040039\n",
      "cls loss 646.172607421875  loc loss 49.532596588134766\n",
      "cls loss 667.6983642578125  loc loss 48.558616638183594\n",
      "cls loss 598.266357421875  loc loss 34.82245635986328\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 8., 8.])\n",
      "cls loss 386.590576171875  loc loss 20.93648338317871\n",
      "cls loss 422.304931640625  loc loss 29.01197052001953\n",
      "cls loss 521.703857421875  loc loss 31.994598388671875\n",
      "cls loss 439.6090087890625  loc loss 25.168798446655273\n",
      "cls loss 505.7722473144531  loc loss 31.10045623779297\n",
      "cls loss 657.3640747070312  loc loss 41.4590950012207\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1., 35., 27., 27.,  1., 27.,  1.])\n",
      "cls loss 919.8092651367188  loc loss 62.192657470703125\n",
      "cls loss 421.70001220703125  loc loss 31.086841583251953\n",
      "cls loss 517.802490234375  loc loss 38.856632232666016\n",
      "cls loss 484.8136291503906  loc loss 42.93325424194336\n",
      "cls loss 448.18243408203125  loc loss 34.39610290527344\n",
      "cls loss 479.2435607910156  loc loss 39.356998443603516\n",
      "cls loss 479.65777587890625  loc loss 39.30948257446289\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  2.,  2.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  2.,  2.])\n",
      "cls loss 310.29803466796875  loc loss 12.137571334838867\n",
      "cls loss 742.380126953125  loc loss 47.600738525390625\n",
      "cls loss 541.4954833984375  loc loss 27.051788330078125\n",
      "cls loss 848.1490478515625  loc loss 62.988059997558594\n",
      "cls loss 360.1952819824219  loc loss 22.477317810058594\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 19., 19., 19., 16.])\n",
      "cls loss 374.9161376953125  loc loss 17.333677291870117\n",
      "cls loss 299.236083984375  loc loss 14.364608764648438\n",
      "cls loss 452.3470764160156  loc loss 24.00453758239746\n",
      "cls loss 590.0437622070312  loc loss 40.78055191040039\n",
      "cls loss 311.25677490234375  loc loss 23.081268310546875\n",
      "cls loss 678.78076171875  loc loss 50.570255279541016\n",
      "cls loss 485.8072204589844  loc loss 35.32990264892578\n",
      "cls loss 536.2001953125  loc loss 36.04591751098633\n",
      "cls loss 653.3916625976562  loc loss 48.451881408691406\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 761.3700561523438  loc loss 33.639678955078125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 941.488525390625  loc loss 82.76410675048828\n",
      "cls loss 1154.165771484375  loc loss 115.40707397460938\n",
      "cls loss 596.128173828125  loc loss 43.231666564941406\n",
      "cls loss 544.081787109375  loc loss 37.40802001953125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3.,  3.,  3.,  3.,  3., 10.])\n",
      "cls loss 326.1201171875  loc loss 17.97847557067871\n",
      "cls loss 581.186767578125  loc loss 32.463626861572266\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 1., 1., 1., 3., 3., 3., 3.])\n",
      "cls loss 467.58941650390625  loc loss 32.04954147338867\n",
      "cls loss 845.1627807617188  loc loss 60.23937225341797\n",
      "cls loss 679.0672607421875  loc loss 47.551231384277344\n",
      "cls loss 485.80352783203125  loc loss 27.568626403808594\n",
      "cls loss 684.962158203125  loc loss 52.7400016784668\n",
      "cls loss 438.7391052246094  loc loss 33.432861328125\n",
      "cls loss 698.7449951171875  loc loss 50.319190979003906\n",
      "cls loss 511.57427978515625  loc loss 47.15836715698242\n",
      "cls loss 515.074462890625  loc loss 35.809722900390625\n",
      "cls loss 1082.8548583984375  loc loss 91.76837158203125\n",
      "cls loss 711.8172607421875  loc loss 51.292503356933594\n",
      "cls loss 491.6160888671875  loc loss 24.746137619018555\n",
      "cls loss 336.26849365234375  loc loss 15.04838752746582\n",
      "cls loss 374.40948486328125  loc loss 19.456398010253906\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3., 10., 10., 10., 10., 10., 10., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10., 10., 10., 10., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 11., 10., 10., 10., 10., 10.,  3.,  3.,  3.,  3.,  3.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 11., 10., 10., 10., 10., 10.,  3.,  3.,  3.,  3.,  3.])\n",
      "cls loss 385.1143798828125  loc loss 17.681806564331055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 446.4292907714844  loc loss 22.327978134155273\n",
      "cls loss 371.69384765625  loc loss 23.948261260986328\n",
      "cls loss 364.232666015625  loc loss 16.130783081054688\n",
      "cls loss 427.5047607421875  loc loss 34.76164245605469\n",
      "cls loss 358.05450439453125  loc loss 14.359332084655762\n",
      "cls loss 655.50341796875  loc loss 44.70412826538086\n",
      "cls loss 572.5372924804688  loc loss 41.842132568359375\n",
      "cls loss 861.42578125  loc loss 57.04069137573242\n",
      "cls loss 424.78753662109375  loc loss 32.95928955078125\n",
      "cls loss 765.4442138671875  loc loss 52.575958251953125\n",
      "cls loss 633.22216796875  loc loss 43.43791198730469\n",
      "cls loss 585.96142578125  loc loss 40.082820892333984\n",
      "cls loss 601.22509765625  loc loss 44.718017578125\n",
      "cls loss 823.086181640625  loc loss 55.130859375\n",
      "cls loss 801.5674438476562  loc loss 49.257659912109375\n",
      "cls loss 382.3310546875  loc loss 22.045988082885742\n",
      "cls loss 671.4632568359375  loc loss 53.002471923828125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 10.,  1., 18.])\n",
      "cls loss 340.80364990234375  loc loss 24.421295166015625\n",
      "cls loss 392.5354919433594  loc loss 17.515378952026367\n",
      "cls loss 679.0888061523438  loc loss 35.87717819213867\n",
      "cls loss 965.360595703125  loc loss 63.76747512817383\n",
      "cls loss 581.9478149414062  loc loss 41.643951416015625\n",
      "cls loss 818.78369140625  loc loss 48.22235107421875\n",
      "cls loss 569.2900390625  loc loss 39.435760498046875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.,  1.,  1.])\n",
      "cls loss 731.9055786132812  loc loss 49.42387008666992\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1., 38.,  1.])\n",
      "cls loss 720.606201171875  loc loss 41.104644775390625\n",
      "cls loss 915.9210205078125  loc loss 66.93767547607422\n",
      "cls loss 468.1762390136719  loc loss 34.98289108276367\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 633.250732421875  loc loss 44.1400032043457\n",
      "cls loss 558.3377075195312  loc loss 36.465946197509766\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3., 10.,  8.,  3., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.])\n",
      "cls loss 669.1032104492188  loc loss 41.71595764160156\n",
      "cls loss 476.194091796875  loc loss 30.28053092956543\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3.,  3., 11.,  3., 10., 10.,  3.,  3., 10.])\n",
      "cls loss 561.1851196289062  loc loss 27.472431182861328\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3., 10., 10., 10.])\n",
      "cls loss 543.2622680664062  loc loss 37.76625061035156\n",
      "cls loss 468.0559387207031  loc loss 26.203224182128906\n",
      "cls loss 558.3525390625  loc loss 40.72000503540039\n",
      "cls loss 880.1455688476562  loc loss 54.20471954345703\n",
      "cls loss 557.13427734375  loc loss 37.32377624511719\n",
      "cls loss 389.8369445800781  loc loss 35.66958236694336\n",
      "cls loss 506.9820556640625  loc loss 36.98786163330078\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 9.,  9., 85., 85.])\n",
      "cls loss 451.6967468261719  loc loss 25.578195571899414\n",
      "cls loss 512.846435546875  loc loss 35.862186431884766\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 844.7017822265625  loc loss 63.38075256347656\n",
      "cls loss 723.1124267578125  loc loss 36.93693923950195\n",
      "cls loss 812.0919799804688  loc loss 58.09968566894531\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10., 10., 10., 10.])\n",
      "cls loss 513.2640380859375  loc loss 32.607322692871094\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([13.])\n",
      "cls loss 813.0579223632812  loc loss 64.36043548583984\n",
      "cls loss 299.5212097167969  loc loss 16.51050567626953\n",
      "cls loss 372.99554443359375  loc loss 19.7125301361084\n",
      "cls loss 510.8629150390625  loc loss 27.395612716674805\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19.,  1.,  1.,  1., 19., 19.])\n",
      "cls loss 524.6795043945312  loc loss 33.75891876220703\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 393.5951232910156  loc loss 32.1683349609375\n",
      "cls loss 585.1617431640625  loc loss 43.398521423339844\n",
      "cls loss 425.0877685546875  loc loss 25.833030700683594\n",
      "cls loss 628.197509765625  loc loss 38.68724822998047\n",
      "cls loss 675.919189453125  loc loss 52.803245544433594\n",
      "cls loss 548.6868286132812  loc loss 30.556886672973633\n",
      "cls loss 763.0167236328125  loc loss 57.79916000366211\n",
      "cls loss 327.0328369140625  loc loss 15.399666786193848\n",
      "cls loss 565.8320922851562  loc loss 36.186363220214844\n",
      "cls loss 448.68695068359375  loc loss 23.4189510345459\n",
      "cls loss 473.5845031738281  loc loss 26.33204460144043\n",
      "cls loss 596.1279907226562  loc loss 41.589324951171875\n",
      "cls loss 567.9317016601562  loc loss 32.59367370605469\n",
      "cls loss 815.9509887695312  loc loss 52.270362854003906\n",
      "cls loss 509.1607360839844  loc loss 35.817989349365234\n",
      "cls loss 648.91162109375  loc loss 44.88380432128906\n",
      "cls loss 965.931884765625  loc loss 61.10035705566406\n",
      "cls loss 527.7139282226562  loc loss 40.71175765991211\n",
      "cls loss 603.4505004882812  loc loss 36.90682601928711\n",
      "cls loss 718.0687255859375  loc loss 54.96735763549805\n",
      "cls loss 752.0897216796875  loc loss 55.02734375\n",
      "cls loss 955.9635009765625  loc loss 52.9426383972168\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 5.])\n",
      "cls loss 292.7851867675781  loc loss 11.219037055969238\n",
      "cls loss 367.0927429199219  loc loss 16.565996170043945\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 13.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 6., 8., 8.])\n",
      "cls loss 315.559814453125  loc loss 16.000415802001953\n",
      "cls loss 376.9102478027344  loc loss 21.30072784423828\n",
      "cls loss 740.61376953125  loc loss 51.994510650634766\n",
      "cls loss 328.6842041015625  loc loss 16.442176818847656\n",
      "cls loss 575.0079345703125  loc loss 44.66144561767578\n",
      "cls loss 930.490234375  loc loss 64.48809051513672\n",
      "cls loss 539.6539306640625  loc loss 42.278343200683594\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([42., 42.,  1.,  1.,  1.,  1.,  1.,  1.,  1., 42., 42.])\n",
      "cls loss 611.8232421875  loc loss 35.98322296142578\n",
      "cls loss 786.4777221679688  loc loss 62.1074104309082\n",
      "cls loss 641.721923828125  loc loss 53.17997360229492\n",
      "cls loss 469.55548095703125  loc loss 28.840913772583008\n",
      "cls loss 624.29931640625  loc loss 38.46527862548828\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 833.9664306640625  loc loss 55.94089126586914\n",
      "cls loss 664.7034912109375  loc loss 48.00165557861328\n",
      "cls loss 435.0452880859375  loc loss 26.47516441345215\n",
      "cls loss 362.2198486328125  loc loss 19.755918502807617\n",
      "cls loss 519.9708862304688  loc loss 30.948806762695312\n",
      "cls loss 685.5315551757812  loc loss 46.03399658203125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15.])\n",
      "cls loss 331.8690185546875  loc loss 16.471738815307617\n",
      "cls loss 540.824951171875  loc loss 36.75690841674805\n",
      "cls loss 490.4761047363281  loc loss 33.00852966308594\n",
      "cls loss 866.4947509765625  loc loss 61.17115020751953\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19.,  7.])\n",
      "cls loss 492.76800537109375  loc loss 29.714454650878906\n",
      "cls loss 977.95703125  loc loss 62.29810333251953\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 816.5623779296875  loc loss 43.7555046081543\n",
      "cls loss 650.3890380859375  loc loss 50.221435546875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([38., 38.,  1., 18.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1., 18., 18.,  1.])\n",
      "cls loss 536.1324462890625  loc loss 27.11549186706543\n",
      "cls loss 483.934326171875  loc loss 24.54648780822754\n",
      "cls loss 865.8463134765625  loc loss 67.41365814208984\n",
      "cls loss 689.4717407226562  loc loss 38.535545349121094\n",
      "cls loss 648.6416015625  loc loss 33.08302307128906\n",
      "cls loss 357.62542724609375  loc loss 27.95077133178711\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.])\n",
      "cls loss 295.8270263671875  loc loss 10.1139554977417\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([32.])\n",
      "cls loss 561.2716674804688  loc loss 29.406368255615234\n",
      "cls loss 485.6867980957031  loc loss 34.92575454711914\n",
      "cls loss 643.1742553710938  loc loss 52.31251525878906\n",
      "cls loss 584.689453125  loc loss 38.69449996948242\n",
      "cls loss 477.433349609375  loc loss 31.423233032226562\n",
      "cls loss 764.99658203125  loc loss 49.181941986083984\n",
      "cls loss 819.1878662109375  loc loss 57.687721252441406\n",
      "cls loss 658.2000122070312  loc loss 44.29893112182617\n",
      "cls loss 549.3865356445312  loc loss 32.2694206237793\n",
      "cls loss 847.000732421875  loc loss 54.567909240722656\n",
      "cls loss 541.1154174804688  loc loss 28.6809024810791\n",
      "cls loss 854.0067749023438  loc loss 68.80560302734375\n",
      "cls loss 631.323486328125  loc loss 36.67790603637695\n",
      "cls loss 523.988525390625  loc loss 38.378238677978516\n",
      "cls loss 397.2891845703125  loc loss 21.083227157592773\n",
      "cls loss 446.56134033203125  loc loss 28.49298858642578\n",
      "cls loss 659.4428100585938  loc loss 44.569786071777344\n",
      "cls loss 672.5628662109375  loc loss 50.020423889160156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 402.72662353515625  loc loss 27.57140350341797\n",
      "cls loss 743.454833984375  loc loss 50.41685485839844\n",
      "cls loss 871.84814453125  loc loss 53.8380241394043\n",
      "cls loss 332.40411376953125  loc loss 22.970911026000977\n",
      "cls loss 834.4757690429688  loc loss 57.674530029296875\n",
      "cls loss 598.2052001953125  loc loss 46.6939811706543\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 823.65869140625  loc loss 64.33887481689453\n",
      "cls loss 414.6627197265625  loc loss 15.962862968444824\n",
      "cls loss 625.874267578125  loc loss 33.88764190673828\n",
      "cls loss 607.6707763671875  loc loss 41.709556579589844\n",
      "cls loss 488.2185363769531  loc loss 28.42609405517578\n",
      "cls loss 301.6351623535156  loc loss 16.35458755493164\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 9., 9., 1., 9., 9., 9., 9., 1., 9.])\n",
      "cls loss 1036.1815185546875  loc loss 90.83930969238281\n",
      "cls loss 610.8662719726562  loc loss 33.05617141723633\n",
      "cls loss 900.9342651367188  loc loss 76.50996398925781\n",
      "cls loss 380.738525390625  loc loss 26.757389068603516\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 42., 42.])\n",
      "cls loss 661.2030029296875  loc loss 49.422523498535156\n",
      "cls loss 708.4039306640625  loc loss 51.683319091796875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  2.,  1.,  1.,  1., 38.,\n",
      "         1.,  1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 38., 38., 38.,  1., 38., 38., 38.,  1.,  1., 38.,  1.,\n",
      "         1.])\n",
      "cls loss 436.52978515625  loc loss 30.86097526550293\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  8.,  8.])\n",
      "cls loss 990.0126953125  loc loss 66.74475860595703\n",
      "cls loss 1001.8118286132812  loc loss 71.03211975097656\n",
      "cls loss 396.79443359375  loc loss 23.159860610961914\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([4., 1., 1., 4.])\n",
      "cls loss 561.259765625  loc loss 39.60133743286133\n",
      "cls loss 667.9207763671875  loc loss 42.383480072021484\n",
      "cls loss 306.4266357421875  loc loss 14.486854553222656\n",
      "cls loss 415.61785888671875  loc loss 25.897747039794922\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([51.,  1.])\n",
      "cls loss 301.3671569824219  loc loss 12.982315063476562\n",
      "cls loss 393.20733642578125  loc loss 23.481975555419922\n",
      "cls loss 697.07568359375  loc loss 41.649723052978516\n",
      "cls loss 767.7465209960938  loc loss 58.08271789550781\n",
      "cls loss 1037.4388427734375  loc loss 58.134971618652344\n",
      "cls loss 1306.0673828125  loc loss 85.86732482910156\n",
      "cls loss 554.3374633789062  loc loss 34.38774490356445\n",
      "cls loss 786.0665283203125  loc loss 55.9197998046875\n",
      "cls loss 828.5751953125  loc loss 59.965755462646484\n",
      "cls loss 649.664794921875  loc loss 37.4517707824707\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  3.,  1.,  1.,  1.,  3.,  1.,  1.,\n",
      "         1.,  1.,  1.])\n",
      "cls loss 679.416015625  loc loss 34.12764358520508\n",
      "cls loss 769.3800659179688  loc loss 39.661197662353516\n",
      "cls loss 689.1995849609375  loc loss 36.6498908996582\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "cls loss 563.5222778320312  loc loss 34.17645263671875\n",
      "cls loss 337.47161865234375  loc loss 27.481937408447266\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3.])\n",
      "cls loss 295.43060302734375  loc loss 13.804121971130371\n",
      "cls loss 509.86419677734375  loc loss 35.88602066040039\n",
      "cls loss 407.6044006347656  loc loss 31.488529205322266\n",
      "cls loss 729.4906005859375  loc loss 50.7412109375\n",
      "cls loss 500.8448181152344  loc loss 25.568803787231445\n",
      "cls loss 402.10906982421875  loc loss 28.656314849853516\n",
      "cls loss 1234.403564453125  loc loss 82.95481872558594\n",
      "cls loss 536.298828125  loc loss 40.267364501953125\n",
      "cls loss 381.5815124511719  loc loss 31.074615478515625\n",
      "cls loss 525.4033203125  loc loss 30.769559860229492\n",
      "cls loss 461.55084228515625  loc loss 33.677730560302734\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 843.4255981445312  loc loss 57.26628875732422\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  9., 64., 64., 64., 64., 64., 64., 64., 64., 64.,  9.,  9.,  9.,\n",
      "         9.])\n",
      "cls loss 478.2220458984375  loc loss 24.06105613708496\n",
      "cls loss 1071.8162841796875  loc loss 86.63320922851562\n",
      "cls loss 550.6741943359375  loc loss 37.760467529296875\n",
      "cls loss 722.8790893554688  loc loss 53.2501220703125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.,  3.,  3.])\n",
      "cls loss 475.2131652832031  loc loss 29.1828670501709\n",
      "cls loss 532.0504150390625  loc loss 34.291507720947266\n",
      "cls loss 512.194580078125  loc loss 38.16154479980469\n",
      "cls loss 566.261962890625  loc loss 40.455101013183594\n",
      "cls loss 541.702880859375  loc loss 45.65226364135742\n",
      "cls loss 539.6867065429688  loc loss 42.525184631347656\n",
      "cls loss 532.9404907226562  loc loss 42.8560676574707\n",
      "cls loss 556.3892211914062  loc loss 35.55297088623047\n",
      "cls loss 690.9818115234375  loc loss 49.529319763183594\n",
      "cls loss 601.8861694335938  loc loss 34.759422302246094\n",
      "cls loss 482.4982604980469  loc loss 21.601699829101562\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21.])\n",
      "cls loss 355.3876953125  loc loss 19.77471160888672\n",
      "cls loss 479.5234375  loc loss 41.15253448486328\n",
      "cls loss 692.3262939453125  loc loss 50.974647521972656\n",
      "cls loss 441.720947265625  loc loss 25.267593383789062\n",
      "cls loss 610.2604370117188  loc loss 37.118797302246094\n",
      "cls loss 1087.016845703125  loc loss 61.47178268432617\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 42., 42.,  1.,  1.])\n",
      "cls loss 545.28271484375  loc loss 35.04893493652344\n",
      "cls loss 360.80914306640625  loc loss 27.04511070251465\n",
      "cls loss 503.87896728515625  loc loss 39.273094177246094\n",
      "cls loss 713.8109130859375  loc loss 59.634498596191406\n",
      "cls loss 460.5084533691406  loc loss 30.737388610839844\n",
      "cls loss 654.9512939453125  loc loss 51.46049880981445\n",
      "cls loss 636.0164184570312  loc loss 49.6528434753418\n",
      "cls loss 689.0009155273438  loc loss 41.292030334472656\n",
      "cls loss 540.4049682617188  loc loss 34.31648254394531\n",
      "cls loss 493.1514892578125  loc loss 30.460975646972656\n",
      "cls loss 393.4844665527344  loc loss 17.26461410522461\n",
      "cls loss 496.4102783203125  loc loss 34.38092803955078\n",
      "cls loss 731.7440185546875  loc loss 61.53364944458008\n",
      "cls loss 586.591064453125  loc loss 38.348506927490234\n",
      "cls loss 575.6778564453125  loc loss 43.38090896606445\n",
      "cls loss 631.2767333984375  loc loss 36.57164001464844\n",
      "cls loss 920.9797973632812  loc loss 62.27872848510742\n",
      "cls loss 642.935791015625  loc loss 50.72315216064453\n",
      "cls loss 760.0689086914062  loc loss 44.16202163696289\n",
      "cls loss 442.42266845703125  loc loss 22.690570831298828\n",
      "cls loss 627.441162109375  loc loss 41.499759674072266\n",
      "cls loss 579.2260131835938  loc loss 37.988494873046875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 5., 5., 5., 5., 5., 5.])\n",
      "cls loss 420.7158203125  loc loss 28.93088722229004\n",
      "cls loss 495.761474609375  loc loss 30.37967300415039\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([13.])\n",
      "cls loss 338.2650146484375  loc loss 22.175647735595703\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([44., 10.,  1.,  1.,  1.])\n",
      "cls loss 359.07513427734375  loc loss 22.1549072265625\n",
      "cls loss 675.4844970703125  loc loss 35.63169860839844\n",
      "cls loss 545.1297607421875  loc loss 31.518142700195312\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19., 19., 19., 19., 19., 19., 19.])\n",
      "cls loss 696.728271484375  loc loss 38.75852966308594\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([56.])\n",
      "cls loss 1219.8382568359375  loc loss 75.1645736694336\n",
      "cls loss 675.545654296875  loc loss 55.333194732666016\n",
      "cls loss 887.3646240234375  loc loss 65.20160675048828\n",
      "cls loss 882.9017333984375  loc loss 69.23580932617188\n",
      "cls loss 536.872314453125  loc loss 32.60558319091797\n",
      "cls loss 863.7988891601562  loc loss 64.2889404296875\n",
      "cls loss 517.4481201171875  loc loss 32.1599235534668\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 36.])\n",
      "cls loss 612.171875  loc loss 35.00138854980469\n",
      "cls loss 536.0778198242188  loc loss 39.370140075683594\n",
      "cls loss 560.5909423828125  loc loss 33.564979553222656\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5.])\n",
      "cls loss 625.0472412109375  loc loss 39.652503967285156\n",
      "cls loss 354.8868408203125  loc loss 19.63491439819336\n",
      "cls loss 783.3900146484375  loc loss 45.64896011352539\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "cls loss 698.8590698242188  loc loss 48.28484344482422\n",
      "cls loss 720.8611450195312  loc loss 46.09966278076172\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 634.7638549804688  loc loss 46.35577392578125\n",
      "cls loss 764.248779296875  loc loss 54.71381378173828\n",
      "cls loss 623.922607421875  loc loss 58.2491340637207\n",
      "cls loss 448.910400390625  loc loss 32.017147064208984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 563.96044921875  loc loss 41.287818908691406\n",
      "cls loss 565.9312133789062  loc loss 37.482421875\n",
      "cls loss 862.1484375  loc loss 52.418426513671875\n",
      "cls loss 406.01007080078125  loc loss 21.099401473999023\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 11., 15., 10., 10., 10., 10., 10.])\n",
      "cls loss 919.6099853515625  loc loss 62.87709426879883\n",
      "cls loss 515.551025390625  loc loss 35.66804504394531\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3.])\n",
      "cls loss 575.3226318359375  loc loss 37.96100616455078\n",
      "cls loss 506.6202392578125  loc loss 29.996007919311523\n",
      "cls loss 553.9739990234375  loc loss 28.451496124267578\n",
      "cls loss 709.4428100585938  loc loss 36.24201583862305\n",
      "cls loss 400.8671875  loc loss 18.746532440185547\n",
      "cls loss 556.176513671875  loc loss 35.831180572509766\n",
      "cls loss 618.1806640625  loc loss 48.67252731323242\n",
      "cls loss 527.1920166015625  loc loss 40.34140396118164\n",
      "cls loss 1203.080078125  loc loss 92.8818359375\n",
      "cls loss 866.5895385742188  loc loss 58.645301818847656\n",
      "cls loss 555.0140380859375  loc loss 41.625572204589844\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  9.,  9.,  9.,  6.,  6., 85., 85.,  8.,  1.,  1.,  1.,  1.,\n",
      "         6.,  6.])\n",
      "cls loss 402.8085632324219  loc loss 28.978736877441406\n",
      "cls loss 906.5185546875  loc loss 65.03218078613281\n",
      "cls loss 1069.4239501953125  loc loss 69.94745635986328\n",
      "cls loss 742.862548828125  loc loss 51.423282623291016\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10.,  3.,  3., 10.])\n",
      "cls loss 492.5018310546875  loc loss 29.215438842773438\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([7.])\n",
      "cls loss 626.0453491210938  loc loss 45.58525085449219\n",
      "cls loss 639.161376953125  loc loss 39.674434661865234\n",
      "cls loss 572.60546875  loc loss 46.07271957397461\n",
      "cls loss 810.8861694335938  loc loss 66.16756439208984\n",
      "cls loss 605.52490234375  loc loss 40.60102081298828\n",
      "cls loss 804.8304443359375  loc loss 53.61166000366211\n",
      "cls loss 987.7281494140625  loc loss 61.496376037597656\n",
      "cls loss 591.8687744140625  loc loss 41.96015930175781\n",
      "cls loss 635.2507934570312  loc loss 44.55110168457031\n",
      "cls loss 539.13623046875  loc loss 40.843414306640625\n",
      "cls loss 751.5528564453125  loc loss 62.920196533203125\n",
      "cls loss 622.7548828125  loc loss 41.05790328979492\n",
      "cls loss 492.70196533203125  loc loss 29.69966697692871\n",
      "cls loss 748.894775390625  loc loss 58.1502571105957\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([62.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([62.])\n",
      "cls loss 335.4621887207031  loc loss 18.971595764160156\n",
      "cls loss 602.0240478515625  loc loss 43.906490325927734\n",
      "cls loss 589.4598388671875  loc loss 39.70002365112305\n",
      "cls loss 421.6763916015625  loc loss 18.201587677001953\n",
      "cls loss 747.9791259765625  loc loss 52.40125274658203\n",
      "cls loss 734.9168701171875  loc loss 44.964256286621094\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([28.])\n",
      "cls loss 817.1326904296875  loc loss 46.31877136230469\n",
      "cls loss 732.6904296875  loc loss 46.46640396118164\n",
      "cls loss 710.196044921875  loc loss 46.39124298095703\n",
      "cls loss 732.5548095703125  loc loss 50.14990997314453\n",
      "cls loss 1001.482421875  loc loss 69.5815200805664\n",
      "cls loss 563.2056884765625  loc loss 37.46809005737305\n",
      "cls loss 700.7642822265625  loc loss 44.05339050292969\n",
      "cls loss 627.6168212890625  loc loss 53.16777801513672\n",
      "cls loss 997.193359375  loc loss 77.65831756591797\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([81.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 696.3839721679688  loc loss 29.883296966552734\n",
      "cls loss 535.53271484375  loc loss 27.232234954833984\n",
      "cls loss 457.1177978515625  loc loss 29.007179260253906\n",
      "cls loss 384.82440185546875  loc loss 16.02741050720215\n",
      "cls loss 430.87457275390625  loc loss 27.985029220581055\n",
      "cls loss 460.7762451171875  loc loss 29.71041488647461\n",
      "cls loss 529.4934692382812  loc loss 34.0638542175293\n",
      "cls loss 688.7493896484375  loc loss 56.75453186035156\n",
      "cls loss 773.8763427734375  loc loss 53.59456253051758\n",
      "cls loss 1469.17822265625  loc loss 103.77427673339844\n",
      "cls loss 604.939208984375  loc loss 31.723451614379883\n",
      "cls loss 714.2409057617188  loc loss 49.26444625854492\n",
      "cls loss 506.133056640625  loc loss 32.13874816894531\n",
      "cls loss 668.7386474609375  loc loss 37.620521545410156\n",
      "cls loss 611.8521728515625  loc loss 34.78104019165039\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([44., 44.])\n",
      "cls loss 538.6234741210938  loc loss 27.409744262695312\n",
      "cls loss 532.0308227539062  loc loss 39.236244201660156\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15.])\n",
      "cls loss 640.224609375  loc loss 33.68186569213867\n",
      "cls loss 304.3294982910156  loc loss 18.00409698486328\n",
      "cls loss 623.5802612304688  loc loss 37.84462356567383\n",
      "cls loss 342.39862060546875  loc loss 22.947845458984375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([1., 3., 3.])\n",
      "cls loss 387.2933654785156  loc loss 30.771438598632812\n",
      "cls loss 332.6524353027344  loc loss 14.629556655883789\n",
      "cls loss 596.7884521484375  loc loss 34.31794357299805\n",
      "cls loss 622.1956176757812  loc loss 37.46027374267578\n",
      "cls loss 564.4228515625  loc loss 37.1552619934082\n",
      "cls loss 589.5546875  loc loss 34.51803970336914\n",
      "cls loss 480.0632019042969  loc loss 36.5858268737793\n",
      "cls loss 626.6368408203125  loc loss 44.22426986694336\n",
      "cls loss 506.2315673828125  loc loss 33.842750549316406\n",
      "cls loss 617.162109375  loc loss 44.72239685058594\n",
      "cls loss 397.1539306640625  loc loss 25.294557571411133\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 724.629150390625  loc loss 45.7708740234375\n",
      "cls loss 838.144287109375  loc loss 43.910133361816406\n",
      "cls loss 754.6282348632812  loc loss 52.64398956298828\n",
      "cls loss 738.3848876953125  loc loss 55.09697341918945\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10., 10., 10.,  1.,  1.,  1.,  1.,  1.,  1.,  8.,  8.,\n",
      "         1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10., 10., 10.,  1.,  1.,  1.,  1.,  1.,  1.,  8.,  8.,\n",
      "         1.])\n",
      "cls loss 723.9697265625  loc loss 36.24562454223633\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 3., 3., 3.])\n",
      "cls loss 596.770751953125  loc loss 38.40010070800781\n",
      "cls loss 414.12408447265625  loc loss 23.254911422729492\n",
      "cls loss 321.40191650390625  loc loss 16.83786392211914\n",
      "cls loss 563.2517700195312  loc loss 41.25591278076172\n",
      "cls loss 441.4864501953125  loc loss 23.687753677368164\n",
      "cls loss 480.3857421875  loc loss 33.45354461669922\n",
      "cls loss 558.6801147460938  loc loss 39.25688934326172\n",
      "cls loss 777.3359985351562  loc loss 55.715309143066406\n",
      "cls loss 645.7522583007812  loc loss 34.19905471801758\n",
      "cls loss 619.99951171875  loc loss 37.767333984375\n",
      "cls loss 705.7344970703125  loc loss 48.050514221191406\n",
      "cls loss 528.2691650390625  loc loss 39.52992248535156\n",
      "cls loss 923.9385986328125  loc loss 70.45222473144531\n",
      "cls loss 492.100830078125  loc loss 26.615575790405273\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 712.7332763671875  loc loss 44.41852569580078\n",
      "cls loss 374.3265380859375  loc loss 16.806495666503906\n",
      "cls loss 900.5322265625  loc loss 58.830989837646484\n",
      "cls loss 475.70703125  loc loss 24.834272384643555\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 34.])\n",
      "cls loss 740.232177734375  loc loss 41.2026481628418\n",
      "cls loss 340.45123291015625  loc loss 23.39679718017578\n",
      "cls loss 646.3021240234375  loc loss 44.47423553466797\n",
      "cls loss 236.17544555664062  loc loss 17.28986930847168\n",
      "cls loss 596.6085205078125  loc loss 39.33730697631836\n",
      "cls loss 572.6416625976562  loc loss 44.89849853515625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 38.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16., 16., 16.,  9.,  9.,  9., 16., 16., 16., 85.,  9.])\n",
      "cls loss 558.935546875  loc loss 36.93885803222656\n",
      "cls loss 633.62158203125  loc loss 51.362247467041016\n",
      "cls loss 888.667724609375  loc loss 65.3995132446289\n",
      "cls loss 1255.9049072265625  loc loss 86.9442367553711\n",
      "cls loss 391.34405517578125  loc loss 20.171911239624023\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3., 10.,  8.,  8., 10., 10., 10.,  3.,  3., 14.])\n",
      "cls loss 479.1687316894531  loc loss 22.914186477661133\n",
      "cls loss 832.3553466796875  loc loss 43.747745513916016\n",
      "cls loss 366.99151611328125  loc loss 13.810267448425293\n",
      "cls loss 547.3847045898438  loc loss 24.23556137084961\n",
      "cls loss 738.0941162109375  loc loss 43.63474655151367\n",
      "cls loss 607.0247192382812  loc loss 41.459957122802734\n",
      "cls loss 364.20611572265625  loc loss 18.980051040649414\n",
      "cls loss 401.679931640625  loc loss 25.638992309570312\n",
      "cls loss 607.8770751953125  loc loss 40.830299377441406\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42., 42.,  1.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 567.224365234375  loc loss 42.46625518798828\n",
      "cls loss 490.2535705566406  loc loss 30.104881286621094\n",
      "cls loss 662.93212890625  loc loss 50.95161056518555\n",
      "cls loss 736.5694580078125  loc loss 50.518367767333984\n",
      "cls loss 527.5811157226562  loc loss 34.37808609008789\n",
      "cls loss 634.4844970703125  loc loss 45.80945587158203\n",
      "cls loss 414.18157958984375  loc loss 27.501209259033203\n",
      "cls loss 449.14837646484375  loc loss 30.83608627319336\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20.])\n",
      "cls loss 351.826416015625  loc loss 20.084497451782227\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([11.])\n",
      "cls loss 434.9830322265625  loc loss 23.644350051879883\n",
      "cls loss 311.8944091796875  loc loss 17.7276611328125\n",
      "cls loss 676.0270385742188  loc loss 54.739505767822266\n",
      "cls loss 324.04400634765625  loc loss 14.663496017456055\n",
      "cls loss 644.8466186523438  loc loss 37.75633239746094\n",
      "cls loss 359.21673583984375  loc loss 22.156221389770508\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 35., 27.])\n",
      "cls loss 607.94873046875  loc loss 40.11745834350586\n",
      "cls loss 615.7020874023438  loc loss 50.11995315551758\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 471.8625183105469  loc loss 29.082006454467773\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([42.,  1.])\n",
      "cls loss 616.0557861328125  loc loss 44.502685546875\n",
      "cls loss 549.3404541015625  loc loss 33.02938461303711\n",
      "cls loss 688.5703125  loc loss 39.28843688964844\n",
      "cls loss 787.9822998046875  loc loss 54.645057678222656\n",
      "cls loss 716.45947265625  loc loss 46.54907989501953\n",
      "cls loss 485.25372314453125  loc loss 38.88534164428711\n",
      "cls loss 420.2215270996094  loc loss 33.701446533203125\n",
      "cls loss 282.2738952636719  loc loss 13.731313705444336\n",
      "cls loss 504.6964416503906  loc loss 29.677196502685547\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 1., 1.])\n",
      "cls loss 487.65594482421875  loc loss 26.52655792236328\n",
      "cls loss 536.667724609375  loc loss 38.121402740478516\n",
      "cls loss 547.7102661132812  loc loss 35.088294982910156\n",
      "cls loss 451.5204162597656  loc loss 32.96910095214844\n",
      "cls loss 533.138671875  loc loss 32.68896484375\n",
      "cls loss 569.2471923828125  loc loss 43.039634704589844\n",
      "cls loss 792.6537475585938  loc loss 47.78404998779297\n",
      "cls loss 668.8040161132812  loc loss 53.11534118652344\n",
      "cls loss 628.619873046875  loc loss 38.63156509399414\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 490.468505859375  loc loss 35.47247314453125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 576.9842529296875  loc loss 29.6108341217041\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([81.])\n",
      "cls loss 702.162109375  loc loss 45.59185028076172\n",
      "cls loss 443.3563232421875  loc loss 30.123510360717773\n",
      "cls loss 313.39703369140625  loc loss 20.060365676879883\n",
      "cls loss 487.6778869628906  loc loss 26.015600204467773\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3.,  1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 19.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 19.])\n",
      "cls loss 640.51611328125  loc loss 45.033355712890625\n",
      "cls loss 373.1304626464844  loc loss 18.814279556274414\n",
      "cls loss 392.9755554199219  loc loss 24.520557403564453\n",
      "cls loss 747.401611328125  loc loss 55.53981018066406\n",
      "cls loss 394.3538818359375  loc loss 25.16266441345215\n",
      "cls loss 482.1871337890625  loc loss 34.748111724853516\n",
      "cls loss 594.4927978515625  loc loss 40.02988815307617\n",
      "cls loss 452.83770751953125  loc loss 34.68668746948242\n",
      "cls loss 603.4165649414062  loc loss 36.875\n",
      "cls loss 675.7986450195312  loc loss 48.09993362426758\n",
      "cls loss 795.5322875976562  loc loss 75.51473236083984\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 81.])\n",
      "cls loss 593.2669677734375  loc loss 33.063720703125\n",
      "cls loss 503.9979553222656  loc loss 30.768722534179688\n",
      "cls loss 591.0399780273438  loc loss 32.73179626464844\n",
      "cls loss 432.8444519042969  loc loss 21.561609268188477\n",
      "cls loss 402.76080322265625  loc loss 25.36490821838379\n",
      "cls loss 468.06097412109375  loc loss 33.97600555419922\n",
      "cls loss 376.47784423828125  loc loss 26.11018943786621\n",
      "cls loss 296.6453552246094  loc loss 20.118104934692383\n",
      "cls loss 387.5903015136719  loc loss 27.607852935791016\n",
      "cls loss 554.123046875  loc loss 34.89667892456055\n",
      "cls loss 461.3760070800781  loc loss 36.152587890625\n",
      "cls loss 483.23565673828125  loc loss 38.95280838012695\n",
      "cls loss 297.9084167480469  loc loss 22.547855377197266\n",
      "cls loss 977.2825317382812  loc loss 71.52822875976562\n",
      "cls loss 653.864013671875  loc loss 44.62186813354492\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 546.415283203125  loc loss 30.127174377441406\n",
      "cls loss 592.3037109375  loc loss 40.601314544677734\n",
      "cls loss 496.836181640625  loc loss 28.100414276123047\n",
      "cls loss 671.6296997070312  loc loss 43.438167572021484\n",
      "cls loss 660.206787109375  loc loss 43.743934631347656\n",
      "cls loss 583.2381591796875  loc loss 38.30766677856445\n",
      "cls loss 489.96429443359375  loc loss 27.8887996673584\n",
      "cls loss 357.8365478515625  loc loss 22.36833953857422\n",
      "cls loss 531.83349609375  loc loss 34.53133010864258\n",
      "cls loss 552.9088134765625  loc loss 39.724029541015625\n",
      "cls loss 600.0753173828125  loc loss 35.14204788208008\n",
      "cls loss 751.4171752929688  loc loss 59.12657928466797\n",
      "cls loss 783.9014282226562  loc loss 60.420982360839844\n",
      "cls loss 547.8596801757812  loc loss 40.759613037109375\n",
      "cls loss 701.7078857421875  loc loss 57.76963806152344\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1., 38., 47.,  1.,  1.,  1.,  1.,  1., 62.])\n",
      "cls loss 522.9830322265625  loc loss 28.268962860107422\n",
      "cls loss 646.1452026367188  loc loss 36.96763229370117\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 666.444091796875  loc loss 40.2260856628418\n",
      "cls loss 734.450439453125  loc loss 54.10334396362305\n",
      "cls loss 508.43206787109375  loc loss 25.92754554748535\n",
      "cls loss 559.593017578125  loc loss 46.35560607910156\n",
      "cls loss 523.4265747070312  loc loss 33.35182189941406\n",
      "cls loss 326.4792785644531  loc loss 13.79106616973877\n",
      "cls loss 512.9345703125  loc loss 29.72937774658203\n",
      "cls loss 418.9462890625  loc loss 20.373762130737305\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1., 35.])\n",
      "cls loss 517.7860107421875  loc loss 26.08114242553711\n",
      "cls loss 711.231201171875  loc loss 39.57701873779297\n",
      "cls loss 673.055908203125  loc loss 45.60127258300781\n",
      "cls loss 613.929931640625  loc loss 51.533355712890625\n",
      "cls loss 494.67242431640625  loc loss 40.52332305908203\n",
      "cls loss 637.5233764648438  loc loss 48.558860778808594\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 369.48681640625  loc loss 21.888837814331055\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 558.226806640625  loc loss 27.223682403564453\n",
      "cls loss 874.151611328125  loc loss 47.33456802368164\n",
      "cls loss 1051.712890625  loc loss 79.009765625\n",
      "cls loss 540.0012817382812  loc loss 28.473800659179688\n",
      "cls loss 468.5254211425781  loc loss 29.306350708007812\n",
      "cls loss 472.702392578125  loc loss 28.179588317871094\n",
      "cls loss 504.2139892578125  loc loss 38.040985107421875\n",
      "cls loss 476.3411865234375  loc loss 20.32655143737793\n",
      "cls loss 787.9749755859375  loc loss 57.92109298706055\n",
      "cls loss 632.242919921875  loc loss 40.026432037353516\n",
      "cls loss 371.875  loc loss 22.640668869018555\n",
      "cls loss 647.07177734375  loc loss 35.94330978393555\n",
      "cls loss 765.6655883789062  loc loss 60.64060974121094\n",
      "cls loss 611.4176635742188  loc loss 40.24882888793945\n",
      "cls loss 565.2452392578125  loc loss 30.916656494140625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.])\n",
      "cls loss 516.3154296875  loc loss 38.736305236816406\n",
      "cls loss 455.063232421875  loc loss 37.03281021118164\n",
      "cls loss 665.2982788085938  loc loss 44.49753952026367\n",
      "cls loss 949.3591918945312  loc loss 79.64372253417969\n",
      "cls loss 444.7054443359375  loc loss 21.235511779785156\n",
      "cls loss 548.5011596679688  loc loss 35.38391876220703\n",
      "cls loss 467.89129638671875  loc loss 26.496984481811523\n",
      "cls loss 503.0654296875  loc loss 30.785720825195312\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 21., 21., 21.])\n",
      "cls loss 541.0772705078125  loc loss 31.334365844726562\n",
      "cls loss 514.66943359375  loc loss 23.58955955505371\n",
      "cls loss 522.905029296875  loc loss 35.156944274902344\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 35.])\n",
      "cls loss 730.1055908203125  loc loss 48.51417922973633\n",
      "cls loss 254.11468505859375  loc loss 14.256305694580078\n",
      "cls loss 395.0913391113281  loc loss 27.517126083374023\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 398.2763671875  loc loss 20.054771423339844\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 38., 38.,  9., 38.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1.,  1.])\n",
      "cls loss 441.374755859375  loc loss 32.21223068237305\n",
      "cls loss 710.72998046875  loc loss 50.45875930786133\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 2.,  1., 77., 31., 10., 10.,  1.,  4., 10.])\n",
      "cls loss 392.711669921875  loc loss 19.02587127685547\n",
      "cls loss 694.4892578125  loc loss 44.78748321533203\n",
      "cls loss 1393.346923828125  loc loss 88.85585021972656\n",
      "cls loss 465.73760986328125  loc loss 29.19285011291504\n",
      "cls loss 621.60205078125  loc loss 49.6130256652832\n",
      "cls loss 462.00738525390625  loc loss 27.513729095458984\n",
      "cls loss 479.7718200683594  loc loss 24.10560417175293\n",
      "cls loss 758.0174560546875  loc loss 32.0532112121582\n",
      "cls loss 699.6715087890625  loc loss 37.79168701171875\n",
      "cls loss 601.5632934570312  loc loss 42.2442626953125\n",
      "cls loss 456.0657958984375  loc loss 23.288724899291992\n",
      "cls loss 512.650146484375  loc loss 26.50475311279297\n",
      "cls loss 936.3636474609375  loc loss 58.901100158691406\n",
      "cls loss 786.3690795898438  loc loss 50.8099479675293\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1., 42., 42., 42., 42., 42., 42.,  1.,\n",
      "         1.,  1.,  1., 42.,  1.,  1., 42.,  1.])\n",
      "cls loss 449.42913818359375  loc loss 31.18846893310547\n",
      "cls loss 674.4244384765625  loc loss 43.119544982910156\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.])\n",
      "cls loss 294.5958251953125  loc loss 19.409183502197266\n",
      "cls loss 643.331298828125  loc loss 45.202728271484375\n",
      "cls loss 524.7069091796875  loc loss 38.263336181640625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([11.])\n",
      "cls loss 324.3230285644531  loc loss 18.873088836669922\n",
      "cls loss 428.09716796875  loc loss 19.553775787353516\n",
      "cls loss 440.72357177734375  loc loss 20.3023738861084\n",
      "cls loss 631.176513671875  loc loss 42.79368591308594\n",
      "cls loss 611.4837036132812  loc loss 33.53718185424805\n",
      "cls loss 574.055419921875  loc loss 41.08027648925781\n",
      "cls loss 849.175048828125  loc loss 45.964962005615234\n",
      "cls loss 449.93829345703125  loc loss 27.255294799804688\n",
      "cls loss 807.8980102539062  loc loss 62.057281494140625\n",
      "cls loss 448.2726135253906  loc loss 27.59900665283203\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 394.54583740234375  loc loss 28.614849090576172\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1., 38., 38., 42.])\n",
      "cls loss 504.20208740234375  loc loss 38.14175796508789\n",
      "cls loss 463.39410400390625  loc loss 26.464313507080078\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 390.274658203125  loc loss 29.61627197265625\n",
      "cls loss 929.08642578125  loc loss 66.52334594726562\n",
      "cls loss 558.697509765625  loc loss 39.70216369628906\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10.,  3.,  3.,  6.,  8.,  8.,  1.,  1.,  1., 10.])\n",
      "cls loss 491.3756408691406  loc loss 27.664947509765625\n",
      "cls loss 294.8115234375  loc loss 11.496750831604004\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10.,  3.])\n",
      "cls loss 458.4144287109375  loc loss 26.11995506286621\n",
      "cls loss 288.4053955078125  loc loss 13.275568008422852\n",
      "cls loss 540.4717407226562  loc loss 41.7923469543457\n",
      "cls loss 611.79541015625  loc loss 42.76054382324219\n",
      "cls loss 472.08990478515625  loc loss 29.03705596923828\n",
      "cls loss 345.16497802734375  loc loss 16.80747413635254\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 34.])\n",
      "cls loss 810.0311889648438  loc loss 49.807132720947266\n",
      "cls loss 832.1376953125  loc loss 70.57283020019531\n",
      "cls loss 543.7181396484375  loc loss 43.40724182128906\n",
      "cls loss 405.74163818359375  loc loss 30.45919418334961\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.,  1.])\n",
      "cls loss 459.736572265625  loc loss 25.21162223815918\n",
      "cls loss 717.2998657226562  loc loss 58.68425369262695\n",
      "cls loss 1081.62158203125  loc loss 72.37576293945312\n",
      "cls loss 910.535400390625  loc loss 48.630653381347656\n",
      "cls loss 533.6876220703125  loc loss 29.859539031982422\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 666.7055053710938  loc loss 38.89904022216797\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10.])\n",
      "cls loss 408.22747802734375  loc loss 22.59807586669922\n",
      "cls loss 587.1124267578125  loc loss 30.30307960510254\n",
      "cls loss 552.94677734375  loc loss 32.265933990478516\n",
      "cls loss 390.625  loc loss 24.751663208007812\n",
      "cls loss 484.8067321777344  loc loss 35.0924072265625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21.,\n",
      "        21.])\n",
      "cls loss 672.59326171875  loc loss 39.53117370605469\n",
      "cls loss 536.4898681640625  loc loss 35.35717010498047\n",
      "cls loss 342.7868957519531  loc loss 16.41401481628418\n",
      "cls loss 714.7132568359375  loc loss 48.53352737426758\n",
      "cls loss 570.0574951171875  loc loss 39.893863677978516\n",
      "cls loss 396.83856201171875  loc loss 25.690780639648438\n",
      "cls loss 835.3021850585938  loc loss 58.830718994140625\n",
      "cls loss 1008.3984375  loc loss 70.97229766845703\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15., 85.])\n",
      "cls loss 643.2117309570312  loc loss 41.828704833984375\n",
      "cls loss 639.1507568359375  loc loss 48.61846160888672\n",
      "cls loss 652.96875  loc loss 47.734893798828125\n",
      "cls loss 589.3715209960938  loc loss 33.968475341796875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 8., 8.])\n",
      "cls loss 382.79718017578125  loc loss 20.506654739379883\n",
      "cls loss 410.8934326171875  loc loss 28.573339462280273\n",
      "cls loss 514.628173828125  loc loss 31.50362205505371\n",
      "cls loss 432.0716552734375  loc loss 24.667278289794922\n",
      "cls loss 497.3810119628906  loc loss 30.492692947387695\n",
      "cls loss 648.5567626953125  loc loss 40.830406188964844\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1., 35., 27., 27.,  1., 27.,  1.])\n",
      "cls loss 894.4874267578125  loc loss 60.98539733886719\n",
      "cls loss 416.11376953125  loc loss 30.312602996826172\n",
      "cls loss 510.04388427734375  loc loss 38.01336669921875\n",
      "cls loss 475.9898986816406  loc loss 42.15658950805664\n",
      "cls loss 436.43927001953125  loc loss 33.731773376464844\n",
      "cls loss 470.3023986816406  loc loss 38.537200927734375\n",
      "cls loss 469.370361328125  loc loss 38.505306243896484\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  2.,  2.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  2.,  2.])\n",
      "cls loss 302.927490234375  loc loss 11.710633277893066\n",
      "cls loss 734.2523193359375  loc loss 46.88554000854492\n",
      "cls loss 533.2987670898438  loc loss 26.326091766357422\n",
      "cls loss 835.3848266601562  loc loss 61.922325134277344\n",
      "cls loss 353.919189453125  loc loss 21.891220092773438\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 19., 19., 19., 16.])\n",
      "cls loss 369.18975830078125  loc loss 16.796947479248047\n",
      "cls loss 295.64306640625  loc loss 13.931890487670898\n",
      "cls loss 446.546875  loc loss 23.557025909423828\n",
      "cls loss 582.484375  loc loss 40.14652633666992\n",
      "cls loss 308.6650390625  loc loss 22.47258186340332\n",
      "cls loss 666.1680908203125  loc loss 49.970481872558594\n",
      "cls loss 478.22454833984375  loc loss 34.56639099121094\n",
      "cls loss 533.0549926757812  loc loss 35.318016052246094\n",
      "cls loss 649.856201171875  loc loss 47.579368591308594\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 752.9534301757812  loc loss 32.8463134765625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 928.83544921875  loc loss 81.73289489746094\n",
      "cls loss 1138.888916015625  loc loss 113.44099426269531\n",
      "cls loss 592.870849609375  loc loss 42.22990417480469\n",
      "cls loss 537.573486328125  loc loss 36.78694152832031\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3.,  3.,  3.,  3.,  3., 10.])\n",
      "cls loss 318.3158264160156  loc loss 17.880727767944336\n",
      "cls loss 570.880126953125  loc loss 31.67306137084961\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 1., 1., 1., 3., 3., 3., 3.])\n",
      "cls loss 457.4725036621094  loc loss 31.200546264648438\n",
      "cls loss 833.98388671875  loc loss 58.77996063232422\n",
      "cls loss 668.9995727539062  loc loss 46.458740234375\n",
      "cls loss 472.62567138671875  loc loss 27.001863479614258\n",
      "cls loss 674.498291015625  loc loss 51.4591178894043\n",
      "cls loss 433.822998046875  loc loss 32.77296829223633\n",
      "cls loss 693.5028076171875  loc loss 49.341094970703125\n",
      "cls loss 499.49066162109375  loc loss 46.63719940185547\n",
      "cls loss 512.782470703125  loc loss 35.0577392578125\n",
      "cls loss 1066.83447265625  loc loss 90.19318389892578\n",
      "cls loss 702.9722900390625  loc loss 50.6926383972168\n",
      "cls loss 484.5478820800781  loc loss 24.30994987487793\n",
      "cls loss 332.7342529296875  loc loss 14.739212036132812\n",
      "cls loss 370.3399658203125  loc loss 18.89900779724121\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3., 10., 10., 10., 10., 10., 10., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10., 10., 10., 10., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 11., 10., 10., 10., 10., 10.,  3.,  3.,  3.,  3.,  3.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 11., 10., 10., 10., 10., 10.,  3.,  3.,  3.,  3.,  3.])\n",
      "cls loss 378.66546630859375  loc loss 17.273351669311523\n",
      "cls loss 436.0490417480469  loc loss 21.828868865966797\n",
      "cls loss 363.0107421875  loc loss 23.431177139282227\n",
      "cls loss 358.7492980957031  loc loss 15.88688850402832\n",
      "cls loss 418.9132080078125  loc loss 34.26642990112305\n",
      "cls loss 347.9586181640625  loc loss 13.9723539352417\n",
      "cls loss 643.016845703125  loc loss 43.861534118652344\n",
      "cls loss 562.68505859375  loc loss 40.90926742553711\n",
      "cls loss 849.8370361328125  loc loss 55.74263381958008\n",
      "cls loss 419.0699462890625  loc loss 32.32775115966797\n",
      "cls loss 756.7222290039062  loc loss 51.59520721435547\n",
      "cls loss 627.3455810546875  loc loss 42.51449966430664\n",
      "cls loss 576.8734130859375  loc loss 39.32453155517578\n",
      "cls loss 591.072998046875  loc loss 43.71881866455078\n",
      "cls loss 810.281005859375  loc loss 54.05249786376953\n",
      "cls loss 790.8748168945312  loc loss 48.48383331298828\n",
      "cls loss 376.7955322265625  loc loss 21.50623893737793\n",
      "cls loss 665.947265625  loc loss 52.0069580078125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 10.,  1., 18.])\n",
      "cls loss 333.9342346191406  loc loss 23.9311580657959\n",
      "cls loss 387.6253356933594  loc loss 17.194856643676758\n",
      "cls loss 669.0697021484375  loc loss 35.35793685913086\n",
      "cls loss 955.6177368164062  loc loss 61.979736328125\n",
      "cls loss 572.8226318359375  loc loss 40.91571807861328\n",
      "cls loss 813.3814086914062  loc loss 47.09884262084961\n",
      "cls loss 566.441650390625  loc loss 38.83443832397461\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.,  1.,  1.])\n",
      "cls loss 720.0640869140625  loc loss 48.5450439453125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1., 38.,  1.])\n",
      "cls loss 712.50146484375  loc loss 40.21425247192383\n",
      "cls loss 903.7762451171875  loc loss 65.53309631347656\n",
      "cls loss 464.7255859375  loc loss 34.18536376953125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 627.2095947265625  loc loss 43.20940017700195\n",
      "cls loss 553.5997314453125  loc loss 35.49739074707031\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3., 10.,  8.,  3., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.])\n",
      "cls loss 661.7158203125  loc loss 40.47713851928711\n",
      "cls loss 470.50555419921875  loc loss 29.700998306274414\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3.,  3., 11.,  3., 10., 10.,  3.,  3., 10.])\n",
      "cls loss 556.2515869140625  loc loss 26.867008209228516\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3., 10., 10., 10.])\n",
      "cls loss 532.6038208007812  loc loss 36.6971549987793\n",
      "cls loss 463.4996337890625  loc loss 25.678953170776367\n",
      "cls loss 545.828369140625  loc loss 39.53277587890625\n",
      "cls loss 858.0895385742188  loc loss 52.782142639160156\n",
      "cls loss 547.9259033203125  loc loss 36.44868850708008\n",
      "cls loss 384.82135009765625  loc loss 34.97001647949219\n",
      "cls loss 505.2287902832031  loc loss 36.14009475708008\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 9.,  9., 85., 85.])\n",
      "cls loss 444.3316650390625  loc loss 24.995790481567383\n",
      "cls loss 507.1017761230469  loc loss 35.444854736328125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 832.968994140625  loc loss 61.96196746826172\n",
      "cls loss 717.6009521484375  loc loss 36.11552810668945\n",
      "cls loss 801.048828125  loc loss 57.168006896972656\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10., 10., 10., 10.])\n",
      "cls loss 502.8546447753906  loc loss 31.97317886352539\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([13.])\n",
      "cls loss 797.57421875  loc loss 63.16010284423828\n",
      "cls loss 293.63897705078125  loc loss 16.134164810180664\n",
      "cls loss 368.4224853515625  loc loss 19.310606002807617\n",
      "cls loss 499.28411865234375  loc loss 26.74457550048828\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19.,  1.,  1.,  1., 19., 19.])\n",
      "cls loss 510.75689697265625  loc loss 33.13666534423828\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 385.76751708984375  loc loss 31.08376693725586\n",
      "cls loss 568.9349365234375  loc loss 42.16046905517578\n",
      "cls loss 418.81304931640625  loc loss 25.218332290649414\n",
      "cls loss 618.212158203125  loc loss 37.48477554321289\n",
      "cls loss 665.2800903320312  loc loss 51.79511260986328\n",
      "cls loss 542.5991821289062  loc loss 30.055587768554688\n",
      "cls loss 754.6458740234375  loc loss 56.62580871582031\n",
      "cls loss 322.9140625  loc loss 15.059049606323242\n",
      "cls loss 561.6051025390625  loc loss 35.5419921875\n",
      "cls loss 445.8058776855469  loc loss 22.91849136352539\n",
      "cls loss 470.0562744140625  loc loss 25.81135368347168\n",
      "cls loss 591.958984375  loc loss 40.293663024902344\n",
      "cls loss 560.6101684570312  loc loss 31.591337203979492\n",
      "cls loss 802.369140625  loc loss 51.27085876464844\n",
      "cls loss 505.818115234375  loc loss 35.092037200927734\n",
      "cls loss 642.43310546875  loc loss 44.32317352294922\n",
      "cls loss 957.9288330078125  loc loss 60.07475280761719\n",
      "cls loss 516.170166015625  loc loss 39.88102340698242\n",
      "cls loss 596.2459716796875  loc loss 36.126895904541016\n",
      "cls loss 701.378173828125  loc loss 53.88641357421875\n",
      "cls loss 745.506103515625  loc loss 54.061805725097656\n",
      "cls loss 943.0585327148438  loc loss 51.73202133178711\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 5.])\n",
      "cls loss 288.66607666015625  loc loss 11.083704948425293\n",
      "cls loss 361.44384765625  loc loss 16.322546005249023\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 13.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 6., 8., 8.])\n",
      "cls loss 307.5524597167969  loc loss 15.777959823608398\n",
      "cls loss 373.258544921875  loc loss 20.70578956604004\n",
      "cls loss 731.704833984375  loc loss 50.99747085571289\n",
      "cls loss 324.99530029296875  loc loss 16.171079635620117\n",
      "cls loss 562.8629150390625  loc loss 43.924537658691406\n",
      "cls loss 918.109375  loc loss 63.55491256713867\n",
      "cls loss 533.258544921875  loc loss 41.490386962890625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([42., 42.,  1.,  1.,  1.,  1.,  1.,  1.,  1., 42., 42.])\n",
      "cls loss 609.6256103515625  loc loss 35.19388198852539\n",
      "cls loss 772.3395385742188  loc loss 60.897151947021484\n",
      "cls loss 637.7854614257812  loc loss 52.17364501953125\n",
      "cls loss 463.39959716796875  loc loss 28.53860092163086\n",
      "cls loss 613.8822021484375  loc loss 37.517662048339844\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 817.5027465820312  loc loss 54.977073669433594\n",
      "cls loss 655.6241455078125  loc loss 46.98524475097656\n",
      "cls loss 427.0121154785156  loc loss 25.82190704345703\n",
      "cls loss 355.29925537109375  loc loss 19.543380737304688\n",
      "cls loss 511.2740478515625  loc loss 30.25961685180664\n",
      "cls loss 676.3114013671875  loc loss 44.84619140625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15.])\n",
      "cls loss 330.1393737792969  loc loss 15.839452743530273\n",
      "cls loss 537.1028442382812  loc loss 36.235816955566406\n",
      "cls loss 487.30517578125  loc loss 32.59953308105469\n",
      "cls loss 862.167724609375  loc loss 60.32839584350586\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19.,  7.])\n",
      "cls loss 489.2763366699219  loc loss 28.798755645751953\n",
      "cls loss 962.0657348632812  loc loss 61.135555267333984\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 802.8890380859375  loc loss 42.54679870605469\n",
      "cls loss 645.8577270507812  loc loss 49.3066520690918\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([38., 38.,  1., 18.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1., 18., 18.,  1.])\n",
      "cls loss 529.802001953125  loc loss 26.489356994628906\n",
      "cls loss 478.0091247558594  loc loss 24.107112884521484\n",
      "cls loss 853.5069580078125  loc loss 66.07313537597656\n",
      "cls loss 679.76025390625  loc loss 37.786190032958984\n",
      "cls loss 635.13330078125  loc loss 32.36097717285156\n",
      "cls loss 353.419189453125  loc loss 27.644575119018555\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.])\n",
      "cls loss 290.9232482910156  loc loss 9.982848167419434\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([32.])\n",
      "cls loss 553.3427734375  loc loss 29.047700881958008\n",
      "cls loss 477.382080078125  loc loss 34.494441986083984\n",
      "cls loss 630.9749755859375  loc loss 51.06803894042969\n",
      "cls loss 570.8065185546875  loc loss 38.007408142089844\n",
      "cls loss 467.82232666015625  loc loss 30.547819137573242\n",
      "cls loss 757.7266845703125  loc loss 48.291954040527344\n",
      "cls loss 810.5028076171875  loc loss 56.627464294433594\n",
      "cls loss 649.4906005859375  loc loss 43.41886901855469\n",
      "cls loss 538.4140625  loc loss 31.52979278564453\n",
      "cls loss 832.702392578125  loc loss 53.41691589355469\n",
      "cls loss 536.1677856445312  loc loss 28.106266021728516\n",
      "cls loss 847.31591796875  loc loss 67.04517364501953\n",
      "cls loss 623.4742431640625  loc loss 35.916133880615234\n",
      "cls loss 517.3504638671875  loc loss 37.872535705566406\n",
      "cls loss 389.35638427734375  loc loss 20.44314956665039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 444.11370849609375  loc loss 27.947399139404297\n",
      "cls loss 651.6174926757812  loc loss 43.751121520996094\n",
      "cls loss 665.1361083984375  loc loss 49.18982696533203\n",
      "cls loss 397.3282470703125  loc loss 26.923160552978516\n",
      "cls loss 731.3182373046875  loc loss 49.46440124511719\n",
      "cls loss 857.3717041015625  loc loss 52.985084533691406\n",
      "cls loss 326.48822021484375  loc loss 22.480894088745117\n",
      "cls loss 824.8427734375  loc loss 56.64535140991211\n",
      "cls loss 590.107177734375  loc loss 46.08085250854492\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 811.0496826171875  loc loss 63.22090148925781\n",
      "cls loss 409.5184326171875  loc loss 15.5540771484375\n",
      "cls loss 614.9012451171875  loc loss 33.20948028564453\n",
      "cls loss 596.990966796875  loc loss 40.879066467285156\n",
      "cls loss 481.8206787109375  loc loss 27.897804260253906\n",
      "cls loss 298.3545227050781  loc loss 16.035236358642578\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 9., 9., 1., 9., 9., 9., 9., 1., 9.])\n",
      "cls loss 1020.3088989257812  loc loss 88.91603088378906\n",
      "cls loss 601.7568359375  loc loss 32.501930236816406\n",
      "cls loss 881.9119873046875  loc loss 75.08804321289062\n",
      "cls loss 373.32476806640625  loc loss 26.319372177124023\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 42., 42.])\n",
      "cls loss 653.8311157226562  loc loss 48.55562210083008\n",
      "cls loss 699.967529296875  loc loss 51.02674102783203\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  2.,  1.,  1.,  1., 38.,\n",
      "         1.,  1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 38., 38., 38.,  1., 38., 38., 38.,  1.,  1., 38.,  1.,\n",
      "         1.])\n",
      "cls loss 429.8424072265625  loc loss 30.522193908691406\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  8.,  8.])\n",
      "cls loss 985.4210205078125  loc loss 65.68003845214844\n",
      "cls loss 991.6668701171875  loc loss 70.28984069824219\n",
      "cls loss 390.74981689453125  loc loss 22.62415313720703\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([4., 1., 1., 4.])\n",
      "cls loss 553.848388671875  loc loss 38.830448150634766\n",
      "cls loss 661.8145751953125  loc loss 41.735069274902344\n",
      "cls loss 300.77447509765625  loc loss 14.279366493225098\n",
      "cls loss 409.5672302246094  loc loss 25.499813079833984\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([51.,  1.])\n",
      "cls loss 297.3421936035156  loc loss 12.65538215637207\n",
      "cls loss 389.8449401855469  loc loss 22.862937927246094\n",
      "cls loss 687.0755004882812  loc loss 40.59088134765625\n",
      "cls loss 752.2197265625  loc loss 56.66945266723633\n",
      "cls loss 1020.7379760742188  loc loss 56.74191665649414\n",
      "cls loss 1275.75732421875  loc loss 84.30165100097656\n",
      "cls loss 547.5499267578125  loc loss 33.618003845214844\n",
      "cls loss 774.01220703125  loc loss 55.16152572631836\n",
      "cls loss 814.9165649414062  loc loss 59.022071838378906\n",
      "cls loss 643.5252685546875  loc loss 36.979854583740234\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  3.,  1.,  1.,  1.,  3.,  1.,  1.,\n",
      "         1.,  1.,  1.])\n",
      "cls loss 666.7654418945312  loc loss 33.11885452270508\n",
      "cls loss 757.5367431640625  loc loss 39.03031539916992\n",
      "cls loss 679.6217651367188  loc loss 36.045249938964844\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "cls loss 558.1143798828125  loc loss 33.63801193237305\n",
      "cls loss 332.221435546875  loc loss 27.111270904541016\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3.])\n",
      "cls loss 288.9680480957031  loc loss 13.609928131103516\n",
      "cls loss 503.27801513671875  loc loss 34.99778747558594\n",
      "cls loss 401.7756652832031  loc loss 31.102455139160156\n",
      "cls loss 719.0408325195312  loc loss 49.65583419799805\n",
      "cls loss 494.67437744140625  loc loss 25.261083602905273\n",
      "cls loss 397.4031982421875  loc loss 28.191120147705078\n",
      "cls loss 1213.26611328125  loc loss 81.56587982177734\n",
      "cls loss 528.3609008789062  loc loss 39.76324462890625\n",
      "cls loss 377.6965026855469  loc loss 30.378543853759766\n",
      "cls loss 517.6182861328125  loc loss 30.09842872619629\n",
      "cls loss 456.0892639160156  loc loss 33.152286529541016\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 834.4276123046875  loc loss 56.3088493347168\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  9., 64., 64., 64., 64., 64., 64., 64., 64., 64.,  9.,  9.,  9.,\n",
      "         9.])\n",
      "cls loss 472.18353271484375  loc loss 23.489669799804688\n",
      "cls loss 1049.1268310546875  loc loss 85.13958740234375\n",
      "cls loss 542.4010009765625  loc loss 37.03309631347656\n",
      "cls loss 713.840087890625  loc loss 52.19721603393555\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.,  3.,  3.])\n",
      "cls loss 466.6374816894531  loc loss 28.336204528808594\n",
      "cls loss 518.5410766601562  loc loss 33.79255676269531\n",
      "cls loss 502.5282897949219  loc loss 37.336395263671875\n",
      "cls loss 552.9931030273438  loc loss 39.75408172607422\n",
      "cls loss 534.49951171875  loc loss 44.665042877197266\n",
      "cls loss 535.8404541015625  loc loss 41.73914337158203\n",
      "cls loss 525.3353271484375  loc loss 42.09470748901367\n",
      "cls loss 553.9989013671875  loc loss 34.83669662475586\n",
      "cls loss 683.0010375976562  loc loss 48.503021240234375\n",
      "cls loss 594.2281494140625  loc loss 33.869598388671875\n",
      "cls loss 477.75909423828125  loc loss 21.20732307434082\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21.])\n",
      "cls loss 350.244873046875  loc loss 19.51004409790039\n",
      "cls loss 471.2509765625  loc loss 40.452388763427734\n",
      "cls loss 686.2693481445312  loc loss 50.125450134277344\n",
      "cls loss 434.0920715332031  loc loss 24.725784301757812\n",
      "cls loss 596.608642578125  loc loss 36.300048828125\n",
      "cls loss 1066.6461181640625  loc loss 59.77452087402344\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 42., 42.,  1.,  1.])\n",
      "cls loss 536.2681884765625  loc loss 34.576168060302734\n",
      "cls loss 353.8780517578125  loc loss 26.49931526184082\n",
      "cls loss 498.4736633300781  loc loss 38.684356689453125\n",
      "cls loss 706.9072265625  loc loss 58.40463638305664\n",
      "cls loss 454.9866638183594  loc loss 30.13545036315918\n",
      "cls loss 649.7891235351562  loc loss 50.76884460449219\n",
      "cls loss 629.271240234375  loc loss 48.66249465942383\n",
      "cls loss 682.6553955078125  loc loss 40.58671569824219\n",
      "cls loss 532.3745727539062  loc loss 33.634376525878906\n",
      "cls loss 487.7321472167969  loc loss 29.98603057861328\n",
      "cls loss 389.085205078125  loc loss 16.739229202270508\n",
      "cls loss 486.99285888671875  loc loss 33.51583480834961\n",
      "cls loss 723.0125122070312  loc loss 59.94786834716797\n",
      "cls loss 580.1732177734375  loc loss 37.709285736083984\n",
      "cls loss 563.63671875  loc loss 42.405067443847656\n",
      "cls loss 620.6239624023438  loc loss 36.225067138671875\n",
      "cls loss 903.4239501953125  loc loss 61.50725555419922\n",
      "cls loss 636.373046875  loc loss 49.75147247314453\n",
      "cls loss 751.0759887695312  loc loss 43.340843200683594\n",
      "cls loss 435.8932189941406  loc loss 22.283376693725586\n",
      "cls loss 618.75927734375  loc loss 40.80442810058594\n",
      "cls loss 574.2625732421875  loc loss 36.896705627441406\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 5., 5., 5., 5., 5., 5.])\n",
      "cls loss 414.9945068359375  loc loss 28.386747360229492\n",
      "cls loss 490.0631103515625  loc loss 29.593725204467773\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([13.])\n",
      "cls loss 333.72515869140625  loc loss 21.806764602661133\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([44., 10.,  1.,  1.,  1.])\n",
      "cls loss 354.0523681640625  loc loss 21.741954803466797\n",
      "cls loss 666.77001953125  loc loss 34.79313278198242\n",
      "cls loss 537.4456787109375  loc loss 30.991323471069336\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19., 19., 19., 19., 19., 19., 19.])\n",
      "cls loss 685.3722534179688  loc loss 37.58123779296875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([56.])\n",
      "cls loss 1187.7156982421875  loc loss 74.12504577636719\n",
      "cls loss 671.951904296875  loc loss 54.60572052001953\n",
      "cls loss 875.3237915039062  loc loss 63.89240646362305\n",
      "cls loss 877.298828125  loc loss 68.06332397460938\n",
      "cls loss 533.4591674804688  loc loss 31.863792419433594\n",
      "cls loss 851.5929565429688  loc loss 62.9864501953125\n",
      "cls loss 507.8341369628906  loc loss 31.81878662109375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 36.])\n",
      "cls loss 603.1074829101562  loc loss 34.31549835205078\n",
      "cls loss 532.6265869140625  loc loss 38.587921142578125\n",
      "cls loss 544.90478515625  loc loss 32.84568786621094\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5.])\n",
      "cls loss 620.4473266601562  loc loss 38.987632751464844\n",
      "cls loss 348.154296875  loc loss 19.167007446289062\n",
      "cls loss 775.2153930664062  loc loss 44.58632278442383\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "cls loss 686.2637939453125  loc loss 47.104305267333984\n",
      "cls loss 704.31982421875  loc loss 45.42544174194336\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 625.4716796875  loc loss 45.58604431152344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 752.4677734375  loc loss 53.70191955566406\n",
      "cls loss 613.2081909179688  loc loss 57.392127990722656\n",
      "cls loss 440.888427734375  loc loss 31.38401985168457\n",
      "cls loss 556.5682373046875  loc loss 40.53633499145508\n",
      "cls loss 559.2186279296875  loc loss 36.732818603515625\n",
      "cls loss 854.6452026367188  loc loss 51.28620147705078\n",
      "cls loss 400.5185241699219  loc loss 20.551944732666016\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 11., 15., 10., 10., 10., 10., 10.])\n",
      "cls loss 911.0281982421875  loc loss 61.10513687133789\n",
      "cls loss 505.94110107421875  loc loss 35.19812774658203\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3.])\n",
      "cls loss 565.9932861328125  loc loss 37.40758514404297\n",
      "cls loss 503.74945068359375  loc loss 29.427764892578125\n",
      "cls loss 548.37060546875  loc loss 27.919776916503906\n",
      "cls loss 700.7494506835938  loc loss 35.38740539550781\n",
      "cls loss 392.81951904296875  loc loss 18.44935417175293\n",
      "cls loss 544.9236450195312  loc loss 35.486167907714844\n",
      "cls loss 605.3045654296875  loc loss 47.74163818359375\n",
      "cls loss 517.8070678710938  loc loss 39.565589904785156\n",
      "cls loss 1192.1414794921875  loc loss 91.14246368408203\n",
      "cls loss 856.0079956054688  loc loss 57.29584503173828\n",
      "cls loss 547.9493408203125  loc loss 40.791683197021484\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  9.,  9.,  9.,  6.,  6., 85., 85.,  8.,  1.,  1.,  1.,  1.,\n",
      "         6.,  6.])\n",
      "cls loss 395.0499267578125  loc loss 28.599449157714844\n",
      "cls loss 898.3215942382812  loc loss 64.0545883178711\n",
      "cls loss 1055.7763671875  loc loss 68.74288940429688\n",
      "cls loss 733.162353515625  loc loss 50.39363479614258\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10.,  3.,  3., 10.])\n",
      "cls loss 487.91558837890625  loc loss 28.445072174072266\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([7.])\n",
      "cls loss 614.7024536132812  loc loss 44.237457275390625\n",
      "cls loss 630.2568359375  loc loss 38.92496871948242\n",
      "cls loss 559.4323120117188  loc loss 45.44853591918945\n",
      "cls loss 789.7914428710938  loc loss 65.1813735961914\n",
      "cls loss 590.72900390625  loc loss 39.904319763183594\n",
      "cls loss 790.7236328125  loc loss 52.65070343017578\n",
      "cls loss 974.3363037109375  loc loss 60.32675552368164\n",
      "cls loss 581.993408203125  loc loss 41.248146057128906\n",
      "cls loss 627.3484497070312  loc loss 44.00791549682617\n",
      "cls loss 531.7939453125  loc loss 40.1395263671875\n",
      "cls loss 742.5238037109375  loc loss 61.874855041503906\n",
      "cls loss 612.7465209960938  loc loss 40.16588592529297\n",
      "cls loss 486.55535888671875  loc loss 29.169084548950195\n",
      "cls loss 741.4696044921875  loc loss 57.104469299316406\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([62.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([62.])\n",
      "cls loss 333.4078063964844  loc loss 18.4342041015625\n",
      "cls loss 595.0028076171875  loc loss 42.902313232421875\n",
      "cls loss 581.4243774414062  loc loss 38.928428649902344\n",
      "cls loss 413.24322509765625  loc loss 17.891422271728516\n",
      "cls loss 735.8997802734375  loc loss 51.047611236572266\n",
      "cls loss 729.0978393554688  loc loss 44.008201599121094\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([28.])\n",
      "cls loss 807.828857421875  loc loss 45.50217819213867\n",
      "cls loss 720.9283447265625  loc loss 45.478294372558594\n",
      "cls loss 703.818115234375  loc loss 45.7557487487793\n",
      "cls loss 721.9521484375  loc loss 48.94778823852539\n",
      "cls loss 990.3672485351562  loc loss 68.28498077392578\n",
      "cls loss 556.3311767578125  loc loss 36.75901794433594\n",
      "cls loss 689.4802856445312  loc loss 43.25883483886719\n",
      "cls loss 615.7210083007812  loc loss 52.15336608886719\n",
      "cls loss 980.5848388671875  loc loss 76.64802551269531\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([81.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 684.9256591796875  loc loss 29.11225128173828\n",
      "cls loss 526.43798828125  loc loss 26.749258041381836\n",
      "cls loss 450.0164794921875  loc loss 28.45639419555664\n",
      "cls loss 379.1925964355469  loc loss 15.432036399841309\n",
      "cls loss 423.7421569824219  loc loss 27.573266983032227\n",
      "cls loss 453.8899841308594  loc loss 28.91524314880371\n",
      "cls loss 525.1326904296875  loc loss 33.60038757324219\n",
      "cls loss 679.6602783203125  loc loss 55.82426452636719\n",
      "cls loss 767.070068359375  loc loss 52.834693908691406\n",
      "cls loss 1453.684814453125  loc loss 101.67410278320312\n",
      "cls loss 598.5848388671875  loc loss 31.24990463256836\n",
      "cls loss 707.239501953125  loc loss 48.742855072021484\n",
      "cls loss 500.7598571777344  loc loss 31.43251609802246\n",
      "cls loss 657.07568359375  loc loss 37.070350646972656\n",
      "cls loss 597.826416015625  loc loss 34.122825622558594\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([44., 44.])\n",
      "cls loss 529.79638671875  loc loss 26.94755744934082\n",
      "cls loss 521.6727294921875  loc loss 38.679954528808594\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15.])\n",
      "cls loss 629.2457275390625  loc loss 32.704891204833984\n",
      "cls loss 301.35052490234375  loc loss 17.755271911621094\n",
      "cls loss 616.717041015625  loc loss 37.080284118652344\n",
      "cls loss 340.6743469238281  loc loss 22.440879821777344\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([1., 3., 3.])\n",
      "cls loss 383.6647033691406  loc loss 30.14923095703125\n",
      "cls loss 327.04522705078125  loc loss 14.261630058288574\n",
      "cls loss 590.488037109375  loc loss 33.791378021240234\n",
      "cls loss 617.1640625  loc loss 36.91884231567383\n",
      "cls loss 557.0155639648438  loc loss 36.66287612915039\n",
      "cls loss 582.863525390625  loc loss 33.65946960449219\n",
      "cls loss 471.146240234375  loc loss 35.97931671142578\n",
      "cls loss 621.1129150390625  loc loss 43.4490852355957\n",
      "cls loss 499.45050048828125  loc loss 33.19932174682617\n",
      "cls loss 607.5581665039062  loc loss 43.81480407714844\n",
      "cls loss 388.4036560058594  loc loss 24.842418670654297\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 715.1102294921875  loc loss 45.02537536621094\n",
      "cls loss 828.9248046875  loc loss 42.849796295166016\n",
      "cls loss 742.0938720703125  loc loss 51.91682434082031\n",
      "cls loss 728.8302001953125  loc loss 54.60503005981445\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10., 10., 10.,  1.,  1.,  1.,  1.,  1.,  1.,  8.,  8.,\n",
      "         1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10., 10., 10.,  1.,  1.,  1.,  1.,  1.,  1.,  8.,  8.,\n",
      "         1.])\n",
      "cls loss 711.6637573242188  loc loss 35.018096923828125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 3., 3., 3.])\n",
      "cls loss 589.6449584960938  loc loss 37.666500091552734\n",
      "cls loss 407.5253601074219  loc loss 22.850303649902344\n",
      "cls loss 318.7289123535156  loc loss 16.422300338745117\n",
      "cls loss 553.5775146484375  loc loss 40.79732131958008\n",
      "cls loss 434.20111083984375  loc loss 23.208465576171875\n",
      "cls loss 474.0695495605469  loc loss 32.807464599609375\n",
      "cls loss 548.5828247070312  loc loss 38.647979736328125\n",
      "cls loss 764.8302001953125  loc loss 54.722076416015625\n",
      "cls loss 638.6541137695312  loc loss 33.35321807861328\n",
      "cls loss 612.1058349609375  loc loss 36.78611755371094\n",
      "cls loss 697.1241455078125  loc loss 47.08097457885742\n",
      "cls loss 516.3905639648438  loc loss 38.6839714050293\n",
      "cls loss 917.2708129882812  loc loss 69.05958557128906\n",
      "cls loss 484.025146484375  loc loss 25.85498046875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 703.9011840820312  loc loss 43.71343231201172\n",
      "cls loss 365.8360595703125  loc loss 16.298587799072266\n",
      "cls loss 881.9691772460938  loc loss 57.42049789428711\n",
      "cls loss 467.2431640625  loc loss 24.382883071899414\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 34.])\n",
      "cls loss 734.2138671875  loc loss 40.46611022949219\n",
      "cls loss 336.7093811035156  loc loss 22.940845489501953\n",
      "cls loss 637.291015625  loc loss 43.77820587158203\n",
      "cls loss 230.10696411132812  loc loss 17.00917625427246\n",
      "cls loss 585.7905883789062  loc loss 38.376220703125\n",
      "cls loss 563.4849243164062  loc loss 44.28238296508789\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 38.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16., 16., 16.,  9.,  9.,  9., 16., 16., 16., 85.,  9.])\n",
      "cls loss 552.1921997070312  loc loss 36.42717361450195\n",
      "cls loss 623.5459594726562  loc loss 50.354915618896484\n",
      "cls loss 870.3009033203125  loc loss 63.70596694946289\n",
      "cls loss 1236.4423828125  loc loss 85.09998321533203\n",
      "cls loss 386.6196594238281  loc loss 19.867210388183594\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3., 10.,  8.,  8., 10., 10., 10.,  3.,  3., 14.])\n",
      "cls loss 473.1817626953125  loc loss 22.559619903564453\n",
      "cls loss 825.605712890625  loc loss 42.9624137878418\n",
      "cls loss 362.34271240234375  loc loss 13.541751861572266\n",
      "cls loss 536.7984008789062  loc loss 23.71830940246582\n",
      "cls loss 715.3638305664062  loc loss 42.723167419433594\n",
      "cls loss 594.68017578125  loc loss 40.4205436706543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 354.9993896484375  loc loss 18.483797073364258\n",
      "cls loss 393.4744873046875  loc loss 25.113113403320312\n",
      "cls loss 598.4761962890625  loc loss 40.078636169433594\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42., 42.,  1.])\n",
      "cls loss 564.1555786132812  loc loss 41.85968017578125\n",
      "cls loss 483.25  loc loss 29.46865463256836\n",
      "cls loss 652.5150756835938  loc loss 50.094051361083984\n",
      "cls loss 729.5032958984375  loc loss 49.64730453491211\n",
      "cls loss 521.248779296875  loc loss 33.990360260009766\n",
      "cls loss 628.6968383789062  loc loss 45.10540771484375\n",
      "cls loss 409.6953430175781  loc loss 27.152700424194336\n",
      "cls loss 440.5778503417969  loc loss 30.318050384521484\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20.])\n",
      "cls loss 348.76641845703125  loc loss 19.659534454345703\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([11.])\n",
      "cls loss 431.5007019042969  loc loss 23.156251907348633\n",
      "cls loss 308.5965270996094  loc loss 17.261056900024414\n",
      "cls loss 666.9010009765625  loc loss 53.621803283691406\n",
      "cls loss 317.5804443359375  loc loss 14.365586280822754\n",
      "cls loss 635.558349609375  loc loss 36.861854553222656\n",
      "cls loss 351.7427673339844  loc loss 21.909725189208984\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 35., 27.])\n",
      "cls loss 597.3291015625  loc loss 39.37284851074219\n",
      "cls loss 612.135986328125  loc loss 49.20462417602539\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 463.0963134765625  loc loss 28.401424407958984\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([42.,  1.])\n",
      "cls loss 604.1150512695312  loc loss 43.348838806152344\n",
      "cls loss 541.8109741210938  loc loss 32.35696792602539\n",
      "cls loss 677.5112915039062  loc loss 38.90886306762695\n",
      "cls loss 776.1455078125  loc loss 53.62764358520508\n",
      "cls loss 708.5706176757812  loc loss 45.46490478515625\n",
      "cls loss 479.6905517578125  loc loss 38.181922912597656\n",
      "cls loss 416.1106262207031  loc loss 33.186912536621094\n",
      "cls loss 279.0176696777344  loc loss 13.438186645507812\n",
      "cls loss 497.5134582519531  loc loss 29.045263290405273\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 1., 1.])\n",
      "cls loss 482.55413818359375  loc loss 26.06907844543457\n",
      "cls loss 532.33984375  loc loss 37.32392883300781\n",
      "cls loss 541.31201171875  loc loss 34.55385208129883\n",
      "cls loss 442.33770751953125  loc loss 32.34832763671875\n",
      "cls loss 524.0347900390625  loc loss 31.992246627807617\n",
      "cls loss 558.3956298828125  loc loss 42.3718376159668\n",
      "cls loss 778.232666015625  loc loss 47.05620193481445\n",
      "cls loss 655.3334350585938  loc loss 52.16483688354492\n",
      "cls loss 620.1282958984375  loc loss 37.986724853515625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 484.4700012207031  loc loss 34.745391845703125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 570.3505859375  loc loss 29.14681625366211\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([81.])\n",
      "cls loss 693.5574951171875  loc loss 44.72005081176758\n",
      "cls loss 439.90338134765625  loc loss 29.702926635742188\n",
      "cls loss 309.0296325683594  loc loss 19.511184692382812\n",
      "cls loss 484.59454345703125  loc loss 25.756404876708984\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3.,  1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 19.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 19.])\n",
      "cls loss 632.4059448242188  loc loss 44.33096694946289\n",
      "cls loss 371.3683776855469  loc loss 18.65763282775879\n",
      "cls loss 389.6255798339844  loc loss 24.099077224731445\n",
      "cls loss 738.9599609375  loc loss 54.67339324951172\n",
      "cls loss 386.6117248535156  loc loss 24.724275588989258\n",
      "cls loss 477.28704833984375  loc loss 34.07293701171875\n",
      "cls loss 583.7098388671875  loc loss 39.37123489379883\n",
      "cls loss 447.24639892578125  loc loss 33.973899841308594\n",
      "cls loss 594.2490234375  loc loss 36.188961029052734\n",
      "cls loss 665.43017578125  loc loss 47.30061721801758\n",
      "cls loss 785.44384765625  loc loss 74.42071533203125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 81.])\n",
      "cls loss 587.6314697265625  loc loss 32.46347427368164\n",
      "cls loss 496.410400390625  loc loss 30.28911018371582\n",
      "cls loss 584.79248046875  loc loss 32.01899719238281\n",
      "cls loss 429.83843994140625  loc loss 21.280799865722656\n",
      "cls loss 399.4510192871094  loc loss 25.04886817932129\n",
      "cls loss 461.228271484375  loc loss 33.42321014404297\n",
      "cls loss 370.4923095703125  loc loss 25.754682540893555\n",
      "cls loss 293.26556396484375  loc loss 19.675493240356445\n",
      "cls loss 383.2421875  loc loss 27.01173210144043\n",
      "cls loss 547.1524047851562  loc loss 34.24399185180664\n",
      "cls loss 453.7261657714844  loc loss 35.626651763916016\n",
      "cls loss 475.3381042480469  loc loss 38.32538604736328\n",
      "cls loss 293.0665283203125  loc loss 22.11111831665039\n",
      "cls loss 964.2756958007812  loc loss 70.4168472290039\n",
      "cls loss 642.6934814453125  loc loss 43.660400390625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 537.080810546875  loc loss 29.468482971191406\n",
      "cls loss 581.33349609375  loc loss 39.89594650268555\n",
      "cls loss 489.7442626953125  loc loss 27.746906280517578\n",
      "cls loss 662.0535888671875  loc loss 43.0128059387207\n",
      "cls loss 652.9981689453125  loc loss 43.103904724121094\n",
      "cls loss 576.839111328125  loc loss 37.82120895385742\n",
      "cls loss 482.9455261230469  loc loss 27.534767150878906\n",
      "cls loss 353.24664306640625  loc loss 22.066938400268555\n",
      "cls loss 528.23095703125  loc loss 33.91150665283203\n",
      "cls loss 548.3517456054688  loc loss 39.07472610473633\n",
      "cls loss 593.008544921875  loc loss 34.70622253417969\n",
      "cls loss 745.072509765625  loc loss 58.16878890991211\n",
      "cls loss 767.5588989257812  loc loss 59.84379959106445\n",
      "cls loss 545.0589599609375  loc loss 40.21017837524414\n",
      "cls loss 696.3934326171875  loc loss 57.055458068847656\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1., 38., 47.,  1.,  1.,  1.,  1.,  1., 62.])\n",
      "cls loss 520.307861328125  loc loss 27.602676391601562\n",
      "cls loss 638.484619140625  loc loss 36.36286926269531\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 652.814453125  loc loss 39.542274475097656\n",
      "cls loss 719.494140625  loc loss 53.21539306640625\n",
      "cls loss 499.8175048828125  loc loss 25.467350006103516\n",
      "cls loss 556.0443115234375  loc loss 45.82911682128906\n",
      "cls loss 515.1600341796875  loc loss 32.539424896240234\n",
      "cls loss 320.9549560546875  loc loss 13.391641616821289\n",
      "cls loss 506.18170166015625  loc loss 29.201780319213867\n",
      "cls loss 415.4052734375  loc loss 19.901384353637695\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1., 35.])\n",
      "cls loss 517.0151977539062  loc loss 25.635717391967773\n",
      "cls loss 697.2855224609375  loc loss 38.81757736206055\n",
      "cls loss 665.563232421875  loc loss 44.86854934692383\n",
      "cls loss 602.6004638671875  loc loss 50.73894500732422\n",
      "cls loss 486.5423278808594  loc loss 39.84928894042969\n",
      "cls loss 629.7625732421875  loc loss 47.919864654541016\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 363.17059326171875  loc loss 21.45903778076172\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 545.8602294921875  loc loss 26.58848762512207\n",
      "cls loss 855.9014892578125  loc loss 46.25077438354492\n",
      "cls loss 1039.4708251953125  loc loss 77.88082122802734\n",
      "cls loss 532.0349731445312  loc loss 27.848007202148438\n",
      "cls loss 462.1064453125  loc loss 29.100297927856445\n",
      "cls loss 469.09259033203125  loc loss 27.43586540222168\n",
      "cls loss 500.0754089355469  loc loss 36.696372985839844\n",
      "cls loss 469.7341003417969  loc loss 20.012540817260742\n",
      "cls loss 777.0479736328125  loc loss 56.59727478027344\n",
      "cls loss 627.5444946289062  loc loss 39.445533752441406\n",
      "cls loss 363.8768310546875  loc loss 22.333484649658203\n",
      "cls loss 634.1248779296875  loc loss 35.21562957763672\n",
      "cls loss 750.5751342773438  loc loss 59.78911590576172\n",
      "cls loss 605.623046875  loc loss 39.54191207885742\n",
      "cls loss 556.6021728515625  loc loss 30.344642639160156\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.])\n",
      "cls loss 508.45965576171875  loc loss 37.968563079833984\n",
      "cls loss 451.39923095703125  loc loss 36.438880920410156\n",
      "cls loss 652.8016357421875  loc loss 43.93587112426758\n",
      "cls loss 941.2525634765625  loc loss 78.38832092285156\n",
      "cls loss 440.0972900390625  loc loss 20.94209098815918\n",
      "cls loss 546.8905029296875  loc loss 34.85438537597656\n",
      "cls loss 460.0937805175781  loc loss 25.8889217376709\n",
      "cls loss 494.7434997558594  loc loss 30.255329132080078\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 21., 21., 21.])\n",
      "cls loss 532.4354248046875  loc loss 30.884441375732422\n",
      "cls loss 507.2105712890625  loc loss 23.20062255859375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 515.603515625  loc loss 34.64692687988281\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 35.])\n",
      "cls loss 711.3507690429688  loc loss 47.00696563720703\n",
      "cls loss 251.43887329101562  loc loss 14.0322265625\n",
      "cls loss 390.6813659667969  loc loss 27.139142990112305\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 394.2339782714844  loc loss 19.42304229736328\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 38., 38.,  9., 38.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1.,  1.])\n",
      "cls loss 438.389404296875  loc loss 31.41082191467285\n",
      "cls loss 705.6531982421875  loc loss 49.40170669555664\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 2.,  1., 77., 31., 10., 10.,  1.,  4., 10.])\n",
      "cls loss 385.6944580078125  loc loss 18.727699279785156\n",
      "cls loss 687.0740356445312  loc loss 43.917213439941406\n",
      "cls loss 1375.08349609375  loc loss 86.5477294921875\n",
      "cls loss 458.8049621582031  loc loss 28.76044273376465\n",
      "cls loss 614.7945556640625  loc loss 48.48046875\n",
      "cls loss 457.3621520996094  loc loss 26.78965950012207\n",
      "cls loss 473.0748291015625  loc loss 23.630260467529297\n",
      "cls loss 736.2540283203125  loc loss 31.492788314819336\n",
      "cls loss 688.88671875  loc loss 36.9937858581543\n",
      "cls loss 592.2274169921875  loc loss 41.43465042114258\n",
      "cls loss 450.4586181640625  loc loss 22.809385299682617\n",
      "cls loss 503.77801513671875  loc loss 26.04392433166504\n",
      "cls loss 915.123291015625  loc loss 57.79624938964844\n",
      "cls loss 772.1686401367188  loc loss 49.595970153808594\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1., 42., 42., 42., 42., 42., 42.,  1.,\n",
      "         1.,  1.,  1., 42.,  1.,  1., 42.,  1.])\n",
      "cls loss 439.4908142089844  loc loss 30.466663360595703\n",
      "cls loss 667.3851318359375  loc loss 42.351959228515625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.])\n",
      "cls loss 287.8904724121094  loc loss 18.853952407836914\n",
      "cls loss 637.17919921875  loc loss 44.2413330078125\n",
      "cls loss 519.323486328125  loc loss 37.544105529785156\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([11.])\n",
      "cls loss 320.44903564453125  loc loss 18.6328182220459\n",
      "cls loss 421.4757080078125  loc loss 19.200679779052734\n",
      "cls loss 437.09014892578125  loc loss 19.81245994567871\n",
      "cls loss 628.518798828125  loc loss 42.14129638671875\n",
      "cls loss 605.8917236328125  loc loss 32.77460479736328\n",
      "cls loss 564.9723510742188  loc loss 40.06564712524414\n",
      "cls loss 837.322021484375  loc loss 45.00053024291992\n",
      "cls loss 441.6929016113281  loc loss 26.60800552368164\n",
      "cls loss 798.1828002929688  loc loss 60.85350036621094\n",
      "cls loss 435.7815246582031  loc loss 27.251522064208984\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 386.3101501464844  loc loss 27.97907066345215\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1., 38., 38., 42.])\n",
      "cls loss 494.5464172363281  loc loss 37.40357208251953\n",
      "cls loss 454.97039794921875  loc loss 26.160114288330078\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 382.6353759765625  loc loss 29.203691482543945\n",
      "cls loss 917.8421020507812  loc loss 65.2894287109375\n",
      "cls loss 555.1690673828125  loc loss 38.765899658203125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10.,  3.,  3.,  6.,  8.,  8.,  1.,  1.,  1., 10.])\n",
      "cls loss 485.63690185546875  loc loss 26.80813217163086\n",
      "cls loss 292.6036071777344  loc loss 11.253599166870117\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10.,  3.])\n",
      "cls loss 451.617431640625  loc loss 25.61930274963379\n",
      "cls loss 286.442138671875  loc loss 13.15992259979248\n",
      "cls loss 536.943359375  loc loss 40.82677459716797\n",
      "cls loss 607.5505981445312  loc loss 41.92460632324219\n",
      "cls loss 463.92828369140625  loc loss 28.534502029418945\n",
      "cls loss 336.4283447265625  loc loss 16.510021209716797\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 34.])\n",
      "cls loss 788.3366088867188  loc loss 49.009822845458984\n",
      "cls loss 818.0990600585938  loc loss 69.64686584472656\n",
      "cls loss 536.7153930664062  loc loss 42.476951599121094\n",
      "cls loss 399.869873046875  loc loss 30.063074111938477\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.,  1.])\n",
      "cls loss 456.83489990234375  loc loss 24.620115280151367\n",
      "cls loss 709.4876708984375  loc loss 57.54658126831055\n",
      "cls loss 1075.650146484375  loc loss 71.07705688476562\n",
      "cls loss 900.0416259765625  loc loss 47.74607467651367\n",
      "cls loss 528.1065673828125  loc loss 29.247116088867188\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 654.2161865234375  loc loss 38.28730773925781\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10.])\n",
      "cls loss 401.381103515625  loc loss 22.12139320373535\n",
      "cls loss 579.1182861328125  loc loss 29.705244064331055\n",
      "cls loss 542.2169189453125  loc loss 31.967079162597656\n",
      "cls loss 384.8510437011719  loc loss 24.393062591552734\n",
      "cls loss 479.29681396484375  loc loss 34.364105224609375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21.,\n",
      "        21.])\n",
      "cls loss 666.76220703125  loc loss 38.75301742553711\n",
      "cls loss 528.6522216796875  loc loss 34.363319396972656\n",
      "cls loss 338.6400146484375  loc loss 16.1108341217041\n",
      "cls loss 708.136962890625  loc loss 47.8530387878418\n",
      "cls loss 563.0150146484375  loc loss 39.053775787353516\n",
      "cls loss 390.54486083984375  loc loss 25.014942169189453\n",
      "cls loss 825.3765258789062  loc loss 57.268672943115234\n",
      "cls loss 997.4683837890625  loc loss 69.7186279296875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15., 85.])\n",
      "cls loss 629.0379638671875  loc loss 41.02898406982422\n",
      "cls loss 632.03955078125  loc loss 47.76711654663086\n",
      "cls loss 640.579345703125  loc loss 46.95523452758789\n",
      "cls loss 581.2777709960938  loc loss 33.1828498840332\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 8., 8.])\n",
      "cls loss 378.95745849609375  loc loss 20.01495361328125\n",
      "cls loss 400.86761474609375  loc loss 28.125812530517578\n",
      "cls loss 506.93365478515625  loc loss 31.027536392211914\n",
      "cls loss 423.251220703125  loc loss 24.188966751098633\n",
      "cls loss 489.45977783203125  loc loss 29.886871337890625\n",
      "cls loss 639.0667724609375  loc loss 40.179866790771484\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1., 35., 27., 27.,  1., 27.,  1.])\n",
      "cls loss 865.4927978515625  loc loss 59.86174011230469\n",
      "cls loss 411.652587890625  loc loss 29.53083038330078\n",
      "cls loss 502.4482727050781  loc loss 37.178985595703125\n",
      "cls loss 468.1212158203125  loc loss 41.40955352783203\n",
      "cls loss 426.8406982421875  loc loss 33.055477142333984\n",
      "cls loss 463.4111022949219  loc loss 37.70059585571289\n",
      "cls loss 461.850341796875  loc loss 37.72817611694336\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  2.,  2.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  2.,  2.])\n",
      "cls loss 296.91876220703125  loc loss 11.311273574829102\n",
      "cls loss 726.455810546875  loc loss 46.17257308959961\n",
      "cls loss 524.7744140625  loc loss 25.63559341430664\n",
      "cls loss 821.2203369140625  loc loss 60.88791275024414\n",
      "cls loss 347.67657470703125  loc loss 21.305633544921875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 19., 19., 19., 16.])\n",
      "cls loss 363.4264831542969  loc loss 16.294418334960938\n",
      "cls loss 292.0406494140625  loc loss 13.517813682556152\n",
      "cls loss 440.75030517578125  loc loss 23.13871955871582\n",
      "cls loss 575.51513671875  loc loss 39.481327056884766\n",
      "cls loss 305.93988037109375  loc loss 21.844663619995117\n",
      "cls loss 654.480224609375  loc loss 49.3522834777832\n",
      "cls loss 471.4586181640625  loc loss 33.84431076049805\n",
      "cls loss 529.2132568359375  loc loss 34.59450912475586\n",
      "cls loss 647.3675537109375  loc loss 46.69139862060547\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 743.0748901367188  loc loss 32.11639404296875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 915.8416748046875  loc loss 80.60025787353516\n",
      "cls loss 1124.9453125  loc loss 111.47186279296875\n",
      "cls loss 588.4793701171875  loc loss 41.231689453125\n",
      "cls loss 531.0245971679688  loc loss 36.148590087890625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3.,  3.,  3.,  3.,  3., 10.])\n",
      "cls loss 311.17095947265625  loc loss 17.75226402282715\n",
      "cls loss 563.2393798828125  loc loss 30.8624210357666\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 1., 1., 1., 3., 3., 3., 3.])\n",
      "cls loss 448.6813659667969  loc loss 30.33684539794922\n",
      "cls loss 824.0974731445312  loc loss 57.446998596191406\n",
      "cls loss 659.670654296875  loc loss 45.4175910949707\n",
      "cls loss 459.85443115234375  loc loss 26.492162704467773\n",
      "cls loss 664.8723754882812  loc loss 50.17890930175781\n",
      "cls loss 428.5466003417969  loc loss 32.15740203857422\n",
      "cls loss 686.9903564453125  loc loss 48.360599517822266\n",
      "cls loss 488.8558654785156  loc loss 46.119773864746094\n",
      "cls loss 510.6229248046875  loc loss 34.30229187011719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 1051.653076171875  loc loss 88.5927734375\n",
      "cls loss 694.6331787109375  loc loss 50.062007904052734\n",
      "cls loss 478.59063720703125  loc loss 23.873783111572266\n",
      "cls loss 328.85986328125  loc loss 14.432624816894531\n",
      "cls loss 366.83026123046875  loc loss 18.370166778564453\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3., 10., 10., 10., 10., 10., 10., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10., 10., 10., 10., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 11., 10., 10., 10., 10., 10.,  3.,  3.,  3.,  3.,  3.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 11., 10., 10., 10., 10., 10.,  3.,  3.,  3.,  3.,  3.])\n",
      "cls loss 371.58673095703125  loc loss 16.843461990356445\n",
      "cls loss 427.76806640625  loc loss 21.332866668701172\n",
      "cls loss 356.3698425292969  loc loss 22.874521255493164\n",
      "cls loss 354.47906494140625  loc loss 15.660940170288086\n",
      "cls loss 411.1650390625  loc loss 33.74219512939453\n",
      "cls loss 340.4517822265625  loc loss 13.609228134155273\n",
      "cls loss 631.167724609375  loc loss 43.111690521240234\n",
      "cls loss 552.9303588867188  loc loss 39.95993423461914\n",
      "cls loss 839.1375732421875  loc loss 54.50714874267578\n",
      "cls loss 413.2720947265625  loc loss 31.71487045288086\n",
      "cls loss 748.1702880859375  loc loss 50.66852569580078\n",
      "cls loss 620.7192993164062  loc loss 41.64677047729492\n",
      "cls loss 568.3009033203125  loc loss 38.61793518066406\n",
      "cls loss 580.2474365234375  loc loss 42.71916198730469\n",
      "cls loss 796.15087890625  loc loss 52.99394607543945\n",
      "cls loss 780.055419921875  loc loss 47.68450927734375\n",
      "cls loss 371.4276123046875  loc loss 20.970840454101562\n",
      "cls loss 661.0970458984375  loc loss 51.049530029296875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 10.,  1., 18.])\n",
      "cls loss 328.82232666015625  loc loss 23.427501678466797\n",
      "cls loss 383.3081359863281  loc loss 16.885807037353516\n",
      "cls loss 660.551513671875  loc loss 34.8990592956543\n",
      "cls loss 945.9158935546875  loc loss 60.22747802734375\n",
      "cls loss 564.3538818359375  loc loss 40.162200927734375\n",
      "cls loss 808.0166015625  loc loss 46.00734329223633\n",
      "cls loss 563.484619140625  loc loss 38.26652908325195\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.,  1.,  1.])\n",
      "cls loss 710.4302978515625  loc loss 47.71430587768555\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1., 38.,  1.])\n",
      "cls loss 702.8583374023438  loc loss 39.34632873535156\n",
      "cls loss 891.1199340820312  loc loss 64.2549057006836\n",
      "cls loss 460.7496337890625  loc loss 33.44076919555664\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 619.6078491210938  loc loss 42.32961654663086\n",
      "cls loss 547.6788940429688  loc loss 34.63839340209961\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3., 10.,  8.,  3., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.])\n",
      "cls loss 653.5841674804688  loc loss 39.22091293334961\n",
      "cls loss 463.5657958984375  loc loss 29.079391479492188\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3.,  3., 11.,  3., 10., 10.,  3.,  3., 10.])\n",
      "cls loss 549.932861328125  loc loss 26.277307510375977\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3., 10., 10., 10.])\n",
      "cls loss 521.5758056640625  loc loss 35.65609359741211\n",
      "cls loss 459.6964111328125  loc loss 25.175048828125\n",
      "cls loss 536.5432739257812  loc loss 38.38979721069336\n",
      "cls loss 839.060791015625  loc loss 51.378623962402344\n",
      "cls loss 540.4861450195312  loc loss 35.60155487060547\n",
      "cls loss 381.9754638671875  loc loss 34.26776885986328\n",
      "cls loss 503.5625  loc loss 35.28831100463867\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 9.,  9., 85., 85.])\n",
      "cls loss 436.7170104980469  loc loss 24.43741226196289\n",
      "cls loss 500.522705078125  loc loss 35.02867889404297\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 821.8560791015625  loc loss 60.5103645324707\n",
      "cls loss 712.0408325195312  loc loss 35.308536529541016\n",
      "cls loss 788.6670532226562  loc loss 56.22245407104492\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10., 10., 10., 10.])\n",
      "cls loss 492.66973876953125  loc loss 31.341466903686523\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([13.])\n",
      "cls loss 784.9193115234375  loc loss 61.94574737548828\n",
      "cls loss 287.72216796875  loc loss 15.748462677001953\n",
      "cls loss 363.89990234375  loc loss 18.93954849243164\n",
      "cls loss 490.3446960449219  loc loss 26.1436710357666\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19.,  1.,  1.,  1., 19., 19.])\n",
      "cls loss 498.03564453125  loc loss 32.55281066894531\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 380.42169189453125  loc loss 30.112871170043945\n",
      "cls loss 556.7252197265625  loc loss 41.05343246459961\n",
      "cls loss 414.33013916015625  loc loss 24.65203094482422\n",
      "cls loss 609.9535522460938  loc loss 36.33562088012695\n",
      "cls loss 655.2991943359375  loc loss 50.81745147705078\n",
      "cls loss 536.069091796875  loc loss 29.5933895111084\n",
      "cls loss 745.64599609375  loc loss 55.50263977050781\n",
      "cls loss 318.0921936035156  loc loss 14.6763334274292\n",
      "cls loss 555.8875732421875  loc loss 34.94404602050781\n",
      "cls loss 441.7217102050781  loc loss 22.470367431640625\n",
      "cls loss 465.7584228515625  loc loss 25.32114028930664\n",
      "cls loss 586.5403442382812  loc loss 39.07793045043945\n",
      "cls loss 553.455078125  loc loss 30.639728546142578\n",
      "cls loss 788.7196044921875  loc loss 50.38774108886719\n",
      "cls loss 501.916015625  loc loss 34.37782287597656\n",
      "cls loss 635.1629638671875  loc loss 43.78291702270508\n",
      "cls loss 950.500244140625  loc loss 59.090370178222656\n",
      "cls loss 505.5845947265625  loc loss 39.077552795410156\n",
      "cls loss 589.0615234375  loc loss 35.38131332397461\n",
      "cls loss 687.09130859375  loc loss 52.86902618408203\n",
      "cls loss 739.36669921875  loc loss 53.11747360229492\n",
      "cls loss 930.614501953125  loc loss 50.597557067871094\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 5.])\n",
      "cls loss 284.4498291015625  loc loss 10.947734832763672\n",
      "cls loss 355.89935302734375  loc loss 16.093021392822266\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 13.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 6., 8., 8.])\n",
      "cls loss 300.169189453125  loc loss 15.570469856262207\n",
      "cls loss 369.507080078125  loc loss 20.171119689941406\n",
      "cls loss 723.4872436523438  loc loss 50.08761978149414\n",
      "cls loss 321.2486572265625  loc loss 15.936944961547852\n",
      "cls loss 552.1712036132812  loc loss 43.25294494628906\n",
      "cls loss 901.2953491210938  loc loss 62.62120056152344\n",
      "cls loss 526.3222045898438  loc loss 40.63849639892578\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([42., 42.,  1.,  1.,  1.,  1.,  1.,  1.,  1., 42., 42.])\n",
      "cls loss 604.925537109375  loc loss 34.447479248046875\n",
      "cls loss 759.3922119140625  loc loss 59.75656509399414\n",
      "cls loss 633.79443359375  loc loss 51.242252349853516\n",
      "cls loss 457.365966796875  loc loss 28.226118087768555\n",
      "cls loss 604.7453002929688  loc loss 36.58870315551758\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 802.8697509765625  loc loss 54.05280303955078\n",
      "cls loss 648.5933837890625  loc loss 46.001773834228516\n",
      "cls loss 419.49774169921875  loc loss 25.16219711303711\n",
      "cls loss 349.8040771484375  loc loss 19.36507225036621\n",
      "cls loss 502.96893310546875  loc loss 29.647193908691406\n",
      "cls loss 667.6722412109375  loc loss 43.68745803833008\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15.])\n",
      "cls loss 328.44256591796875  loc loss 15.255654335021973\n",
      "cls loss 533.254638671875  loc loss 35.731929779052734\n",
      "cls loss 483.0987548828125  loc loss 32.24236297607422\n",
      "cls loss 856.0865478515625  loc loss 59.577842712402344\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19.,  7.])\n",
      "cls loss 485.0907897949219  loc loss 27.92234992980957\n",
      "cls loss 942.9663696289062  loc loss 60.07352828979492\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 787.681884765625  loc loss 41.45273971557617\n",
      "cls loss 641.298583984375  loc loss 48.39528274536133\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([38., 38.,  1., 18.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1., 18., 18.,  1.])\n",
      "cls loss 521.7683715820312  loc loss 25.899337768554688\n",
      "cls loss 473.1182861328125  loc loss 23.692153930664062\n",
      "cls loss 844.66357421875  loc loss 64.71543884277344\n",
      "cls loss 670.0877685546875  loc loss 37.09369659423828\n",
      "cls loss 621.9078369140625  loc loss 31.706012725830078\n",
      "cls loss 349.4728698730469  loc loss 27.354400634765625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.])\n",
      "cls loss 286.1671142578125  loc loss 9.86085033416748\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([32.])\n",
      "cls loss 546.2193603515625  loc loss 28.68661117553711\n",
      "cls loss 470.0579528808594  loc loss 34.0579719543457\n",
      "cls loss 620.077880859375  loc loss 49.97675323486328\n",
      "cls loss 556.245361328125  loc loss 37.32490158081055\n",
      "cls loss 457.2483825683594  loc loss 29.725120544433594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 748.2218017578125  loc loss 47.298423767089844\n",
      "cls loss 800.6810302734375  loc loss 55.6072883605957\n",
      "cls loss 640.1153564453125  loc loss 42.54072189331055\n",
      "cls loss 528.1520385742188  loc loss 30.860864639282227\n",
      "cls loss 820.2196655273438  loc loss 52.34723663330078\n",
      "cls loss 531.5087890625  loc loss 27.594463348388672\n",
      "cls loss 841.1048583984375  loc loss 65.26292419433594\n",
      "cls loss 615.3124389648438  loc loss 35.17130661010742\n",
      "cls loss 511.3804626464844  loc loss 37.42415237426758\n",
      "cls loss 382.6279296875  loc loss 19.83123779296875\n",
      "cls loss 441.07196044921875  loc loss 27.431468963623047\n",
      "cls loss 643.7059326171875  loc loss 42.957969665527344\n",
      "cls loss 658.0344848632812  loc loss 48.34137725830078\n",
      "cls loss 391.7684020996094  loc loss 26.25668716430664\n",
      "cls loss 719.8568725585938  loc loss 48.504432678222656\n",
      "cls loss 843.0302734375  loc loss 52.21064758300781\n",
      "cls loss 320.24664306640625  loc loss 21.965221405029297\n",
      "cls loss 816.027099609375  loc loss 55.642852783203125\n",
      "cls loss 582.0509033203125  loc loss 45.450897216796875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 799.0706787109375  loc loss 62.14118194580078\n",
      "cls loss 404.7479248046875  loc loss 15.147636413574219\n",
      "cls loss 603.5179443359375  loc loss 32.57233810424805\n",
      "cls loss 587.1278686523438  loc loss 40.028594970703125\n",
      "cls loss 476.52716064453125  loc loss 27.435495376586914\n",
      "cls loss 295.47296142578125  loc loss 15.660602569580078\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 9., 9., 1., 9., 9., 9., 9., 1., 9.])\n",
      "cls loss 1006.333251953125  loc loss 87.01072692871094\n",
      "cls loss 593.82666015625  loc loss 31.97829818725586\n",
      "cls loss 864.0083618164062  loc loss 73.70187377929688\n",
      "cls loss 366.73797607421875  loc loss 25.895851135253906\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 42., 42.])\n",
      "cls loss 645.9381103515625  loc loss 47.74379348754883\n",
      "cls loss 691.3717651367188  loc loss 50.41476058959961\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  2.,  1.,  1.,  1., 38.,\n",
      "         1.,  1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 38., 38., 38.,  1., 38., 38., 38.,  1.,  1., 38.,  1.,\n",
      "         1.])\n",
      "cls loss 423.3681640625  loc loss 30.177322387695312\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  8.,  8.])\n",
      "cls loss 980.3744506835938  loc loss 64.60990142822266\n",
      "cls loss 980.0379638671875  loc loss 69.52645874023438\n",
      "cls loss 384.69073486328125  loc loss 22.1418514251709\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([4., 1., 1., 4.])\n",
      "cls loss 547.7647094726562  loc loss 38.083106994628906\n",
      "cls loss 656.2299194335938  loc loss 41.065853118896484\n",
      "cls loss 295.4819641113281  loc loss 14.083669662475586\n",
      "cls loss 403.4024353027344  loc loss 25.088594436645508\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([51.,  1.])\n",
      "cls loss 293.4990539550781  loc loss 12.332453727722168\n",
      "cls loss 387.0288391113281  loc loss 22.253807067871094\n",
      "cls loss 678.1790161132812  loc loss 39.591636657714844\n",
      "cls loss 737.2977294921875  loc loss 55.25979232788086\n",
      "cls loss 1005.5961303710938  loc loss 55.43309020996094\n",
      "cls loss 1243.0892333984375  loc loss 82.84070587158203\n",
      "cls loss 540.0471801757812  loc loss 32.89582061767578\n",
      "cls loss 759.4016723632812  loc loss 54.44612503051758\n",
      "cls loss 799.5734252929688  loc loss 58.08481979370117\n",
      "cls loss 633.7176513671875  loc loss 36.51790237426758\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  3.,  1.,  1.,  1.,  3.,  1.,  1.,\n",
      "         1.,  1.,  1.])\n",
      "cls loss 652.6019897460938  loc loss 32.14495849609375\n",
      "cls loss 747.2235107421875  loc loss 38.40909194946289\n",
      "cls loss 671.0118408203125  loc loss 35.492958068847656\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "cls loss 552.9523315429688  loc loss 33.086124420166016\n",
      "cls loss 327.1640625  loc loss 26.744234085083008\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3.])\n",
      "cls loss 283.073486328125  loc loss 13.42104721069336\n",
      "cls loss 495.2419128417969  loc loss 34.172637939453125\n",
      "cls loss 396.0218505859375  loc loss 30.6601505279541\n",
      "cls loss 708.1742553710938  loc loss 48.657047271728516\n",
      "cls loss 488.845947265625  loc loss 24.981433868408203\n",
      "cls loss 393.21087646484375  loc loss 27.73404312133789\n",
      "cls loss 1189.8800048828125  loc loss 80.14375305175781\n",
      "cls loss 518.9929809570312  loc loss 39.2969856262207\n",
      "cls loss 375.36309814453125  loc loss 29.65340805053711\n",
      "cls loss 507.48272705078125  loc loss 29.4426326751709\n",
      "cls loss 449.9602966308594  loc loss 32.594730377197266\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 821.3633422851562  loc loss 55.30490493774414\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  9., 64., 64., 64., 64., 64., 64., 64., 64., 64.,  9.,  9.,  9.,\n",
      "         9.])\n",
      "cls loss 462.5195007324219  loc loss 22.871055603027344\n",
      "cls loss 1027.846435546875  loc loss 83.6463623046875\n",
      "cls loss 535.1416015625  loc loss 36.320159912109375\n",
      "cls loss 704.646728515625  loc loss 51.14960861206055\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.,  3.,  3.])\n",
      "cls loss 457.76531982421875  loc loss 27.500255584716797\n",
      "cls loss 505.9887390136719  loc loss 33.28023910522461\n",
      "cls loss 494.691650390625  loc loss 36.54425048828125\n",
      "cls loss 540.3201904296875  loc loss 39.08403778076172\n",
      "cls loss 529.755615234375  loc loss 43.74994659423828\n",
      "cls loss 532.5048828125  loc loss 41.02762222290039\n",
      "cls loss 517.0960693359375  loc loss 41.26889419555664\n",
      "cls loss 550.8567504882812  loc loss 34.15494918823242\n",
      "cls loss 674.769775390625  loc loss 47.513038635253906\n",
      "cls loss 584.93798828125  loc loss 33.1089973449707\n",
      "cls loss 472.01434326171875  loc loss 20.81586265563965\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21.])\n",
      "cls loss 345.02996826171875  loc loss 19.280460357666016\n",
      "cls loss 464.2274475097656  loc loss 39.78422546386719\n",
      "cls loss 679.4600830078125  loc loss 49.27619552612305\n",
      "cls loss 426.08367919921875  loc loss 24.179872512817383\n",
      "cls loss 582.230224609375  loc loss 35.48993682861328\n",
      "cls loss 1047.3526611328125  loc loss 58.18796920776367\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 42., 42.,  1.,  1.])\n",
      "cls loss 528.2969970703125  loc loss 34.09615707397461\n",
      "cls loss 347.9571838378906  loc loss 25.951669692993164\n",
      "cls loss 494.2108459472656  loc loss 38.05725860595703\n",
      "cls loss 700.5296630859375  loc loss 57.228187561035156\n",
      "cls loss 450.36260986328125  loc loss 29.5455265045166\n",
      "cls loss 645.2726440429688  loc loss 50.0829963684082\n",
      "cls loss 623.1465454101562  loc loss 47.657737731933594\n",
      "cls loss 675.9600830078125  loc loss 39.88811111450195\n",
      "cls loss 524.5902709960938  loc loss 32.95809555053711\n",
      "cls loss 482.22265625  loc loss 29.510414123535156\n",
      "cls loss 384.919677734375  loc loss 16.246124267578125\n",
      "cls loss 477.6009521484375  loc loss 32.72890853881836\n",
      "cls loss 714.7313842773438  loc loss 58.353111267089844\n",
      "cls loss 574.5255737304688  loc loss 37.07568359375\n",
      "cls loss 551.7904663085938  loc loss 41.41763687133789\n",
      "cls loss 609.4254150390625  loc loss 35.851806640625\n",
      "cls loss 884.3989868164062  loc loss 60.747337341308594\n",
      "cls loss 629.76953125  loc loss 48.76856994628906\n",
      "cls loss 741.7821655273438  loc loss 42.52666473388672\n",
      "cls loss 429.73004150390625  loc loss 21.897693634033203\n",
      "cls loss 610.1380004882812  loc loss 40.102439880371094\n",
      "cls loss 568.078369140625  loc loss 35.85044860839844\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 5., 5., 5., 5., 5., 5.])\n",
      "cls loss 408.8802185058594  loc loss 27.84933853149414\n",
      "cls loss 484.477294921875  loc loss 28.841888427734375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([13.])\n",
      "cls loss 329.8904724121094  loc loss 21.39179039001465\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([44., 10.,  1.,  1.,  1.])\n",
      "cls loss 348.9833984375  loc loss 21.34157943725586\n",
      "cls loss 657.659423828125  loc loss 33.9366340637207\n",
      "cls loss 529.7392578125  loc loss 30.474536895751953\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19., 19., 19., 19., 19., 19., 19.])\n",
      "cls loss 672.6385498046875  loc loss 36.454978942871094\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([56.])\n",
      "cls loss 1156.261474609375  loc loss 73.14649963378906\n",
      "cls loss 666.92236328125  loc loss 53.84857177734375\n",
      "cls loss 864.2953491210938  loc loss 62.60826110839844\n",
      "cls loss 869.309326171875  loc loss 66.98892211914062\n",
      "cls loss 529.8864135742188  loc loss 31.121089935302734\n",
      "cls loss 840.1651611328125  loc loss 61.754695892333984\n",
      "cls loss 497.6217041015625  loc loss 31.50092887878418\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 36.])\n",
      "cls loss 594.3843383789062  loc loss 33.70956802368164\n",
      "cls loss 529.2268676757812  loc loss 37.843421936035156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 530.9403076171875  loc loss 32.072235107421875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5.])\n",
      "cls loss 616.8985595703125  loc loss 38.28639221191406\n",
      "cls loss 341.95245361328125  loc loss 18.746109008789062\n",
      "cls loss 767.1990966796875  loc loss 43.53550338745117\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "cls loss 673.9539794921875  loc loss 45.911380767822266\n",
      "cls loss 687.721923828125  loc loss 44.713706970214844\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 617.0810546875  loc loss 44.833648681640625\n",
      "cls loss 739.7810668945312  loc loss 52.69609451293945\n",
      "cls loss 603.09326171875  loc loss 56.53944396972656\n",
      "cls loss 433.54827880859375  loc loss 30.797588348388672\n",
      "cls loss 548.1031494140625  loc loss 39.74823760986328\n",
      "cls loss 552.3480224609375  loc loss 35.95038986206055\n",
      "cls loss 847.2308349609375  loc loss 50.171871185302734\n",
      "cls loss 395.0901184082031  loc loss 20.082721710205078\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 11., 15., 10., 10., 10., 10., 10.])\n",
      "cls loss 904.22802734375  loc loss 59.413509368896484\n",
      "cls loss 497.46533203125  loc loss 34.72597122192383\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3.])\n",
      "cls loss 557.3213500976562  loc loss 36.88813400268555\n",
      "cls loss 499.9510498046875  loc loss 28.88401222229004\n",
      "cls loss 542.5510864257812  loc loss 27.385343551635742\n",
      "cls loss 691.7551879882812  loc loss 34.58485412597656\n",
      "cls loss 385.08892822265625  loc loss 18.1524715423584\n",
      "cls loss 534.4805908203125  loc loss 35.11358642578125\n",
      "cls loss 592.7236938476562  loc loss 46.77589797973633\n",
      "cls loss 509.0984191894531  loc loss 38.756011962890625\n",
      "cls loss 1181.210693359375  loc loss 89.46588134765625\n",
      "cls loss 844.8883666992188  loc loss 56.06186294555664\n",
      "cls loss 540.9901123046875  loc loss 39.968177795410156\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  9.,  9.,  9.,  6.,  6., 85., 85.,  8.,  1.,  1.,  1.,  1.,\n",
      "         6.,  6.])\n",
      "cls loss 386.67401123046875  loc loss 28.286550521850586\n",
      "cls loss 889.501953125  loc loss 63.085750579833984\n",
      "cls loss 1042.792236328125  loc loss 67.4954605102539\n",
      "cls loss 723.332275390625  loc loss 49.35566711425781\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10.,  3.,  3., 10.])\n",
      "cls loss 483.45233154296875  loc loss 27.724546432495117\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([7.])\n",
      "cls loss 605.942138671875  loc loss 42.92839050292969\n",
      "cls loss 622.22314453125  loc loss 38.19771957397461\n",
      "cls loss 548.8204956054688  loc loss 44.840492248535156\n",
      "cls loss 772.6591796875  loc loss 64.25044250488281\n",
      "cls loss 576.4229736328125  loc loss 39.1635856628418\n",
      "cls loss 776.52197265625  loc loss 51.66712951660156\n",
      "cls loss 960.40234375  loc loss 59.18376922607422\n",
      "cls loss 571.8917236328125  loc loss 40.52814483642578\n",
      "cls loss 618.5734252929688  loc loss 43.44713592529297\n",
      "cls loss 524.90771484375  loc loss 39.412498474121094\n",
      "cls loss 732.947998046875  loc loss 60.87432861328125\n",
      "cls loss 603.1829223632812  loc loss 39.263919830322266\n",
      "cls loss 481.16558837890625  loc loss 28.67456817626953\n",
      "cls loss 734.3661499023438  loc loss 56.09025573730469\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([62.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([62.])\n",
      "cls loss 331.8236083984375  loc loss 17.913843154907227\n",
      "cls loss 588.0716552734375  loc loss 41.97842788696289\n",
      "cls loss 572.59619140625  loc loss 38.170894622802734\n",
      "cls loss 404.39471435546875  loc loss 17.61410140991211\n",
      "cls loss 724.6729736328125  loc loss 49.764434814453125\n",
      "cls loss 723.0311279296875  loc loss 43.093482971191406\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([28.])\n",
      "cls loss 798.73046875  loc loss 44.70499801635742\n",
      "cls loss 710.165771484375  loc loss 44.58045959472656\n",
      "cls loss 697.7012329101562  loc loss 45.22477722167969\n",
      "cls loss 711.09716796875  loc loss 47.80707550048828\n",
      "cls loss 979.6063232421875  loc loss 67.05555725097656\n",
      "cls loss 548.9736328125  loc loss 36.050899505615234\n",
      "cls loss 678.9425048828125  loc loss 42.491580963134766\n",
      "cls loss 604.2989501953125  loc loss 51.148170471191406\n",
      "cls loss 965.4238891601562  loc loss 75.71990203857422\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([81.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 674.1881103515625  loc loss 28.467287063598633\n",
      "cls loss 517.343994140625  loc loss 26.306121826171875\n",
      "cls loss 442.42486572265625  loc loss 27.971662521362305\n",
      "cls loss 373.7494201660156  loc loss 14.87954044342041\n",
      "cls loss 417.2044677734375  loc loss 27.194644927978516\n",
      "cls loss 447.8056640625  loc loss 28.235876083374023\n",
      "cls loss 521.3984375  loc loss 33.12062072753906\n",
      "cls loss 671.84033203125  loc loss 54.870826721191406\n",
      "cls loss 758.7701416015625  loc loss 52.022762298583984\n",
      "cls loss 1437.9676513671875  loc loss 99.60462951660156\n",
      "cls loss 590.5928955078125  loc loss 30.752853393554688\n",
      "cls loss 699.729248046875  loc loss 48.21385192871094\n",
      "cls loss 494.5246887207031  loc loss 30.749940872192383\n",
      "cls loss 646.1563720703125  loc loss 36.56660079956055\n",
      "cls loss 585.5938720703125  loc loss 33.473960876464844\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([44., 44.])\n",
      "cls loss 521.4203491210938  loc loss 26.444713592529297\n",
      "cls loss 513.9012451171875  loc loss 37.993167877197266\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15.])\n",
      "cls loss 618.4531860351562  loc loss 31.851978302001953\n",
      "cls loss 298.2689514160156  loc loss 17.463876724243164\n",
      "cls loss 610.2697143554688  loc loss 36.36374282836914\n",
      "cls loss 339.12042236328125  loc loss 21.945363998413086\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([1., 3., 3.])\n",
      "cls loss 380.41949462890625  loc loss 29.52049446105957\n",
      "cls loss 321.19732666015625  loc loss 13.90518856048584\n",
      "cls loss 583.7327880859375  loc loss 33.24433135986328\n",
      "cls loss 611.9852294921875  loc loss 36.399383544921875\n",
      "cls loss 550.0362548828125  loc loss 36.20648193359375\n",
      "cls loss 575.4315795898438  loc loss 32.80045700073242\n",
      "cls loss 461.9879150390625  loc loss 35.37037658691406\n",
      "cls loss 615.4619140625  loc loss 42.65424728393555\n",
      "cls loss 491.34912109375  loc loss 32.549678802490234\n",
      "cls loss 598.9990844726562  loc loss 42.95823287963867\n",
      "cls loss 381.5802307128906  loc loss 24.386629104614258\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 706.6639404296875  loc loss 44.3167724609375\n",
      "cls loss 819.7429809570312  loc loss 41.90822219848633\n",
      "cls loss 730.2115478515625  loc loss 51.209800720214844\n",
      "cls loss 719.0384521484375  loc loss 54.093692779541016\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10., 10., 10.,  1.,  1.,  1.,  1.,  1.,  1.,  8.,  8.,\n",
      "         1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10., 10., 10.,  1.,  1.,  1.,  1.,  1.,  1.,  8.,  8.,\n",
      "         1.])\n",
      "cls loss 698.4627685546875  loc loss 33.88874435424805\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 3., 3., 3.])\n",
      "cls loss 581.8333129882812  loc loss 37.00128936767578\n",
      "cls loss 401.2138671875  loc loss 22.479961395263672\n",
      "cls loss 315.6746826171875  loc loss 16.034690856933594\n",
      "cls loss 543.9949951171875  loc loss 40.359745025634766\n",
      "cls loss 427.4519958496094  loc loss 22.731685638427734\n",
      "cls loss 469.7543029785156  loc loss 32.18951416015625\n",
      "cls loss 538.8400268554688  loc loss 38.01195526123047\n",
      "cls loss 752.9945068359375  loc loss 53.751800537109375\n",
      "cls loss 632.024658203125  loc loss 32.51436996459961\n",
      "cls loss 605.13134765625  loc loss 35.871307373046875\n",
      "cls loss 689.084228515625  loc loss 46.18522644042969\n",
      "cls loss 505.576416015625  loc loss 37.94810104370117\n",
      "cls loss 909.8406982421875  loc loss 67.77953338623047\n",
      "cls loss 475.92279052734375  loc loss 25.11509895324707\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 695.845458984375  loc loss 43.056636810302734\n",
      "cls loss 358.0404357910156  loc loss 15.808518409729004\n",
      "cls loss 865.5233764648438  loc loss 56.04678726196289\n",
      "cls loss 459.21142578125  loc loss 23.959468841552734\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 34.])\n",
      "cls loss 727.80908203125  loc loss 39.67656326293945\n",
      "cls loss 332.8428649902344  loc loss 22.498424530029297\n",
      "cls loss 627.866455078125  loc loss 43.103599548339844\n",
      "cls loss 224.06594848632812  loc loss 16.73870086669922\n",
      "cls loss 573.8651123046875  loc loss 37.49087905883789\n",
      "cls loss 553.7719116210938  loc loss 43.653656005859375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 38.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16., 16., 16.,  9.,  9.,  9., 16., 16., 16., 85.,  9.])\n",
      "cls loss 544.889404296875  loc loss 35.908668518066406\n",
      "cls loss 613.869384765625  loc loss 49.36333465576172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 852.9370727539062  loc loss 61.97121047973633\n",
      "cls loss 1214.6197509765625  loc loss 83.38743591308594\n",
      "cls loss 381.66156005859375  loc loss 19.540416717529297\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3., 10.,  8.,  8., 10., 10., 10.,  3.,  3., 14.])\n",
      "cls loss 467.3833923339844  loc loss 22.14681625366211\n",
      "cls loss 818.481201171875  loc loss 42.19760513305664\n",
      "cls loss 356.9427490234375  loc loss 13.277204513549805\n",
      "cls loss 526.8698120117188  loc loss 23.22434425354004\n",
      "cls loss 698.047607421875  loc loss 41.850189208984375\n",
      "cls loss 584.27978515625  loc loss 39.40544128417969\n",
      "cls loss 346.42279052734375  loc loss 18.028871536254883\n",
      "cls loss 385.61541748046875  loc loss 24.63337516784668\n",
      "cls loss 587.84765625  loc loss 39.29355239868164\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42., 42.,  1.])\n",
      "cls loss 560.4036254882812  loc loss 41.2574348449707\n",
      "cls loss 476.9701232910156  loc loss 28.87575340270996\n",
      "cls loss 640.9849853515625  loc loss 49.280826568603516\n",
      "cls loss 721.9996337890625  loc loss 48.7278938293457\n",
      "cls loss 514.8553466796875  loc loss 33.517704010009766\n",
      "cls loss 622.943603515625  loc loss 44.427711486816406\n",
      "cls loss 405.23162841796875  loc loss 26.851985931396484\n",
      "cls loss 432.6885070800781  loc loss 29.841686248779297\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20.])\n",
      "cls loss 344.8389892578125  loc loss 19.231653213500977\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([11.])\n",
      "cls loss 427.7794494628906  loc loss 22.672365188598633\n",
      "cls loss 305.13519287109375  loc loss 16.81854820251465\n",
      "cls loss 656.9068603515625  loc loss 52.491600036621094\n",
      "cls loss 311.5943298339844  loc loss 14.063910484313965\n",
      "cls loss 627.2620849609375  loc loss 36.06276321411133\n",
      "cls loss 345.7745361328125  loc loss 21.671255111694336\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 35., 27.])\n",
      "cls loss 586.6932373046875  loc loss 38.66399383544922\n",
      "cls loss 609.2032470703125  loc loss 48.38309097290039\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 454.74493408203125  loc loss 27.749616622924805\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([42.,  1.])\n",
      "cls loss 592.2960205078125  loc loss 42.21792984008789\n",
      "cls loss 533.9183959960938  loc loss 31.693021774291992\n",
      "cls loss 666.6185302734375  loc loss 38.552391052246094\n",
      "cls loss 764.9765625  loc loss 52.682350158691406\n",
      "cls loss 700.7533569335938  loc loss 44.529296875\n",
      "cls loss 474.7895812988281  loc loss 37.506309509277344\n",
      "cls loss 411.943359375  loc loss 32.63136672973633\n",
      "cls loss 275.6013488769531  loc loss 13.161044120788574\n",
      "cls loss 490.797607421875  loc loss 28.384431838989258\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 1., 1.])\n",
      "cls loss 476.84564208984375  loc loss 25.66189193725586\n",
      "cls loss 526.9154663085938  loc loss 36.546356201171875\n",
      "cls loss 534.4661865234375  loc loss 33.98846435546875\n",
      "cls loss 433.8822937011719  loc loss 31.77460479736328\n",
      "cls loss 515.620849609375  loc loss 31.37449836730957\n",
      "cls loss 547.7462158203125  loc loss 41.71186065673828\n",
      "cls loss 763.54248046875  loc loss 46.319618225097656\n",
      "cls loss 643.7064819335938  loc loss 51.210174560546875\n",
      "cls loss 612.5118408203125  loc loss 37.31660079956055\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 478.32171630859375  loc loss 34.01212692260742\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 563.6331787109375  loc loss 28.6794376373291\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([81.])\n",
      "cls loss 685.3115234375  loc loss 43.842525482177734\n",
      "cls loss 436.1319885253906  loc loss 29.303335189819336\n",
      "cls loss 304.2119140625  loc loss 18.958398818969727\n",
      "cls loss 480.4197082519531  loc loss 25.464759826660156\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3.,  1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 19.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 19.])\n",
      "cls loss 624.6400756835938  loc loss 43.64884567260742\n",
      "cls loss 369.331787109375  loc loss 18.502904891967773\n",
      "cls loss 385.62957763671875  loc loss 23.661211013793945\n",
      "cls loss 730.7972412109375  loc loss 53.88862609863281\n",
      "cls loss 379.8469543457031  loc loss 24.28219985961914\n",
      "cls loss 472.3222351074219  loc loss 33.403995513916016\n",
      "cls loss 572.5494995117188  loc loss 38.70512390136719\n",
      "cls loss 442.18603515625  loc loss 33.28352737426758\n",
      "cls loss 586.3350219726562  loc loss 35.50609588623047\n",
      "cls loss 656.2001953125  loc loss 46.529048919677734\n",
      "cls loss 777.2626342773438  loc loss 73.28722381591797\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 81.])\n",
      "cls loss 581.6238403320312  loc loss 31.86358642578125\n",
      "cls loss 489.6536560058594  loc loss 29.754770278930664\n",
      "cls loss 578.2567138671875  loc loss 31.299877166748047\n",
      "cls loss 426.9761962890625  loc loss 20.982261657714844\n",
      "cls loss 395.16571044921875  loc loss 24.674226760864258\n",
      "cls loss 455.22772216796875  loc loss 32.850494384765625\n",
      "cls loss 365.05181884765625  loc loss 25.368391036987305\n",
      "cls loss 289.8753356933594  loc loss 19.19503402709961\n",
      "cls loss 379.2128601074219  loc loss 26.44060707092285\n",
      "cls loss 539.6502685546875  loc loss 33.55801010131836\n",
      "cls loss 445.1415710449219  loc loss 35.12134552001953\n",
      "cls loss 466.87347412109375  loc loss 37.65483093261719\n",
      "cls loss 288.0738525390625  loc loss 21.640430450439453\n",
      "cls loss 950.3558349609375  loc loss 69.28343963623047\n",
      "cls loss 630.3104248046875  loc loss 42.709861755371094\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 528.1904296875  loc loss 28.851070404052734\n",
      "cls loss 571.214599609375  loc loss 39.182342529296875\n",
      "cls loss 481.68927001953125  loc loss 27.397380828857422\n",
      "cls loss 653.6285400390625  loc loss 42.58074188232422\n",
      "cls loss 646.0314331054688  loc loss 42.36210632324219\n",
      "cls loss 571.482177734375  loc loss 37.30491638183594\n",
      "cls loss 475.82568359375  loc loss 27.194299697875977\n",
      "cls loss 348.86407470703125  loc loss 21.79690933227539\n",
      "cls loss 524.705322265625  loc loss 33.28471755981445\n",
      "cls loss 544.0173950195312  loc loss 38.491703033447266\n",
      "cls loss 587.5111694335938  loc loss 34.25347900390625\n",
      "cls loss 737.8436279296875  loc loss 57.168819427490234\n",
      "cls loss 750.1793823242188  loc loss 59.251487731933594\n",
      "cls loss 541.2979736328125  loc loss 39.62031173706055\n",
      "cls loss 692.693603515625  loc loss 56.38290023803711\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1., 38., 47.,  1.,  1.,  1.,  1.,  1., 62.])\n",
      "cls loss 517.6691284179688  loc loss 27.00546646118164\n",
      "cls loss 631.3150024414062  loc loss 35.84012985229492\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 641.359619140625  loc loss 38.87901306152344\n",
      "cls loss 705.4258422851562  loc loss 52.33545684814453\n",
      "cls loss 492.0133972167969  loc loss 25.024028778076172\n",
      "cls loss 551.864013671875  loc loss 45.326927185058594\n",
      "cls loss 507.5504150390625  loc loss 31.78826332092285\n",
      "cls loss 315.5320739746094  loc loss 13.03176498413086\n",
      "cls loss 499.79962158203125  loc loss 28.724531173706055\n",
      "cls loss 412.54522705078125  loc loss 19.46126937866211\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1., 35.])\n",
      "cls loss 515.118408203125  loc loss 25.204334259033203\n",
      "cls loss 683.236572265625  loc loss 38.079586029052734\n",
      "cls loss 658.4287109375  loc loss 44.17768478393555\n",
      "cls loss 592.5455932617188  loc loss 49.95524597167969\n",
      "cls loss 478.86798095703125  loc loss 39.17962646484375\n",
      "cls loss 622.6846923828125  loc loss 47.32175064086914\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 357.44635009765625  loc loss 21.05524444580078\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 533.87744140625  loc loss 25.916534423828125\n",
      "cls loss 839.1729125976562  loc loss 45.27313232421875\n",
      "cls loss 1025.093994140625  loc loss 76.85234069824219\n",
      "cls loss 525.0902099609375  loc loss 27.256954193115234\n",
      "cls loss 455.80645751953125  loc loss 28.877038955688477\n",
      "cls loss 465.1968078613281  loc loss 26.744937896728516\n",
      "cls loss 495.6307067871094  loc loss 35.38783264160156\n",
      "cls loss 463.2435302734375  loc loss 19.70151710510254\n",
      "cls loss 765.89013671875  loc loss 55.33051681518555\n",
      "cls loss 621.9051513671875  loc loss 38.87709045410156\n",
      "cls loss 356.7662353515625  loc loss 22.03519630432129\n",
      "cls loss 621.46630859375  loc loss 34.58567810058594\n",
      "cls loss 735.703857421875  loc loss 58.960968017578125\n",
      "cls loss 600.5374755859375  loc loss 38.8723258972168\n",
      "cls loss 549.660888671875  loc loss 29.766685485839844\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.])\n",
      "cls loss 501.6790771484375  loc loss 37.22641372680664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 448.1105041503906  loc loss 35.84171676635742\n",
      "cls loss 641.2896118164062  loc loss 43.34843444824219\n",
      "cls loss 933.7975463867188  loc loss 77.2222900390625\n",
      "cls loss 435.3385925292969  loc loss 20.636154174804688\n",
      "cls loss 545.045654296875  loc loss 34.2974739074707\n",
      "cls loss 451.5640869140625  loc loss 25.28257179260254\n",
      "cls loss 486.02337646484375  loc loss 29.72791862487793\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 21., 21., 21.])\n",
      "cls loss 522.91162109375  loc loss 30.4681339263916\n",
      "cls loss 497.82073974609375  loc loss 22.808326721191406\n",
      "cls loss 507.8807373046875  loc loss 34.06218719482422\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 35.])\n",
      "cls loss 691.7702026367188  loc loss 45.601844787597656\n",
      "cls loss 248.858642578125  loc loss 13.792238235473633\n",
      "cls loss 386.9010009765625  loc loss 26.814910888671875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 390.8533935546875  loc loss 18.857421875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 38., 38.,  9., 38.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1.,  1.])\n",
      "cls loss 435.81207275390625  loc loss 30.605806350708008\n",
      "cls loss 701.8408813476562  loc loss 48.373634338378906\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 2.,  1., 77., 31., 10., 10.,  1.,  4., 10.])\n",
      "cls loss 379.0679626464844  loc loss 18.408889770507812\n",
      "cls loss 680.2950439453125  loc loss 42.95189666748047\n",
      "cls loss 1356.997802734375  loc loss 84.43698120117188\n",
      "cls loss 452.25885009765625  loc loss 28.379608154296875\n",
      "cls loss 608.2545776367188  loc loss 47.4201545715332\n",
      "cls loss 452.50811767578125  loc loss 26.07770538330078\n",
      "cls loss 465.56427001953125  loc loss 23.08612823486328\n",
      "cls loss 714.829345703125  loc loss 30.990734100341797\n",
      "cls loss 678.932861328125  loc loss 36.217124938964844\n",
      "cls loss 583.307861328125  loc loss 40.69939041137695\n",
      "cls loss 445.54071044921875  loc loss 22.34778594970703\n",
      "cls loss 495.22564697265625  loc loss 25.55133628845215\n",
      "cls loss 895.1826171875  loc loss 56.69968795776367\n",
      "cls loss 758.9944458007812  loc loss 48.41500473022461\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1., 42., 42., 42., 42., 42., 42.,  1.,\n",
      "         1.,  1.,  1., 42.,  1.,  1., 42.,  1.])\n",
      "cls loss 430.6014404296875  loc loss 29.832979202270508\n",
      "cls loss 660.152587890625  loc loss 41.54904556274414\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.])\n",
      "cls loss 282.26300048828125  loc loss 18.3139705657959\n",
      "cls loss 631.3991088867188  loc loss 43.32490539550781\n",
      "cls loss 514.1107788085938  loc loss 36.88583755493164\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([11.])\n",
      "cls loss 316.3714904785156  loc loss 18.414569854736328\n",
      "cls loss 414.4462890625  loc loss 18.844892501831055\n",
      "cls loss 432.293701171875  loc loss 19.386680603027344\n",
      "cls loss 625.2341918945312  loc loss 41.51383972167969\n",
      "cls loss 598.9932861328125  loc loss 32.04581832885742\n",
      "cls loss 556.7027587890625  loc loss 39.13391876220703\n",
      "cls loss 823.0267333984375  loc loss 44.06858825683594\n",
      "cls loss 432.1466979980469  loc loss 25.960012435913086\n",
      "cls loss 789.3099975585938  loc loss 59.58961486816406\n",
      "cls loss 423.6865234375  loc loss 26.832748413085938\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 378.95159912109375  loc loss 27.411500930786133\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1., 38., 38., 42.])\n",
      "cls loss 485.9410400390625  loc loss 36.65793991088867\n",
      "cls loss 447.57568359375  loc loss 25.863210678100586\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 377.02862548828125  loc loss 28.785545349121094\n",
      "cls loss 905.8663940429688  loc loss 64.0046157836914\n",
      "cls loss 551.3355712890625  loc loss 37.85964584350586\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10.,  3.,  3.,  6.,  8.,  8.,  1.,  1.,  1., 10.])\n",
      "cls loss 479.23175048828125  loc loss 26.03304100036621\n",
      "cls loss 290.17279052734375  loc loss 11.043825149536133\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10.,  3.])\n",
      "cls loss 445.47235107421875  loc loss 25.157514572143555\n",
      "cls loss 282.6546630859375  loc loss 13.032097816467285\n",
      "cls loss 533.0859375  loc loss 39.91127014160156\n",
      "cls loss 602.8067626953125  loc loss 41.13532638549805\n",
      "cls loss 456.06622314453125  loc loss 28.05875015258789\n",
      "cls loss 327.9594421386719  loc loss 16.249160766601562\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 34.])\n",
      "cls loss 766.8383178710938  loc loss 48.195396423339844\n",
      "cls loss 803.5333251953125  loc loss 68.68650817871094\n",
      "cls loss 529.0111694335938  loc loss 41.52326965332031\n",
      "cls loss 394.65899658203125  loc loss 29.62906837463379\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.,  1.])\n",
      "cls loss 454.18994140625  loc loss 24.037521362304688\n",
      "cls loss 701.8331298828125  loc loss 56.447120666503906\n",
      "cls loss 1068.1397705078125  loc loss 69.92509460449219\n",
      "cls loss 888.1707763671875  loc loss 46.87584686279297\n",
      "cls loss 521.4893188476562  loc loss 28.67070770263672\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 642.3624267578125  loc loss 37.61497497558594\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10.])\n",
      "cls loss 394.706787109375  loc loss 21.63970184326172\n",
      "cls loss 571.3592529296875  loc loss 29.164480209350586\n",
      "cls loss 531.7587890625  loc loss 31.69940948486328\n",
      "cls loss 379.02685546875  loc loss 24.015499114990234\n",
      "cls loss 474.4643249511719  loc loss 33.62143325805664\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21.,\n",
      "        21.])\n",
      "cls loss 661.7727661132812  loc loss 38.02719497680664\n",
      "cls loss 521.4017333984375  loc loss 33.48365020751953\n",
      "cls loss 335.498046875  loc loss 15.855607986450195\n",
      "cls loss 701.9918212890625  loc loss 47.121273040771484\n",
      "cls loss 555.1327514648438  loc loss 38.30510330200195\n",
      "cls loss 384.9815673828125  loc loss 24.305809020996094\n",
      "cls loss 815.5493774414062  loc loss 55.753822326660156\n",
      "cls loss 986.5857543945312  loc loss 68.491943359375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15., 85.])\n",
      "cls loss 614.2706298828125  loc loss 40.256900787353516\n",
      "cls loss 624.51318359375  loc loss 46.95862579345703\n",
      "cls loss 630.3027954101562  loc loss 46.243778228759766\n",
      "cls loss 573.4041748046875  loc loss 32.489315032958984\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 8., 8.])\n",
      "cls loss 374.3057861328125  loc loss 19.517417907714844\n",
      "cls loss 392.40301513671875  loc loss 27.73007583618164\n",
      "cls loss 499.23223876953125  loc loss 30.58624267578125\n",
      "cls loss 414.23822021484375  loc loss 23.688922882080078\n",
      "cls loss 482.3199462890625  loc loss 29.26516342163086\n",
      "cls loss 629.1325073242188  loc loss 39.5335578918457\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1., 35., 27., 27.,  1., 27.,  1.])\n",
      "cls loss 835.7457885742188  loc loss 58.7518196105957\n",
      "cls loss 408.1231384277344  loc loss 28.74146270751953\n",
      "cls loss 493.87493896484375  loc loss 36.38631820678711\n",
      "cls loss 460.0408935546875  loc loss 40.71623229980469\n",
      "cls loss 418.528564453125  loc loss 32.45819854736328\n",
      "cls loss 456.9048156738281  loc loss 36.92615509033203\n",
      "cls loss 454.8699035644531  loc loss 36.997501373291016\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  2.,  2.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  2.,  2.])\n",
      "cls loss 289.74261474609375  loc loss 10.960744857788086\n",
      "cls loss 719.16162109375  loc loss 45.51913070678711\n",
      "cls loss 515.743408203125  loc loss 24.97648811340332\n",
      "cls loss 807.49169921875  loc loss 59.88700485229492\n",
      "cls loss 342.5689392089844  loc loss 20.7420654296875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 19., 19., 19., 16.])\n",
      "cls loss 358.1596374511719  loc loss 15.837555885314941\n",
      "cls loss 288.12701416015625  loc loss 13.058003425598145\n",
      "cls loss 435.2193298339844  loc loss 22.750492095947266\n",
      "cls loss 568.7185668945312  loc loss 38.800682067871094\n",
      "cls loss 303.1302185058594  loc loss 21.259763717651367\n",
      "cls loss 643.482177734375  loc loss 48.7703971862793\n",
      "cls loss 464.721923828125  loc loss 33.13172912597656\n",
      "cls loss 524.3148803710938  loc loss 33.922645568847656\n",
      "cls loss 644.6458740234375  loc loss 45.81648635864258\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 731.7261962890625  loc loss 31.475921630859375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 902.4276123046875  loc loss 79.45633697509766\n",
      "cls loss 1111.9088134765625  loc loss 109.57886505126953\n",
      "cls loss 583.01904296875  loc loss 40.24944305419922\n",
      "cls loss 524.5813598632812  loc loss 35.49415588378906\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3.,  3.,  3.,  3.,  3., 10.])\n",
      "cls loss 305.5855712890625  loc loss 17.62331771850586\n",
      "cls loss 556.485107421875  loc loss 30.152420043945312\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 1., 1., 1., 3., 3., 3., 3.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 440.62982177734375  loc loss 29.507444381713867\n",
      "cls loss 815.114013671875  loc loss 56.17763900756836\n",
      "cls loss 650.5455322265625  loc loss 44.455284118652344\n",
      "cls loss 448.1073303222656  loc loss 26.015769958496094\n",
      "cls loss 656.4442749023438  loc loss 48.86696243286133\n",
      "cls loss 422.7083740234375  loc loss 31.57265853881836\n",
      "cls loss 679.2410278320312  loc loss 47.42338943481445\n",
      "cls loss 479.53155517578125  loc loss 45.587440490722656\n",
      "cls loss 508.4987487792969  loc loss 33.50761795043945\n",
      "cls loss 1037.4378662109375  loc loss 87.10111999511719\n",
      "cls loss 686.5181884765625  loc loss 49.434783935546875\n",
      "cls loss 474.1448974609375  loc loss 23.449844360351562\n",
      "cls loss 324.74652099609375  loc loss 14.158149719238281\n",
      "cls loss 363.3919372558594  loc loss 17.898788452148438\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3., 10., 10., 10., 10., 10., 10., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10., 10., 10., 10., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 11., 10., 10., 10., 10., 10.,  3.,  3.,  3.,  3.,  3.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 11., 10., 10., 10., 10., 10.,  3.,  3.,  3.,  3.,  3.])\n",
      "cls loss 363.3957824707031  loc loss 16.43374252319336\n",
      "cls loss 420.45721435546875  loc loss 20.832731246948242\n",
      "cls loss 351.0927734375  loc loss 22.32761001586914\n",
      "cls loss 350.5846252441406  loc loss 15.451913833618164\n",
      "cls loss 404.5046691894531  loc loss 33.22118377685547\n",
      "cls loss 334.57147216796875  loc loss 13.27727222442627\n",
      "cls loss 620.1102294921875  loc loss 42.458824157714844\n",
      "cls loss 542.6233520507812  loc loss 39.09725570678711\n",
      "cls loss 828.201904296875  loc loss 53.406166076660156\n",
      "cls loss 407.47930908203125  loc loss 31.077505111694336\n",
      "cls loss 739.9153442382812  loc loss 49.764869689941406\n",
      "cls loss 613.2971801757812  loc loss 40.844085693359375\n",
      "cls loss 560.4716796875  loc loss 37.954933166503906\n",
      "cls loss 569.25146484375  loc loss 41.73225784301758\n",
      "cls loss 779.340576171875  loc loss 51.93254852294922\n",
      "cls loss 770.1402587890625  loc loss 46.95122146606445\n",
      "cls loss 366.0790100097656  loc loss 20.511911392211914\n",
      "cls loss 656.2825927734375  loc loss 50.12887954711914\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 10.,  1., 18.])\n",
      "cls loss 324.8150329589844  loc loss 22.899837493896484\n",
      "cls loss 380.328125  loc loss 16.589237213134766\n",
      "cls loss 653.5350341796875  loc loss 34.47688293457031\n",
      "cls loss 936.172607421875  loc loss 58.551910400390625\n",
      "cls loss 556.194091796875  loc loss 39.434532165527344\n",
      "cls loss 801.4229736328125  loc loss 44.96635055541992\n",
      "cls loss 559.6507568359375  loc loss 37.764984130859375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.,  1.,  1.])\n",
      "cls loss 702.2686767578125  loc loss 46.9151611328125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1., 38.,  1.])\n",
      "cls loss 692.0269775390625  loc loss 38.482215881347656\n",
      "cls loss 877.7344970703125  loc loss 63.09590148925781\n",
      "cls loss 457.22406005859375  loc loss 32.69148254394531\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 611.9576416015625  loc loss 41.4799690246582\n",
      "cls loss 541.4144897460938  loc loss 33.8571891784668\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3., 10.,  8.,  3., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.])\n",
      "cls loss 645.1929931640625  loc loss 38.03522872924805\n",
      "cls loss 455.75701904296875  loc loss 28.472278594970703\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3.,  3., 11.,  3., 10., 10.,  3.,  3., 10.])\n",
      "cls loss 542.1541748046875  loc loss 25.703886032104492\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3., 10., 10., 10.])\n",
      "cls loss 511.748046875  loc loss 34.68393325805664\n",
      "cls loss 455.890380859375  loc loss 24.723968505859375\n",
      "cls loss 529.1490478515625  loc loss 37.338722229003906\n",
      "cls loss 821.3666381835938  loc loss 50.0371208190918\n",
      "cls loss 533.4824829101562  loc loss 34.816322326660156\n",
      "cls loss 379.3750915527344  loc loss 33.63112258911133\n",
      "cls loss 501.4118957519531  loc loss 34.47157669067383\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 9.,  9., 85., 85.])\n",
      "cls loss 428.21551513671875  loc loss 23.942012786865234\n",
      "cls loss 493.1710510253906  loc loss 34.64016342163086\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 811.6466064453125  loc loss 59.11130142211914\n",
      "cls loss 706.1116333007812  loc loss 34.533119201660156\n",
      "cls loss 774.91845703125  loc loss 55.32414245605469\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10., 10., 10., 10.])\n",
      "cls loss 483.7042541503906  loc loss 30.734477996826172\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([13.])\n",
      "cls loss 773.6346435546875  loc loss 60.81385803222656\n",
      "cls loss 282.27392578125  loc loss 15.368000030517578\n",
      "cls loss 359.70037841796875  loc loss 18.572463989257812\n",
      "cls loss 482.7958679199219  loc loss 25.612613677978516\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19.,  1.,  1.,  1., 19., 19.])\n",
      "cls loss 486.98065185546875  loc loss 32.027183532714844\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 376.482421875  loc loss 29.21281623840332\n",
      "cls loss 546.7957763671875  loc loss 40.037437438964844\n",
      "cls loss 409.9759826660156  loc loss 24.11899185180664\n",
      "cls loss 602.765869140625  loc loss 35.23420333862305\n",
      "cls loss 645.39697265625  loc loss 49.827239990234375\n",
      "cls loss 529.0997314453125  loc loss 29.110811233520508\n",
      "cls loss 736.7177734375  loc loss 54.468955993652344\n",
      "cls loss 312.65350341796875  loc loss 14.316813468933105\n",
      "cls loss 549.35693359375  loc loss 34.35648727416992\n",
      "cls loss 437.08935546875  loc loss 22.045576095581055\n",
      "cls loss 461.74761962890625  loc loss 24.871166229248047\n",
      "cls loss 580.3607788085938  loc loss 37.97935104370117\n",
      "cls loss 546.2267456054688  loc loss 29.691516876220703\n",
      "cls loss 774.5479736328125  loc loss 49.56970977783203\n",
      "cls loss 496.76953125  loc loss 33.680816650390625\n",
      "cls loss 627.031982421875  loc loss 43.33406448364258\n",
      "cls loss 942.6349487304688  loc loss 58.11853790283203\n",
      "cls loss 496.48052978515625  loc loss 38.2626838684082\n",
      "cls loss 581.8795166015625  loc loss 34.65461349487305\n",
      "cls loss 674.0161743164062  loc loss 51.91210174560547\n",
      "cls loss 732.39794921875  loc loss 52.21471405029297\n",
      "cls loss 917.722900390625  loc loss 49.50103759765625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 5.])\n",
      "cls loss 280.225341796875  loc loss 10.812088012695312\n",
      "cls loss 350.27978515625  loc loss 15.867898941040039\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 13.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 6., 8., 8.])\n",
      "cls loss 293.66278076171875  loc loss 15.353008270263672\n",
      "cls loss 366.636962890625  loc loss 19.6820125579834\n",
      "cls loss 716.265380859375  loc loss 49.211669921875\n",
      "cls loss 318.02008056640625  loc loss 15.699396133422852\n",
      "cls loss 542.9186401367188  loc loss 42.584144592285156\n",
      "cls loss 881.7710571289062  loc loss 61.69879913330078\n",
      "cls loss 518.8310546875  loc loss 39.81105041503906\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([42., 42.,  1.,  1.,  1.,  1.,  1.,  1.,  1., 42., 42.])\n",
      "cls loss 597.6797485351562  loc loss 33.683876037597656\n",
      "cls loss 747.534423828125  loc loss 58.60736846923828\n",
      "cls loss 628.9581298828125  loc loss 50.167625427246094\n",
      "cls loss 450.40594482421875  loc loss 27.886119842529297\n",
      "cls loss 594.8648681640625  loc loss 35.67612075805664\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 788.7322387695312  loc loss 53.15504837036133\n",
      "cls loss 643.1292114257812  loc loss 45.18705368041992\n",
      "cls loss 412.63299560546875  loc loss 24.517532348632812\n",
      "cls loss 345.1912536621094  loc loss 19.17011260986328\n",
      "cls loss 495.6158447265625  loc loss 29.068984985351562\n",
      "cls loss 658.4144897460938  loc loss 42.61196517944336\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15.])\n",
      "cls loss 326.7805480957031  loc loss 14.68396282196045\n",
      "cls loss 529.6787109375  loc loss 35.24700164794922\n",
      "cls loss 478.639892578125  loc loss 31.904830932617188\n",
      "cls loss 847.4993896484375  loc loss 58.84276580810547\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19.,  7.])\n",
      "cls loss 479.9935302734375  loc loss 27.03736114501953\n",
      "cls loss 921.6541748046875  loc loss 59.11928939819336\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 771.0493774414062  loc loss 40.42997360229492\n",
      "cls loss 636.9192504882812  loc loss 47.514801025390625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([38., 38.,  1., 18.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1., 18., 18.,  1.])\n",
      "cls loss 512.7857055664062  loc loss 25.38060188293457\n",
      "cls loss 468.2882080078125  loc loss 23.248729705810547\n",
      "cls loss 837.91650390625  loc loss 63.41769027709961\n",
      "cls loss 660.1133422851562  loc loss 36.415016174316406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 608.947265625  loc loss 31.103490829467773\n",
      "cls loss 345.9800109863281  loc loss 27.13251495361328\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.])\n",
      "cls loss 281.5992126464844  loc loss 9.780868530273438\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([32.])\n",
      "cls loss 539.6132202148438  loc loss 28.337520599365234\n",
      "cls loss 463.4443664550781  loc loss 33.627525329589844\n",
      "cls loss 610.244140625  loc loss 48.94606018066406\n",
      "cls loss 542.1207275390625  loc loss 36.614688873291016\n",
      "cls loss 446.56884765625  loc loss 28.950536727905273\n",
      "cls loss 738.4548950195312  loc loss 46.31761169433594\n",
      "cls loss 789.5133056640625  loc loss 54.67953109741211\n",
      "cls loss 630.37841796875  loc loss 41.64189529418945\n",
      "cls loss 517.9141845703125  loc loss 30.257770538330078\n",
      "cls loss 808.323974609375  loc loss 51.367095947265625\n",
      "cls loss 526.4542236328125  loc loss 27.121665954589844\n",
      "cls loss 834.4349365234375  loc loss 63.52924346923828\n",
      "cls loss 607.1591186523438  loc loss 34.43058395385742\n",
      "cls loss 505.5845031738281  loc loss 36.98042297363281\n",
      "cls loss 377.0722961425781  loc loss 19.280715942382812\n",
      "cls loss 437.11846923828125  loc loss 26.942506790161133\n",
      "cls loss 636.314697265625  loc loss 42.187713623046875\n",
      "cls loss 651.8782958984375  loc loss 47.4839973449707\n",
      "cls loss 386.30169677734375  loc loss 25.613603591918945\n",
      "cls loss 708.6063232421875  loc loss 47.57501983642578\n",
      "cls loss 829.9921875  loc loss 51.48965835571289\n",
      "cls loss 313.60882568359375  loc loss 21.48001480102539\n",
      "cls loss 807.8921508789062  loc loss 54.70366668701172\n",
      "cls loss 574.5624389648438  loc loss 44.85719299316406\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 787.8350830078125  loc loss 61.11674118041992\n",
      "cls loss 399.83148193359375  loc loss 14.803702354431152\n",
      "cls loss 592.4314575195312  loc loss 31.982070922851562\n",
      "cls loss 576.485595703125  loc loss 39.152992248535156\n",
      "cls loss 470.0494079589844  loc loss 26.95220184326172\n",
      "cls loss 292.4608459472656  loc loss 15.29460334777832\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 9., 9., 1., 9., 9., 9., 9., 1., 9.])\n",
      "cls loss 993.9791259765625  loc loss 84.9791030883789\n",
      "cls loss 587.2188720703125  loc loss 31.4696102142334\n",
      "cls loss 847.595458984375  loc loss 72.30350494384766\n",
      "cls loss 360.8855895996094  loc loss 25.491586685180664\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 42., 42.])\n",
      "cls loss 636.8853149414062  loc loss 46.93491744995117\n",
      "cls loss 682.8533325195312  loc loss 49.780330657958984\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  2.,  1.,  1.,  1., 38.,\n",
      "         1.,  1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 38., 38., 38.,  1., 38., 38., 38.,  1.,  1., 38.,  1.,\n",
      "         1.])\n",
      "cls loss 416.68994140625  loc loss 29.770214080810547\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  8.,  8.])\n",
      "cls loss 974.448974609375  loc loss 63.518898010253906\n",
      "cls loss 966.6317138671875  loc loss 68.70877838134766\n",
      "cls loss 378.36328125  loc loss 21.716167449951172\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([4., 1., 1., 4.])\n",
      "cls loss 542.06640625  loc loss 37.3591423034668\n",
      "cls loss 650.3584594726562  loc loss 40.406002044677734\n",
      "cls loss 290.30670166015625  loc loss 13.892986297607422\n",
      "cls loss 397.0152587890625  loc loss 24.673086166381836\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([51.,  1.])\n",
      "cls loss 289.88348388671875  loc loss 12.029582023620605\n",
      "cls loss 384.56451416015625  loc loss 21.646320343017578\n",
      "cls loss 670.0148315429688  loc loss 38.65257263183594\n",
      "cls loss 723.4631958007812  loc loss 53.826900482177734\n",
      "cls loss 988.7763061523438  loc loss 54.20170593261719\n",
      "cls loss 1209.59375  loc loss 81.46746826171875\n",
      "cls loss 532.2998046875  loc loss 32.135013580322266\n",
      "cls loss 745.5758666992188  loc loss 53.71946716308594\n",
      "cls loss 785.482177734375  loc loss 57.12137222290039\n",
      "cls loss 624.5404052734375  loc loss 36.05427932739258\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  3.,  1.,  1.,  1.,  3.,  1.,  1.,\n",
      "         1.,  1.,  1.])\n",
      "cls loss 637.7999267578125  loc loss 31.20709991455078\n",
      "cls loss 737.1937866210938  loc loss 37.789886474609375\n",
      "cls loss 661.9769287109375  loc loss 34.984840393066406\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "cls loss 546.9487915039062  loc loss 32.5546760559082\n",
      "cls loss 321.9866027832031  loc loss 26.371889114379883\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3.])\n",
      "cls loss 276.9286804199219  loc loss 13.248120307922363\n",
      "cls loss 486.71527099609375  loc loss 33.339698791503906\n",
      "cls loss 390.2672424316406  loc loss 30.16049575805664\n",
      "cls loss 698.2579345703125  loc loss 47.719764709472656\n",
      "cls loss 482.9281005859375  loc loss 24.697216033935547\n",
      "cls loss 389.102294921875  loc loss 27.301166534423828\n",
      "cls loss 1166.85791015625  loc loss 78.97381591796875\n",
      "cls loss 509.21087646484375  loc loss 38.871551513671875\n",
      "cls loss 373.8538818359375  loc loss 28.929237365722656\n",
      "cls loss 496.309814453125  loc loss 28.811750411987305\n",
      "cls loss 443.5859375  loc loss 32.03789520263672\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 807.8529052734375  loc loss 54.34293746948242\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  9., 64., 64., 64., 64., 64., 64., 64., 64., 64.,  9.,  9.,  9.,\n",
      "         9.])\n",
      "cls loss 451.68994140625  loc loss 22.308713912963867\n",
      "cls loss 1008.26953125  loc loss 82.18267822265625\n",
      "cls loss 528.9821166992188  loc loss 35.662715911865234\n",
      "cls loss 695.8822631835938  loc loss 50.09980392456055\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.,  3.,  3.])\n",
      "cls loss 449.602294921875  loc loss 26.691322326660156\n",
      "cls loss 495.07122802734375  loc loss 32.81043243408203\n",
      "cls loss 487.050048828125  loc loss 35.80847930908203\n",
      "cls loss 527.0185546875  loc loss 38.394432067871094\n",
      "cls loss 525.8641357421875  loc loss 42.839332580566406\n",
      "cls loss 529.032958984375  loc loss 40.32766342163086\n",
      "cls loss 508.4778137207031  loc loss 40.420318603515625\n",
      "cls loss 547.592529296875  loc loss 33.52080154418945\n",
      "cls loss 666.916259765625  loc loss 46.57271194458008\n",
      "cls loss 575.4962158203125  loc loss 32.399898529052734\n",
      "cls loss 465.92401123046875  loc loss 20.471908569335938\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21.])\n",
      "cls loss 339.92626953125  loc loss 19.0439510345459\n",
      "cls loss 458.5367126464844  loc loss 39.17190170288086\n",
      "cls loss 672.1702880859375  loc loss 48.44963836669922\n",
      "cls loss 417.2132568359375  loc loss 23.66021728515625\n",
      "cls loss 567.8508911132812  loc loss 34.706626892089844\n",
      "cls loss 1029.0938720703125  loc loss 56.76665115356445\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 42., 42.,  1.,  1.])\n",
      "cls loss 520.29150390625  loc loss 33.58274841308594\n",
      "cls loss 342.75164794921875  loc loss 25.385311126708984\n",
      "cls loss 490.3058776855469  loc loss 37.413177490234375\n",
      "cls loss 693.425048828125  loc loss 56.136783599853516\n",
      "cls loss 445.56298828125  loc loss 28.966014862060547\n",
      "cls loss 640.7076416015625  loc loss 49.3941764831543\n",
      "cls loss 616.84912109375  loc loss 46.647483825683594\n",
      "cls loss 668.7142944335938  loc loss 39.245540618896484\n",
      "cls loss 517.5896606445312  loc loss 32.29074478149414\n",
      "cls loss 476.2215576171875  loc loss 29.005111694335938\n",
      "cls loss 381.00360107421875  loc loss 15.78452205657959\n",
      "cls loss 469.14324951171875  loc loss 31.998981475830078\n",
      "cls loss 707.569091796875  loc loss 56.819488525390625\n",
      "cls loss 569.754638671875  loc loss 36.47069549560547\n",
      "cls loss 540.6722412109375  loc loss 40.53380584716797\n",
      "cls loss 598.6287841796875  loc loss 35.45489501953125\n",
      "cls loss 867.1141967773438  loc loss 60.078182220458984\n",
      "cls loss 623.3258056640625  loc loss 47.84395217895508\n",
      "cls loss 731.2108154296875  loc loss 41.75255584716797\n",
      "cls loss 422.7190246582031  loc loss 21.476303100585938\n",
      "cls loss 600.6139526367188  loc loss 39.406776428222656\n",
      "cls loss 559.1477661132812  loc loss 34.82426071166992\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 5., 5., 5., 5., 5., 5.])\n",
      "cls loss 402.1799011230469  loc loss 27.248828887939453\n",
      "cls loss 478.5694274902344  loc loss 28.140348434448242\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([13.])\n",
      "cls loss 326.88531494140625  loc loss 21.009660720825195\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([44., 10.,  1.,  1.,  1.])\n",
      "cls loss 343.6676025390625  loc loss 20.906923294067383\n",
      "cls loss 648.817626953125  loc loss 33.16701126098633\n",
      "cls loss 522.772216796875  loc loss 29.96914291381836\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19., 19., 19., 19., 19., 19., 19.])\n",
      "cls loss 660.942626953125  loc loss 35.45557403564453\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([56.])\n",
      "cls loss 1126.8118896484375  loc loss 72.15744018554688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 661.815673828125  loc loss 53.00396728515625\n",
      "cls loss 854.1534423828125  loc loss 61.387718200683594\n",
      "cls loss 858.595947265625  loc loss 65.87413024902344\n",
      "cls loss 526.299072265625  loc loss 30.447811126708984\n",
      "cls loss 828.15283203125  loc loss 60.531497955322266\n",
      "cls loss 486.24761962890625  loc loss 31.208803176879883\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 36.])\n",
      "cls loss 586.1356201171875  loc loss 33.09334945678711\n",
      "cls loss 525.305908203125  loc loss 37.09996032714844\n",
      "cls loss 518.2191162109375  loc loss 31.484111785888672\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5.])\n",
      "cls loss 613.8007202148438  loc loss 37.618919372558594\n",
      "cls loss 335.84710693359375  loc loss 18.276918411254883\n",
      "cls loss 758.747314453125  loc loss 42.61162567138672\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "cls loss 661.7724609375  loc loss 44.793426513671875\n",
      "cls loss 671.3353271484375  loc loss 43.97889709472656\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 608.2763061523438  loc loss 44.14678955078125\n",
      "cls loss 726.4679565429688  loc loss 51.72096252441406\n",
      "cls loss 593.8233642578125  loc loss 55.60871505737305\n",
      "cls loss 426.92169189453125  loc loss 30.26702117919922\n",
      "cls loss 538.6618041992188  loc loss 38.99117660522461\n",
      "cls loss 545.8181762695312  loc loss 35.26063919067383\n",
      "cls loss 839.884765625  loc loss 49.074764251708984\n",
      "cls loss 389.5713806152344  loc loss 19.61513328552246\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 11., 15., 10., 10., 10., 10., 10.])\n",
      "cls loss 899.2265625  loc loss 57.74541473388672\n",
      "cls loss 490.1971740722656  loc loss 34.271297454833984\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3.])\n",
      "cls loss 549.6988525390625  loc loss 36.32404327392578\n",
      "cls loss 496.17340087890625  loc loss 28.330604553222656\n",
      "cls loss 535.9659423828125  loc loss 26.84547233581543\n",
      "cls loss 682.0073852539062  loc loss 33.784698486328125\n",
      "cls loss 377.2083740234375  loc loss 17.83104705810547\n",
      "cls loss 525.9777221679688  loc loss 34.73662185668945\n",
      "cls loss 582.0621337890625  loc loss 45.75171661376953\n",
      "cls loss 500.9720458984375  loc loss 38.01407241821289\n",
      "cls loss 1168.874267578125  loc loss 87.79841613769531\n",
      "cls loss 833.103759765625  loc loss 54.890926361083984\n",
      "cls loss 535.3021240234375  loc loss 39.159034729003906\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  9.,  9.,  9.,  6.,  6., 85., 85.,  8.,  1.,  1.,  1.,  1.,\n",
      "         6.,  6.])\n",
      "cls loss 377.836669921875  loc loss 27.933942794799805\n",
      "cls loss 879.580810546875  loc loss 62.160911560058594\n",
      "cls loss 1030.455322265625  loc loss 66.30473327636719\n",
      "cls loss 714.0186157226562  loc loss 48.369930267333984\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10.,  3.,  3., 10.])\n",
      "cls loss 479.2070617675781  loc loss 27.038097381591797\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([7.])\n",
      "cls loss 597.569091796875  loc loss 41.67367935180664\n",
      "cls loss 614.0086059570312  loc loss 37.462982177734375\n",
      "cls loss 538.9251098632812  loc loss 44.242095947265625\n",
      "cls loss 758.2377319335938  loc loss 63.229339599609375\n",
      "cls loss 562.89111328125  loc loss 38.413421630859375\n",
      "cls loss 763.3468017578125  loc loss 50.72098159790039\n",
      "cls loss 946.176513671875  loc loss 58.097679138183594\n",
      "cls loss 561.5318603515625  loc loss 39.78178405761719\n",
      "cls loss 608.97998046875  loc loss 42.96033477783203\n",
      "cls loss 518.0087890625  loc loss 38.71600341796875\n",
      "cls loss 723.2806396484375  loc loss 59.828121185302734\n",
      "cls loss 593.780029296875  loc loss 38.41291809082031\n",
      "cls loss 475.70172119140625  loc loss 28.17817497253418\n",
      "cls loss 727.4007568359375  loc loss 55.13323211669922\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([62.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([62.])\n",
      "cls loss 330.1229248046875  loc loss 17.41376495361328\n",
      "cls loss 580.5728149414062  loc loss 41.077484130859375\n",
      "cls loss 564.162841796875  loc loss 37.41452407836914\n",
      "cls loss 395.63897705078125  loc loss 17.347719192504883\n",
      "cls loss 714.9171142578125  loc loss 48.55363464355469\n",
      "cls loss 717.1658935546875  loc loss 42.226043701171875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([28.])\n",
      "cls loss 790.4927978515625  loc loss 43.906883239746094\n",
      "cls loss 699.843994140625  loc loss 43.71717834472656\n",
      "cls loss 689.9410400390625  loc loss 44.65577697753906\n",
      "cls loss 698.6594848632812  loc loss 46.674102783203125\n",
      "cls loss 968.6967163085938  loc loss 65.8629150390625\n",
      "cls loss 541.2098999023438  loc loss 35.34441375732422\n",
      "cls loss 669.2673950195312  loc loss 41.698402404785156\n",
      "cls loss 593.9157104492188  loc loss 50.16326904296875\n",
      "cls loss 951.1248168945312  loc loss 74.73434448242188\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([81.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 664.971923828125  loc loss 27.869403839111328\n",
      "cls loss 507.89532470703125  loc loss 25.867631912231445\n",
      "cls loss 433.89910888671875  loc loss 27.528709411621094\n",
      "cls loss 368.216796875  loc loss 14.389708518981934\n",
      "cls loss 410.78228759765625  loc loss 26.856122970581055\n",
      "cls loss 442.37188720703125  loc loss 27.627910614013672\n",
      "cls loss 517.57373046875  loc loss 32.64225769042969\n",
      "cls loss 665.6281127929688  loc loss 53.90482711791992\n",
      "cls loss 749.2758178710938  loc loss 51.11458206176758\n",
      "cls loss 1421.24951171875  loc loss 97.56271362304688\n",
      "cls loss 581.6961669921875  loc loss 30.21282196044922\n",
      "cls loss 692.555419921875  loc loss 47.68260955810547\n",
      "cls loss 488.4644775390625  loc loss 30.116926193237305\n",
      "cls loss 636.0928955078125  loc loss 36.051361083984375\n",
      "cls loss 573.2607421875  loc loss 32.829437255859375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([44., 44.])\n",
      "cls loss 513.2866821289062  loc loss 25.9044132232666\n",
      "cls loss 507.8708190917969  loc loss 37.24760055541992\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15.])\n",
      "cls loss 607.88720703125  loc loss 30.97885513305664\n",
      "cls loss 295.00518798828125  loc loss 17.206573486328125\n",
      "cls loss 603.487548828125  loc loss 35.689674377441406\n",
      "cls loss 337.1114196777344  loc loss 21.405210494995117\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([1., 3., 3.])\n",
      "cls loss 376.71826171875  loc loss 28.862594604492188\n",
      "cls loss 315.62481689453125  loc loss 13.5443696975708\n",
      "cls loss 576.6845092773438  loc loss 32.76887512207031\n",
      "cls loss 606.3820190429688  loc loss 35.935272216796875\n",
      "cls loss 543.458740234375  loc loss 35.74888229370117\n",
      "cls loss 568.487060546875  loc loss 31.98046875\n",
      "cls loss 452.7305908203125  loc loss 34.78126525878906\n",
      "cls loss 609.4619750976562  loc loss 41.860626220703125\n",
      "cls loss 481.84771728515625  loc loss 31.86924171447754\n",
      "cls loss 590.7183837890625  loc loss 42.143409729003906\n",
      "cls loss 375.7366943359375  loc loss 23.88233184814453\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 697.931884765625  loc loss 43.64234161376953\n",
      "cls loss 809.81298828125  loc loss 40.96573257446289\n",
      "cls loss 718.6550903320312  loc loss 50.42542266845703\n",
      "cls loss 709.00341796875  loc loss 53.59421157836914\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10., 10., 10.,  1.,  1.,  1.,  1.,  1.,  1.,  8.,  8.,\n",
      "         1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10., 10., 10.,  1.,  1.,  1.,  1.,  1.,  1.,  8.,  8.,\n",
      "         1.])\n",
      "cls loss 684.8325805664062  loc loss 32.873878479003906\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 3., 3., 3.])\n",
      "cls loss 573.4098510742188  loc loss 36.3177375793457\n",
      "cls loss 395.46795654296875  loc loss 22.12900733947754\n",
      "cls loss 312.8521423339844  loc loss 15.65684700012207\n",
      "cls loss 535.12109375  loc loss 39.90000915527344\n",
      "cls loss 420.59619140625  loc loss 22.261587142944336\n",
      "cls loss 466.59136962890625  loc loss 31.601119995117188\n",
      "cls loss 529.2431640625  loc loss 37.37907791137695\n",
      "cls loss 741.0405883789062  loc loss 52.771751403808594\n",
      "cls loss 624.8162841796875  loc loss 31.75897216796875\n",
      "cls loss 598.4970703125  loc loss 34.95645523071289\n",
      "cls loss 680.7979125976562  loc loss 45.31465530395508\n",
      "cls loss 495.9671325683594  loc loss 37.23075485229492\n",
      "cls loss 900.4166259765625  loc loss 66.57319641113281\n",
      "cls loss 467.0047912597656  loc loss 24.400253295898438\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 687.0635986328125  loc loss 42.44716262817383\n",
      "cls loss 350.3217468261719  loc loss 15.332252502441406\n",
      "cls loss 851.1923217773438  loc loss 54.811859130859375\n",
      "cls loss 452.7531433105469  loc loss 23.590591430664062\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 34.])\n",
      "cls loss 722.63232421875  loc loss 38.88752365112305\n",
      "cls loss 329.27728271484375  loc loss 22.07754898071289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 618.01806640625  loc loss 42.436641693115234\n",
      "cls loss 218.47718811035156  loc loss 16.479137420654297\n",
      "cls loss 562.0279541015625  loc loss 36.633358001708984\n",
      "cls loss 543.6464233398438  loc loss 43.04237365722656\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 38.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16., 16., 16.,  9.,  9.,  9., 16., 16., 16., 85.,  9.])\n",
      "cls loss 537.459716796875  loc loss 35.38549041748047\n",
      "cls loss 605.40283203125  loc loss 48.405792236328125\n",
      "cls loss 836.2391357421875  loc loss 60.20785903930664\n",
      "cls loss 1191.09912109375  loc loss 81.69593811035156\n",
      "cls loss 376.56622314453125  loc loss 19.24310874938965\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3., 10.,  8.,  8., 10., 10., 10.,  3.,  3., 14.])\n",
      "cls loss 461.4759521484375  loc loss 21.76003646850586\n",
      "cls loss 810.4388427734375  loc loss 41.42632293701172\n",
      "cls loss 351.798583984375  loc loss 13.031874656677246\n",
      "cls loss 518.7462158203125  loc loss 22.74060821533203\n",
      "cls loss 684.4805908203125  loc loss 41.0555305480957\n",
      "cls loss 575.6909790039062  loc loss 38.418479919433594\n",
      "cls loss 339.0169677734375  loc loss 17.620262145996094\n",
      "cls loss 378.7618713378906  loc loss 24.137096405029297\n",
      "cls loss 577.7833251953125  loc loss 38.54450988769531\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42., 42.,  1.])\n",
      "cls loss 556.5950927734375  loc loss 40.58033752441406\n",
      "cls loss 470.13848876953125  loc loss 28.28067970275879\n",
      "cls loss 628.33203125  loc loss 48.42688751220703\n",
      "cls loss 715.161865234375  loc loss 47.79978942871094\n",
      "cls loss 508.16632080078125  loc loss 33.01905822753906\n",
      "cls loss 617.203125  loc loss 43.750423431396484\n",
      "cls loss 401.43017578125  loc loss 26.550413131713867\n",
      "cls loss 424.7901916503906  loc loss 29.356462478637695\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20.])\n",
      "cls loss 339.88421630859375  loc loss 18.823930740356445\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([11.])\n",
      "cls loss 423.8428649902344  loc loss 22.19557762145996\n",
      "cls loss 301.27813720703125  loc loss 16.36204719543457\n",
      "cls loss 647.0977783203125  loc loss 51.45485305786133\n",
      "cls loss 306.2235107421875  loc loss 13.801149368286133\n",
      "cls loss 620.2225341796875  loc loss 35.272178649902344\n",
      "cls loss 340.8826599121094  loc loss 21.436996459960938\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 35., 27.])\n",
      "cls loss 577.1358032226562  loc loss 37.85205841064453\n",
      "cls loss 606.2667236328125  loc loss 47.546119689941406\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 445.3843994140625  loc loss 27.159570693969727\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([42.,  1.])\n",
      "cls loss 579.7642211914062  loc loss 41.15630340576172\n",
      "cls loss 524.407470703125  loc loss 31.046112060546875\n",
      "cls loss 655.1947631835938  loc loss 38.190460205078125\n",
      "cls loss 755.134765625  loc loss 51.74748992919922\n",
      "cls loss 692.934326171875  loc loss 43.576995849609375\n",
      "cls loss 470.0652770996094  loc loss 36.760902404785156\n",
      "cls loss 407.4864501953125  loc loss 32.04957962036133\n",
      "cls loss 272.1650085449219  loc loss 12.881563186645508\n",
      "cls loss 484.8463134765625  loc loss 27.766407012939453\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 1., 1.])\n",
      "cls loss 471.02874755859375  loc loss 25.31414222717285\n",
      "cls loss 520.111572265625  loc loss 35.76747131347656\n",
      "cls loss 527.2459716796875  loc loss 33.46100997924805\n",
      "cls loss 425.6783447265625  loc loss 31.185455322265625\n",
      "cls loss 508.7112121582031  loc loss 30.86402130126953\n",
      "cls loss 537.3222045898438  loc loss 40.99876022338867\n",
      "cls loss 747.8475341796875  loc loss 45.605655670166016\n",
      "cls loss 633.1712646484375  loc loss 50.23477554321289\n",
      "cls loss 605.7431640625  loc loss 36.71849822998047\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 471.55340576171875  loc loss 33.32374572753906\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 556.2328491210938  loc loss 28.20599365234375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([81.])\n",
      "cls loss 676.6065673828125  loc loss 43.01262664794922\n",
      "cls loss 431.4322204589844  loc loss 28.90726089477539\n",
      "cls loss 300.095703125  loc loss 18.464614868164062\n",
      "cls loss 475.80450439453125  loc loss 25.16671371459961\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3.,  1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 19.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 19.])\n",
      "cls loss 617.7305908203125  loc loss 43.014583587646484\n",
      "cls loss 367.2030944824219  loc loss 18.35269546508789\n",
      "cls loss 381.4150085449219  loc loss 23.236717224121094\n",
      "cls loss 722.7398071289062  loc loss 53.09234619140625\n",
      "cls loss 373.9730224609375  loc loss 23.853864669799805\n",
      "cls loss 467.14190673828125  loc loss 32.72373962402344\n",
      "cls loss 561.7040405273438  loc loss 38.07372283935547\n",
      "cls loss 437.6716613769531  loc loss 32.65653610229492\n",
      "cls loss 579.6259155273438  loc loss 34.83171463012695\n",
      "cls loss 648.2156372070312  loc loss 45.72807312011719\n",
      "cls loss 769.7492065429688  loc loss 72.12279510498047\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 81.])\n",
      "cls loss 575.605712890625  loc loss 31.257436752319336\n",
      "cls loss 485.2998352050781  loc loss 29.205312728881836\n",
      "cls loss 570.8460083007812  loc loss 30.612924575805664\n",
      "cls loss 423.618896484375  loc loss 20.722091674804688\n",
      "cls loss 388.9566650390625  loc loss 24.29429817199707\n",
      "cls loss 448.37115478515625  loc loss 32.28307342529297\n",
      "cls loss 359.4090270996094  loc loss 25.0163631439209\n",
      "cls loss 286.46478271484375  loc loss 18.7645263671875\n",
      "cls loss 375.03521728515625  loc loss 25.893224716186523\n",
      "cls loss 531.7847290039062  loc loss 32.91923522949219\n",
      "cls loss 435.84295654296875  loc loss 34.61732864379883\n",
      "cls loss 459.27001953125  loc loss 36.99711990356445\n",
      "cls loss 283.4595947265625  loc loss 21.167314529418945\n",
      "cls loss 937.1986083984375  loc loss 68.19798278808594\n",
      "cls loss 618.1171264648438  loc loss 41.7794075012207\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 520.45703125  loc loss 28.190092086791992\n",
      "cls loss 561.7914428710938  loc loss 38.51168441772461\n",
      "cls loss 472.62432861328125  loc loss 27.0576229095459\n",
      "cls loss 646.4610595703125  loc loss 42.210514068603516\n",
      "cls loss 638.3919677734375  loc loss 41.61161804199219\n",
      "cls loss 565.9949951171875  loc loss 36.73560333251953\n",
      "cls loss 467.81884765625  loc loss 26.858551025390625\n",
      "cls loss 345.08758544921875  loc loss 21.508987426757812\n",
      "cls loss 520.6710815429688  loc loss 32.64031982421875\n",
      "cls loss 539.929443359375  loc loss 37.94270324707031\n",
      "cls loss 582.8147583007812  loc loss 33.760807037353516\n",
      "cls loss 730.1022338867188  loc loss 56.11731719970703\n",
      "cls loss 734.0219116210938  loc loss 58.688934326171875\n",
      "cls loss 536.2420654296875  loc loss 39.0371208190918\n",
      "cls loss 690.33154296875  loc loss 55.816383361816406\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1., 38., 47.,  1.,  1.,  1.,  1.,  1., 62.])\n",
      "cls loss 514.7474975585938  loc loss 26.417987823486328\n",
      "cls loss 624.79638671875  loc loss 35.392738342285156\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 632.5985107421875  loc loss 38.222225189208984\n",
      "cls loss 693.2097778320312  loc loss 51.50166702270508\n",
      "cls loss 485.4289855957031  loc loss 24.615419387817383\n",
      "cls loss 546.095458984375  loc loss 44.773773193359375\n",
      "cls loss 500.4721374511719  loc loss 31.067304611206055\n",
      "cls loss 309.99981689453125  loc loss 12.697685241699219\n",
      "cls loss 492.9727783203125  loc loss 28.252685546875\n",
      "cls loss 409.6966552734375  loc loss 19.065534591674805\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1., 35.])\n",
      "cls loss 509.5462646484375  loc loss 24.788936614990234\n",
      "cls loss 669.5482177734375  loc loss 37.33711624145508\n",
      "cls loss 651.449462890625  loc loss 43.47886657714844\n",
      "cls loss 583.4415283203125  loc loss 49.15437316894531\n",
      "cls loss 471.6641540527344  loc loss 38.491825103759766\n",
      "cls loss 616.0054931640625  loc loss 46.70573806762695\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 352.3878173828125  loc loss 20.68795394897461\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 522.7938232421875  loc loss 25.25297737121582\n",
      "cls loss 824.2499389648438  loc loss 44.369686126708984\n",
      "cls loss 1009.9696044921875  loc loss 75.93689727783203\n",
      "cls loss 518.7061767578125  loc loss 26.708751678466797\n",
      "cls loss 449.41790771484375  loc loss 28.64609146118164\n",
      "cls loss 460.28204345703125  loc loss 26.093008041381836\n",
      "cls loss 490.6399230957031  loc loss 34.13951873779297\n",
      "cls loss 455.461669921875  loc loss 19.394548416137695\n",
      "cls loss 753.5713500976562  loc loss 54.093910217285156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 614.9013671875  loc loss 38.375\n",
      "cls loss 350.2679443359375  loc loss 21.760835647583008\n",
      "cls loss 609.678955078125  loc loss 33.97407531738281\n",
      "cls loss 722.0538330078125  loc loss 58.15274429321289\n",
      "cls loss 596.2513427734375  loc loss 38.23617935180664\n",
      "cls loss 543.4895629882812  loc loss 29.238527297973633\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.])\n",
      "cls loss 495.53594970703125  loc loss 36.51158142089844\n",
      "cls loss 445.5775146484375  loc loss 35.20318603515625\n",
      "cls loss 630.0718994140625  loc loss 42.7743034362793\n",
      "cls loss 926.8822631835938  loc loss 76.14945220947266\n",
      "cls loss 429.5418701171875  loc loss 20.361328125\n",
      "cls loss 542.0738525390625  loc loss 33.78105926513672\n",
      "cls loss 442.33673095703125  loc loss 24.704484939575195\n",
      "cls loss 477.7787780761719  loc loss 29.285144805908203\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 21., 21., 21.])\n",
      "cls loss 513.3453979492188  loc loss 30.018707275390625\n",
      "cls loss 487.40679931640625  loc loss 22.438060760498047\n",
      "cls loss 500.590087890625  loc loss 33.46433639526367\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 35.])\n",
      "cls loss 673.2846069335938  loc loss 44.2255859375\n",
      "cls loss 245.535400390625  loc loss 13.555403709411621\n",
      "cls loss 383.8294677734375  loc loss 26.48484230041504\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 387.517822265625  loc loss 18.409555435180664\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 38., 38.,  9., 38.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1.,  1.])\n",
      "cls loss 432.50543212890625  loc loss 29.866952896118164\n",
      "cls loss 698.0003051757812  loc loss 47.34990310668945\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 2.,  1., 77., 31., 10., 10.,  1.,  4., 10.])\n",
      "cls loss 372.46685791015625  loc loss 18.116365432739258\n",
      "cls loss 672.9761352539062  loc loss 41.99272537231445\n",
      "cls loss 1339.561279296875  loc loss 82.44378662109375\n",
      "cls loss 445.5905456542969  loc loss 28.00090980529785\n",
      "cls loss 602.1849365234375  loc loss 46.36103820800781\n",
      "cls loss 447.5966796875  loc loss 25.35608673095703\n",
      "cls loss 458.2618408203125  loc loss 22.561769485473633\n",
      "cls loss 694.8096923828125  loc loss 30.588953018188477\n",
      "cls loss 668.929443359375  loc loss 35.440860748291016\n",
      "cls loss 576.6980590820312  loc loss 39.94429016113281\n",
      "cls loss 440.9128723144531  loc loss 21.916969299316406\n",
      "cls loss 487.6527099609375  loc loss 25.079832077026367\n",
      "cls loss 877.5922241210938  loc loss 55.617576599121094\n",
      "cls loss 746.4354248046875  loc loss 47.30311584472656\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1., 42., 42., 42., 42., 42., 42.,  1.,\n",
      "         1.,  1.,  1., 42.,  1.,  1., 42.,  1.])\n",
      "cls loss 422.26068115234375  loc loss 29.23189926147461\n",
      "cls loss 652.4375  loc loss 40.714298248291016\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.])\n",
      "cls loss 277.84796142578125  loc loss 17.782939910888672\n",
      "cls loss 625.8359375  loc loss 42.44801712036133\n",
      "cls loss 509.18341064453125  loc loss 36.2231559753418\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([11.])\n",
      "cls loss 312.83251953125  loc loss 18.14293670654297\n",
      "cls loss 407.0552673339844  loc loss 18.47386932373047\n",
      "cls loss 426.4583740234375  loc loss 18.927989959716797\n",
      "cls loss 621.626220703125  loc loss 40.8331413269043\n",
      "cls loss 591.23974609375  loc loss 31.429473876953125\n",
      "cls loss 548.500732421875  loc loss 38.2102165222168\n",
      "cls loss 809.7457275390625  loc loss 43.146888732910156\n",
      "cls loss 421.003173828125  loc loss 25.28731918334961\n",
      "cls loss 781.0086669921875  loc loss 58.414241790771484\n",
      "cls loss 411.917236328125  loc loss 26.407623291015625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 372.37823486328125  loc loss 26.84630012512207\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1., 38., 38., 42.])\n",
      "cls loss 477.94635009765625  loc loss 35.95486068725586\n",
      "cls loss 441.1170349121094  loc loss 25.569358825683594\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 372.93243408203125  loc loss 28.3952579498291\n",
      "cls loss 893.9105224609375  loc loss 62.80312728881836\n",
      "cls loss 546.5205078125  loc loss 36.92218017578125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10.,  3.,  3.,  6.,  8.,  8.,  1.,  1.,  1., 10.])\n",
      "cls loss 472.0660400390625  loc loss 25.302703857421875\n",
      "cls loss 287.84271240234375  loc loss 10.848882675170898\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10.,  3.])\n",
      "cls loss 439.3378601074219  loc loss 24.700563430786133\n",
      "cls loss 276.9855651855469  loc loss 12.92434310913086\n",
      "cls loss 529.1378784179688  loc loss 39.04893493652344\n",
      "cls loss 597.8822021484375  loc loss 40.40929412841797\n",
      "cls loss 448.69677734375  loc loss 27.556724548339844\n",
      "cls loss 320.93701171875  loc loss 16.003196716308594\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 34.])\n",
      "cls loss 746.6986083984375  loc loss 47.38653564453125\n",
      "cls loss 789.8392944335938  loc loss 67.70394897460938\n",
      "cls loss 520.4302978515625  loc loss 40.60115051269531\n",
      "cls loss 389.9927673339844  loc loss 29.1550235748291\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.,  1.])\n",
      "cls loss 451.77886962890625  loc loss 23.41979217529297\n",
      "cls loss 693.9287109375  loc loss 55.33773422241211\n",
      "cls loss 1057.490966796875  loc loss 68.80764770507812\n",
      "cls loss 875.5819091796875  loc loss 46.0396614074707\n",
      "cls loss 515.9051513671875  loc loss 28.129749298095703\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 631.8182373046875  loc loss 36.9299201965332\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10.])\n",
      "cls loss 389.4366455078125  loc loss 21.148582458496094\n",
      "cls loss 563.52001953125  loc loss 28.573108673095703\n",
      "cls loss 521.5084228515625  loc loss 31.4080810546875\n",
      "cls loss 373.78228759765625  loc loss 23.5875186920166\n",
      "cls loss 469.7587890625  loc loss 32.92499923706055\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21.,\n",
      "        21.])\n",
      "cls loss 656.2789306640625  loc loss 37.337242126464844\n",
      "cls loss 513.8662719726562  loc loss 32.66110610961914\n",
      "cls loss 332.2483825683594  loc loss 15.606242179870605\n",
      "cls loss 695.1224365234375  loc loss 46.37295150756836\n",
      "cls loss 546.31640625  loc loss 37.531917572021484\n",
      "cls loss 380.19305419921875  loc loss 23.621585845947266\n",
      "cls loss 805.683349609375  loc loss 54.36438751220703\n",
      "cls loss 976.2108764648438  loc loss 67.3089599609375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15., 85.])\n",
      "cls loss 600.0728759765625  loc loss 39.50331497192383\n",
      "cls loss 617.4332275390625  loc loss 46.209781646728516\n",
      "cls loss 621.2908935546875  loc loss 45.57773971557617\n",
      "cls loss 565.6771240234375  loc loss 31.85650634765625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 8., 8.])\n",
      "cls loss 369.43017578125  loc loss 19.023963928222656\n",
      "cls loss 385.6788330078125  loc loss 27.363025665283203\n",
      "cls loss 491.842529296875  loc loss 30.136669158935547\n",
      "cls loss 406.10821533203125  loc loss 23.218360900878906\n",
      "cls loss 474.92291259765625  loc loss 28.63524055480957\n",
      "cls loss 619.08154296875  loc loss 38.87974548339844\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1., 35., 27., 27.,  1., 27.,  1.])\n",
      "cls loss 807.087890625  loc loss 57.70903778076172\n",
      "cls loss 404.86767578125  loc loss 27.954668045043945\n",
      "cls loss 483.9085693359375  loc loss 35.55437469482422\n",
      "cls loss 451.61212158203125  loc loss 40.036582946777344\n",
      "cls loss 411.0047912597656  loc loss 31.984548568725586\n",
      "cls loss 449.99102783203125  loc loss 36.18001937866211\n",
      "cls loss 448.0230712890625  loc loss 36.2540168762207\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  2.,  2.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  2.,  2.])\n",
      "cls loss 281.3873291015625  loc loss 10.623377799987793\n",
      "cls loss 711.058837890625  loc loss 44.874488830566406\n",
      "cls loss 507.28741455078125  loc loss 24.346960067749023\n",
      "cls loss 794.2403564453125  loc loss 58.91752624511719\n",
      "cls loss 337.8067626953125  loc loss 20.22256851196289\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 19., 19., 19., 16.])\n",
      "cls loss 353.4985046386719  loc loss 15.43864917755127\n",
      "cls loss 284.3018493652344  loc loss 12.623361587524414\n",
      "cls loss 430.28900146484375  loc loss 22.40298080444336\n",
      "cls loss 562.076171875  loc loss 38.14103698730469\n",
      "cls loss 300.221923828125  loc loss 20.634614944458008\n",
      "cls loss 633.2197875976562  loc loss 48.217613220214844\n",
      "cls loss 457.8614196777344  loc loss 32.42039489746094\n",
      "cls loss 517.679931640625  loc loss 33.21394729614258\n",
      "cls loss 640.1781005859375  loc loss 44.93354034423828\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 719.1590576171875  loc loss 30.867626190185547\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 888.5364990234375  loc loss 78.1811294555664\n",
      "cls loss 1099.57275390625  loc loss 107.6839599609375\n",
      "cls loss 576.5125732421875  loc loss 39.1836051940918\n",
      "cls loss 518.443115234375  loc loss 34.810508728027344\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3.,  3.,  3.,  3.,  3., 10.])\n",
      "cls loss 300.4344177246094  loc loss 17.4306640625\n",
      "cls loss 550.312255859375  loc loss 29.401531219482422\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 1., 1., 1., 3., 3., 3., 3.])\n",
      "cls loss 433.8103332519531  loc loss 28.69605827331543\n",
      "cls loss 807.1884765625  loc loss 54.95478439331055\n",
      "cls loss 642.8480834960938  loc loss 43.570945739746094\n",
      "cls loss 437.7999267578125  loc loss 25.544736862182617\n",
      "cls loss 649.142333984375  loc loss 47.60367202758789\n",
      "cls loss 415.98333740234375  loc loss 30.994625091552734\n",
      "cls loss 670.3919677734375  loc loss 46.43889236450195\n",
      "cls loss 470.6065673828125  loc loss 45.0338020324707\n",
      "cls loss 505.3525085449219  loc loss 32.758941650390625\n",
      "cls loss 1023.8923950195312  loc loss 85.55474090576172\n",
      "cls loss 678.2376708984375  loc loss 48.819122314453125\n",
      "cls loss 470.71630859375  loc loss 23.0462646484375\n",
      "cls loss 320.55206298828125  loc loss 13.86242961883545\n",
      "cls loss 360.54486083984375  loc loss 17.44620132446289\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3., 10., 10., 10., 10., 10., 10., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10., 10., 10., 10., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 11., 10., 10., 10., 10., 10.,  3.,  3.,  3.,  3.,  3.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 11., 10., 10., 10., 10., 10.,  3.,  3.,  3.,  3.,  3.])\n",
      "cls loss 355.4576721191406  loc loss 16.03944206237793\n",
      "cls loss 414.18634033203125  loc loss 20.317832946777344\n",
      "cls loss 347.24237060546875  loc loss 21.746475219726562\n",
      "cls loss 347.35760498046875  loc loss 15.264811515808105\n",
      "cls loss 398.9022216796875  loc loss 32.65848159790039\n",
      "cls loss 329.7611083984375  loc loss 12.954696655273438\n",
      "cls loss 609.7527465820312  loc loss 41.85286331176758\n",
      "cls loss 531.95458984375  loc loss 38.228904724121094\n",
      "cls loss 817.183349609375  loc loss 52.361846923828125\n",
      "cls loss 401.4927673339844  loc loss 30.470043182373047\n",
      "cls loss 730.5748291015625  loc loss 48.85377502441406\n",
      "cls loss 604.6241455078125  loc loss 40.021461486816406\n",
      "cls loss 552.9443359375  loc loss 37.27119827270508\n",
      "cls loss 558.4669189453125  loc loss 40.78717803955078\n",
      "cls loss 761.1529541015625  loc loss 50.9222412109375\n",
      "cls loss 760.9656982421875  loc loss 46.21175765991211\n",
      "cls loss 361.41864013671875  loc loss 20.055755615234375\n",
      "cls loss 651.420654296875  loc loss 49.1681022644043\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 10.,  1., 18.])\n",
      "cls loss 322.5552673339844  loc loss 22.403894424438477\n",
      "cls loss 379.7230224609375  loc loss 16.327367782592773\n",
      "cls loss 648.5137939453125  loc loss 34.078330993652344\n",
      "cls loss 926.5377197265625  loc loss 57.0408821105957\n",
      "cls loss 548.5841064453125  loc loss 38.77444076538086\n",
      "cls loss 793.6156005859375  loc loss 43.932708740234375\n",
      "cls loss 554.0604248046875  loc loss 37.2850341796875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.,  1.,  1.])\n",
      "cls loss 693.7689208984375  loc loss 46.06767654418945\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1., 38.,  1.])\n",
      "cls loss 678.9109497070312  loc loss 37.67536544799805\n",
      "cls loss 863.2576293945312  loc loss 62.05415344238281\n",
      "cls loss 453.16986083984375  loc loss 32.01288986206055\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 603.5075073242188  loc loss 40.70390319824219\n",
      "cls loss 534.0142211914062  loc loss 33.13561248779297\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3., 10.,  8.,  3., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.])\n",
      "cls loss 636.0979614257812  loc loss 36.975914001464844\n",
      "cls loss 447.8224792480469  loc loss 27.879518508911133\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3.,  3., 11.,  3., 10., 10.,  3.,  3., 10.])\n",
      "cls loss 533.81201171875  loc loss 25.182966232299805\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3., 10., 10., 10.])\n",
      "cls loss 504.055419921875  loc loss 33.723487854003906\n",
      "cls loss 452.509765625  loc loss 24.284011840820312\n",
      "cls loss 523.9613037109375  loc loss 36.41660690307617\n",
      "cls loss 806.1586303710938  loc loss 48.80433654785156\n",
      "cls loss 526.0338134765625  loc loss 34.016658782958984\n",
      "cls loss 376.35308837890625  loc loss 32.98939514160156\n",
      "cls loss 498.3129577636719  loc loss 33.68899154663086\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 9.,  9., 85., 85.])\n",
      "cls loss 418.9085388183594  loc loss 23.428142547607422\n",
      "cls loss 484.6534118652344  loc loss 34.27521514892578\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 802.1728515625  loc loss 57.74400329589844\n",
      "cls loss 700.0570068359375  loc loss 33.81400680541992\n",
      "cls loss 760.3775634765625  loc loss 54.45661163330078\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10., 10., 10., 10.])\n",
      "cls loss 475.5666198730469  loc loss 30.14694595336914\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([13.])\n",
      "cls loss 762.7794189453125  loc loss 59.72275161743164\n",
      "cls loss 277.5168151855469  loc loss 15.005443572998047\n",
      "cls loss 356.1590270996094  loc loss 18.203262329101562\n",
      "cls loss 477.4803466796875  loc loss 25.16046142578125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19.,  1.,  1.,  1., 19., 19.])\n",
      "cls loss 478.4315185546875  loc loss 31.51721954345703\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 374.1885070800781  loc loss 28.407424926757812\n",
      "cls loss 537.9222412109375  loc loss 39.09616470336914\n",
      "cls loss 405.9400634765625  loc loss 23.637401580810547\n",
      "cls loss 595.6515502929688  loc loss 34.17012023925781\n",
      "cls loss 634.760986328125  loc loss 48.862483978271484\n",
      "cls loss 521.163330078125  loc loss 28.642927169799805\n",
      "cls loss 727.3895874023438  loc loss 53.5506477355957\n",
      "cls loss 306.4706115722656  loc loss 13.96229076385498\n",
      "cls loss 542.667724609375  loc loss 33.82072067260742\n",
      "cls loss 431.90057373046875  loc loss 21.650236129760742\n",
      "cls loss 458.8029479980469  loc loss 24.466278076171875\n",
      "cls loss 574.177490234375  loc loss 36.94828414916992\n",
      "cls loss 539.3770751953125  loc loss 28.764150619506836\n",
      "cls loss 760.9158935546875  loc loss 48.78852081298828\n",
      "cls loss 489.72540283203125  loc loss 33.002166748046875\n",
      "cls loss 618.4481201171875  loc loss 42.88121032714844\n",
      "cls loss 934.36376953125  loc loss 57.138771057128906\n",
      "cls loss 488.29034423828125  loc loss 37.46392822265625\n",
      "cls loss 574.3314208984375  loc loss 33.96889877319336\n",
      "cls loss 660.8507690429688  loc loss 51.011871337890625\n",
      "cls loss 724.1297607421875  loc loss 51.3421516418457\n",
      "cls loss 903.9315185546875  loc loss 48.499507904052734\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 5.])\n",
      "cls loss 275.13446044921875  loc loss 10.685258865356445\n",
      "cls loss 344.3878479003906  loc loss 15.599723815917969\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 13.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 6., 8., 8.])\n",
      "cls loss 287.7054443359375  loc loss 15.135766983032227\n",
      "cls loss 365.3114318847656  loc loss 19.187835693359375\n",
      "cls loss 709.336181640625  loc loss 48.379337310791016\n",
      "cls loss 315.381103515625  loc loss 15.506306648254395\n",
      "cls loss 534.8541259765625  loc loss 41.96534729003906\n",
      "cls loss 860.0728759765625  loc loss 60.78436279296875\n",
      "cls loss 510.7617492675781  loc loss 38.957759857177734\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([42., 42.,  1.,  1.,  1.,  1.,  1.,  1.,  1., 42., 42.])\n",
      "cls loss 587.6341552734375  loc loss 32.949012756347656\n",
      "cls loss 735.513671875  loc loss 57.495758056640625\n",
      "cls loss 623.4100341796875  loc loss 49.0872802734375\n",
      "cls loss 443.1933288574219  loc loss 27.50567626953125\n",
      "cls loss 585.2269897460938  loc loss 34.82273483276367\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 776.6760864257812  loc loss 52.28537368774414\n",
      "cls loss 638.1864013671875  loc loss 44.39213562011719\n",
      "cls loss 405.58148193359375  loc loss 23.874385833740234\n",
      "cls loss 339.50469970703125  loc loss 18.963674545288086\n",
      "cls loss 487.9793395996094  loc loss 28.519729614257812\n",
      "cls loss 648.6753540039062  loc loss 41.54310989379883\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15.])\n",
      "cls loss 324.5888977050781  loc loss 14.154064178466797\n",
      "cls loss 525.9590454101562  loc loss 34.728702545166016\n",
      "cls loss 473.9964599609375  loc loss 31.51751708984375\n",
      "cls loss 837.489990234375  loc loss 58.049041748046875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19.,  7.])\n",
      "cls loss 474.91473388671875  loc loss 26.206512451171875\n",
      "cls loss 899.828857421875  loc loss 58.21098709106445\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 754.5616455078125  loc loss 39.44632339477539\n",
      "cls loss 632.4111328125  loc loss 46.632911682128906\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([38., 38.,  1., 18.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1., 18., 18.,  1.])\n",
      "cls loss 503.7713623046875  loc loss 24.856704711914062\n",
      "cls loss 463.32568359375  loc loss 22.79476547241211\n",
      "cls loss 833.271728515625  loc loss 62.08735656738281\n",
      "cls loss 650.2493896484375  loc loss 35.807254791259766\n",
      "cls loss 596.3951416015625  loc loss 30.573989868164062\n",
      "cls loss 342.97943115234375  loc loss 26.86319351196289\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.])\n",
      "cls loss 276.42742919921875  loc loss 9.680291175842285\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([32.])\n",
      "cls loss 533.4082641601562  loc loss 28.03025245666504\n",
      "cls loss 457.0556640625  loc loss 33.15208053588867\n",
      "cls loss 601.0762939453125  loc loss 47.985050201416016\n",
      "cls loss 527.9856567382812  loc loss 35.877593994140625\n",
      "cls loss 437.21630859375  loc loss 28.21970558166504\n",
      "cls loss 728.912109375  loc loss 45.28645324707031\n",
      "cls loss 779.0567626953125  loc loss 53.7651252746582\n",
      "cls loss 620.9500732421875  loc loss 40.8623161315918\n",
      "cls loss 508.2350769042969  loc loss 29.70000457763672\n",
      "cls loss 796.17333984375  loc loss 50.457759857177734\n",
      "cls loss 520.7514038085938  loc loss 26.703086853027344\n",
      "cls loss 827.1629638671875  loc loss 61.94281005859375\n",
      "cls loss 598.3258056640625  loc loss 33.724212646484375\n",
      "cls loss 499.6212158203125  loc loss 36.53257751464844\n",
      "cls loss 372.5892028808594  loc loss 18.740392684936523\n",
      "cls loss 432.29095458984375  loc loss 26.482017517089844\n",
      "cls loss 629.01171875  loc loss 41.439476013183594\n",
      "cls loss 646.3773803710938  loc loss 46.62520980834961\n",
      "cls loss 381.36114501953125  loc loss 24.995141983032227\n",
      "cls loss 697.636962890625  loc loss 46.64781951904297\n",
      "cls loss 819.165771484375  loc loss 50.78450012207031\n",
      "cls loss 306.8019714355469  loc loss 20.998064041137695\n",
      "cls loss 799.474853515625  loc loss 53.77353286743164\n",
      "cls loss 567.253662109375  loc loss 44.21166229248047\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 776.4654541015625  loc loss 60.0887451171875\n",
      "cls loss 393.59063720703125  loc loss 14.475398063659668\n",
      "cls loss 582.9757080078125  loc loss 31.432483673095703\n",
      "cls loss 566.4488525390625  loc loss 38.288536071777344\n",
      "cls loss 464.6722717285156  loc loss 26.462406158447266\n",
      "cls loss 289.3216552734375  loc loss 14.924468994140625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 9., 9., 1., 9., 9., 9., 9., 1., 9.])\n",
      "cls loss 982.81494140625  loc loss 82.9761734008789\n",
      "cls loss 581.3304443359375  loc loss 30.97937774658203\n",
      "cls loss 832.640625  loc loss 70.9114990234375\n",
      "cls loss 355.670166015625  loc loss 25.1127872467041\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 42., 42.])\n",
      "cls loss 626.5419921875  loc loss 46.163028717041016\n",
      "cls loss 673.352783203125  loc loss 49.09059143066406\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  2.,  1.,  1.,  1., 38.,\n",
      "         1.,  1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 38., 38., 38.,  1., 38., 38., 38.,  1.,  1., 38.,  1.,\n",
      "         1.])\n",
      "cls loss 409.02679443359375  loc loss 29.394174575805664\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  8.,  8.])\n",
      "cls loss 966.9594116210938  loc loss 62.415000915527344\n",
      "cls loss 951.9306030273438  loc loss 68.01155853271484\n",
      "cls loss 372.5057067871094  loc loss 21.327848434448242\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([4., 1., 1., 4.])\n",
      "cls loss 536.9591674804688  loc loss 36.644012451171875\n",
      "cls loss 644.4822998046875  loc loss 39.7376708984375\n",
      "cls loss 285.5279846191406  loc loss 13.739385604858398\n",
      "cls loss 390.3448486328125  loc loss 24.277183532714844\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([51.,  1.])\n",
      "cls loss 286.1386413574219  loc loss 11.757564544677734\n",
      "cls loss 381.892822265625  loc loss 21.116119384765625\n",
      "cls loss 662.4974975585938  loc loss 37.91253662109375\n",
      "cls loss 711.427490234375  loc loss 52.53828430175781\n",
      "cls loss 968.2545776367188  loc loss 53.02521896362305\n",
      "cls loss 1178.0032958984375  loc loss 80.04995727539062\n",
      "cls loss 524.1878051757812  loc loss 31.42910385131836\n",
      "cls loss 732.829833984375  loc loss 53.051963806152344\n",
      "cls loss 773.806640625  loc loss 56.12184524536133\n",
      "cls loss 617.11767578125  loc loss 35.620601654052734\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  3.,  1.,  1.,  1.,  3.,  1.,  1.,\n",
      "         1.,  1.,  1.])\n",
      "cls loss 624.9111328125  loc loss 30.294212341308594\n",
      "cls loss 726.7863159179688  loc loss 37.17824935913086\n",
      "cls loss 651.972412109375  loc loss 34.50452423095703\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "cls loss 540.0438842773438  loc loss 32.0208740234375\n",
      "cls loss 317.1748046875  loc loss 25.95277214050293\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3.])\n",
      "cls loss 270.44793701171875  loc loss 13.081979751586914\n",
      "cls loss 477.2548828125  loc loss 32.54603958129883\n",
      "cls loss 384.6242370605469  loc loss 29.682588577270508\n",
      "cls loss 688.989501953125  loc loss 46.87457275390625\n",
      "cls loss 476.7795104980469  loc loss 24.406044006347656\n",
      "cls loss 384.8720703125  loc loss 26.872398376464844\n",
      "cls loss 1146.576904296875  loc loss 77.82530212402344\n",
      "cls loss 500.23199462890625  loc loss 38.426544189453125\n",
      "cls loss 371.9314880371094  loc loss 28.285015106201172\n",
      "cls loss 484.94903564453125  loc loss 28.197158813476562\n",
      "cls loss 435.96429443359375  loc loss 31.494781494140625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 792.805908203125  loc loss 53.39649200439453\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  9., 64., 64., 64., 64., 64., 64., 64., 64., 64.,  9.,  9.,  9.,\n",
      "         9.])\n",
      "cls loss 438.4586181640625  loc loss 21.702472686767578\n",
      "cls loss 990.057861328125  loc loss 80.66268157958984\n",
      "cls loss 523.46142578125  loc loss 35.06599426269531\n",
      "cls loss 687.369873046875  loc loss 48.99739456176758\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.,  3.,  3.])\n",
      "cls loss 442.6519775390625  loc loss 25.861328125\n",
      "cls loss 486.1533203125  loc loss 32.33902359008789\n",
      "cls loss 480.5467529296875  loc loss 35.05491256713867\n",
      "cls loss 514.164306640625  loc loss 37.70125961303711\n",
      "cls loss 521.1915283203125  loc loss 41.95759582519531\n",
      "cls loss 525.6314697265625  loc loss 39.609336853027344\n",
      "cls loss 500.1997985839844  loc loss 39.55786895751953\n",
      "cls loss 544.0205078125  loc loss 32.864837646484375\n",
      "cls loss 659.8167724609375  loc loss 45.60272216796875\n",
      "cls loss 565.3314819335938  loc loss 31.714391708374023\n",
      "cls loss 458.9251708984375  loc loss 20.15428924560547\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21.])\n",
      "cls loss 335.161376953125  loc loss 18.783767700195312\n",
      "cls loss 453.77496337890625  loc loss 38.59651565551758\n",
      "cls loss 664.7974853515625  loc loss 47.605262756347656\n",
      "cls loss 408.33428955078125  loc loss 23.139720916748047\n",
      "cls loss 552.923828125  loc loss 33.93678665161133\n",
      "cls loss 1011.6952514648438  loc loss 55.40475082397461\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 42., 42.,  1.,  1.])\n",
      "cls loss 512.6297607421875  loc loss 33.10728454589844\n",
      "cls loss 338.29547119140625  loc loss 24.85716438293457\n",
      "cls loss 486.45806884765625  loc loss 36.79623031616211\n",
      "cls loss 685.7691650390625  loc loss 55.00092697143555\n",
      "cls loss 439.9935607910156  loc loss 28.425045013427734\n",
      "cls loss 635.3409423828125  loc loss 48.723106384277344\n",
      "cls loss 610.4122314453125  loc loss 45.643402099609375\n",
      "cls loss 660.8099975585938  loc loss 38.6380500793457\n",
      "cls loss 511.48040771484375  loc loss 31.646488189697266\n",
      "cls loss 469.6678466796875  loc loss 28.5369873046875\n",
      "cls loss 376.7322082519531  loc loss 15.358797073364258\n",
      "cls loss 461.9383239746094  loc loss 31.327129364013672\n",
      "cls loss 701.3320922851562  loc loss 55.254737854003906\n",
      "cls loss 564.7534790039062  loc loss 35.818485260009766\n",
      "cls loss 530.1455688476562  loc loss 39.657325744628906\n",
      "cls loss 588.091796875  loc loss 35.04718780517578\n",
      "cls loss 849.989501953125  loc loss 59.4356803894043\n",
      "cls loss 616.607666015625  loc loss 46.9356803894043\n",
      "cls loss 720.7994384765625  loc loss 41.002235412597656\n",
      "cls loss 415.6939697265625  loc loss 21.05614471435547\n",
      "cls loss 591.884033203125  loc loss 38.690391540527344\n",
      "cls loss 549.4620361328125  loc loss 33.868629455566406\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 5., 5., 5., 5., 5., 5.])\n",
      "cls loss 394.73291015625  loc loss 26.726058959960938\n",
      "cls loss 472.65533447265625  loc loss 27.47361946105957\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([13.])\n",
      "cls loss 324.60821533203125  loc loss 20.596233367919922\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([44., 10.,  1.,  1.,  1.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 338.0626220703125  loc loss 20.49834442138672\n",
      "cls loss 639.48193359375  loc loss 32.37647247314453\n",
      "cls loss 515.8870849609375  loc loss 29.487701416015625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19., 19., 19., 19., 19., 19., 19.])\n",
      "cls loss 650.9225463867188  loc loss 34.525691986083984\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([56.])\n",
      "cls loss 1102.1590576171875  loc loss 71.2125244140625\n",
      "cls loss 656.9429321289062  loc loss 52.15544509887695\n",
      "cls loss 843.8612670898438  loc loss 60.16721725463867\n",
      "cls loss 845.9502563476562  loc loss 64.7939453125\n",
      "cls loss 522.39306640625  loc loss 29.818828582763672\n",
      "cls loss 817.5079345703125  loc loss 59.35403060913086\n",
      "cls loss 477.02593994140625  loc loss 30.92635154724121\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 36.])\n",
      "cls loss 580.2692260742188  loc loss 32.49831771850586\n",
      "cls loss 521.3759765625  loc loss 36.312286376953125\n",
      "cls loss 506.9327087402344  loc loss 30.891036987304688\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5.])\n",
      "cls loss 609.2042236328125  loc loss 36.93058776855469\n",
      "cls loss 329.4732666015625  loc loss 17.830537796020508\n",
      "cls loss 749.99560546875  loc loss 41.70925521850586\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "cls loss 650.8629150390625  loc loss 43.75918197631836\n",
      "cls loss 656.5631103515625  loc loss 43.25533676147461\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 598.64599609375  loc loss 43.48851776123047\n",
      "cls loss 712.7440185546875  loc loss 50.72187042236328\n",
      "cls loss 585.0421752929688  loc loss 54.650634765625\n",
      "cls loss 420.63140869140625  loc loss 29.777469635009766\n",
      "cls loss 528.396728515625  loc loss 38.215145111083984\n",
      "cls loss 540.3067626953125  loc loss 34.591217041015625\n",
      "cls loss 831.0966796875  loc loss 47.994468688964844\n",
      "cls loss 383.9135437011719  loc loss 19.16358757019043\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 11., 15., 10., 10., 10., 10., 10.])\n",
      "cls loss 893.9779052734375  loc loss 56.167076110839844\n",
      "cls loss 482.2738342285156  loc loss 33.888729095458984\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3.])\n",
      "cls loss 541.3949584960938  loc loss 35.798641204833984\n",
      "cls loss 492.262451171875  loc loss 27.792207717895508\n",
      "cls loss 529.16748046875  loc loss 26.299028396606445\n",
      "cls loss 673.1751708984375  loc loss 33.02488327026367\n",
      "cls loss 370.7469177246094  loc loss 17.54580307006836\n",
      "cls loss 520.44287109375  loc loss 34.347164154052734\n",
      "cls loss 573.9881591796875  loc loss 44.73151779174805\n",
      "cls loss 493.087158203125  loc loss 37.40671157836914\n",
      "cls loss 1155.771240234375  loc loss 86.17542266845703\n",
      "cls loss 821.545166015625  loc loss 53.80815505981445\n",
      "cls loss 530.3862915039062  loc loss 38.40167999267578\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  9.,  9.,  9.,  6.,  6., 85., 85.,  8.,  1.,  1.,  1.,  1.,\n",
      "         6.,  6.])\n",
      "cls loss 368.5920104980469  loc loss 27.638547897338867\n",
      "cls loss 868.1978759765625  loc loss 61.25107955932617\n",
      "cls loss 1017.2427978515625  loc loss 65.15620422363281\n",
      "cls loss 704.500244140625  loc loss 47.48701858520508\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10.,  3.,  3., 10.])\n",
      "cls loss 474.52239990234375  loc loss 26.36319351196289\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([7.])\n",
      "cls loss 589.21435546875  loc loss 40.4809684753418\n",
      "cls loss 605.6669921875  loc loss 36.725074768066406\n",
      "cls loss 529.4466552734375  loc loss 43.64871597290039\n",
      "cls loss 747.127685546875  loc loss 62.29450225830078\n",
      "cls loss 548.6461791992188  loc loss 37.65896224975586\n",
      "cls loss 750.7061157226562  loc loss 49.759647369384766\n",
      "cls loss 931.7083740234375  loc loss 57.03153991699219\n",
      "cls loss 551.7219848632812  loc loss 39.0545654296875\n",
      "cls loss 600.0841674804688  loc loss 42.44466781616211\n",
      "cls loss 511.99713134765625  loc loss 38.00092697143555\n",
      "cls loss 714.0517578125  loc loss 58.89830780029297\n",
      "cls loss 585.5926513671875  loc loss 37.60663604736328\n",
      "cls loss 470.7577819824219  loc loss 27.720521926879883\n",
      "cls loss 718.7967529296875  loc loss 54.230552673339844\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([62.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([62.])\n",
      "cls loss 327.31439208984375  loc loss 16.957069396972656\n",
      "cls loss 572.0589599609375  loc loss 40.197357177734375\n",
      "cls loss 555.7521362304688  loc loss 36.59999465942383\n",
      "cls loss 386.70233154296875  loc loss 17.10537338256836\n",
      "cls loss 705.0902709960938  loc loss 47.43159866333008\n",
      "cls loss 711.538330078125  loc loss 41.36555480957031\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([28.])\n",
      "cls loss 782.2489013671875  loc loss 43.13069152832031\n",
      "cls loss 689.6204833984375  loc loss 42.83739471435547\n",
      "cls loss 682.823974609375  loc loss 44.135528564453125\n",
      "cls loss 688.679931640625  loc loss 45.61894989013672\n",
      "cls loss 958.0484008789062  loc loss 64.70345306396484\n",
      "cls loss 533.6126708984375  loc loss 34.65969467163086\n",
      "cls loss 660.9891357421875  loc loss 40.95709991455078\n",
      "cls loss 583.5308837890625  loc loss 49.25291061401367\n",
      "cls loss 935.9772338867188  loc loss 73.82318878173828\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([81.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 656.6883544921875  loc loss 27.33028221130371\n",
      "cls loss 498.4068603515625  loc loss 25.49057388305664\n",
      "cls loss 424.839599609375  loc loss 27.099693298339844\n",
      "cls loss 362.7327880859375  loc loss 13.922800064086914\n",
      "cls loss 404.32196044921875  loc loss 26.5427188873291\n",
      "cls loss 437.76446533203125  loc loss 27.066478729248047\n",
      "cls loss 513.84228515625  loc loss 32.1379508972168\n",
      "cls loss 660.5565795898438  loc loss 53.00155258178711\n",
      "cls loss 739.6567993164062  loc loss 50.23794937133789\n",
      "cls loss 1403.6715087890625  loc loss 95.54435729980469\n",
      "cls loss 571.2789916992188  loc loss 29.72123908996582\n",
      "cls loss 683.6241455078125  loc loss 47.11481857299805\n",
      "cls loss 482.3308410644531  loc loss 29.59827995300293\n",
      "cls loss 626.9281005859375  loc loss 35.564395904541016\n",
      "cls loss 561.5134887695312  loc loss 32.17890167236328\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([44., 44.])\n",
      "cls loss 505.94873046875  loc loss 25.357288360595703\n",
      "cls loss 504.0692443847656  loc loss 36.51568603515625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15.])\n",
      "cls loss 598.2670288085938  loc loss 30.165794372558594\n",
      "cls loss 291.935791015625  loc loss 16.923158645629883\n",
      "cls loss 596.6994018554688  loc loss 35.025699615478516\n",
      "cls loss 334.9296875  loc loss 20.838871002197266\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([1., 3., 3.])\n",
      "cls loss 372.85736083984375  loc loss 28.204442977905273\n",
      "cls loss 310.8538818359375  loc loss 13.228696823120117\n",
      "cls loss 569.45703125  loc loss 32.317081451416016\n",
      "cls loss 599.7621459960938  loc loss 35.42104721069336\n",
      "cls loss 537.1438598632812  loc loss 35.29467010498047\n",
      "cls loss 561.2630615234375  loc loss 31.189769744873047\n",
      "cls loss 444.07098388671875  loc loss 34.21507263183594\n",
      "cls loss 603.2600708007812  loc loss 41.05077362060547\n",
      "cls loss 469.91455078125  loc loss 31.15903663635254\n",
      "cls loss 581.3881225585938  loc loss 41.32352828979492\n",
      "cls loss 370.2945861816406  loc loss 23.384727478027344\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 690.43115234375  loc loss 43.03730010986328\n",
      "cls loss 801.1865234375  loc loss 40.066688537597656\n",
      "cls loss 707.82421875  loc loss 49.70225143432617\n",
      "cls loss 700.221923828125  loc loss 53.11778259277344\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10., 10., 10.,  1.,  1.,  1.,  1.,  1.,  1.,  8.,  8.,\n",
      "         1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10., 10., 10.,  1.,  1.,  1.,  1.,  1.,  1.,  8.,  8.,\n",
      "         1.])\n",
      "cls loss 672.114013671875  loc loss 31.962369918823242\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 3., 3., 3.])\n",
      "cls loss 564.9908447265625  loc loss 35.64509582519531\n",
      "cls loss 390.5209655761719  loc loss 21.784086227416992\n",
      "cls loss 309.2593994140625  loc loss 15.278853416442871\n",
      "cls loss 526.2161254882812  loc loss 39.430423736572266\n",
      "cls loss 411.61578369140625  loc loss 21.722827911376953\n",
      "cls loss 463.74932861328125  loc loss 31.04632568359375\n",
      "cls loss 520.5083618164062  loc loss 36.67642593383789\n",
      "cls loss 730.9111328125  loc loss 51.79257583618164\n",
      "cls loss 617.802734375  loc loss 31.075538635253906\n",
      "cls loss 592.5907592773438  loc loss 34.112056732177734\n",
      "cls loss 672.8519897460938  loc loss 44.505027770996094\n",
      "cls loss 487.5284423828125  loc loss 36.55941390991211\n",
      "cls loss 889.2831420898438  loc loss 65.45785522460938\n",
      "cls loss 457.43878173828125  loc loss 23.692214965820312\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 678.727294921875  loc loss 41.866729736328125\n",
      "cls loss 343.1298828125  loc loss 14.872520446777344\n",
      "cls loss 838.1820068359375  loc loss 53.606632232666016\n",
      "cls loss 446.1147155761719  loc loss 23.259126663208008\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 34.])\n",
      "cls loss 715.5972900390625  loc loss 38.06494903564453\n",
      "cls loss 326.4825134277344  loc loss 21.6791934967041\n",
      "cls loss 609.594970703125  loc loss 41.81303024291992\n",
      "cls loss 213.65676879882812  loc loss 16.226591110229492\n",
      "cls loss 551.29248046875  loc loss 35.78969192504883\n",
      "cls loss 533.3370971679688  loc loss 42.463592529296875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 38.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16., 16., 16.,  9.,  9.,  9., 16., 16., 16., 85.,  9.])\n",
      "cls loss 530.0975952148438  loc loss 34.88603973388672\n",
      "cls loss 598.1038818359375  loc loss 47.46143341064453\n",
      "cls loss 820.1300048828125  loc loss 58.504425048828125\n",
      "cls loss 1167.65625  loc loss 80.03430938720703\n",
      "cls loss 370.89605712890625  loc loss 18.93829345703125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3., 10.,  8.,  8., 10., 10., 10.,  3.,  3., 14.])\n",
      "cls loss 454.855224609375  loc loss 21.381771087646484\n",
      "cls loss 800.8963012695312  loc loss 40.705284118652344\n",
      "cls loss 345.7103271484375  loc loss 12.755367279052734\n",
      "cls loss 510.2012939453125  loc loss 22.23964500427246\n",
      "cls loss 673.8430786132812  loc loss 40.27977752685547\n",
      "cls loss 568.4732666015625  loc loss 37.50792694091797\n",
      "cls loss 332.18701171875  loc loss 17.249488830566406\n",
      "cls loss 372.29486083984375  loc loss 23.627960205078125\n",
      "cls loss 568.5540771484375  loc loss 37.743568420410156\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42., 42.,  1.])\n",
      "cls loss 551.5975952148438  loc loss 39.926300048828125\n",
      "cls loss 462.691650390625  loc loss 27.685407638549805\n",
      "cls loss 614.99365234375  loc loss 47.63976287841797\n",
      "cls loss 709.4896240234375  loc loss 46.840789794921875\n",
      "cls loss 500.5873718261719  loc loss 32.5142822265625\n",
      "cls loss 611.5484619140625  loc loss 43.15186309814453\n",
      "cls loss 397.70294189453125  loc loss 26.249305725097656\n",
      "cls loss 417.3302917480469  loc loss 28.87651252746582\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20.])\n",
      "cls loss 334.91436767578125  loc loss 18.46207046508789\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([11.])\n",
      "cls loss 419.8302307128906  loc loss 21.703903198242188\n",
      "cls loss 297.1393737792969  loc loss 15.9110107421875\n",
      "cls loss 638.48828125  loc loss 50.43369674682617\n",
      "cls loss 301.4951477050781  loc loss 13.565816879272461\n",
      "cls loss 614.0550537109375  loc loss 34.57086944580078\n",
      "cls loss 336.49407958984375  loc loss 21.1961612701416\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 35., 27.])\n",
      "cls loss 567.6400146484375  loc loss 37.02095031738281\n",
      "cls loss 602.4932250976562  loc loss 46.77290725708008\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 435.163330078125  loc loss 26.56730842590332\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([42.,  1.])\n",
      "cls loss 566.7114868164062  loc loss 40.12962341308594\n",
      "cls loss 515.5073852539062  loc loss 30.373088836669922\n",
      "cls loss 644.24755859375  loc loss 37.802345275878906\n",
      "cls loss 746.90576171875  loc loss 50.8397331237793\n",
      "cls loss 685.2747802734375  loc loss 42.671424865722656\n",
      "cls loss 465.8828125  loc loss 36.03919982910156\n",
      "cls loss 403.11871337890625  loc loss 31.466289520263672\n",
      "cls loss 269.0694580078125  loc loss 12.614273071289062\n",
      "cls loss 479.7444763183594  loc loss 27.134571075439453\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 1., 1.])\n",
      "cls loss 465.44757080078125  loc loss 24.97585678100586\n",
      "cls loss 512.963134765625  loc loss 35.024696350097656\n",
      "cls loss 518.9074096679688  loc loss 32.91440200805664\n",
      "cls loss 418.22027587890625  loc loss 30.5781307220459\n",
      "cls loss 502.6797790527344  loc loss 30.38399887084961\n",
      "cls loss 527.72509765625  loc loss 40.265281677246094\n",
      "cls loss 732.95654296875  loc loss 44.91796875\n",
      "cls loss 624.1980590820312  loc loss 49.325618743896484\n",
      "cls loss 598.7852172851562  loc loss 36.1426887512207\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 465.3502502441406  loc loss 32.68254852294922\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 549.3179931640625  loc loss 27.73508644104004\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([81.])\n",
      "cls loss 668.2053833007812  loc loss 42.133548736572266\n",
      "cls loss 426.3267822265625  loc loss 28.486488342285156\n",
      "cls loss 296.1075439453125  loc loss 17.98604965209961\n",
      "cls loss 470.9081726074219  loc loss 24.853952407836914\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3.,  1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 19.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 19.])\n",
      "cls loss 611.52490234375  loc loss 42.35193634033203\n",
      "cls loss 364.471923828125  loc loss 18.219831466674805\n",
      "cls loss 377.06585693359375  loc loss 22.81373405456543\n",
      "cls loss 714.6551513671875  loc loss 52.3418083190918\n",
      "cls loss 368.7305908203125  loc loss 23.420249938964844\n",
      "cls loss 461.5513916015625  loc loss 32.0258903503418\n",
      "cls loss 552.0087890625  loc loss 37.48057556152344\n",
      "cls loss 433.8021545410156  loc loss 32.059871673583984\n",
      "cls loss 572.3394165039062  loc loss 34.16912078857422\n",
      "cls loss 640.2261352539062  loc loss 44.93707275390625\n",
      "cls loss 763.0411376953125  loc loss 70.98812866210938\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 81.])\n",
      "cls loss 569.312744140625  loc loss 30.683095932006836\n",
      "cls loss 481.18853759765625  loc loss 28.6414737701416\n",
      "cls loss 562.5185546875  loc loss 29.926095962524414\n",
      "cls loss 419.7348937988281  loc loss 20.49854850769043\n",
      "cls loss 382.25933837890625  loc loss 23.90890884399414\n",
      "cls loss 441.47027587890625  loc loss 31.74429702758789\n",
      "cls loss 354.0868835449219  loc loss 24.65500831604004\n",
      "cls loss 282.88604736328125  loc loss 18.36693572998047\n",
      "cls loss 371.77056884765625  loc loss 25.34471321105957\n",
      "cls loss 523.79638671875  loc loss 32.270484924316406\n",
      "cls loss 426.56396484375  loc loss 34.12882995605469\n",
      "cls loss 451.4687805175781  loc loss 36.351829528808594\n",
      "cls loss 279.5404052734375  loc loss 20.690019607543945\n",
      "cls loss 924.855224609375  loc loss 67.13743591308594\n",
      "cls loss 606.1800537109375  loc loss 40.86481475830078\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 513.5985107421875  loc loss 27.573070526123047\n",
      "cls loss 552.7730712890625  loc loss 37.81110382080078\n",
      "cls loss 462.79132080078125  loc loss 26.761796951293945\n",
      "cls loss 639.2369384765625  loc loss 41.878971099853516\n",
      "cls loss 630.5833740234375  loc loss 40.82662582397461\n",
      "cls loss 560.9436645507812  loc loss 36.15019607543945\n",
      "cls loss 459.6141052246094  loc loss 26.556507110595703\n",
      "cls loss 341.3741760253906  loc loss 21.228572845458984\n",
      "cls loss 516.6536865234375  loc loss 31.971622467041016\n",
      "cls loss 536.1160888671875  loc loss 37.38044738769531\n",
      "cls loss 578.5938720703125  loc loss 33.227935791015625\n",
      "cls loss 722.476318359375  loc loss 55.08053970336914\n",
      "cls loss 718.8731079101562  loc loss 58.09947204589844\n",
      "cls loss 530.28271484375  loc loss 38.418487548828125\n",
      "cls loss 688.4224243164062  loc loss 55.22686767578125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1., 38., 47.,  1.,  1.,  1.,  1.,  1., 62.])\n",
      "cls loss 510.8305358886719  loc loss 25.82931900024414\n",
      "cls loss 618.4805908203125  loc loss 34.96453857421875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 625.3216552734375  loc loss 37.56342697143555\n",
      "cls loss 681.9288330078125  loc loss 50.74725341796875\n",
      "cls loss 479.4551696777344  loc loss 24.2180233001709\n",
      "cls loss 538.951416015625  loc loss 44.20292663574219\n",
      "cls loss 494.2630920410156  loc loss 30.372154235839844\n",
      "cls loss 304.54168701171875  loc loss 12.335831642150879\n",
      "cls loss 486.1338195800781  loc loss 27.736896514892578\n",
      "cls loss 407.12298583984375  loc loss 18.669246673583984\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1., 35.])\n",
      "cls loss 501.1642150878906  loc loss 24.36409568786621\n",
      "cls loss 657.67919921875  loc loss 36.60027313232422\n",
      "cls loss 643.9950561523438  loc loss 42.7630500793457\n",
      "cls loss 575.3106689453125  loc loss 48.340843200683594\n",
      "cls loss 465.4782409667969  loc loss 37.82950973510742\n",
      "cls loss 609.7069091796875  loc loss 46.102752685546875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 347.99078369140625  loc loss 20.329448699951172\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 512.8692626953125  loc loss 24.603540420532227\n",
      "cls loss 812.4558715820312  loc loss 43.51592254638672\n",
      "cls loss 993.7119140625  loc loss 74.9400634765625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 512.6900024414062  loc loss 26.182106018066406\n",
      "cls loss 443.2717590332031  loc loss 28.353633880615234\n",
      "cls loss 454.1278076171875  loc loss 25.471412658691406\n",
      "cls loss 484.16943359375  loc loss 32.90245056152344\n",
      "cls loss 447.3762512207031  loc loss 19.06751251220703\n",
      "cls loss 741.6572265625  loc loss 52.91659927368164\n",
      "cls loss 606.2701416015625  loc loss 37.88359451293945\n",
      "cls loss 344.5614318847656  loc loss 21.529787063598633\n",
      "cls loss 599.1591796875  loc loss 33.3847770690918\n",
      "cls loss 710.3594360351562  loc loss 57.382179260253906\n",
      "cls loss 591.3358154296875  loc loss 37.6486930847168\n",
      "cls loss 536.6083984375  loc loss 28.70184326171875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.])\n",
      "cls loss 489.76141357421875  loc loss 35.81779479980469\n",
      "cls loss 443.1870422363281  loc loss 34.57123565673828\n",
      "cls loss 618.7820434570312  loc loss 42.12907028198242\n",
      "cls loss 920.541259765625  loc loss 75.15022277832031\n",
      "cls loss 422.9394226074219  loc loss 20.10382843017578\n",
      "cls loss 538.0364990234375  loc loss 33.23980712890625\n",
      "cls loss 433.46282958984375  loc loss 24.151580810546875\n",
      "cls loss 470.49615478515625  loc loss 28.83399772644043\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 21., 21., 21.])\n",
      "cls loss 503.6506652832031  loc loss 29.576236724853516\n",
      "cls loss 476.8818359375  loc loss 22.065977096557617\n",
      "cls loss 493.3767395019531  loc loss 32.85547637939453\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 35.])\n",
      "cls loss 657.2066650390625  loc loss 42.907569885253906\n",
      "cls loss 241.05789184570312  loc loss 13.288021087646484\n",
      "cls loss 381.1265869140625  loc loss 26.14191436767578\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 383.70135498046875  loc loss 17.98377799987793\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 38., 38.,  9., 38.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1.,  1.])\n",
      "cls loss 428.74957275390625  loc loss 29.151283264160156\n",
      "cls loss 694.0555419921875  loc loss 46.424129486083984\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 2.,  1., 77., 31., 10., 10.,  1.,  4., 10.])\n",
      "cls loss 366.1943359375  loc loss 17.81960105895996\n",
      "cls loss 666.8336181640625  loc loss 41.08038330078125\n",
      "cls loss 1322.271484375  loc loss 80.55313873291016\n",
      "cls loss 438.5354309082031  loc loss 27.622419357299805\n",
      "cls loss 596.4427490234375  loc loss 45.32377243041992\n",
      "cls loss 442.9127197265625  loc loss 24.637340545654297\n",
      "cls loss 451.14141845703125  loc loss 22.069377899169922\n",
      "cls loss 673.7216186523438  loc loss 30.158042907714844\n",
      "cls loss 658.29248046875  loc loss 34.717952728271484\n",
      "cls loss 570.4732666015625  loc loss 39.191436767578125\n",
      "cls loss 436.9111328125  loc loss 21.498245239257812\n",
      "cls loss 480.9432373046875  loc loss 24.67807388305664\n",
      "cls loss 863.2183837890625  loc loss 54.57164001464844\n",
      "cls loss 735.8231201171875  loc loss 46.27123260498047\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1., 42., 42., 42., 42., 42., 42.,  1.,\n",
      "         1.,  1.,  1., 42.,  1.,  1., 42.,  1.])\n",
      "cls loss 413.8466796875  loc loss 28.698204040527344\n",
      "cls loss 644.30908203125  loc loss 39.909889221191406\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.])\n",
      "cls loss 274.12689208984375  loc loss 17.27691078186035\n",
      "cls loss 620.4557495117188  loc loss 41.58592987060547\n",
      "cls loss 503.95703125  loc loss 35.60561752319336\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([11.])\n",
      "cls loss 309.0754089355469  loc loss 17.862701416015625\n",
      "cls loss 398.163330078125  loc loss 18.11966896057129\n",
      "cls loss 419.11956787109375  loc loss 18.50606346130371\n",
      "cls loss 618.0396728515625  loc loss 40.160457611083984\n",
      "cls loss 582.7500610351562  loc loss 30.853130340576172\n",
      "cls loss 539.8565673828125  loc loss 37.36251449584961\n",
      "cls loss 797.4029541015625  loc loss 42.214019775390625\n",
      "cls loss 410.17413330078125  loc loss 24.64194107055664\n",
      "cls loss 773.669921875  loc loss 57.229522705078125\n",
      "cls loss 400.67254638671875  loc loss 25.96294403076172\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 366.2964172363281  loc loss 26.248653411865234\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1., 38., 38., 42.])\n",
      "cls loss 470.37725830078125  loc loss 35.227882385253906\n",
      "cls loss 434.7924499511719  loc loss 25.275108337402344\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 369.67034912109375  loc loss 27.9902286529541\n",
      "cls loss 882.213623046875  loc loss 61.66442108154297\n",
      "cls loss 540.7796630859375  loc loss 36.04969024658203\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10.,  3.,  3.,  6.,  8.,  8.,  1.,  1.,  1., 10.])\n",
      "cls loss 464.4512023925781  loc loss 24.596084594726562\n",
      "cls loss 285.35919189453125  loc loss 10.66224193572998\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10.,  3.])\n",
      "cls loss 433.0613708496094  loc loss 24.24562644958496\n",
      "cls loss 271.03228759765625  loc loss 12.800210952758789\n",
      "cls loss 525.402587890625  loc loss 38.233280181884766\n",
      "cls loss 593.420166015625  loc loss 39.66078186035156\n",
      "cls loss 442.443359375  loc loss 27.035079956054688\n",
      "cls loss 314.8871154785156  loc loss 15.754592895507812\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 34.])\n",
      "cls loss 729.281005859375  loc loss 46.57850646972656\n",
      "cls loss 777.9249267578125  loc loss 66.73283386230469\n",
      "cls loss 511.2872314453125  loc loss 39.69546127319336\n",
      "cls loss 386.0129089355469  loc loss 28.65045166015625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.,  1.])\n",
      "cls loss 449.5600280761719  loc loss 22.8007755279541\n",
      "cls loss 686.1622314453125  loc loss 54.27333068847656\n",
      "cls loss 1044.51513671875  loc loss 67.6947250366211\n",
      "cls loss 864.183837890625  loc loss 45.274261474609375\n",
      "cls loss 510.8172912597656  loc loss 27.610469818115234\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 621.18505859375  loc loss 36.25156784057617\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10.])\n",
      "cls loss 383.7750244140625  loc loss 20.67840003967285\n",
      "cls loss 555.76220703125  loc loss 28.009075164794922\n",
      "cls loss 511.9627990722656  loc loss 31.10203742980957\n",
      "cls loss 369.35260009765625  loc loss 23.122074127197266\n",
      "cls loss 465.83697509765625  loc loss 32.27305221557617\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21.,\n",
      "        21.])\n",
      "cls loss 651.819091796875  loc loss 36.68559265136719\n",
      "cls loss 507.24652099609375  loc loss 31.914091110229492\n",
      "cls loss 329.10772705078125  loc loss 15.366067886352539\n",
      "cls loss 688.1815185546875  loc loss 45.60841369628906\n",
      "cls loss 537.9976196289062  loc loss 36.81717300415039\n",
      "cls loss 376.1336669921875  loc loss 22.917722702026367\n",
      "cls loss 795.58203125  loc loss 53.02767562866211\n",
      "cls loss 964.319580078125  loc loss 66.16712951660156\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15., 85.])\n",
      "cls loss 586.7760009765625  loc loss 38.76200485229492\n",
      "cls loss 611.446044921875  loc loss 45.49652099609375\n",
      "cls loss 614.0787353515625  loc loss 44.89683532714844\n",
      "cls loss 558.4389038085938  loc loss 31.24630355834961\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 8., 8.])\n",
      "cls loss 364.103759765625  loc loss 18.49355697631836\n",
      "cls loss 379.44207763671875  loc loss 27.011873245239258\n",
      "cls loss 483.9125671386719  loc loss 29.691152572631836\n",
      "cls loss 397.55328369140625  loc loss 22.738849639892578\n",
      "cls loss 466.3115539550781  loc loss 27.98158073425293\n",
      "cls loss 608.4151611328125  loc loss 38.189334869384766\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1., 35., 27., 27.,  1., 27.,  1.])\n",
      "cls loss 782.6826171875  loc loss 56.59745788574219\n",
      "cls loss 401.9407958984375  loc loss 27.24669075012207\n",
      "cls loss 473.48828125  loc loss 34.807647705078125\n",
      "cls loss 444.2747802734375  loc loss 39.36701583862305\n",
      "cls loss 404.0654296875  loc loss 31.49116325378418\n",
      "cls loss 443.25238037109375  loc loss 35.48858642578125\n",
      "cls loss 442.206787109375  loc loss 35.51349639892578\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  2.,  2.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  2.,  2.])\n",
      "cls loss 272.7176513671875  loc loss 10.318646430969238\n",
      "cls loss 704.242919921875  loc loss 44.17345428466797\n",
      "cls loss 499.26239013671875  loc loss 23.74904441833496\n",
      "cls loss 781.39453125  loc loss 57.91985321044922\n",
      "cls loss 333.0789489746094  loc loss 19.694669723510742\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 19., 19., 19., 16.])\n",
      "cls loss 348.5429992675781  loc loss 15.068292617797852\n",
      "cls loss 280.161376953125  loc loss 12.211036682128906\n",
      "cls loss 425.5188293457031  loc loss 22.061386108398438\n",
      "cls loss 555.6043090820312  loc loss 37.47713851928711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 296.7212829589844  loc loss 20.05194091796875\n",
      "cls loss 624.191162109375  loc loss 47.67164611816406\n",
      "cls loss 451.16064453125  loc loss 31.728153228759766\n",
      "cls loss 508.6986083984375  loc loss 32.528167724609375\n",
      "cls loss 634.1893920898438  loc loss 44.03342819213867\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 705.3896484375  loc loss 30.329898834228516\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 875.119384765625  loc loss 76.89862060546875\n",
      "cls loss 1088.9718017578125  loc loss 105.7611083984375\n",
      "cls loss 570.6942749023438  loc loss 38.11705017089844\n",
      "cls loss 513.1154174804688  loc loss 34.147647857666016\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3.,  3.,  3.,  3.,  3., 10.])\n",
      "cls loss 295.6584777832031  loc loss 17.187850952148438\n",
      "cls loss 545.90576171875  loc loss 28.63433074951172\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 1., 1., 1., 3., 3., 3., 3.])\n",
      "cls loss 428.2542419433594  loc loss 27.840682983398438\n",
      "cls loss 800.144287109375  loc loss 53.70899200439453\n",
      "cls loss 635.725830078125  loc loss 42.741416931152344\n",
      "cls loss 427.9400634765625  loc loss 25.11235809326172\n",
      "cls loss 642.808349609375  loc loss 46.43439483642578\n",
      "cls loss 408.282470703125  loc loss 30.43183708190918\n",
      "cls loss 659.746337890625  loc loss 45.50952911376953\n",
      "cls loss 462.8861389160156  loc loss 44.43097686767578\n",
      "cls loss 501.44329833984375  loc loss 32.01958465576172\n",
      "cls loss 1009.89306640625  loc loss 84.02761840820312\n",
      "cls loss 669.663330078125  loc loss 48.11842727661133\n",
      "cls loss 465.7894287109375  loc loss 22.662403106689453\n",
      "cls loss 316.70428466796875  loc loss 13.574522972106934\n",
      "cls loss 358.1173095703125  loc loss 17.052371978759766\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3., 10., 10., 10., 10., 10., 10., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10., 10., 10., 10., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 11., 10., 10., 10., 10., 10.,  3.,  3.,  3.,  3.,  3.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 11., 10., 10., 10., 10., 10.,  3.,  3.,  3.,  3.,  3.])\n",
      "cls loss 348.2089538574219  loc loss 15.67005729675293\n",
      "cls loss 409.0091247558594  loc loss 19.782100677490234\n",
      "cls loss 344.0155334472656  loc loss 21.14716148376465\n",
      "cls loss 344.40997314453125  loc loss 15.07020092010498\n",
      "cls loss 394.35479736328125  loc loss 32.10254669189453\n",
      "cls loss 325.53765869140625  loc loss 12.672471046447754\n",
      "cls loss 600.46337890625  loc loss 41.279937744140625\n",
      "cls loss 521.4618530273438  loc loss 37.39492416381836\n",
      "cls loss 806.9347534179688  loc loss 51.408321380615234\n",
      "cls loss 396.19940185546875  loc loss 29.8658447265625\n",
      "cls loss 720.70458984375  loc loss 47.96232604980469\n",
      "cls loss 595.4779663085938  loc loss 39.288543701171875\n",
      "cls loss 545.9456787109375  loc loss 36.639305114746094\n",
      "cls loss 548.776123046875  loc loss 39.879512786865234\n",
      "cls loss 746.4462890625  loc loss 49.95199966430664\n",
      "cls loss 752.01025390625  loc loss 45.489219665527344\n",
      "cls loss 356.2346496582031  loc loss 19.592252731323242\n",
      "cls loss 645.2645874023438  loc loss 48.23357391357422\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 10.,  1., 18.])\n",
      "cls loss 320.32427978515625  loc loss 21.918804168701172\n",
      "cls loss 379.26593017578125  loc loss 16.08852195739746\n",
      "cls loss 643.9141235351562  loc loss 33.7849006652832\n",
      "cls loss 916.4390869140625  loc loss 55.57871627807617\n",
      "cls loss 541.1561279296875  loc loss 38.1449089050293\n",
      "cls loss 784.4759521484375  loc loss 42.888710021972656\n",
      "cls loss 547.95654296875  loc loss 36.80768585205078\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.,  1.,  1.])\n",
      "cls loss 684.8975219726562  loc loss 45.24928665161133\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1., 38.,  1.])\n",
      "cls loss 665.7901611328125  loc loss 36.9132080078125\n",
      "cls loss 848.1434326171875  loc loss 61.07514190673828\n",
      "cls loss 449.2125549316406  loc loss 31.38457489013672\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 595.6343994140625  loc loss 39.945640563964844\n",
      "cls loss 525.6668701171875  loc loss 32.47353744506836\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3., 10.,  8.,  3., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.])\n",
      "cls loss 626.0087280273438  loc loss 35.98134231567383\n",
      "cls loss 440.21697998046875  loc loss 27.341718673706055\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3.,  3., 11.,  3., 10., 10.,  3.,  3., 10.])\n",
      "cls loss 525.2935791015625  loc loss 24.675548553466797\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3., 10., 10., 10.])\n",
      "cls loss 497.587890625  loc loss 32.84794616699219\n",
      "cls loss 447.72998046875  loc loss 23.870397567749023\n",
      "cls loss 519.8145751953125  loc loss 35.54161834716797\n",
      "cls loss 791.9696655273438  loc loss 47.5682373046875\n",
      "cls loss 518.0970458984375  loc loss 33.268577575683594\n",
      "cls loss 373.18377685546875  loc loss 32.341697692871094\n",
      "cls loss 494.6698913574219  loc loss 33.00096893310547\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 9.,  9., 85., 85.])\n",
      "cls loss 409.8056945800781  loc loss 22.95681381225586\n",
      "cls loss 476.1988220214844  loc loss 33.919254302978516\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 792.685546875  loc loss 56.39826965332031\n",
      "cls loss 693.15234375  loc loss 33.10902404785156\n",
      "cls loss 746.095458984375  loc loss 53.57975769042969\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10., 10., 10., 10.])\n",
      "cls loss 468.302978515625  loc loss 29.572738647460938\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([13.])\n",
      "cls loss 752.7664794921875  loc loss 58.662269592285156\n",
      "cls loss 273.42034912109375  loc loss 14.618790626525879\n",
      "cls loss 352.7359619140625  loc loss 17.85479736328125\n",
      "cls loss 472.8511657714844  loc loss 24.750587463378906\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19.,  1.,  1.,  1., 19., 19.])\n",
      "cls loss 470.9327087402344  loc loss 31.032207489013672\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 371.85491943359375  loc loss 27.68301773071289\n",
      "cls loss 530.0301513671875  loc loss 38.269683837890625\n",
      "cls loss 402.00439453125  loc loss 23.161592483520508\n",
      "cls loss 588.890625  loc loss 33.13739776611328\n",
      "cls loss 624.205810546875  loc loss 47.90522003173828\n",
      "cls loss 513.2733154296875  loc loss 28.12805938720703\n",
      "cls loss 719.1292724609375  loc loss 52.636817932128906\n",
      "cls loss 300.3642883300781  loc loss 13.56857681274414\n",
      "cls loss 536.4139404296875  loc loss 33.25501251220703\n",
      "cls loss 426.40478515625  loc loss 21.26006317138672\n",
      "cls loss 455.61358642578125  loc loss 24.075401306152344\n",
      "cls loss 568.1992797851562  loc loss 35.99079132080078\n",
      "cls loss 532.46240234375  loc loss 27.839771270751953\n",
      "cls loss 747.0880126953125  loc loss 48.09069061279297\n",
      "cls loss 481.04052734375  loc loss 32.277587890625\n",
      "cls loss 609.4074096679688  loc loss 42.50025177001953\n",
      "cls loss 925.9974975585938  loc loss 56.193336486816406\n",
      "cls loss 480.31085205078125  loc loss 36.66304016113281\n",
      "cls loss 566.0452270507812  loc loss 33.304264068603516\n",
      "cls loss 648.1005859375  loc loss 50.16743850708008\n",
      "cls loss 715.9916381835938  loc loss 50.57133865356445\n",
      "cls loss 889.5375366210938  loc loss 47.505191802978516\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 5.])\n",
      "cls loss 268.9134521484375  loc loss 10.562545776367188\n",
      "cls loss 337.81732177734375  loc loss 15.335969924926758\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 13.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 6., 8., 8.])\n",
      "cls loss 282.3948974609375  loc loss 14.914788246154785\n",
      "cls loss 364.0532531738281  loc loss 18.757854461669922\n",
      "cls loss 701.8955078125  loc loss 47.501686096191406\n",
      "cls loss 313.173095703125  loc loss 15.344791412353516\n",
      "cls loss 527.7117919921875  loc loss 41.36975860595703\n",
      "cls loss 839.1702880859375  loc loss 59.80884552001953\n",
      "cls loss 503.62738037109375  loc loss 38.1005859375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([42., 42.,  1.,  1.,  1.,  1.,  1.,  1.,  1., 42., 42.])\n",
      "cls loss 578.1004638671875  loc loss 32.203250885009766\n",
      "cls loss 724.7927856445312  loc loss 56.37849044799805\n",
      "cls loss 618.577880859375  loc loss 48.02117156982422\n",
      "cls loss 435.469482421875  loc loss 27.093210220336914\n",
      "cls loss 575.083740234375  loc loss 33.96745681762695\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 765.9081420898438  loc loss 51.44397735595703\n",
      "cls loss 633.22412109375  loc loss 43.695556640625\n",
      "cls loss 398.14959716796875  loc loss 23.243671417236328\n",
      "cls loss 332.7632141113281  loc loss 18.77193832397461\n",
      "cls loss 480.34710693359375  loc loss 28.016223907470703\n",
      "cls loss 638.7163696289062  loc loss 40.55043411254883\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 321.8214111328125  loc loss 13.639530181884766\n",
      "cls loss 522.3485107421875  loc loss 34.19365310668945\n",
      "cls loss 468.7546691894531  loc loss 31.129661560058594\n",
      "cls loss 826.563232421875  loc loss 57.31108474731445\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19.,  7.])\n",
      "cls loss 469.13848876953125  loc loss 25.4478702545166\n",
      "cls loss 879.0216064453125  loc loss 57.36402130126953\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 739.6592407226562  loc loss 38.52165222167969\n",
      "cls loss 625.48095703125  loc loss 45.78354263305664\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([38., 38.,  1., 18.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1., 18., 18.,  1.])\n",
      "cls loss 493.5735168457031  loc loss 24.3815975189209\n",
      "cls loss 457.5279541015625  loc loss 22.30353546142578\n",
      "cls loss 825.8662109375  loc loss 60.800724029541016\n",
      "cls loss 641.5050048828125  loc loss 35.18385314941406\n",
      "cls loss 585.2162475585938  loc loss 30.05365753173828\n",
      "cls loss 340.713623046875  loc loss 26.574016571044922\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.])\n",
      "cls loss 271.63031005859375  loc loss 9.609729766845703\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([32.])\n",
      "cls loss 527.4652099609375  loc loss 27.746740341186523\n",
      "cls loss 451.0804748535156  loc loss 32.67780685424805\n",
      "cls loss 592.2684326171875  loc loss 47.08100128173828\n",
      "cls loss 516.1412353515625  loc loss 35.15365219116211\n",
      "cls loss 429.110595703125  loc loss 27.5788631439209\n",
      "cls loss 716.4953002929688  loc loss 44.270751953125\n",
      "cls loss 768.625  loc loss 52.84848403930664\n",
      "cls loss 611.9020385742188  loc loss 40.098270416259766\n",
      "cls loss 499.89959716796875  loc loss 29.160808563232422\n",
      "cls loss 783.650390625  loc loss 49.668121337890625\n",
      "cls loss 515.3114013671875  loc loss 26.331798553466797\n",
      "cls loss 820.2772216796875  loc loss 60.481788635253906\n",
      "cls loss 590.7286376953125  loc loss 33.063331604003906\n",
      "cls loss 493.58001708984375  loc loss 36.118778228759766\n",
      "cls loss 368.4803466796875  loc loss 18.30950164794922\n",
      "cls loss 426.41912841796875  loc loss 26.045841217041016\n",
      "cls loss 621.61669921875  loc loss 40.70869064331055\n",
      "cls loss 640.697998046875  loc loss 45.728065490722656\n",
      "cls loss 376.6431884765625  loc loss 24.35774803161621\n",
      "cls loss 687.4636840820312  loc loss 45.72373580932617\n",
      "cls loss 808.436767578125  loc loss 50.084110260009766\n",
      "cls loss 300.37353515625  loc loss 20.56918716430664\n",
      "cls loss 791.056640625  loc loss 52.83915710449219\n",
      "cls loss 560.780029296875  loc loss 43.46257019042969\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 765.9827880859375  loc loss 59.09157943725586\n",
      "cls loss 386.6783447265625  loc loss 14.175578117370605\n",
      "cls loss 573.8555297851562  loc loss 30.896608352661133\n",
      "cls loss 557.1390380859375  loc loss 37.42340087890625\n",
      "cls loss 458.94677734375  loc loss 26.021244049072266\n",
      "cls loss 285.889892578125  loc loss 14.518468856811523\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 9., 9., 1., 9., 9., 9., 9., 1., 9.])\n",
      "cls loss 972.6765747070312  loc loss 80.97528076171875\n",
      "cls loss 576.7147827148438  loc loss 30.482364654541016\n",
      "cls loss 819.7818603515625  loc loss 69.50518798828125\n",
      "cls loss 351.5890808105469  loc loss 24.737953186035156\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 42., 42.])\n",
      "cls loss 615.5062255859375  loc loss 45.41325759887695\n",
      "cls loss 663.5735473632812  loc loss 48.379756927490234\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  2.,  1.,  1.,  1., 38.,\n",
      "         1.,  1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 38., 38., 38.,  1., 38., 38., 38.,  1.,  1., 38.,  1.,\n",
      "         1.])\n",
      "cls loss 401.9298400878906  loc loss 29.016754150390625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  8.,  8.])\n",
      "cls loss 960.5169677734375  loc loss 61.36465835571289\n",
      "cls loss 938.0850219726562  loc loss 67.32164764404297\n",
      "cls loss 366.8323059082031  loc loss 20.966428756713867\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([4., 1., 1., 4.])\n",
      "cls loss 531.123291015625  loc loss 35.94229507446289\n",
      "cls loss 638.5201416015625  loc loss 39.04973602294922\n",
      "cls loss 280.91717529296875  loc loss 13.567224502563477\n",
      "cls loss 383.4788513183594  loc loss 23.87019920349121\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([51.,  1.])\n",
      "cls loss 282.29632568359375  loc loss 11.47390079498291\n",
      "cls loss 379.12567138671875  loc loss 20.6468448638916\n",
      "cls loss 655.0859985351562  loc loss 37.169639587402344\n",
      "cls loss 702.13330078125  loc loss 51.266239166259766\n",
      "cls loss 948.8309326171875  loc loss 51.88652038574219\n",
      "cls loss 1151.32958984375  loc loss 78.70782470703125\n",
      "cls loss 515.795166015625  loc loss 30.79413604736328\n",
      "cls loss 721.5362548828125  loc loss 52.37342834472656\n",
      "cls loss 762.8438110351562  loc loss 55.089725494384766\n",
      "cls loss 610.1444091796875  loc loss 35.170494079589844\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  3.,  1.,  1.,  1.,  3.,  1.,  1.,\n",
      "         1.,  1.,  1.])\n",
      "cls loss 613.9085693359375  loc loss 29.47134017944336\n",
      "cls loss 715.3451538085938  loc loss 36.59800720214844\n",
      "cls loss 642.0724487304688  loc loss 33.97481918334961\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "cls loss 533.9501953125  loc loss 31.50960922241211\n",
      "cls loss 312.98406982421875  loc loss 25.535865783691406\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3.])\n",
      "cls loss 264.3509521484375  loc loss 12.903277397155762\n",
      "cls loss 468.2402038574219  loc loss 31.723655700683594\n",
      "cls loss 379.14825439453125  loc loss 29.177980422973633\n",
      "cls loss 680.7530517578125  loc loss 46.131935119628906\n",
      "cls loss 470.50701904296875  loc loss 24.086143493652344\n",
      "cls loss 380.3671875  loc loss 26.463275909423828\n",
      "cls loss 1129.77783203125  loc loss 76.70264434814453\n",
      "cls loss 490.913330078125  loc loss 37.94089889526367\n",
      "cls loss 368.46636962890625  loc loss 27.640460968017578\n",
      "cls loss 473.29083251953125  loc loss 27.613971710205078\n",
      "cls loss 428.8449401855469  loc loss 30.93972396850586\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 779.09765625  loc loss 52.48796463012695\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  9., 64., 64., 64., 64., 64., 64., 64., 64., 64.,  9.,  9.,  9.,\n",
      "         9.])\n",
      "cls loss 427.0696716308594  loc loss 21.11750030517578\n",
      "cls loss 975.09521484375  loc loss 79.22077178955078\n",
      "cls loss 519.3341674804688  loc loss 34.52586364746094\n",
      "cls loss 679.6828002929688  loc loss 47.86543273925781\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.,  3.,  3.])\n",
      "cls loss 437.1781005859375  loc loss 25.050561904907227\n",
      "cls loss 478.2077331542969  loc loss 31.856338500976562\n",
      "cls loss 473.59869384765625  loc loss 34.2891845703125\n",
      "cls loss 501.6488037109375  loc loss 36.999549865722656\n",
      "cls loss 514.5202026367188  loc loss 41.099571228027344\n",
      "cls loss 521.140625  loc loss 38.902130126953125\n",
      "cls loss 491.4159851074219  loc loss 38.66496658325195\n",
      "cls loss 538.503173828125  loc loss 32.1787223815918\n",
      "cls loss 652.7466430664062  loc loss 44.68011474609375\n",
      "cls loss 555.0421142578125  loc loss 31.091480255126953\n",
      "cls loss 451.93170166015625  loc loss 19.85074806213379\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21.])\n",
      "cls loss 331.027099609375  loc loss 18.538742065429688\n",
      "cls loss 451.11968994140625  loc loss 38.01612091064453\n",
      "cls loss 661.5538330078125  loc loss 46.75917434692383\n",
      "cls loss 401.06878662109375  loc loss 22.569839477539062\n",
      "cls loss 539.6102294921875  loc loss 33.192283630371094\n",
      "cls loss 996.2117309570312  loc loss 54.160377502441406\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 42., 42.,  1.,  1.])\n",
      "cls loss 505.18817138671875  loc loss 32.616127014160156\n",
      "cls loss 334.3513488769531  loc loss 24.333972930908203\n",
      "cls loss 480.82122802734375  loc loss 36.12265396118164\n",
      "cls loss 675.97705078125  loc loss 54.013126373291016\n",
      "cls loss 433.452880859375  loc loss 27.895244598388672\n",
      "cls loss 628.7969970703125  loc loss 48.0296630859375\n",
      "cls loss 604.6656494140625  loc loss 44.652061462402344\n",
      "cls loss 652.1624755859375  loc loss 38.086151123046875\n",
      "cls loss 505.6616516113281  loc loss 30.987531661987305\n",
      "cls loss 462.9432373046875  loc loss 28.06381607055664\n",
      "cls loss 372.49908447265625  loc loss 14.953913688659668\n",
      "cls loss 456.3233642578125  loc loss 30.67169189453125\n",
      "cls loss 695.7745361328125  loc loss 53.746192932128906\n",
      "cls loss 560.0877685546875  loc loss 35.13064956665039\n",
      "cls loss 521.2283325195312  loc loss 38.92043685913086\n",
      "cls loss 580.2064208984375  loc loss 34.60423278808594\n",
      "cls loss 835.3831787109375  loc loss 58.796966552734375\n",
      "cls loss 610.282958984375  loc loss 46.077816009521484\n",
      "cls loss 710.71923828125  loc loss 40.2354850769043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 407.72064208984375  loc loss 20.652843475341797\n",
      "cls loss 583.0479125976562  loc loss 37.944847106933594\n",
      "cls loss 539.803955078125  loc loss 32.98404312133789\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 5., 5., 5., 5., 5., 5.])\n",
      "cls loss 386.90679931640625  loc loss 26.184764862060547\n",
      "cls loss 466.7957763671875  loc loss 26.773818969726562\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([13.])\n",
      "cls loss 322.19964599609375  loc loss 20.14472198486328\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([44., 10.,  1.,  1.,  1.])\n",
      "cls loss 332.0363464355469  loc loss 20.12792205810547\n",
      "cls loss 630.9942626953125  loc loss 31.662450790405273\n",
      "cls loss 509.3427734375  loc loss 28.976964950561523\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19., 19., 19., 19., 19., 19., 19.])\n",
      "cls loss 641.8458251953125  loc loss 33.636474609375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([56.])\n",
      "cls loss 1081.5440673828125  loc loss 70.24596405029297\n",
      "cls loss 651.5814208984375  loc loss 51.28141784667969\n",
      "cls loss 832.7632446289062  loc loss 58.97028350830078\n",
      "cls loss 830.1307983398438  loc loss 63.745033264160156\n",
      "cls loss 517.7188720703125  loc loss 29.276979446411133\n",
      "cls loss 808.2364501953125  loc loss 58.1544189453125\n",
      "cls loss 469.7952575683594  loc loss 30.62306022644043\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 36.])\n",
      "cls loss 575.3760986328125  loc loss 31.943693161010742\n",
      "cls loss 517.8597412109375  loc loss 35.571434020996094\n",
      "cls loss 497.6507568359375  loc loss 30.31561851501465\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5.])\n",
      "cls loss 605.7980346679688  loc loss 36.27302169799805\n",
      "cls loss 323.4814758300781  loc loss 17.38675880432129\n",
      "cls loss 741.9933471679688  loc loss 40.902854919433594\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "cls loss 641.10302734375  loc loss 42.76015853881836\n",
      "cls loss 638.2584228515625  loc loss 42.512451171875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 589.1763916015625  loc loss 42.819366455078125\n",
      "cls loss 699.8148193359375  loc loss 49.77886199951172\n",
      "cls loss 577.318359375  loc loss 53.637062072753906\n",
      "cls loss 415.3340759277344  loc loss 29.259859085083008\n",
      "cls loss 517.958984375  loc loss 37.454185485839844\n",
      "cls loss 536.3538818359375  loc loss 33.93522262573242\n",
      "cls loss 821.3748168945312  loc loss 46.9423942565918\n",
      "cls loss 378.3365478515625  loc loss 18.762609481811523\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 11., 15., 10., 10., 10., 10., 10.])\n",
      "cls loss 887.4019165039062  loc loss 54.715599060058594\n",
      "cls loss 473.7749938964844  loc loss 33.433109283447266\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3.])\n",
      "cls loss 532.5050659179688  loc loss 35.26174545288086\n",
      "cls loss 487.479736328125  loc loss 27.189483642578125\n",
      "cls loss 521.6239013671875  loc loss 25.783342361450195\n",
      "cls loss 664.5806884765625  loc loss 32.246700286865234\n",
      "cls loss 365.3508605957031  loc loss 17.248525619506836\n",
      "cls loss 515.74169921875  loc loss 33.97627639770508\n",
      "cls loss 567.6307373046875  loc loss 43.65446472167969\n",
      "cls loss 486.2556457519531  loc loss 36.75273132324219\n",
      "cls loss 1144.0286865234375  loc loss 84.51136016845703\n",
      "cls loss 810.895751953125  loc loss 52.764644622802734\n",
      "cls loss 525.7288818359375  loc loss 37.638763427734375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  9.,  9.,  9.,  6.,  6., 85., 85.,  8.,  1.,  1.,  1.,  1.,\n",
      "         6.,  6.])\n",
      "cls loss 359.59747314453125  loc loss 27.285058975219727\n",
      "cls loss 854.929931640625  loc loss 60.398963928222656\n",
      "cls loss 1004.96875  loc loss 63.995758056640625\n",
      "cls loss 694.218994140625  loc loss 46.68033218383789\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10.,  3.,  3., 10.])\n",
      "cls loss 469.3223876953125  loc loss 25.678382873535156\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([7.])\n",
      "cls loss 580.8751220703125  loc loss 39.350685119628906\n",
      "cls loss 597.8460693359375  loc loss 35.9956169128418\n",
      "cls loss 521.1928100585938  loc loss 43.113311767578125\n",
      "cls loss 740.7269287109375  loc loss 61.31756591796875\n",
      "cls loss 536.5477905273438  loc loss 36.891395568847656\n",
      "cls loss 738.4703369140625  loc loss 48.82744598388672\n",
      "cls loss 918.5201416015625  loc loss 55.95684814453125\n",
      "cls loss 542.769287109375  loc loss 38.37467575073242\n",
      "cls loss 592.6993408203125  loc loss 41.95067596435547\n",
      "cls loss 505.817626953125  loc loss 37.332725524902344\n",
      "cls loss 705.985107421875  loc loss 57.92928695678711\n",
      "cls loss 577.91845703125  loc loss 36.84544372558594\n",
      "cls loss 465.06146240234375  loc loss 27.31586456298828\n",
      "cls loss 709.1395263671875  loc loss 53.378929138183594\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([62.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([62.])\n",
      "cls loss 324.1333312988281  loc loss 16.529563903808594\n",
      "cls loss 563.3287353515625  loc loss 39.36076736450195\n",
      "cls loss 547.7177124023438  loc loss 35.852169036865234\n",
      "cls loss 378.6423034667969  loc loss 16.894977569580078\n",
      "cls loss 695.5936279296875  loc loss 46.372283935546875\n",
      "cls loss 706.3908081054688  loc loss 40.537322998046875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([28.])\n",
      "cls loss 774.1810302734375  loc loss 42.334503173828125\n",
      "cls loss 680.9198608398438  loc loss 41.96720504760742\n",
      "cls loss 675.5579833984375  loc loss 43.63512420654297\n",
      "cls loss 678.9273681640625  loc loss 44.604251861572266\n",
      "cls loss 945.6226196289062  loc loss 63.576377868652344\n",
      "cls loss 526.5870361328125  loc loss 33.96516036987305\n",
      "cls loss 653.9501953125  loc loss 40.232887268066406\n",
      "cls loss 574.102294921875  loc loss 48.318695068359375\n",
      "cls loss 923.4430541992188  loc loss 72.83932495117188\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([81.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 650.0149536132812  loc loss 26.81672477722168\n",
      "cls loss 489.3382263183594  loc loss 25.134729385375977\n",
      "cls loss 415.4081115722656  loc loss 26.645973205566406\n",
      "cls loss 356.65216064453125  loc loss 13.497133255004883\n",
      "cls loss 397.7471923828125  loc loss 26.23499870300293\n",
      "cls loss 433.12945556640625  loc loss 26.58658790588379\n",
      "cls loss 509.49163818359375  loc loss 31.644832611083984\n",
      "cls loss 656.3775024414062  loc loss 52.19035339355469\n",
      "cls loss 730.949462890625  loc loss 49.359710693359375\n",
      "cls loss 1385.498291015625  loc loss 93.53688049316406\n",
      "cls loss 560.7850341796875  loc loss 29.192195892333984\n",
      "cls loss 675.0636596679688  loc loss 46.59743118286133\n",
      "cls loss 477.04974365234375  loc loss 29.151351928710938\n",
      "cls loss 618.02001953125  loc loss 35.07962417602539\n",
      "cls loss 550.1201782226562  loc loss 31.543899536132812\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([44., 44.])\n",
      "cls loss 499.1785888671875  loc loss 24.790830612182617\n",
      "cls loss 501.37274169921875  loc loss 35.79423522949219\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15.])\n",
      "cls loss 589.1900634765625  loc loss 29.399824142456055\n",
      "cls loss 288.7705078125  loc loss 16.629716873168945\n",
      "cls loss 589.625732421875  loc loss 34.34458923339844\n",
      "cls loss 331.640625  loc loss 20.22439956665039\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([1., 3., 3.])\n",
      "cls loss 368.4977722167969  loc loss 27.512331008911133\n",
      "cls loss 306.46356201171875  loc loss 12.947887420654297\n",
      "cls loss 562.05322265625  loc loss 31.86005973815918\n",
      "cls loss 592.3436279296875  loc loss 34.8703498840332\n",
      "cls loss 530.96826171875  loc loss 34.831085205078125\n",
      "cls loss 554.1248779296875  loc loss 30.381113052368164\n",
      "cls loss 436.5772399902344  loc loss 33.63907241821289\n",
      "cls loss 597.174560546875  loc loss 40.26934814453125\n",
      "cls loss 457.47552490234375  loc loss 30.484128952026367\n",
      "cls loss 572.7736206054688  loc loss 40.579959869384766\n",
      "cls loss 366.0884704589844  loc loss 22.854251861572266\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 683.4841918945312  loc loss 42.42038345336914\n",
      "cls loss 793.1778564453125  loc loss 39.21459197998047\n",
      "cls loss 697.7772216796875  loc loss 48.975242614746094\n",
      "cls loss 692.807861328125  loc loss 52.6024284362793\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10., 10., 10.,  1.,  1.,  1.,  1.,  1.,  1.,  8.,  8.,\n",
      "         1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10., 10., 10.,  1.,  1.,  1.,  1.,  1.,  1.,  8.,  8.,\n",
      "         1.])\n",
      "cls loss 660.7962646484375  loc loss 31.130943298339844\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 3., 3., 3.])\n",
      "cls loss 555.8497924804688  loc loss 35.00798416137695\n",
      "cls loss 386.4299011230469  loc loss 21.457298278808594\n",
      "cls loss 305.69451904296875  loc loss 14.90286922454834\n",
      "cls loss 517.5789184570312  loc loss 38.924659729003906\n",
      "cls loss 401.985107421875  loc loss 21.183605194091797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 460.8940124511719  loc loss 30.501049041748047\n",
      "cls loss 512.006103515625  loc loss 35.94287109375\n",
      "cls loss 721.703369140625  loc loss 50.79026412963867\n",
      "cls loss 609.83984375  loc loss 30.438270568847656\n",
      "cls loss 587.442626953125  loc loss 33.37688064575195\n",
      "cls loss 664.9401245117188  loc loss 43.71199035644531\n",
      "cls loss 479.12713623046875  loc loss 35.90631866455078\n",
      "cls loss 876.6673583984375  loc loss 64.44041442871094\n",
      "cls loss 447.9671325683594  loc loss 23.049991607666016\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 670.888427734375  loc loss 41.32091522216797\n",
      "cls loss 336.8726501464844  loc loss 14.41965389251709\n",
      "cls loss 826.4512329101562  loc loss 52.45121765136719\n",
      "cls loss 439.0293273925781  loc loss 22.95722770690918\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 34.])\n",
      "cls loss 706.7938232421875  loc loss 37.232635498046875\n",
      "cls loss 323.7052917480469  loc loss 21.27858543395996\n",
      "cls loss 601.1195678710938  loc loss 41.109039306640625\n",
      "cls loss 209.57595825195312  loc loss 15.960567474365234\n",
      "cls loss 541.1830444335938  loc loss 34.91853332519531\n",
      "cls loss 523.57470703125  loc loss 41.887935638427734\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 38.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16., 16., 16.,  9.,  9.,  9., 16., 16., 16., 85.,  9.])\n",
      "cls loss 522.918212890625  loc loss 34.38105010986328\n",
      "cls loss 591.687255859375  loc loss 46.54081344604492\n",
      "cls loss 805.5558471679688  loc loss 56.88343048095703\n",
      "cls loss 1147.37548828125  loc loss 78.41910552978516\n",
      "cls loss 365.10345458984375  loc loss 18.640226364135742\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3., 10.,  8.,  8., 10., 10., 10.,  3.,  3., 14.])\n",
      "cls loss 448.73809814453125  loc loss 20.98394012451172\n",
      "cls loss 791.5735473632812  loc loss 39.94854736328125\n",
      "cls loss 339.908447265625  loc loss 12.49226188659668\n",
      "cls loss 501.26568603515625  loc loss 21.774608612060547\n",
      "cls loss 663.4312744140625  loc loss 39.49391174316406\n",
      "cls loss 561.4381103515625  loc loss 36.61466598510742\n",
      "cls loss 325.66265869140625  loc loss 16.913406372070312\n",
      "cls loss 365.6136474609375  loc loss 23.17426300048828\n",
      "cls loss 560.4171142578125  loc loss 36.958099365234375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42., 42.,  1.])\n",
      "cls loss 545.6957397460938  loc loss 39.25170135498047\n",
      "cls loss 455.70367431640625  loc loss 27.129079818725586\n",
      "cls loss 602.3645629882812  loc loss 46.897193908691406\n",
      "cls loss 704.9388427734375  loc loss 45.93254470825195\n",
      "cls loss 492.5314025878906  loc loss 31.97144889831543\n",
      "cls loss 605.7094116210938  loc loss 42.56658172607422\n",
      "cls loss 393.56781005859375  loc loss 25.96101188659668\n",
      "cls loss 410.93267822265625  loc loss 28.424518585205078\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20.])\n",
      "cls loss 330.0672607421875  loc loss 18.10765266418457\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([11.])\n",
      "cls loss 415.6929931640625  loc loss 21.21476173400879\n",
      "cls loss 293.1120300292969  loc loss 15.489789009094238\n",
      "cls loss 629.993896484375  loc loss 49.42291259765625\n",
      "cls loss 296.9755859375  loc loss 13.324684143066406\n",
      "cls loss 607.722900390625  loc loss 33.88847732543945\n",
      "cls loss 332.36517333984375  loc loss 20.922502517700195\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 35., 27.])\n",
      "cls loss 558.8975219726562  loc loss 36.16274642944336\n",
      "cls loss 598.1707763671875  loc loss 46.051090240478516\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 425.94329833984375  loc loss 26.009449005126953\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([42.,  1.])\n",
      "cls loss 554.3875732421875  loc loss 39.15299606323242\n",
      "cls loss 506.3099060058594  loc loss 29.751296997070312\n",
      "cls loss 632.8590698242188  loc loss 37.39276885986328\n",
      "cls loss 739.9705200195312  loc loss 49.93659210205078\n",
      "cls loss 677.6578979492188  loc loss 41.845237731933594\n",
      "cls loss 461.8452453613281  loc loss 35.312381744384766\n",
      "cls loss 399.16314697265625  loc loss 30.883129119873047\n",
      "cls loss 266.47406005859375  loc loss 12.348526000976562\n",
      "cls loss 475.4159240722656  loc loss 26.525100708007812\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 1., 1.])\n",
      "cls loss 461.30438232421875  loc loss 24.69452667236328\n",
      "cls loss 506.87384033203125  loc loss 34.315494537353516\n",
      "cls loss 510.2946472167969  loc loss 32.363006591796875\n",
      "cls loss 411.1995544433594  loc loss 29.94466209411621\n",
      "cls loss 496.9217529296875  loc loss 29.943172454833984\n",
      "cls loss 518.4063110351562  loc loss 39.5245361328125\n",
      "cls loss 719.135986328125  loc loss 44.234439849853516\n",
      "cls loss 615.44140625  loc loss 48.41006088256836\n",
      "cls loss 591.37548828125  loc loss 35.548248291015625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 459.63031005859375  loc loss 32.02375030517578\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 543.3207397460938  loc loss 27.248838424682617\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([81.])\n",
      "cls loss 660.6736450195312  loc loss 41.284523010253906\n",
      "cls loss 421.058837890625  loc loss 28.065664291381836\n",
      "cls loss 292.7227783203125  loc loss 17.526451110839844\n",
      "cls loss 466.32391357421875  loc loss 24.545927047729492\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3.,  1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 19.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 19.])\n",
      "cls loss 605.801513671875  loc loss 41.77484130859375\n",
      "cls loss 361.291748046875  loc loss 18.08783531188965\n",
      "cls loss 373.1410217285156  loc loss 22.368850708007812\n",
      "cls loss 707.0584716796875  loc loss 51.62392807006836\n",
      "cls loss 364.14825439453125  loc loss 22.999462127685547\n",
      "cls loss 455.3828430175781  loc loss 31.302827835083008\n",
      "cls loss 543.0902099609375  loc loss 36.91019058227539\n",
      "cls loss 429.94403076171875  loc loss 31.515321731567383\n",
      "cls loss 564.2267456054688  loc loss 33.493438720703125\n",
      "cls loss 631.642578125  loc loss 44.136260986328125\n",
      "cls loss 756.8861694335938  loc loss 69.78280639648438\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 81.])\n",
      "cls loss 562.7531127929688  loc loss 30.12977409362793\n",
      "cls loss 475.8497009277344  loc loss 28.058683395385742\n",
      "cls loss 554.2674560546875  loc loss 29.31264877319336\n",
      "cls loss 415.8890380859375  loc loss 20.301959991455078\n",
      "cls loss 376.6746826171875  loc loss 23.529748916625977\n",
      "cls loss 434.72296142578125  loc loss 31.26405143737793\n",
      "cls loss 349.3143310546875  loc loss 24.31084632873535\n",
      "cls loss 279.27850341796875  loc loss 18.004995346069336\n",
      "cls loss 368.9194641113281  loc loss 24.820547103881836\n",
      "cls loss 516.0557250976562  loc loss 31.648908615112305\n",
      "cls loss 418.687744140625  loc loss 33.644474029541016\n",
      "cls loss 444.1470031738281  loc loss 35.732173919677734\n",
      "cls loss 275.17938232421875  loc loss 20.241912841796875\n",
      "cls loss 913.8241577148438  loc loss 66.15821838378906\n",
      "cls loss 595.0750732421875  loc loss 40.01268768310547\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 506.4843444824219  loc loss 26.95594024658203\n",
      "cls loss 544.6453857421875  loc loss 37.171287536621094\n",
      "cls loss 452.2240905761719  loc loss 26.458118438720703\n",
      "cls loss 633.0579223632812  loc loss 41.537879943847656\n",
      "cls loss 623.857666015625  loc loss 40.0236930847168\n",
      "cls loss 555.947265625  loc loss 35.505271911621094\n",
      "cls loss 452.19415283203125  loc loss 26.249359130859375\n",
      "cls loss 337.7289123535156  loc loss 20.98794174194336\n",
      "cls loss 512.4755859375  loc loss 31.293323516845703\n",
      "cls loss 532.9459228515625  loc loss 36.85091018676758\n",
      "cls loss 574.0779418945312  loc loss 32.688472747802734\n",
      "cls loss 715.2750244140625  loc loss 54.0265007019043\n",
      "cls loss 705.987060546875  loc loss 57.47970199584961\n",
      "cls loss 523.001708984375  loc loss 37.776527404785156\n",
      "cls loss 685.0933227539062  loc loss 54.683311462402344\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1., 38., 47.,  1.,  1.,  1.,  1.,  1., 62.])\n",
      "cls loss 504.04241943359375  loc loss 25.2923526763916\n",
      "cls loss 610.4465942382812  loc loss 34.55709457397461\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 618.9103393554688  loc loss 36.96647262573242\n",
      "cls loss 671.077392578125  loc loss 50.00743865966797\n",
      "cls loss 473.63836669921875  loc loss 23.814090728759766\n",
      "cls loss 531.46484375  loc loss 43.63124084472656\n",
      "cls loss 488.8189697265625  loc loss 29.762357711791992\n",
      "cls loss 299.37548828125  loc loss 12.013083457946777\n",
      "cls loss 479.58612060546875  loc loss 27.246810913085938\n",
      "cls loss 404.87921142578125  loc loss 18.31822967529297\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1., 35.])\n",
      "cls loss 491.3384094238281  loc loss 23.98168182373047\n",
      "cls loss 648.0247802734375  loc loss 35.89504623413086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 635.8994750976562  loc loss 42.10252380371094\n",
      "cls loss 567.5167846679688  loc loss 47.56965637207031\n",
      "cls loss 461.3148193359375  loc loss 37.1462516784668\n",
      "cls loss 604.302001953125  loc loss 45.536109924316406\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 343.610595703125  loc loss 19.993459701538086\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 503.2580261230469  loc loss 23.977060317993164\n",
      "cls loss 800.7084350585938  loc loss 42.69898223876953\n",
      "cls loss 976.842529296875  loc loss 73.94792175292969\n",
      "cls loss 504.33837890625  loc loss 25.71010971069336\n",
      "cls loss 437.0569763183594  loc loss 28.041027069091797\n",
      "cls loss 446.65374755859375  loc loss 24.848003387451172\n",
      "cls loss 476.90521240234375  loc loss 31.718303680419922\n",
      "cls loss 440.22637939453125  loc loss 18.718564987182617\n",
      "cls loss 731.849853515625  loc loss 51.79352951049805\n",
      "cls loss 598.1389770507812  loc loss 37.36832809448242\n",
      "cls loss 340.1788024902344  loc loss 21.252914428710938\n",
      "cls loss 589.8155517578125  loc loss 32.849308013916016\n",
      "cls loss 700.0850830078125  loc loss 56.62049102783203\n",
      "cls loss 585.83544921875  loc loss 37.08438491821289\n",
      "cls loss 528.1166381835938  loc loss 28.194673538208008\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.])\n",
      "cls loss 483.75860595703125  loc loss 35.202571868896484\n",
      "cls loss 440.5870056152344  loc loss 33.90391159057617\n",
      "cls loss 606.7061767578125  loc loss 41.45594787597656\n",
      "cls loss 913.8738403320312  loc loss 74.22245025634766\n",
      "cls loss 415.13494873046875  loc loss 19.81949806213379\n",
      "cls loss 533.0142822265625  loc loss 32.73689651489258\n",
      "cls loss 426.069091796875  loc loss 23.62262535095215\n",
      "cls loss 464.3578796386719  loc loss 28.40241813659668\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 21., 21., 21.])\n",
      "cls loss 495.1260681152344  loc loss 29.145397186279297\n",
      "cls loss 466.70025634765625  loc loss 21.71468162536621\n",
      "cls loss 486.89471435546875  loc loss 32.29959487915039\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 35.])\n",
      "cls loss 643.966552734375  loc loss 41.61085510253906\n",
      "cls loss 235.83351135253906  loc loss 13.040727615356445\n",
      "cls loss 378.2685546875  loc loss 25.76296615600586\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 378.8009033203125  loc loss 17.56914710998535\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 38., 38.,  9., 38.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1.,  1.])\n",
      "cls loss 423.8783264160156  loc loss 28.460948944091797\n",
      "cls loss 688.9066162109375  loc loss 45.505008697509766\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 2.,  1., 77., 31., 10., 10.,  1.,  4., 10.])\n",
      "cls loss 360.2290344238281  loc loss 17.494537353515625\n",
      "cls loss 660.0335693359375  loc loss 40.13086700439453\n",
      "cls loss 1306.66015625  loc loss 78.65809631347656\n",
      "cls loss 430.8074645996094  loc loss 27.26764678955078\n",
      "cls loss 590.9298706054688  loc loss 44.333274841308594\n",
      "cls loss 438.477294921875  loc loss 23.914478302001953\n",
      "cls loss 445.0954284667969  loc loss 21.54866600036621\n",
      "cls loss 656.0812377929688  loc loss 29.76136016845703\n",
      "cls loss 647.33251953125  loc loss 34.00922775268555\n",
      "cls loss 564.6590576171875  loc loss 38.520301818847656\n",
      "cls loss 432.5452575683594  loc loss 21.09499740600586\n",
      "cls loss 473.6394348144531  loc loss 24.271987915039062\n",
      "cls loss 850.0752563476562  loc loss 53.5130615234375\n",
      "cls loss 726.3275756835938  loc loss 45.312744140625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1., 42., 42., 42., 42., 42., 42.,  1.,\n",
      "         1.,  1.,  1., 42.,  1.,  1., 42.,  1.])\n",
      "cls loss 406.1227111816406  loc loss 28.199798583984375\n",
      "cls loss 635.632080078125  loc loss 39.10616683959961\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.])\n",
      "cls loss 270.7474365234375  loc loss 16.782886505126953\n",
      "cls loss 615.174560546875  loc loss 40.79278564453125\n",
      "cls loss 497.9328918457031  loc loss 34.931297302246094\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([11.])\n",
      "cls loss 305.55267333984375  loc loss 17.55634307861328\n",
      "cls loss 389.31390380859375  loc loss 17.746868133544922\n",
      "cls loss 411.16229248046875  loc loss 18.08554458618164\n",
      "cls loss 614.271240234375  loc loss 39.452571868896484\n",
      "cls loss 573.9332275390625  loc loss 30.295679092407227\n",
      "cls loss 531.24560546875  loc loss 36.57463836669922\n",
      "cls loss 786.8095703125  loc loss 41.28254699707031\n",
      "cls loss 400.30462646484375  loc loss 24.00693702697754\n",
      "cls loss 767.2530517578125  loc loss 56.07704162597656\n",
      "cls loss 390.35675048828125  loc loss 25.486574172973633\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 360.670166015625  loc loss 25.660274505615234\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1., 38., 38., 42.])\n",
      "cls loss 463.36932373046875  loc loss 34.53805923461914\n",
      "cls loss 428.70330810546875  loc loss 25.00469970703125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 367.2679748535156  loc loss 27.563121795654297\n",
      "cls loss 871.2764892578125  loc loss 60.53986358642578\n",
      "cls loss 534.3014526367188  loc loss 35.253936767578125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10.,  3.,  3.,  6.,  8.,  8.,  1.,  1.,  1., 10.])\n",
      "cls loss 456.8804931640625  loc loss 23.93807601928711\n",
      "cls loss 282.8014831542969  loc loss 10.486501693725586\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10.,  3.])\n",
      "cls loss 426.6605529785156  loc loss 23.82964324951172\n",
      "cls loss 263.9554443359375  loc loss 12.660930633544922\n",
      "cls loss 521.74951171875  loc loss 37.4598503112793\n",
      "cls loss 590.0675048828125  loc loss 38.96220779418945\n",
      "cls loss 436.9923400878906  loc loss 26.51622200012207\n",
      "cls loss 310.4873046875  loc loss 15.525463104248047\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 34.])\n",
      "cls loss 715.0530395507812  loc loss 45.77056121826172\n",
      "cls loss 768.5386352539062  loc loss 65.75106811523438\n",
      "cls loss 502.54248046875  loc loss 38.81047439575195\n",
      "cls loss 382.84539794921875  loc loss 28.12554168701172\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.,  1.])\n",
      "cls loss 446.55938720703125  loc loss 22.2000675201416\n",
      "cls loss 678.6065063476562  loc loss 53.24358367919922\n",
      "cls loss 1029.198974609375  loc loss 66.62318420410156\n",
      "cls loss 853.0673828125  loc loss 44.50984191894531\n",
      "cls loss 505.6712646484375  loc loss 27.075252532958984\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 611.8024291992188  loc loss 35.55607986450195\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10.])\n",
      "cls loss 378.7288513183594  loc loss 20.199974060058594\n",
      "cls loss 548.6202392578125  loc loss 27.436853408813477\n",
      "cls loss 502.858154296875  loc loss 30.753746032714844\n",
      "cls loss 365.3424072265625  loc loss 22.624670028686523\n",
      "cls loss 462.12811279296875  loc loss 31.610183715820312\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21.,\n",
      "        21.])\n",
      "cls loss 647.177978515625  loc loss 36.06864929199219\n",
      "cls loss 500.9683837890625  loc loss 31.19500732421875\n",
      "cls loss 325.80859375  loc loss 15.119974136352539\n",
      "cls loss 681.1534423828125  loc loss 44.87263107299805\n",
      "cls loss 529.90380859375  loc loss 36.08273696899414\n",
      "cls loss 372.63934326171875  loc loss 22.239273071289062\n",
      "cls loss 785.335205078125  loc loss 51.75527572631836\n",
      "cls loss 951.2080078125  loc loss 64.98674011230469\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15., 85.])\n",
      "cls loss 575.1553955078125  loc loss 38.044273376464844\n",
      "cls loss 604.5430908203125  loc loss 44.83644485473633\n",
      "cls loss 607.802001953125  loc loss 44.266082763671875\n",
      "cls loss 551.305908203125  loc loss 30.653942108154297\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 8., 8.])\n",
      "cls loss 358.53857421875  loc loss 17.935352325439453\n",
      "cls loss 373.9773254394531  loc loss 26.63907241821289\n",
      "cls loss 476.3460693359375  loc loss 29.204265594482422\n",
      "cls loss 390.5614318847656  loc loss 22.26906394958496\n",
      "cls loss 457.62750244140625  loc loss 27.32906723022461\n",
      "cls loss 599.6906127929688  loc loss 37.510169982910156\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1., 35., 27., 27.,  1., 27.,  1.])\n",
      "cls loss 763.9651489257812  loc loss 55.51171875\n",
      "cls loss 399.4046630859375  loc loss 26.551753997802734\n",
      "cls loss 463.1403503417969  loc loss 34.08507537841797\n",
      "cls loss 436.88226318359375  loc loss 38.72334671020508\n",
      "cls loss 397.15814208984375  loc loss 30.917142868041992\n",
      "cls loss 434.9130859375  loc loss 34.800994873046875\n",
      "cls loss 435.3629455566406  loc loss 34.815460205078125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  2.,  2.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  2.,  2.])\n",
      "cls loss 263.5473327636719  loc loss 10.035076141357422\n",
      "cls loss 697.571044921875  loc loss 43.47066879272461\n",
      "cls loss 492.3087463378906  loc loss 23.136573791503906\n",
      "cls loss 771.6527709960938  loc loss 56.90147399902344\n",
      "cls loss 328.63092041015625  loc loss 19.14516830444336\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 19., 19., 19., 16.])\n",
      "cls loss 343.7197265625  loc loss 14.735029220581055\n",
      "cls loss 275.91217041015625  loc loss 11.815328598022461\n",
      "cls loss 421.05389404296875  loc loss 21.72537612915039\n",
      "cls loss 549.2275390625  loc loss 36.791019439697266\n",
      "cls loss 292.2813415527344  loc loss 19.521862030029297\n",
      "cls loss 616.0874633789062  loc loss 47.13079071044922\n",
      "cls loss 444.1820983886719  loc loss 31.05231475830078\n",
      "cls loss 498.890625  loc loss 31.84898567199707\n",
      "cls loss 626.7239379882812  loc loss 43.16511535644531\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 691.666015625  loc loss 29.851354598999023\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 863.1492919921875  loc loss 75.57958984375\n",
      "cls loss 1079.52490234375  loc loss 103.89907836914062\n",
      "cls loss 565.9653930664062  loc loss 37.10586166381836\n",
      "cls loss 508.186767578125  loc loss 33.49049377441406\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3.,  3.,  3.,  3.,  3., 10.])\n",
      "cls loss 290.2982177734375  loc loss 16.93193244934082\n",
      "cls loss 541.6038208007812  loc loss 27.898193359375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 1., 1., 1., 3., 3., 3., 3.])\n",
      "cls loss 422.68048095703125  loc loss 27.038070678710938\n",
      "cls loss 793.8551635742188  loc loss 52.55455780029297\n",
      "cls loss 628.2684326171875  loc loss 41.93025207519531\n",
      "cls loss 418.6532287597656  loc loss 24.691959381103516\n",
      "cls loss 636.1400146484375  loc loss 45.24421691894531\n",
      "cls loss 400.5902099609375  loc loss 29.868682861328125\n",
      "cls loss 648.526611328125  loc loss 44.587921142578125\n",
      "cls loss 456.39202880859375  loc loss 43.857879638671875\n",
      "cls loss 497.1537170410156  loc loss 31.366212844848633\n",
      "cls loss 995.3236083984375  loc loss 82.47703552246094\n",
      "cls loss 661.8087158203125  loc loss 47.4437255859375\n",
      "cls loss 461.1174011230469  loc loss 22.266674041748047\n",
      "cls loss 312.789794921875  loc loss 13.29076099395752\n",
      "cls loss 355.255859375  loc loss 16.704572677612305\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3., 10., 10., 10., 10., 10., 10., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10., 10., 10., 10., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 11., 10., 10., 10., 10., 10.,  3.,  3.,  3.,  3.,  3.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 11., 10., 10., 10., 10., 10.,  3.,  3.,  3.,  3.,  3.])\n",
      "cls loss 340.95098876953125  loc loss 15.270545959472656\n",
      "cls loss 403.17254638671875  loc loss 19.249893188476562\n",
      "cls loss 338.8451232910156  loc loss 20.570510864257812\n",
      "cls loss 340.642822265625  loc loss 14.866865158081055\n",
      "cls loss 389.9870300292969  loc loss 31.542081832885742\n",
      "cls loss 321.2642517089844  loc loss 12.409076690673828\n",
      "cls loss 592.4269409179688  loc loss 40.64629364013672\n",
      "cls loss 512.64306640625  loc loss 36.543609619140625\n",
      "cls loss 797.3525390625  loc loss 50.46552658081055\n",
      "cls loss 391.5940246582031  loc loss 29.263938903808594\n",
      "cls loss 711.7871704101562  loc loss 47.101318359375\n",
      "cls loss 585.7901000976562  loc loss 38.61079025268555\n",
      "cls loss 538.854736328125  loc loss 36.053131103515625\n",
      "cls loss 539.4356079101562  loc loss 39.021488189697266\n",
      "cls loss 734.570068359375  loc loss 49.0650749206543\n",
      "cls loss 743.3922729492188  loc loss 44.76737976074219\n",
      "cls loss 351.4269104003906  loc loss 19.15229034423828\n",
      "cls loss 638.9229736328125  loc loss 47.304832458496094\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 10.,  1., 18.])\n",
      "cls loss 318.05859375  loc loss 21.445871353149414\n",
      "cls loss 379.2956848144531  loc loss 15.860462188720703\n",
      "cls loss 639.5887451171875  loc loss 33.46686553955078\n",
      "cls loss 906.2239990234375  loc loss 54.18964385986328\n",
      "cls loss 533.69775390625  loc loss 37.51337814331055\n",
      "cls loss 773.791259765625  loc loss 41.826080322265625\n",
      "cls loss 541.6640014648438  loc loss 36.35398864746094\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.,  1.,  1.])\n",
      "cls loss 675.649658203125  loc loss 44.416656494140625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1., 38.,  1.])\n",
      "cls loss 653.2294921875  loc loss 36.1169548034668\n",
      "cls loss 833.3709716796875  loc loss 60.165245056152344\n",
      "cls loss 445.2794494628906  loc loss 30.791057586669922\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 588.623046875  loc loss 39.217369079589844\n",
      "cls loss 517.4226684570312  loc loss 31.87607192993164\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3., 10.,  8.,  3., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.])\n",
      "cls loss 615.9217529296875  loc loss 35.070587158203125\n",
      "cls loss 432.6444396972656  loc loss 26.799453735351562\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3.,  3., 11.,  3., 10., 10.,  3.,  3., 10.])\n",
      "cls loss 514.9393920898438  loc loss 24.165870666503906\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3., 10., 10., 10.])\n",
      "cls loss 491.6018371582031  loc loss 31.986576080322266\n",
      "cls loss 441.97821044921875  loc loss 23.51704978942871\n",
      "cls loss 516.0982666015625  loc loss 34.722164154052734\n",
      "cls loss 779.946044921875  loc loss 46.37062454223633\n",
      "cls loss 510.298583984375  loc loss 32.49552917480469\n",
      "cls loss 369.801513671875  loc loss 31.714555740356445\n",
      "cls loss 491.2701416015625  loc loss 32.364681243896484\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 9.,  9., 85., 85.])\n",
      "cls loss 401.2208251953125  loc loss 22.476884841918945\n",
      "cls loss 468.6274719238281  loc loss 33.5751953125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 782.7741088867188  loc loss 55.12175750732422\n",
      "cls loss 684.7410888671875  loc loss 32.42852783203125\n",
      "cls loss 733.4159545898438  loc loss 52.696441650390625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10., 10., 10., 10.])\n",
      "cls loss 461.706298828125  loc loss 28.998926162719727\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([13.])\n",
      "cls loss 742.195556640625  loc loss 57.65839385986328\n",
      "cls loss 268.73992919921875  loc loss 14.24789047241211\n",
      "cls loss 348.2410583496094  loc loss 17.494922637939453\n",
      "cls loss 467.45660400390625  loc loss 24.392900466918945\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19.,  1.,  1.,  1., 19., 19.])\n",
      "cls loss 463.7993469238281  loc loss 30.59391975402832\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 369.0182189941406  loc loss 27.06732177734375\n",
      "cls loss 522.2689208984375  loc loss 37.55768585205078\n",
      "cls loss 397.8375549316406  loc loss 22.688613891601562\n",
      "cls loss 582.4923095703125  loc loss 32.25228500366211\n",
      "cls loss 613.9937744140625  loc loss 46.96681213378906\n",
      "cls loss 505.67822265625  loc loss 27.578495025634766\n",
      "cls loss 711.9473266601562  loc loss 51.80315017700195\n",
      "cls loss 294.6362609863281  loc loss 13.204655647277832\n",
      "cls loss 531.1392822265625  loc loss 32.74835968017578\n",
      "cls loss 420.5500183105469  loc loss 20.893341064453125\n",
      "cls loss 452.16656494140625  loc loss 23.721418380737305\n",
      "cls loss 562.5756225585938  loc loss 35.157894134521484\n",
      "cls loss 525.7991943359375  loc loss 26.98079490661621\n",
      "cls loss 734.03662109375  loc loss 47.43477249145508\n",
      "cls loss 471.9336242675781  loc loss 31.556196212768555\n",
      "cls loss 600.5099487304688  loc loss 42.09189224243164\n",
      "cls loss 916.846923828125  loc loss 55.294673919677734\n",
      "cls loss 472.61407470703125  loc loss 35.84585952758789\n",
      "cls loss 556.724365234375  loc loss 32.70138168334961\n",
      "cls loss 636.3076171875  loc loss 49.3832893371582\n",
      "cls loss 708.16162109375  loc loss 49.814231872558594\n",
      "cls loss 875.9970703125  loc loss 46.564491271972656\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 5.])\n",
      "cls loss 262.01324462890625  loc loss 10.442273139953613\n",
      "cls loss 331.1502990722656  loc loss 15.046707153320312\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 13.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 6., 8., 8.])\n",
      "cls loss 276.9407043457031  loc loss 14.675580978393555\n",
      "cls loss 362.62408447265625  loc loss 18.316802978515625\n",
      "cls loss 693.326171875  loc loss 46.5289306640625\n",
      "cls loss 310.6714782714844  loc loss 15.195135116577148\n",
      "cls loss 521.7549438476562  loc loss 40.75263977050781\n",
      "cls loss 820.9556884765625  loc loss 58.882591247558594\n",
      "cls loss 497.1545715332031  loc loss 37.251739501953125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([42., 42.,  1.,  1.,  1.,  1.,  1.,  1.,  1., 42., 42.])\n",
      "cls loss 569.4929809570312  loc loss 31.465816497802734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 714.322998046875  loc loss 55.32699203491211\n",
      "cls loss 613.810791015625  loc loss 46.91663360595703\n",
      "cls loss 426.9587097167969  loc loss 26.644580841064453\n",
      "cls loss 564.4846801757812  loc loss 33.102352142333984\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 756.3821411132812  loc loss 50.643951416015625\n",
      "cls loss 628.4786376953125  loc loss 43.02096176147461\n",
      "cls loss 391.2793884277344  loc loss 22.660886764526367\n",
      "cls loss 325.85211181640625  loc loss 18.589876174926758\n",
      "cls loss 472.62445068359375  loc loss 27.505483627319336\n",
      "cls loss 628.6182861328125  loc loss 39.56901931762695\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15.])\n",
      "cls loss 318.7682800292969  loc loss 13.163396835327148\n",
      "cls loss 518.4481201171875  loc loss 33.608734130859375\n",
      "cls loss 462.76971435546875  loc loss 30.69417381286621\n",
      "cls loss 815.5674438476562  loc loss 56.4384765625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19.,  7.])\n",
      "cls loss 462.7263488769531  loc loss 24.745853424072266\n",
      "cls loss 859.5302734375  loc loss 56.52544403076172\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 725.116455078125  loc loss 37.63622283935547\n",
      "cls loss 616.4562377929688  loc loss 44.97508239746094\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([38., 38.,  1., 18.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1., 18., 18.,  1.])\n",
      "cls loss 482.72705078125  loc loss 23.953834533691406\n",
      "cls loss 451.297119140625  loc loss 21.845346450805664\n",
      "cls loss 818.6661376953125  loc loss 59.53791427612305\n",
      "cls loss 634.7177124023438  loc loss 34.57155990600586\n",
      "cls loss 575.24658203125  loc loss 29.590633392333984\n",
      "cls loss 338.68072509765625  loc loss 26.263046264648438\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.])\n",
      "cls loss 266.50341796875  loc loss 9.507509231567383\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([32.])\n",
      "cls loss 521.7010498046875  loc loss 27.519193649291992\n",
      "cls loss 445.47271728515625  loc loss 32.17002487182617\n",
      "cls loss 584.3001708984375  loc loss 46.19466781616211\n",
      "cls loss 506.4915466308594  loc loss 34.420799255371094\n",
      "cls loss 421.99957275390625  loc loss 26.963481903076172\n",
      "cls loss 704.2691040039062  loc loss 43.2322998046875\n",
      "cls loss 758.3786010742188  loc loss 51.9432258605957\n",
      "cls loss 602.244873046875  loc loss 39.33977127075195\n",
      "cls loss 491.7701416015625  loc loss 28.630056381225586\n",
      "cls loss 770.67626953125  loc loss 48.87527084350586\n",
      "cls loss 509.39141845703125  loc loss 25.974882125854492\n",
      "cls loss 814.5344848632812  loc loss 59.276004791259766\n",
      "cls loss 583.5350341796875  loc loss 32.450313568115234\n",
      "cls loss 487.37408447265625  loc loss 35.71271896362305\n",
      "cls loss 364.65606689453125  loc loss 17.88636016845703\n",
      "cls loss 420.26165771484375  loc loss 25.553308486938477\n",
      "cls loss 614.0704345703125  loc loss 40.01591873168945\n",
      "cls loss 635.5736083984375  loc loss 44.85120391845703\n",
      "cls loss 372.12640380859375  loc loss 23.748153686523438\n",
      "cls loss 677.697265625  loc loss 44.83531951904297\n",
      "cls loss 797.9909057617188  loc loss 49.30088424682617\n",
      "cls loss 294.4820861816406  loc loss 20.109567642211914\n",
      "cls loss 781.8834228515625  loc loss 51.93370819091797\n",
      "cls loss 554.7152099609375  loc loss 42.70195388793945\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 755.8394775390625  loc loss 58.10685348510742\n",
      "cls loss 378.8587646484375  loc loss 13.897664070129395\n",
      "cls loss 564.1449584960938  loc loss 30.3313045501709\n",
      "cls loss 548.439453125  loc loss 36.5281982421875\n",
      "cls loss 452.58697509765625  loc loss 25.527441024780273\n",
      "cls loss 282.7507629394531  loc loss 14.15070629119873\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 9., 9., 1., 9., 9., 9., 9., 1., 9.])\n",
      "cls loss 962.7223510742188  loc loss 79.12026977539062\n",
      "cls loss 572.57373046875  loc loss 30.0090274810791\n",
      "cls loss 809.324462890625  loc loss 68.10572814941406\n",
      "cls loss 348.0212097167969  loc loss 24.375133514404297\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 42., 42.])\n",
      "cls loss 604.2640991210938  loc loss 44.63636016845703\n",
      "cls loss 653.4239501953125  loc loss 47.65407180786133\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  2.,  1.,  1.,  1., 38.,\n",
      "         1.,  1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 38., 38., 38.,  1., 38., 38., 38.,  1.,  1., 38.,  1.,\n",
      "         1.])\n",
      "cls loss 394.4166259765625  loc loss 28.590478897094727\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  8.,  8.])\n",
      "cls loss 951.1812133789062  loc loss 60.3468017578125\n",
      "cls loss 922.261962890625  loc loss 66.5869369506836\n",
      "cls loss 361.57562255859375  loc loss 20.63119125366211\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([4., 1., 1., 4.])\n",
      "cls loss 525.969482421875  loc loss 35.22348403930664\n",
      "cls loss 632.8089599609375  loc loss 38.41484069824219\n",
      "cls loss 277.04132080078125  loc loss 13.399977684020996\n",
      "cls loss 376.69476318359375  loc loss 23.428627014160156\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([51.,  1.])\n",
      "cls loss 278.6017150878906  loc loss 11.21859359741211\n",
      "cls loss 376.07440185546875  loc loss 20.213590621948242\n",
      "cls loss 648.1746826171875  loc loss 36.49609375\n",
      "cls loss 693.54248046875  loc loss 49.91435241699219\n",
      "cls loss 931.2799072265625  loc loss 50.87944412231445\n",
      "cls loss 1130.0274658203125  loc loss 77.32330322265625\n",
      "cls loss 506.7845764160156  loc loss 30.193729400634766\n",
      "cls loss 712.46630859375  loc loss 51.66725158691406\n",
      "cls loss 751.8629760742188  loc loss 53.98593521118164\n",
      "cls loss 601.3706665039062  loc loss 34.69344711303711\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  3.,  1.,  1.,  1.,  3.,  1.,  1.,\n",
      "         1.,  1.,  1.])\n",
      "cls loss 602.1044921875  loc loss 28.65682029724121\n",
      "cls loss 702.3341064453125  loc loss 36.03901672363281\n",
      "cls loss 630.999755859375  loc loss 33.467864990234375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "cls loss 528.449462890625  loc loss 31.008056640625\n",
      "cls loss 309.39971923828125  loc loss 25.085880279541016\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3.])\n",
      "cls loss 258.71173095703125  loc loss 12.756628036499023\n",
      "cls loss 459.65972900390625  loc loss 30.911272048950195\n",
      "cls loss 373.8914794921875  loc loss 28.688077926635742\n",
      "cls loss 673.0368041992188  loc loss 45.41907501220703\n",
      "cls loss 464.0271911621094  loc loss 23.736482620239258\n",
      "cls loss 375.8306579589844  loc loss 26.094202041625977\n",
      "cls loss 1114.9705810546875  loc loss 75.65284729003906\n",
      "cls loss 482.80157470703125  loc loss 37.42015075683594\n",
      "cls loss 365.408203125  loc loss 27.02037811279297\n",
      "cls loss 462.95892333984375  loc loss 27.032527923583984\n",
      "cls loss 421.6041259765625  loc loss 30.386056900024414\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 765.217041015625  loc loss 51.59834289550781\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  9., 64., 64., 64., 64., 64., 64., 64., 64., 64.,  9.,  9.,  9.,\n",
      "         9.])\n",
      "cls loss 415.925537109375  loc loss 20.503856658935547\n",
      "cls loss 961.3692626953125  loc loss 77.8427963256836\n",
      "cls loss 514.9822998046875  loc loss 33.99251937866211\n",
      "cls loss 672.0899658203125  loc loss 46.80643844604492\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.,  3.,  3.])\n",
      "cls loss 431.86004638671875  loc loss 24.329280853271484\n",
      "cls loss 471.2286376953125  loc loss 31.36176109313965\n",
      "cls loss 466.60662841796875  loc loss 33.525047302246094\n",
      "cls loss 490.708740234375  loc loss 36.241817474365234\n",
      "cls loss 507.0657043457031  loc loss 40.24177551269531\n",
      "cls loss 516.6544189453125  loc loss 38.21426773071289\n",
      "cls loss 483.1903076171875  loc loss 37.76266860961914\n",
      "cls loss 532.0536499023438  loc loss 31.507976531982422\n",
      "cls loss 645.7178955078125  loc loss 43.819000244140625\n",
      "cls loss 543.3079833984375  loc loss 30.492433547973633\n",
      "cls loss 443.1737365722656  loc loss 19.555946350097656\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21.])\n",
      "cls loss 326.8938293457031  loc loss 18.28793716430664\n",
      "cls loss 448.5198059082031  loc loss 37.473331451416016\n",
      "cls loss 659.0046997070312  loc loss 45.93883514404297\n",
      "cls loss 393.98602294921875  loc loss 22.032711029052734\n",
      "cls loss 528.2424926757812  loc loss 32.54117965698242\n",
      "cls loss 981.8134765625  loc loss 52.959938049316406\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 42., 42.,  1.,  1.])\n",
      "cls loss 497.95220947265625  loc loss 32.12669372558594\n",
      "cls loss 330.4375915527344  loc loss 23.84600257873535\n",
      "cls loss 474.5778503417969  loc loss 35.47337341308594\n",
      "cls loss 665.4581298828125  loc loss 53.0933837890625\n",
      "cls loss 426.07257080078125  loc loss 27.37029266357422\n",
      "cls loss 621.847412109375  loc loss 47.37828063964844\n",
      "cls loss 598.4749755859375  loc loss 43.67743682861328\n",
      "cls loss 642.1802978515625  loc loss 37.56306076049805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 500.28594970703125  loc loss 30.341670989990234\n",
      "cls loss 455.88482666015625  loc loss 27.61908531188965\n",
      "cls loss 367.7109375  loc loss 14.566535949707031\n",
      "cls loss 452.06964111328125  loc loss 30.069427490234375\n",
      "cls loss 690.611572265625  loc loss 52.294864654541016\n",
      "cls loss 554.4661865234375  loc loss 34.469295501708984\n",
      "cls loss 512.8218383789062  loc loss 38.16178894042969\n",
      "cls loss 572.9549560546875  loc loss 34.13156509399414\n",
      "cls loss 821.791748046875  loc loss 58.18854904174805\n",
      "cls loss 603.7901000976562  loc loss 45.25979995727539\n",
      "cls loss 700.9594116210938  loc loss 39.48081970214844\n",
      "cls loss 400.4561462402344  loc loss 20.2642822265625\n",
      "cls loss 574.7205200195312  loc loss 37.21435546875\n",
      "cls loss 531.2613525390625  loc loss 32.15093994140625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 5., 5., 5., 5., 5., 5.])\n",
      "cls loss 379.0938720703125  loc loss 25.675622940063477\n",
      "cls loss 461.7572021484375  loc loss 26.141767501831055\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([13.])\n",
      "cls loss 319.81951904296875  loc loss 19.719911575317383\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([44., 10.,  1.,  1.,  1.])\n",
      "cls loss 325.6192932128906  loc loss 19.796123504638672\n",
      "cls loss 622.3963623046875  loc loss 30.917984008789062\n",
      "cls loss 503.2110595703125  loc loss 28.46871566772461\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19., 19., 19., 19., 19., 19., 19.])\n",
      "cls loss 633.0081787109375  loc loss 32.76999282836914\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([56.])\n",
      "cls loss 1062.2620849609375  loc loss 69.26097869873047\n",
      "cls loss 646.02880859375  loc loss 50.40651321411133\n",
      "cls loss 822.3643798828125  loc loss 57.757049560546875\n",
      "cls loss 816.2359619140625  loc loss 62.67048645019531\n",
      "cls loss 513.205810546875  loc loss 28.746007919311523\n",
      "cls loss 799.973876953125  loc loss 56.95539855957031\n",
      "cls loss 464.0768737792969  loc loss 30.345788955688477\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 36.])\n",
      "cls loss 569.2899780273438  loc loss 31.337038040161133\n",
      "cls loss 513.2882080078125  loc loss 34.84062957763672\n",
      "cls loss 489.432373046875  loc loss 29.714797973632812\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5.])\n",
      "cls loss 601.5828857421875  loc loss 35.61250305175781\n",
      "cls loss 317.5031433105469  loc loss 16.96321678161621\n",
      "cls loss 734.6233520507812  loc loss 40.18681335449219\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "cls loss 632.53369140625  loc loss 41.77946853637695\n",
      "cls loss 622.4412231445312  loc loss 41.758689880371094\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 581.305908203125  loc loss 42.192081451416016\n",
      "cls loss 687.8400268554688  loc loss 48.864845275878906\n",
      "cls loss 570.0943603515625  loc loss 52.60162353515625\n",
      "cls loss 410.4183349609375  loc loss 28.76820945739746\n",
      "cls loss 507.0191650390625  loc loss 36.741859436035156\n",
      "cls loss 530.857177734375  loc loss 33.25876235961914\n",
      "cls loss 810.5743408203125  loc loss 45.8640251159668\n",
      "cls loss 371.95281982421875  loc loss 18.32918357849121\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 11., 15., 10., 10., 10., 10., 10.])\n",
      "cls loss 879.2977294921875  loc loss 53.328857421875\n",
      "cls loss 466.06072998046875  loc loss 33.03401184082031\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3.])\n",
      "cls loss 524.11865234375  loc loss 34.747352600097656\n",
      "cls loss 483.9601135253906  loc loss 26.647958755493164\n",
      "cls loss 515.8604125976562  loc loss 25.276214599609375\n",
      "cls loss 656.3421020507812  loc loss 31.47255516052246\n",
      "cls loss 360.01861572265625  loc loss 16.93720245361328\n",
      "cls loss 509.9808044433594  loc loss 33.56977844238281\n",
      "cls loss 562.765625  loc loss 42.509498596191406\n",
      "cls loss 479.4747314453125  loc loss 36.10285186767578\n",
      "cls loss 1132.510986328125  loc loss 82.85414123535156\n",
      "cls loss 800.1541137695312  loc loss 51.76848602294922\n",
      "cls loss 520.4935913085938  loc loss 36.886287689208984\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  9.,  9.,  9.,  6.,  6., 85., 85.,  8.,  1.,  1.,  1.,  1.,\n",
      "         6.,  6.])\n",
      "cls loss 351.5188903808594  loc loss 26.946914672851562\n",
      "cls loss 842.2684326171875  loc loss 59.504207611083984\n",
      "cls loss 995.9420776367188  loc loss 62.754478454589844\n",
      "cls loss 684.3638305664062  loc loss 45.82318115234375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10.,  3.,  3., 10.])\n",
      "cls loss 464.1260986328125  loc loss 25.037839889526367\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([7.])\n",
      "cls loss 571.6034545898438  loc loss 38.29449462890625\n",
      "cls loss 588.5927124023438  loc loss 35.28912353515625\n",
      "cls loss 513.20849609375  loc loss 42.6545295715332\n",
      "cls loss 735.239990234375  loc loss 60.412872314453125\n",
      "cls loss 526.2100830078125  loc loss 36.14071273803711\n",
      "cls loss 728.3564453125  loc loss 47.905052185058594\n",
      "cls loss 906.6674194335938  loc loss 54.875572204589844\n",
      "cls loss 535.4124755859375  loc loss 37.691246032714844\n",
      "cls loss 586.3768310546875  loc loss 41.5283317565918\n",
      "cls loss 498.82867431640625  loc loss 36.6397819519043\n",
      "cls loss 699.3262939453125  loc loss 57.00820541381836\n",
      "cls loss 570.6455078125  loc loss 36.10887908935547\n",
      "cls loss 458.28973388671875  loc loss 26.8952579498291\n",
      "cls loss 699.2357177734375  loc loss 52.575767517089844\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([62.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([62.])\n",
      "cls loss 320.986328125  loc loss 16.140766143798828\n",
      "cls loss 554.0027465820312  loc loss 38.54108810424805\n",
      "cls loss 540.1480712890625  loc loss 35.121978759765625\n",
      "cls loss 371.19342041015625  loc loss 16.647136688232422\n",
      "cls loss 686.0831298828125  loc loss 45.39197540283203\n",
      "cls loss 701.7376098632812  loc loss 39.75187683105469\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([28.])\n",
      "cls loss 766.6806030273438  loc loss 41.553836822509766\n",
      "cls loss 672.1727905273438  loc loss 41.13500213623047\n",
      "cls loss 667.555419921875  loc loss 43.13520812988281\n",
      "cls loss 669.3311767578125  loc loss 43.60354995727539\n",
      "cls loss 930.7536010742188  loc loss 62.40019989013672\n",
      "cls loss 520.1102905273438  loc loss 33.27395248413086\n",
      "cls loss 647.8759765625  loc loss 39.518821716308594\n",
      "cls loss 566.1255493164062  loc loss 47.4053955078125\n",
      "cls loss 913.211181640625  loc loss 71.85765838623047\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([81.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 644.2924194335938  loc loss 26.32354164123535\n",
      "cls loss 480.90460205078125  loc loss 24.788066864013672\n",
      "cls loss 405.5574035644531  loc loss 26.208633422851562\n",
      "cls loss 350.57891845703125  loc loss 13.126862525939941\n",
      "cls loss 390.95770263671875  loc loss 25.932598114013672\n",
      "cls loss 428.1263427734375  loc loss 26.142366409301758\n",
      "cls loss 504.672607421875  loc loss 31.13157844543457\n",
      "cls loss 652.2216186523438  loc loss 51.38616180419922\n",
      "cls loss 722.8399658203125  loc loss 48.44142532348633\n",
      "cls loss 1366.725830078125  loc loss 91.53192138671875\n",
      "cls loss 551.173828125  loc loss 28.6488094329834\n",
      "cls loss 666.535400390625  loc loss 46.02875900268555\n",
      "cls loss 471.3429870605469  loc loss 28.728160858154297\n",
      "cls loss 610.5748291015625  loc loss 34.61007308959961\n",
      "cls loss 540.4434814453125  loc loss 30.928125381469727\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([44., 44.])\n",
      "cls loss 492.5831298828125  loc loss 24.236154556274414\n",
      "cls loss 499.180419921875  loc loss 35.014408111572266\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15.])\n",
      "cls loss 579.7589111328125  loc loss 28.6407470703125\n",
      "cls loss 285.421630859375  loc loss 16.369367599487305\n",
      "cls loss 581.8206787109375  loc loss 33.70847702026367\n",
      "cls loss 327.3799743652344  loc loss 19.636762619018555\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([1., 3., 3.])\n",
      "cls loss 364.05523681640625  loc loss 26.799535751342773\n",
      "cls loss 302.17803955078125  loc loss 12.664057731628418\n",
      "cls loss 554.3068237304688  loc loss 31.442689895629883\n",
      "cls loss 584.3692626953125  loc loss 34.2747688293457\n",
      "cls loss 524.6931762695312  loc loss 34.375244140625\n",
      "cls loss 546.139892578125  loc loss 29.632478713989258\n",
      "cls loss 429.4632568359375  loc loss 33.08256912231445\n",
      "cls loss 590.7691650390625  loc loss 39.478633880615234\n",
      "cls loss 445.0527648925781  loc loss 29.83256721496582\n",
      "cls loss 563.7752685546875  loc loss 39.87985610961914\n",
      "cls loss 362.2511901855469  loc loss 22.341201782226562\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 676.63427734375  loc loss 41.816261291503906\n",
      "cls loss 786.7210083007812  loc loss 38.39030838012695\n",
      "cls loss 688.6551513671875  loc loss 48.23967361450195\n",
      "cls loss 686.1475830078125  loc loss 52.13511657714844\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10., 10., 10.,  1.,  1.,  1.,  1.,  1.,  1.,  8.,  8.,\n",
      "         1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10., 10., 10.,  1.,  1.,  1.,  1.,  1.,  1.,  8.,  8.,\n",
      "         1.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 650.186279296875  loc loss 30.413005828857422\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 3., 3., 3.])\n",
      "cls loss 547.2344970703125  loc loss 34.33852767944336\n",
      "cls loss 382.7159423828125  loc loss 21.1564884185791\n",
      "cls loss 301.7388916015625  loc loss 14.575977325439453\n",
      "cls loss 509.244384765625  loc loss 38.37826919555664\n",
      "cls loss 392.718017578125  loc loss 20.64463233947754\n",
      "cls loss 457.34283447265625  loc loss 30.025394439697266\n",
      "cls loss 505.3485412597656  loc loss 35.16262435913086\n",
      "cls loss 713.9046630859375  loc loss 49.845577239990234\n",
      "cls loss 602.2086181640625  loc loss 29.853031158447266\n",
      "cls loss 582.280029296875  loc loss 32.651763916015625\n",
      "cls loss 656.0370483398438  loc loss 42.978553771972656\n",
      "cls loss 469.68475341796875  loc loss 35.23455810546875\n",
      "cls loss 862.823486328125  loc loss 63.45917892456055\n",
      "cls loss 438.8250732421875  loc loss 22.42169761657715\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 663.457763671875  loc loss 40.78418731689453\n",
      "cls loss 331.781005859375  loc loss 13.97823715209961\n",
      "cls loss 815.954833984375  loc loss 51.29404830932617\n",
      "cls loss 430.91424560546875  loc loss 22.68259620666504\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 34.])\n",
      "cls loss 696.5614624023438  loc loss 36.351478576660156\n",
      "cls loss 321.1774597167969  loc loss 20.8872127532959\n",
      "cls loss 594.509033203125  loc loss 40.360294342041016\n",
      "cls loss 206.2452392578125  loc loss 15.688888549804688\n",
      "cls loss 531.7271118164062  loc loss 34.08393478393555\n",
      "cls loss 514.8653564453125  loc loss 41.290767669677734\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 38.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16., 16., 16.,  9.,  9.,  9., 16., 16., 16., 85.,  9.])\n",
      "cls loss 515.41064453125  loc loss 33.90281677246094\n",
      "cls loss 585.1156005859375  loc loss 45.693668365478516\n",
      "cls loss 792.569580078125  loc loss 55.26435852050781\n",
      "cls loss 1131.4307861328125  loc loss 76.8881607055664\n",
      "cls loss 359.07269287109375  loc loss 18.346277236938477\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3., 10.,  8.,  8., 10., 10., 10.,  3.,  3., 14.])\n",
      "cls loss 441.1165466308594  loc loss 20.609825134277344\n",
      "cls loss 780.3546142578125  loc loss 39.209228515625\n",
      "cls loss 333.6462097167969  loc loss 12.20887565612793\n",
      "cls loss 492.9548034667969  loc loss 21.310016632080078\n",
      "cls loss 654.0760498046875  loc loss 38.714073181152344\n",
      "cls loss 555.302734375  loc loss 35.77994918823242\n",
      "cls loss 319.77093505859375  loc loss 16.57505226135254\n",
      "cls loss 359.5682373046875  loc loss 22.764360427856445\n",
      "cls loss 553.8236694335938  loc loss 36.2081298828125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42., 42.,  1.])\n",
      "cls loss 539.871826171875  loc loss 38.59913635253906\n",
      "cls loss 448.98126220703125  loc loss 26.588314056396484\n",
      "cls loss 591.566650390625  loc loss 46.22089767456055\n",
      "cls loss 700.8082275390625  loc loss 44.933677673339844\n",
      "cls loss 484.3453369140625  loc loss 31.437097549438477\n",
      "cls loss 599.668212890625  loc loss 42.02766036987305\n",
      "cls loss 389.05078125  loc loss 25.687410354614258\n",
      "cls loss 404.7513427734375  loc loss 28.004974365234375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20.])\n",
      "cls loss 325.2822265625  loc loss 17.843713760375977\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([11.])\n",
      "cls loss 410.70263671875  loc loss 20.76250457763672\n",
      "cls loss 288.2779541015625  loc loss 15.129634857177734\n",
      "cls loss 622.3431396484375  loc loss 48.47309875488281\n",
      "cls loss 292.6551208496094  loc loss 13.096830368041992\n",
      "cls loss 601.95849609375  loc loss 33.25669860839844\n",
      "cls loss 328.72198486328125  loc loss 20.649311065673828\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 35., 27.])\n",
      "cls loss 551.7513427734375  loc loss 35.29222106933594\n",
      "cls loss 594.256103515625  loc loss 45.37185287475586\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 417.81378173828125  loc loss 25.42955780029297\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([42.,  1.])\n",
      "cls loss 542.9688110351562  loc loss 38.203861236572266\n",
      "cls loss 498.5762939453125  loc loss 29.115280151367188\n",
      "cls loss 621.912353515625  loc loss 36.980594635009766\n",
      "cls loss 734.249755859375  loc loss 49.06007766723633\n",
      "cls loss 670.5760498046875  loc loss 41.01410675048828\n",
      "cls loss 457.87591552734375  loc loss 34.56077575683594\n",
      "cls loss 394.67608642578125  loc loss 30.28395652770996\n",
      "cls loss 262.92474365234375  loc loss 12.105009078979492\n",
      "cls loss 470.3179931640625  loc loss 25.93916893005371\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 1., 1.])\n",
      "cls loss 456.798583984375  loc loss 24.484039306640625\n",
      "cls loss 501.05853271484375  loc loss 33.620018005371094\n",
      "cls loss 502.22357177734375  loc loss 31.805667877197266\n",
      "cls loss 405.6021728515625  loc loss 29.32352638244629\n",
      "cls loss 492.0880432128906  loc loss 29.453895568847656\n",
      "cls loss 511.3365783691406  loc loss 38.76177978515625\n",
      "cls loss 707.8945922851562  loc loss 43.554927825927734\n",
      "cls loss 607.356689453125  loc loss 47.49119567871094\n",
      "cls loss 583.291015625  loc loss 34.959285736083984\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 453.8400573730469  loc loss 31.34160804748535\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 537.1314697265625  loc loss 26.78494644165039\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([81.])\n",
      "cls loss 652.8990478515625  loc loss 40.425575256347656\n",
      "cls loss 415.64599609375  loc loss 27.635854721069336\n",
      "cls loss 289.6142272949219  loc loss 17.09248161315918\n",
      "cls loss 461.7440490722656  loc loss 24.236419677734375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3.,  1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 19.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 19.])\n",
      "cls loss 598.8541259765625  loc loss 41.1690673828125\n",
      "cls loss 356.99261474609375  loc loss 17.968217849731445\n",
      "cls loss 369.3963623046875  loc loss 21.903308868408203\n",
      "cls loss 698.9805908203125  loc loss 50.982147216796875\n",
      "cls loss 359.61676025390625  loc loss 22.58183479309082\n",
      "cls loss 448.7413330078125  loc loss 30.618181228637695\n",
      "cls loss 535.6561889648438  loc loss 36.302677154541016\n",
      "cls loss 426.0537109375  loc loss 30.93826675415039\n",
      "cls loss 555.923828125  loc loss 32.86675262451172\n",
      "cls loss 623.7017822265625  loc loss 43.348976135253906\n",
      "cls loss 751.113525390625  loc loss 68.55061340332031\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 81.])\n",
      "cls loss 555.930908203125  loc loss 29.589035034179688\n",
      "cls loss 470.5011291503906  loc loss 27.513431549072266\n",
      "cls loss 545.874267578125  loc loss 28.757888793945312\n",
      "cls loss 411.3809814453125  loc loss 20.079898834228516\n",
      "cls loss 370.812744140625  loc loss 23.15933609008789\n",
      "cls loss 426.65289306640625  loc loss 30.817075729370117\n",
      "cls loss 344.51239013671875  loc loss 23.933568954467773\n",
      "cls loss 275.5572204589844  loc loss 17.67791748046875\n",
      "cls loss 365.6004638671875  loc loss 24.302478790283203\n",
      "cls loss 508.5526428222656  loc loss 31.028932571411133\n",
      "cls loss 412.7445068359375  loc loss 33.11433410644531\n",
      "cls loss 437.8721923828125  loc loss 35.04401397705078\n",
      "cls loss 271.2381896972656  loc loss 19.753273010253906\n",
      "cls loss 904.387939453125  loc loss 65.12952423095703\n",
      "cls loss 584.3616943359375  loc loss 39.187599182128906\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 499.122314453125  loc loss 26.322147369384766\n",
      "cls loss 537.3556518554688  loc loss 36.520042419433594\n",
      "cls loss 441.8599548339844  loc loss 26.159767150878906\n",
      "cls loss 626.8002319335938  loc loss 41.161354064941406\n",
      "cls loss 616.2200927734375  loc loss 39.23778533935547\n",
      "cls loss 550.8208618164062  loc loss 34.874412536621094\n",
      "cls loss 445.2720642089844  loc loss 25.987987518310547\n",
      "cls loss 333.8187255859375  loc loss 20.757108688354492\n",
      "cls loss 507.5212097167969  loc loss 30.6442928314209\n",
      "cls loss 530.029052734375  loc loss 36.361473083496094\n",
      "cls loss 569.130859375  loc loss 32.15204620361328\n",
      "cls loss 708.1921997070312  loc loss 52.97142028808594\n",
      "cls loss 695.598876953125  loc loss 56.84553527832031\n",
      "cls loss 515.4021606445312  loc loss 37.16749954223633\n",
      "cls loss 681.7574462890625  loc loss 54.12621307373047\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1., 38., 47.,  1.,  1.,  1.,  1.,  1., 62.])\n",
      "cls loss 497.36029052734375  loc loss 24.789987564086914\n",
      "cls loss 603.1922607421875  loc loss 34.20165252685547\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 614.4730224609375  loc loss 36.424983978271484\n",
      "cls loss 661.1837768554688  loc loss 49.27301788330078\n",
      "cls loss 467.5602722167969  loc loss 23.40688133239746\n",
      "cls loss 523.8428955078125  loc loss 43.06147384643555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 483.2396545410156  loc loss 29.187070846557617\n",
      "cls loss 294.0076904296875  loc loss 11.72160816192627\n",
      "cls loss 471.72332763671875  loc loss 26.74716567993164\n",
      "cls loss 401.6043701171875  loc loss 18.002002716064453\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1., 35.])\n",
      "cls loss 481.10211181640625  loc loss 23.640249252319336\n",
      "cls loss 639.8976440429688  loc loss 35.20327377319336\n",
      "cls loss 628.2097778320312  loc loss 41.460899353027344\n",
      "cls loss 559.8804321289062  loc loss 46.78226089477539\n",
      "cls loss 457.4185791015625  loc loss 36.488975524902344\n",
      "cls loss 599.0933837890625  loc loss 44.969383239746094\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 339.59136962890625  loc loss 19.69875144958496\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 494.7861328125  loc loss 23.323894500732422\n",
      "cls loss 790.6661987304688  loc loss 41.96759796142578\n",
      "cls loss 960.7861328125  loc loss 73.0083236694336\n",
      "cls loss 495.477294921875  loc loss 25.26058006286621\n",
      "cls loss 430.96588134765625  loc loss 27.71356201171875\n",
      "cls loss 438.65972900390625  loc loss 24.23810386657715\n",
      "cls loss 468.18768310546875  loc loss 30.633193969726562\n",
      "cls loss 432.2564392089844  loc loss 18.353784561157227\n",
      "cls loss 722.446044921875  loc loss 50.7554817199707\n",
      "cls loss 590.2294311523438  loc loss 36.855712890625\n",
      "cls loss 336.04241943359375  loc loss 21.008975982666016\n",
      "cls loss 581.6178588867188  loc loss 32.32073211669922\n",
      "cls loss 690.791748046875  loc loss 55.87553405761719\n",
      "cls loss 580.2405395507812  loc loss 36.57662582397461\n",
      "cls loss 518.3516235351562  loc loss 27.733264923095703\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.])\n",
      "cls loss 477.93829345703125  loc loss 34.60289764404297\n",
      "cls loss 438.7948913574219  loc loss 33.21343231201172\n",
      "cls loss 596.3952026367188  loc loss 40.71473693847656\n",
      "cls loss 907.6500244140625  loc loss 73.25607299804688\n",
      "cls loss 407.3155517578125  loc loss 19.526639938354492\n",
      "cls loss 526.8214111328125  loc loss 32.222251892089844\n",
      "cls loss 419.2682189941406  loc loss 23.12126922607422\n",
      "cls loss 458.39678955078125  loc loss 28.0123233795166\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 21., 21., 21.])\n",
      "cls loss 486.57989501953125  loc loss 28.732471466064453\n",
      "cls loss 455.85107421875  loc loss 21.386667251586914\n",
      "cls loss 480.46258544921875  loc loss 31.75251007080078\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 35.])\n",
      "cls loss 631.325439453125  loc loss 40.34706497192383\n",
      "cls loss 230.29766845703125  loc loss 12.7741117477417\n",
      "cls loss 375.0450744628906  loc loss 25.33975601196289\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 373.4922180175781  loc loss 17.174888610839844\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 38., 38.,  9., 38.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1.,  1.])\n",
      "cls loss 417.9444580078125  loc loss 27.822053909301758\n",
      "cls loss 684.1753540039062  loc loss 44.63313674926758\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 2.,  1., 77., 31., 10., 10.,  1.,  4., 10.])\n",
      "cls loss 355.27789306640625  loc loss 17.158920288085938\n",
      "cls loss 653.36572265625  loc loss 39.172607421875\n",
      "cls loss 1291.712646484375  loc loss 76.91295623779297\n",
      "cls loss 422.5040588378906  loc loss 26.914262771606445\n",
      "cls loss 584.9093627929688  loc loss 43.393714904785156\n",
      "cls loss 433.31024169921875  loc loss 23.22406578063965\n",
      "cls loss 438.2252502441406  loc loss 21.0633487701416\n",
      "cls loss 636.6077880859375  loc loss 29.379180908203125\n",
      "cls loss 634.416015625  loc loss 33.29594421386719\n",
      "cls loss 558.7650146484375  loc loss 37.864540100097656\n",
      "cls loss 428.2665100097656  loc loss 20.741758346557617\n",
      "cls loss 466.88250732421875  loc loss 23.88698387145996\n",
      "cls loss 837.8311767578125  loc loss 52.42729187011719\n",
      "cls loss 717.47705078125  loc loss 44.342262268066406\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1., 42., 42., 42., 42., 42., 42.,  1.,\n",
      "         1.,  1.,  1., 42.,  1.,  1., 42.,  1.])\n",
      "cls loss 398.8857727050781  loc loss 27.764066696166992\n",
      "cls loss 626.2304077148438  loc loss 38.243038177490234\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.])\n",
      "cls loss 267.441650390625  loc loss 16.31615447998047\n",
      "cls loss 609.0487670898438  loc loss 39.9818115234375\n",
      "cls loss 491.01336669921875  loc loss 34.354984283447266\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([11.])\n",
      "cls loss 301.944091796875  loc loss 17.253446578979492\n",
      "cls loss 381.032470703125  loc loss 17.403491973876953\n",
      "cls loss 402.4574890136719  loc loss 17.670316696166992\n",
      "cls loss 609.02197265625  loc loss 38.72446060180664\n",
      "cls loss 562.7517700195312  loc loss 29.748769760131836\n",
      "cls loss 521.0426025390625  loc loss 35.799434661865234\n",
      "cls loss 774.0574340820312  loc loss 40.35089111328125\n",
      "cls loss 391.63250732421875  loc loss 23.371292114257812\n",
      "cls loss 761.1387329101562  loc loss 54.906028747558594\n",
      "cls loss 382.60015869140625  loc loss 25.03887367248535\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 356.25555419921875  loc loss 25.06696128845215\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1., 38., 38., 42.])\n",
      "cls loss 457.25994873046875  loc loss 33.86353302001953\n",
      "cls loss 423.57763671875  loc loss 24.71294593811035\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 365.3088684082031  loc loss 27.0982608795166\n",
      "cls loss 861.0371704101562  loc loss 59.505210876464844\n",
      "cls loss 527.1102294921875  loc loss 34.48223114013672\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10.,  3.,  3.,  6.,  8.,  8.,  1.,  1.,  1., 10.])\n",
      "cls loss 448.9804382324219  loc loss 23.32424545288086\n",
      "cls loss 279.2374572753906  loc loss 10.307167053222656\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10.,  3.])\n",
      "cls loss 419.3704833984375  loc loss 23.39006233215332\n",
      "cls loss 255.83749389648438  loc loss 12.481515884399414\n",
      "cls loss 517.0013427734375  loc loss 36.691078186035156\n",
      "cls loss 586.4334106445312  loc loss 38.28437042236328\n",
      "cls loss 432.44970703125  loc loss 26.0128231048584\n",
      "cls loss 308.0335998535156  loc loss 15.308854103088379\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 34.])\n",
      "cls loss 704.3789672851562  loc loss 44.97328567504883\n",
      "cls loss 759.8258056640625  loc loss 64.70223236083984\n",
      "cls loss 494.072021484375  loc loss 37.883583068847656\n",
      "cls loss 379.8344421386719  loc loss 27.624574661254883\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.,  1.])\n",
      "cls loss 442.1338195800781  loc loss 21.592708587646484\n",
      "cls loss 670.35205078125  loc loss 52.223087310791016\n",
      "cls loss 1010.6735229492188  loc loss 65.5177230834961\n",
      "cls loss 842.47705078125  loc loss 43.80095672607422\n",
      "cls loss 500.66259765625  loc loss 26.566503524780273\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 602.83154296875  loc loss 34.80318069458008\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10.])\n",
      "cls loss 374.22320556640625  loc loss 19.750621795654297\n",
      "cls loss 541.9531860351562  loc loss 26.902374267578125\n",
      "cls loss 494.4059753417969  loc loss 30.407245635986328\n",
      "cls loss 361.1382141113281  loc loss 22.062639236450195\n",
      "cls loss 458.47027587890625  loc loss 30.94403076171875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21.,\n",
      "        21.])\n",
      "cls loss 641.2073364257812  loc loss 35.46796417236328\n",
      "cls loss 494.3487854003906  loc loss 30.484703063964844\n",
      "cls loss 321.8065490722656  loc loss 14.877161026000977\n",
      "cls loss 673.637939453125  loc loss 44.213104248046875\n",
      "cls loss 522.3224487304688  loc loss 35.337833404541016\n",
      "cls loss 369.625732421875  loc loss 21.579730987548828\n",
      "cls loss 774.0869750976562  loc loss 50.513668060302734\n",
      "cls loss 937.2078247070312  loc loss 63.86792755126953\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15., 85.])\n",
      "cls loss 565.968505859375  loc loss 37.33705520629883\n",
      "cls loss 597.51904296875  loc loss 44.09284591674805\n",
      "cls loss 602.4195556640625  loc loss 43.651702880859375\n",
      "cls loss 544.5264892578125  loc loss 30.08028793334961\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 8., 8.])\n",
      "cls loss 353.051513671875  loc loss 17.38918685913086\n",
      "cls loss 368.676513671875  loc loss 26.253969192504883\n",
      "cls loss 468.776611328125  loc loss 28.713369369506836\n",
      "cls loss 383.6916198730469  loc loss 21.81863021850586\n",
      "cls loss 448.3376159667969  loc loss 26.626623153686523\n",
      "cls loss 591.0933837890625  loc loss 36.82621765136719\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1., 35., 27., 27.,  1., 27.,  1.])\n",
      "cls loss 748.1862182617188  loc loss 54.44157409667969\n",
      "cls loss 397.1238098144531  loc loss 25.88165855407715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 453.72979736328125  loc loss 33.4033203125\n",
      "cls loss 430.392333984375  loc loss 38.09105682373047\n",
      "cls loss 391.1656188964844  loc loss 30.338937759399414\n",
      "cls loss 427.97662353515625  loc loss 34.12942886352539\n",
      "cls loss 429.59759521484375  loc loss 34.135677337646484\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  2.,  2.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  2.,  2.])\n",
      "cls loss 255.728515625  loc loss 9.765841484069824\n",
      "cls loss 691.9094848632812  loc loss 42.80290603637695\n",
      "cls loss 484.81884765625  loc loss 22.567148208618164\n",
      "cls loss 760.9544677734375  loc loss 55.91387176513672\n",
      "cls loss 323.78546142578125  loc loss 18.610397338867188\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 19., 19., 19., 16.])\n",
      "cls loss 338.447509765625  loc loss 14.45312213897705\n",
      "cls loss 271.371337890625  loc loss 11.444719314575195\n",
      "cls loss 416.99639892578125  loc loss 21.360761642456055\n",
      "cls loss 543.3173217773438  loc loss 36.16843795776367\n",
      "cls loss 286.859375  loc loss 18.998043060302734\n",
      "cls loss 608.8724365234375  loc loss 46.56797790527344\n",
      "cls loss 437.5948181152344  loc loss 30.366207122802734\n",
      "cls loss 488.9749755859375  loc loss 31.19000816345215\n",
      "cls loss 618.6531372070312  loc loss 42.275787353515625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 677.1983642578125  loc loss 29.392505645751953\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 853.5638427734375  loc loss 74.25559997558594\n",
      "cls loss 1071.01611328125  loc loss 102.0401382446289\n",
      "cls loss 562.2449951171875  loc loss 36.06068801879883\n",
      "cls loss 503.092041015625  loc loss 32.835330963134766\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3.,  3.,  3.,  3.,  3., 10.])\n",
      "cls loss 283.81158447265625  loc loss 16.65673828125\n",
      "cls loss 536.9341430664062  loc loss 27.164730072021484\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 1., 1., 1., 3., 3., 3., 3.])\n",
      "cls loss 416.7229919433594  loc loss 26.17824363708496\n",
      "cls loss 787.781494140625  loc loss 51.48569869995117\n",
      "cls loss 620.7105102539062  loc loss 41.10558319091797\n",
      "cls loss 410.7141418457031  loc loss 24.28501319885254\n",
      "cls loss 629.86328125  loc loss 44.18291473388672\n",
      "cls loss 393.79180908203125  loc loss 29.300033569335938\n",
      "cls loss 638.8607788085938  loc loss 43.71845626831055\n",
      "cls loss 450.81524658203125  loc loss 43.269779205322266\n",
      "cls loss 492.1783447265625  loc loss 30.73611831665039\n",
      "cls loss 980.2968139648438  loc loss 80.96005249023438\n",
      "cls loss 653.4285888671875  loc loss 46.7115592956543\n",
      "cls loss 455.279052734375  loc loss 21.897258758544922\n",
      "cls loss 307.39788818359375  loc loss 13.023122787475586\n",
      "cls loss 351.3891906738281  loc loss 16.37027359008789\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3., 10., 10., 10., 10., 10., 10., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10., 10., 10., 10., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 11., 10., 10., 10., 10., 10.,  3.,  3.,  3.,  3.,  3.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 11., 10., 10., 10., 10., 10.,  3.,  3.,  3.,  3.,  3.])\n",
      "cls loss 333.5374755859375  loc loss 14.883440017700195\n",
      "cls loss 396.657470703125  loc loss 18.726198196411133\n",
      "cls loss 332.652099609375  loc loss 20.024547576904297\n",
      "cls loss 336.8665771484375  loc loss 14.679055213928223\n",
      "cls loss 386.01885986328125  loc loss 30.981822967529297\n",
      "cls loss 317.4998474121094  loc loss 12.17422103881836\n",
      "cls loss 586.161376953125  loc loss 40.045570373535156\n",
      "cls loss 505.1775207519531  loc loss 35.75644302368164\n",
      "cls loss 788.5862426757812  loc loss 49.58332061767578\n",
      "cls loss 387.89129638671875  loc loss 28.683116912841797\n",
      "cls loss 703.4806518554688  loc loss 46.23006820678711\n",
      "cls loss 576.0303955078125  loc loss 37.91696548461914\n",
      "cls loss 531.7755737304688  loc loss 35.446414947509766\n",
      "cls loss 530.6432495117188  loc loss 38.2135009765625\n",
      "cls loss 722.440185546875  loc loss 48.20805358886719\n",
      "cls loss 734.59814453125  loc loss 44.07103729248047\n",
      "cls loss 346.90362548828125  loc loss 18.68824005126953\n",
      "cls loss 632.2374267578125  loc loss 46.396514892578125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 10.,  1., 18.])\n",
      "cls loss 315.2042236328125  loc loss 20.975061416625977\n",
      "cls loss 379.701171875  loc loss 15.670049667358398\n",
      "cls loss 636.0528564453125  loc loss 33.161407470703125\n",
      "cls loss 896.4967041015625  loc loss 52.94340133666992\n",
      "cls loss 525.8930053710938  loc loss 36.91753005981445\n",
      "cls loss 762.0797119140625  loc loss 40.76576614379883\n",
      "cls loss 535.5321044921875  loc loss 35.8974494934082\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.,  1.,  1.])\n",
      "cls loss 666.4190673828125  loc loss 43.5673942565918\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1., 38.,  1.])\n",
      "cls loss 640.0463256835938  loc loss 35.34347915649414\n",
      "cls loss 818.9962158203125  loc loss 59.31810760498047\n",
      "cls loss 441.08966064453125  loc loss 30.23361587524414\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 582.2764892578125  loc loss 38.49860763549805\n",
      "cls loss 509.74127197265625  loc loss 31.311901092529297\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3., 10.,  8.,  3., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.])\n",
      "cls loss 605.8472290039062  loc loss 34.26620101928711\n",
      "cls loss 425.0513610839844  loc loss 26.23256492614746\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3.,  3., 11.,  3., 10., 10.,  3.,  3., 10.])\n",
      "cls loss 504.70391845703125  loc loss 23.689071655273438\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3., 10., 10., 10.])\n",
      "cls loss 485.72760009765625  loc loss 31.150306701660156\n",
      "cls loss 435.1156311035156  loc loss 23.21335792541504\n",
      "cls loss 511.7210693359375  loc loss 34.04521179199219\n",
      "cls loss 768.3626098632812  loc loss 45.12120056152344\n",
      "cls loss 502.41802978515625  loc loss 31.707307815551758\n",
      "cls loss 366.757080078125  loc loss 31.139432907104492\n",
      "cls loss 487.39599609375  loc loss 31.775604248046875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 9.,  9., 85., 85.])\n",
      "cls loss 393.1552734375  loc loss 22.021568298339844\n",
      "cls loss 462.0315246582031  loc loss 33.277793884277344\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 772.181884765625  loc loss 53.937660217285156\n",
      "cls loss 674.785888671875  loc loss 31.765268325805664\n",
      "cls loss 722.0665283203125  loc loss 51.93633270263672\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10., 10., 10., 10.])\n",
      "cls loss 456.17822265625  loc loss 28.444028854370117\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([13.])\n",
      "cls loss 730.917236328125  loc loss 56.7015266418457\n",
      "cls loss 263.81915283203125  loc loss 13.873493194580078\n",
      "cls loss 343.259033203125  loc loss 17.14004135131836\n",
      "cls loss 461.0010681152344  loc loss 24.085525512695312\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19.,  1.,  1.,  1., 19., 19.])\n",
      "cls loss 456.2864685058594  loc loss 30.166322708129883\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 365.24267578125  loc loss 26.613906860351562\n",
      "cls loss 514.7621459960938  loc loss 36.85524368286133\n",
      "cls loss 393.25335693359375  loc loss 22.257633209228516\n",
      "cls loss 576.0672607421875  loc loss 31.453815460205078\n",
      "cls loss 604.4915771484375  loc loss 46.12797927856445\n",
      "cls loss 498.504638671875  loc loss 27.041046142578125\n",
      "cls loss 705.5330810546875  loc loss 51.01018524169922\n",
      "cls loss 289.23016357421875  loc loss 12.885052680969238\n",
      "cls loss 526.3436279296875  loc loss 32.238853454589844\n",
      "cls loss 414.6936950683594  loc loss 20.530736923217773\n",
      "cls loss 448.5181884765625  loc loss 23.466827392578125\n",
      "cls loss 557.3369140625  loc loss 34.37364196777344\n",
      "cls loss 519.71630859375  loc loss 26.162866592407227\n",
      "cls loss 721.566650390625  loc loss 46.79865264892578\n",
      "cls loss 463.4436340332031  loc loss 30.818401336669922\n",
      "cls loss 590.658935546875  loc loss 41.696903228759766\n",
      "cls loss 904.5960693359375  loc loss 54.291141510009766\n",
      "cls loss 464.5639953613281  loc loss 35.073055267333984\n",
      "cls loss 546.928955078125  loc loss 32.154510498046875\n",
      "cls loss 625.362548828125  loc loss 48.64082336425781\n",
      "cls loss 700.78515625  loc loss 49.11676025390625\n",
      "cls loss 863.71533203125  loc loss 45.68204879760742\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 5.])\n",
      "cls loss 255.87313842773438  loc loss 10.311639785766602\n",
      "cls loss 324.9630126953125  loc loss 14.736030578613281\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 13.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 6., 8., 8.])\n",
      "cls loss 271.72650146484375  loc loss 14.426881790161133\n",
      "cls loss 360.30279541015625  loc loss 17.86524200439453\n",
      "cls loss 683.48974609375  loc loss 45.46804428100586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 307.72174072265625  loc loss 15.037826538085938\n",
      "cls loss 516.7738647460938  loc loss 40.11366271972656\n",
      "cls loss 805.0679931640625  loc loss 58.05996322631836\n",
      "cls loss 491.30303955078125  loc loss 36.4370002746582\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([42., 42.,  1.,  1.,  1.,  1.,  1.,  1.,  1., 42., 42.])\n",
      "cls loss 562.632080078125  loc loss 30.737092971801758\n",
      "cls loss 704.537841796875  loc loss 54.249141693115234\n",
      "cls loss 609.9968872070312  loc loss 45.71674346923828\n",
      "cls loss 418.7817687988281  loc loss 26.210668563842773\n",
      "cls loss 554.7100219726562  loc loss 32.17671203613281\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 748.814208984375  loc loss 49.78129196166992\n",
      "cls loss 622.7955322265625  loc loss 42.37560272216797\n",
      "cls loss 384.61993408203125  loc loss 22.115234375\n",
      "cls loss 318.78289794921875  loc loss 18.429039001464844\n",
      "cls loss 464.21124267578125  loc loss 27.02081298828125\n",
      "cls loss 618.0257568359375  loc loss 38.56510543823242\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15.])\n",
      "cls loss 315.3690490722656  loc loss 12.685342788696289\n",
      "cls loss 514.1585083007812  loc loss 32.91909408569336\n",
      "cls loss 456.15545654296875  loc loss 30.194231033325195\n",
      "cls loss 804.5493774414062  loc loss 55.314727783203125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19.,  7.])\n",
      "cls loss 456.51654052734375  loc loss 24.08357048034668\n",
      "cls loss 843.9580078125  loc loss 55.691307067871094\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 714.54296875  loc loss 36.789485931396484\n",
      "cls loss 607.3204956054688  loc loss 44.17176818847656\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([38., 38.,  1., 18.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1., 18., 18.,  1.])\n",
      "cls loss 472.5669860839844  loc loss 23.565582275390625\n",
      "cls loss 444.92041015625  loc loss 21.3551025390625\n",
      "cls loss 810.4160766601562  loc loss 58.2635383605957\n",
      "cls loss 626.5647583007812  loc loss 33.967376708984375\n",
      "cls loss 565.229736328125  loc loss 29.210262298583984\n",
      "cls loss 336.3017883300781  loc loss 25.892078399658203\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.])\n",
      "cls loss 260.73162841796875  loc loss 9.362316131591797\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([32.])\n",
      "cls loss 515.9852294921875  loc loss 27.255409240722656\n",
      "cls loss 440.1228332519531  loc loss 31.6619873046875\n",
      "cls loss 576.548583984375  loc loss 45.34490203857422\n",
      "cls loss 498.890869140625  loc loss 33.71793746948242\n",
      "cls loss 415.6248779296875  loc loss 26.424274444580078\n",
      "cls loss 692.91259765625  loc loss 42.280677795410156\n",
      "cls loss 749.5903930664062  loc loss 51.02461624145508\n",
      "cls loss 592.9148559570312  loc loss 38.63447952270508\n",
      "cls loss 483.29559326171875  loc loss 28.086702346801758\n",
      "cls loss 757.8469848632812  loc loss 48.058006286621094\n",
      "cls loss 502.9482421875  loc loss 25.695892333984375\n",
      "cls loss 809.866455078125  loc loss 58.13047409057617\n",
      "cls loss 577.1687622070312  loc loss 31.853687286376953\n",
      "cls loss 480.8996276855469  loc loss 35.29764175415039\n",
      "cls loss 360.4454345703125  loc loss 17.441608428955078\n",
      "cls loss 414.1793212890625  loc loss 25.088783264160156\n",
      "cls loss 605.8021240234375  loc loss 39.25422286987305\n",
      "cls loss 629.7113037109375  loc loss 43.94860076904297\n",
      "cls loss 366.9221496582031  loc loss 23.169870376586914\n",
      "cls loss 667.7542724609375  loc loss 43.9891471862793\n",
      "cls loss 788.2605590820312  loc loss 48.588775634765625\n",
      "cls loss 289.2427062988281  loc loss 19.637327194213867\n",
      "cls loss 772.305419921875  loc loss 51.08995056152344\n",
      "cls loss 548.9293212890625  loc loss 41.8386344909668\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 746.6341552734375  loc loss 57.164573669433594\n",
      "cls loss 372.03521728515625  loc loss 13.632526397705078\n",
      "cls loss 554.0465087890625  loc loss 29.745227813720703\n",
      "cls loss 539.898193359375  loc loss 35.71318817138672\n",
      "cls loss 446.02581787109375  loc loss 25.006427764892578\n",
      "cls loss 279.85821533203125  loc loss 13.813926696777344\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 9., 9., 1., 9., 9., 9., 9., 1., 9.])\n",
      "cls loss 952.4631958007812  loc loss 77.32740783691406\n",
      "cls loss 567.7015380859375  loc loss 29.493589401245117\n",
      "cls loss 799.7739868164062  loc loss 66.72248840332031\n",
      "cls loss 344.30657958984375  loc loss 24.05852699279785\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 42., 42.])\n",
      "cls loss 593.7894287109375  loc loss 43.86900329589844\n",
      "cls loss 643.6876220703125  loc loss 46.82545852661133\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  2.,  1.,  1.,  1., 38.,\n",
      "         1.,  1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 38., 38., 38.,  1., 38., 38., 38.,  1.,  1., 38.,  1.,\n",
      "         1.])\n",
      "cls loss 387.878173828125  loc loss 28.2358341217041\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  8.,  8.])\n",
      "cls loss 942.4478759765625  loc loss 59.387115478515625\n",
      "cls loss 907.0293579101562  loc loss 65.99337768554688\n",
      "cls loss 356.56292724609375  loc loss 20.30661964416504\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([4., 1., 1., 4.])\n",
      "cls loss 520.48095703125  loc loss 34.52623748779297\n",
      "cls loss 627.019287109375  loc loss 37.719791412353516\n",
      "cls loss 273.20489501953125  loc loss 13.234638214111328\n",
      "cls loss 369.8464660644531  loc loss 23.016399383544922\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([51.,  1.])\n",
      "cls loss 275.09564208984375  loc loss 11.001605033874512\n",
      "cls loss 372.88970947265625  loc loss 19.854351043701172\n",
      "cls loss 641.1258544921875  loc loss 36.003604888916016\n",
      "cls loss 684.5545654296875  loc loss 48.820709228515625\n",
      "cls loss 915.8859252929688  loc loss 49.9354133605957\n",
      "cls loss 1112.973876953125  loc loss 75.97835540771484\n",
      "cls loss 498.05419921875  loc loss 29.616779327392578\n",
      "cls loss 705.1975708007812  loc loss 51.064090728759766\n",
      "cls loss 741.8956298828125  loc loss 52.877838134765625\n",
      "cls loss 592.7467041015625  loc loss 34.28147506713867\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  3.,  1.,  1.,  1.,  3.,  1.,  1.,\n",
      "         1.,  1.,  1.])\n",
      "cls loss 592.3763427734375  loc loss 27.922319412231445\n",
      "cls loss 690.3797607421875  loc loss 35.4610481262207\n",
      "cls loss 619.2445068359375  loc loss 32.94243621826172\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "cls loss 522.9159545898438  loc loss 30.50399398803711\n",
      "cls loss 305.40673828125  loc loss 24.623676300048828\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3.])\n",
      "cls loss 252.88946533203125  loc loss 12.603208541870117\n",
      "cls loss 451.46759033203125  loc loss 30.11068344116211\n",
      "cls loss 369.15087890625  loc loss 28.2135009765625\n",
      "cls loss 666.19677734375  loc loss 44.77006912231445\n",
      "cls loss 456.6237487792969  loc loss 23.334590911865234\n",
      "cls loss 370.9592590332031  loc loss 25.701595306396484\n",
      "cls loss 1100.68896484375  loc loss 74.49554443359375\n",
      "cls loss 476.6707763671875  loc loss 36.8863525390625\n",
      "cls loss 363.0863342285156  loc loss 26.454862594604492\n",
      "cls loss 454.81744384765625  loc loss 26.483972549438477\n",
      "cls loss 415.209716796875  loc loss 29.824628829956055\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 753.7891235351562  loc loss 50.66825866699219\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  9., 64., 64., 64., 64., 64., 64., 64., 64., 64.,  9.,  9.,  9.,\n",
      "         9.])\n",
      "cls loss 406.0315856933594  loc loss 19.927459716796875\n",
      "cls loss 948.908447265625  loc loss 76.4779281616211\n",
      "cls loss 510.7982482910156  loc loss 33.51734924316406\n",
      "cls loss 664.9393310546875  loc loss 45.743621826171875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.,  3.,  3.])\n",
      "cls loss 426.84521484375  loc loss 23.62444305419922\n",
      "cls loss 464.1088562011719  loc loss 30.836923599243164\n",
      "cls loss 458.54290771484375  loc loss 32.79076385498047\n",
      "cls loss 481.0377197265625  loc loss 35.520721435546875\n",
      "cls loss 498.9179382324219  loc loss 39.380516052246094\n",
      "cls loss 512.0905151367188  loc loss 37.5240478515625\n",
      "cls loss 475.5036926269531  loc loss 36.91869354248047\n",
      "cls loss 525.51806640625  loc loss 30.787912368774414\n",
      "cls loss 639.335205078125  loc loss 42.98236083984375\n",
      "cls loss 531.2938232421875  loc loss 29.92041015625\n",
      "cls loss 433.78631591796875  loc loss 19.264829635620117\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21.])\n",
      "cls loss 322.61376953125  loc loss 18.037574768066406\n",
      "cls loss 445.4094543457031  loc loss 36.9165153503418\n",
      "cls loss 655.2357177734375  loc loss 45.15776443481445\n",
      "cls loss 386.36279296875  loc loss 21.457090377807617\n",
      "cls loss 518.5361938476562  loc loss 31.948816299438477\n",
      "cls loss 968.0863037109375  loc loss 51.806732177734375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 42., 42.,  1.,  1.])\n",
      "cls loss 490.97711181640625  loc loss 31.646818161010742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 326.83447265625  loc loss 23.35845947265625\n",
      "cls loss 468.593505859375  loc loss 34.85378646850586\n",
      "cls loss 654.7384033203125  loc loss 52.20177459716797\n",
      "cls loss 418.995849609375  loc loss 26.865772247314453\n",
      "cls loss 615.5384521484375  loc loss 46.72245788574219\n",
      "cls loss 592.1226196289062  loc loss 42.73927307128906\n",
      "cls loss 631.78564453125  loc loss 37.00185775756836\n",
      "cls loss 495.00396728515625  loc loss 29.74021339416504\n",
      "cls loss 448.03472900390625  loc loss 27.1664981842041\n",
      "cls loss 362.5388488769531  loc loss 14.238951683044434\n",
      "cls loss 447.9934387207031  loc loss 29.492143630981445\n",
      "cls loss 685.2024536132812  loc loss 50.841102600097656\n",
      "cls loss 547.513916015625  loc loss 33.812950134277344\n",
      "cls loss 505.1485595703125  loc loss 37.46583557128906\n",
      "cls loss 565.169677734375  loc loss 33.67699432373047\n",
      "cls loss 809.8247680664062  loc loss 57.53369140625\n",
      "cls loss 598.4627685546875  loc loss 44.44441223144531\n",
      "cls loss 692.1160888671875  loc loss 38.76831817626953\n",
      "cls loss 394.2574462890625  loc loss 19.880300521850586\n",
      "cls loss 567.2391357421875  loc loss 36.53208923339844\n",
      "cls loss 523.8641357421875  loc loss 31.385608673095703\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 5., 5., 5., 5., 5., 5.])\n",
      "cls loss 371.5640563964844  loc loss 25.116779327392578\n",
      "cls loss 456.86676025390625  loc loss 25.531042098999023\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([13.])\n",
      "cls loss 316.995849609375  loc loss 19.289278030395508\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([44., 10.,  1.,  1.,  1.])\n",
      "cls loss 319.0765686035156  loc loss 19.459035873413086\n",
      "cls loss 613.751220703125  loc loss 30.201187133789062\n",
      "cls loss 496.67462158203125  loc loss 27.988605499267578\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19., 19., 19., 19., 19., 19., 19.])\n",
      "cls loss 622.48828125  loc loss 31.965547561645508\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([56.])\n",
      "cls loss 1045.770263671875  loc loss 68.33055877685547\n",
      "cls loss 639.2903442382812  loc loss 49.498836517333984\n",
      "cls loss 812.9127197265625  loc loss 56.6125602722168\n",
      "cls loss 804.561279296875  loc loss 61.637882232666016\n",
      "cls loss 508.8544921875  loc loss 28.24453353881836\n",
      "cls loss 793.4830322265625  loc loss 55.807960510253906\n",
      "cls loss 459.2497863769531  loc loss 30.05430793762207\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 36.])\n",
      "cls loss 562.339111328125  loc loss 30.75878143310547\n",
      "cls loss 508.169921875  loc loss 34.135032653808594\n",
      "cls loss 481.8008117675781  loc loss 29.154203414916992\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5.])\n",
      "cls loss 595.120849609375  loc loss 34.98094177246094\n",
      "cls loss 311.37432861328125  loc loss 16.547340393066406\n",
      "cls loss 727.3140258789062  loc loss 39.43670654296875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "cls loss 624.42822265625  loc loss 40.92519760131836\n",
      "cls loss 609.8360595703125  loc loss 41.014495849609375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 575.0589599609375  loc loss 41.521427154541016\n",
      "cls loss 676.8701171875  loc loss 47.97734832763672\n",
      "cls loss 563.2711181640625  loc loss 51.54271697998047\n",
      "cls loss 405.841064453125  loc loss 28.285476684570312\n",
      "cls loss 495.8387451171875  loc loss 36.040069580078125\n",
      "cls loss 523.4342041015625  loc loss 32.65327835083008\n",
      "cls loss 799.32568359375  loc loss 44.81156921386719\n",
      "cls loss 365.4130859375  loc loss 17.948225021362305\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 11., 15., 10., 10., 10., 10., 10.])\n",
      "cls loss 869.8972778320312  loc loss 52.11500549316406\n",
      "cls loss 459.284912109375  loc loss 32.6729850769043\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3.])\n",
      "cls loss 516.274169921875  loc loss 34.22115707397461\n",
      "cls loss 480.0588684082031  loc loss 26.06732749938965\n",
      "cls loss 510.2658386230469  loc loss 24.809467315673828\n",
      "cls loss 648.44775390625  loc loss 30.729427337646484\n",
      "cls loss 354.2441101074219  loc loss 16.64633560180664\n",
      "cls loss 503.4378356933594  loc loss 33.20476531982422\n",
      "cls loss 558.7335205078125  loc loss 41.43927764892578\n",
      "cls loss 473.02398681640625  loc loss 35.53118133544922\n",
      "cls loss 1120.6834716796875  loc loss 81.21156311035156\n",
      "cls loss 789.2120361328125  loc loss 50.77601623535156\n",
      "cls loss 515.0051879882812  loc loss 36.17961502075195\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  9.,  9.,  9.,  6.,  6., 85., 85.,  8.,  1.,  1.,  1.,  1.,\n",
      "         6.,  6.])\n",
      "cls loss 344.43701171875  loc loss 26.612110137939453\n",
      "cls loss 831.1610107421875  loc loss 58.649288177490234\n",
      "cls loss 989.175048828125  loc loss 61.59379577636719\n",
      "cls loss 675.718505859375  loc loss 45.12080764770508\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10.,  3.,  3., 10.])\n",
      "cls loss 459.1029968261719  loc loss 24.415576934814453\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([7.])\n",
      "cls loss 561.5452880859375  loc loss 37.28147888183594\n",
      "cls loss 577.9572143554688  loc loss 34.561180114746094\n",
      "cls loss 505.59844970703125  loc loss 42.18436813354492\n",
      "cls loss 728.0386962890625  loc loss 59.55995559692383\n",
      "cls loss 517.0020141601562  loc loss 35.402645111083984\n",
      "cls loss 719.3909301757812  loc loss 46.98744583129883\n",
      "cls loss 895.2662963867188  loc loss 53.79180145263672\n",
      "cls loss 528.6671752929688  loc loss 37.021121978759766\n",
      "cls loss 579.6597900390625  loc loss 41.045692443847656\n",
      "cls loss 490.83026123046875  loc loss 35.992984771728516\n",
      "cls loss 694.0891723632812  loc loss 56.05937957763672\n",
      "cls loss 562.8644409179688  loc loss 35.3892936706543\n",
      "cls loss 451.2046813964844  loc loss 26.49990463256836\n",
      "cls loss 689.411376953125  loc loss 51.793678283691406\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([62.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([62.])\n",
      "cls loss 317.9207763671875  loc loss 15.763134002685547\n",
      "cls loss 544.2992553710938  loc loss 37.74378967285156\n",
      "cls loss 532.7662963867188  loc loss 34.39091491699219\n",
      "cls loss 364.5083312988281  loc loss 16.414087295532227\n",
      "cls loss 676.705810546875  loc loss 44.5380744934082\n",
      "cls loss 697.5302734375  loc loss 38.931339263916016\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([28.])\n",
      "cls loss 760.0709228515625  loc loss 40.77056121826172\n",
      "cls loss 664.1771240234375  loc loss 40.38776397705078\n",
      "cls loss 659.3236083984375  loc loss 42.69396209716797\n",
      "cls loss 659.8504638671875  loc loss 42.64509582519531\n",
      "cls loss 916.1239013671875  loc loss 61.30938720703125\n",
      "cls loss 513.7891235351562  loc loss 32.62388229370117\n",
      "cls loss 642.1195068359375  loc loss 38.88139343261719\n",
      "cls loss 557.9962158203125  loc loss 46.452693939208984\n",
      "cls loss 903.295654296875  loc loss 70.86193084716797\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([81.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 637.0458374023438  loc loss 25.847158432006836\n",
      "cls loss 473.06219482421875  loc loss 24.44251251220703\n",
      "cls loss 395.6660461425781  loc loss 25.778623580932617\n",
      "cls loss 344.0816650390625  loc loss 12.796083450317383\n",
      "cls loss 383.9429931640625  loc loss 25.617033004760742\n",
      "cls loss 422.70611572265625  loc loss 25.719728469848633\n",
      "cls loss 499.1558837890625  loc loss 30.614473342895508\n",
      "cls loss 647.3277587890625  loc loss 50.665061950683594\n",
      "cls loss 715.7828369140625  loc loss 47.49817657470703\n",
      "cls loss 1346.57958984375  loc loss 89.56980895996094\n",
      "cls loss 542.5264892578125  loc loss 28.137056350708008\n",
      "cls loss 657.58251953125  loc loss 45.54513931274414\n",
      "cls loss 464.7438049316406  loc loss 28.386220932006836\n",
      "cls loss 603.1616821289062  loc loss 34.1829948425293\n",
      "cls loss 529.9989013671875  loc loss 30.32735824584961\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([44., 44.])\n",
      "cls loss 485.5140075683594  loc loss 23.673004150390625\n",
      "cls loss 496.2030029296875  loc loss 34.26061248779297\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15.])\n",
      "cls loss 570.5294189453125  loc loss 27.94434928894043\n",
      "cls loss 281.643310546875  loc loss 16.114213943481445\n",
      "cls loss 573.161376953125  loc loss 33.07722091674805\n",
      "cls loss 321.93682861328125  loc loss 19.057106018066406\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([1., 3., 3.])\n",
      "cls loss 359.20355224609375  loc loss 26.11808967590332\n",
      "cls loss 297.2533264160156  loc loss 12.434514045715332\n",
      "cls loss 545.7437133789062  loc loss 30.991533279418945\n",
      "cls loss 576.348876953125  loc loss 33.648155212402344\n",
      "cls loss 518.206298828125  loc loss 33.894432067871094\n",
      "cls loss 535.7123413085938  loc loss 28.915325164794922\n",
      "cls loss 422.70892333984375  loc loss 32.56890869140625\n",
      "cls loss 584.92236328125  loc loss 38.69916534423828\n",
      "cls loss 434.4527282714844  loc loss 29.20160675048828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 556.1614990234375  loc loss 39.25571823120117\n",
      "cls loss 358.76300048828125  loc loss 21.815597534179688\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 669.7396240234375  loc loss 41.1813850402832\n",
      "cls loss 779.843994140625  loc loss 37.616966247558594\n",
      "cls loss 679.652587890625  loc loss 47.47277069091797\n",
      "cls loss 679.9268798828125  loc loss 51.71284866333008\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10., 10., 10.,  1.,  1.,  1.,  1.,  1.,  1.,  8.,  8.,\n",
      "         1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10., 10., 10.,  1.,  1.,  1.,  1.,  1.,  1.,  8.,  8.,\n",
      "         1.])\n",
      "cls loss 639.2791137695312  loc loss 29.738754272460938\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 3., 3., 3.])\n",
      "cls loss 539.1915893554688  loc loss 33.670135498046875\n",
      "cls loss 379.4359436035156  loc loss 20.884044647216797\n",
      "cls loss 297.11712646484375  loc loss 14.228018760681152\n",
      "cls loss 501.1805725097656  loc loss 37.76428985595703\n",
      "cls loss 385.16961669921875  loc loss 20.09663200378418\n",
      "cls loss 452.6749267578125  loc loss 29.587400436401367\n",
      "cls loss 499.9373779296875  loc loss 34.46647262573242\n",
      "cls loss 706.1242065429688  loc loss 48.892906188964844\n",
      "cls loss 595.2281494140625  loc loss 29.27385139465332\n",
      "cls loss 577.1790161132812  loc loss 32.00930404663086\n",
      "cls loss 645.187255859375  loc loss 42.29182815551758\n",
      "cls loss 459.415771484375  loc loss 34.59907531738281\n",
      "cls loss 848.4808349609375  loc loss 62.57844924926758\n",
      "cls loss 429.7239990234375  loc loss 21.803983688354492\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 655.8695068359375  loc loss 40.18122482299805\n",
      "cls loss 327.03973388671875  loc loss 13.58645248413086\n",
      "cls loss 805.016357421875  loc loss 50.22509002685547\n",
      "cls loss 421.78448486328125  loc loss 22.441679000854492\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 34.])\n",
      "cls loss 686.9354248046875  loc loss 35.580291748046875\n",
      "cls loss 318.3814697265625  loc loss 20.511133193969727\n",
      "cls loss 588.9161987304688  loc loss 39.62031173706055\n",
      "cls loss 203.29135131835938  loc loss 15.446453094482422\n",
      "cls loss 521.868408203125  loc loss 33.29201126098633\n",
      "cls loss 506.532470703125  loc loss 40.730892181396484\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 38.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16., 16., 16.,  9.,  9.,  9., 16., 16., 16., 85.,  9.])\n",
      "cls loss 507.6314392089844  loc loss 33.418495178222656\n",
      "cls loss 578.4088134765625  loc loss 44.859230041503906\n",
      "cls loss 780.5160522460938  loc loss 53.807552337646484\n",
      "cls loss 1118.6953125  loc loss 75.34903717041016\n",
      "cls loss 353.283935546875  loc loss 18.06683349609375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3., 10.,  8.,  8., 10., 10., 10.,  3.,  3., 14.])\n",
      "cls loss 432.85357666015625  loc loss 20.221538543701172\n",
      "cls loss 768.291259765625  loc loss 38.50640106201172\n",
      "cls loss 328.0387268066406  loc loss 11.93994140625\n",
      "cls loss 485.36376953125  loc loss 20.876121520996094\n",
      "cls loss 644.5023803710938  loc loss 37.955604553222656\n",
      "cls loss 548.42822265625  loc loss 34.93968200683594\n",
      "cls loss 314.2149658203125  loc loss 16.273269653320312\n",
      "cls loss 353.74920654296875  loc loss 22.339664459228516\n",
      "cls loss 548.5621337890625  loc loss 35.46404266357422\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42., 42.,  1.])\n",
      "cls loss 534.4569091796875  loc loss 37.95290756225586\n",
      "cls loss 442.1957702636719  loc loss 26.082042694091797\n",
      "cls loss 582.7579956054688  loc loss 45.510948181152344\n",
      "cls loss 696.0596313476562  loc loss 43.98451232910156\n",
      "cls loss 476.48797607421875  loc loss 30.887948989868164\n",
      "cls loss 592.3618774414062  loc loss 41.4788932800293\n",
      "cls loss 384.07415771484375  loc loss 25.398813247680664\n",
      "cls loss 398.9437561035156  loc loss 27.592239379882812\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20.])\n",
      "cls loss 319.4896240234375  loc loss 17.552417755126953\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([11.])\n",
      "cls loss 404.9828796386719  loc loss 20.298118591308594\n",
      "cls loss 283.03948974609375  loc loss 14.799033164978027\n",
      "cls loss 615.051025390625  loc loss 47.57469177246094\n",
      "cls loss 288.5946044921875  loc loss 12.890121459960938\n",
      "cls loss 596.6671142578125  loc loss 32.635562896728516\n",
      "cls loss 325.284912109375  loc loss 20.36324691772461\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 35., 27.])\n",
      "cls loss 545.9937744140625  loc loss 34.39456558227539\n",
      "cls loss 590.2118530273438  loc loss 44.699066162109375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 410.6106872558594  loc loss 24.83620834350586\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([42.,  1.])\n",
      "cls loss 532.442626953125  loc loss 37.28173828125\n",
      "cls loss 491.5074462890625  loc loss 28.523164749145508\n",
      "cls loss 610.9031372070312  loc loss 36.56186294555664\n",
      "cls loss 729.0899658203125  loc loss 48.128196716308594\n",
      "cls loss 663.6116943359375  loc loss 40.168540954589844\n",
      "cls loss 453.19482421875  loc loss 33.814849853515625\n",
      "cls loss 389.7065124511719  loc loss 29.666332244873047\n",
      "cls loss 259.1877746582031  loc loss 11.861688613891602\n",
      "cls loss 464.6055908203125  loc loss 25.40394401550293\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 1., 1.])\n",
      "cls loss 451.5325622558594  loc loss 24.294946670532227\n",
      "cls loss 495.2887878417969  loc loss 32.999393463134766\n",
      "cls loss 493.76275634765625  loc loss 31.255502700805664\n",
      "cls loss 400.58734130859375  loc loss 28.721202850341797\n",
      "cls loss 486.8724365234375  loc loss 29.007076263427734\n",
      "cls loss 505.8969421386719  loc loss 37.990325927734375\n",
      "cls loss 698.974853515625  loc loss 42.88633728027344\n",
      "cls loss 600.1217651367188  loc loss 46.615478515625\n",
      "cls loss 575.0941772460938  loc loss 34.394901275634766\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 447.8414001464844  loc loss 30.678037643432617\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 531.332275390625  loc loss 26.344879150390625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([81.])\n",
      "cls loss 644.890380859375  loc loss 39.61882781982422\n",
      "cls loss 410.0792541503906  loc loss 27.24488639831543\n",
      "cls loss 286.9057312011719  loc loss 16.681865692138672\n",
      "cls loss 456.99432373046875  loc loss 23.910751342773438\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3.,  1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 19.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 19.])\n",
      "cls loss 590.4011840820312  loc loss 40.58699417114258\n",
      "cls loss 351.97515869140625  loc loss 17.831371307373047\n",
      "cls loss 365.4381103515625  loc loss 21.425180435180664\n",
      "cls loss 690.2485961914062  loc loss 50.29947280883789\n",
      "cls loss 354.8322448730469  loc loss 22.1855525970459\n",
      "cls loss 441.6317138671875  loc loss 29.887622833251953\n",
      "cls loss 529.4971313476562  loc loss 35.72378158569336\n",
      "cls loss 422.0481262207031  loc loss 30.404516220092773\n",
      "cls loss 548.0999755859375  loc loss 32.237823486328125\n",
      "cls loss 615.9376220703125  loc loss 42.558536529541016\n",
      "cls loss 744.9208984375  loc loss 67.34336853027344\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 81.])\n",
      "cls loss 549.2277221679688  loc loss 29.037158966064453\n",
      "cls loss 464.34320068359375  loc loss 26.93816375732422\n",
      "cls loss 537.3988037109375  loc loss 28.22647476196289\n",
      "cls loss 406.6786193847656  loc loss 19.86686134338379\n",
      "cls loss 365.2720031738281  loc loss 22.797454833984375\n",
      "cls loss 417.0559387207031  loc loss 30.43508529663086\n",
      "cls loss 339.1470947265625  loc loss 23.532581329345703\n",
      "cls loss 271.58392333984375  loc loss 17.410228729248047\n",
      "cls loss 361.4725341796875  loc loss 23.790842056274414\n",
      "cls loss 501.0690002441406  loc loss 30.427745819091797\n",
      "cls loss 407.70257568359375  loc loss 32.62133026123047\n",
      "cls loss 431.83978271484375  loc loss 34.33621597290039\n",
      "cls loss 267.1767578125  loc loss 19.268234252929688\n",
      "cls loss 895.083251953125  loc loss 64.05015563964844\n",
      "cls loss 573.6563720703125  loc loss 38.34333801269531\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 491.3659973144531  loc loss 25.70746612548828\n",
      "cls loss 531.06982421875  loc loss 35.917842864990234\n",
      "cls loss 431.828369140625  loc loss 25.838090896606445\n",
      "cls loss 621.1004638671875  loc loss 40.833839416503906\n",
      "cls loss 607.9521484375  loc loss 38.42510223388672\n",
      "cls loss 545.8392944335938  loc loss 34.24434280395508\n",
      "cls loss 438.8936767578125  loc loss 25.713706970214844\n",
      "cls loss 329.5828552246094  loc loss 20.489900588989258\n",
      "cls loss 502.20123291015625  loc loss 30.00069808959961\n",
      "cls loss 527.1780395507812  loc loss 35.861610412597656\n",
      "cls loss 563.6922607421875  loc loss 31.57758331298828\n",
      "cls loss 700.9868774414062  loc loss 51.90094757080078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 687.2265014648438  loc loss 56.21385192871094\n",
      "cls loss 507.6249694824219  loc loss 36.55730056762695\n",
      "cls loss 677.632568359375  loc loss 53.57875061035156\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1., 38., 47.,  1.,  1.,  1.,  1.,  1., 62.])\n",
      "cls loss 490.72747802734375  loc loss 24.281784057617188\n",
      "cls loss 595.3341674804688  loc loss 33.89804458618164\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 609.791015625  loc loss 35.87749099731445\n",
      "cls loss 651.9176025390625  loc loss 48.54682159423828\n",
      "cls loss 460.91864013671875  loc loss 22.98171615600586\n",
      "cls loss 516.5816650390625  loc loss 42.48478317260742\n",
      "cls loss 477.7763671875  loc loss 28.656978607177734\n",
      "cls loss 288.4925537109375  loc loss 11.445898056030273\n",
      "cls loss 463.53265380859375  loc loss 26.255596160888672\n",
      "cls loss 397.1219787597656  loc loss 17.693288803100586\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1., 35.])\n",
      "cls loss 470.26318359375  loc loss 23.313262939453125\n",
      "cls loss 632.3453369140625  loc loss 34.55501174926758\n",
      "cls loss 620.988037109375  loc loss 40.823280334472656\n",
      "cls loss 552.120849609375  loc loss 45.968849182128906\n",
      "cls loss 453.436767578125  loc loss 35.85160827636719\n",
      "cls loss 593.84716796875  loc loss 44.40821838378906\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 335.7607421875  loc loss 19.386491775512695\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 486.8702392578125  loc loss 22.726259231567383\n",
      "cls loss 781.0623779296875  loc loss 41.26486587524414\n",
      "cls loss 945.9039306640625  loc loss 72.06124114990234\n",
      "cls loss 486.6135559082031  loc loss 24.848663330078125\n",
      "cls loss 425.3275451660156  loc loss 27.33425521850586\n",
      "cls loss 431.1632080078125  loc loss 23.615522384643555\n",
      "cls loss 458.8411865234375  loc loss 29.576295852661133\n",
      "cls loss 422.7906494140625  loc loss 18.001314163208008\n",
      "cls loss 712.8262329101562  loc loss 49.72771453857422\n",
      "cls loss 582.9943237304688  loc loss 36.36578369140625\n",
      "cls loss 331.42138671875  loc loss 20.78740119934082\n",
      "cls loss 574.0864868164062  loc loss 31.819982528686523\n",
      "cls loss 682.1563110351562  loc loss 55.12209701538086\n",
      "cls loss 574.1533203125  loc loss 36.05852508544922\n",
      "cls loss 507.61016845703125  loc loss 27.270029067993164\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.])\n",
      "cls loss 472.24798583984375  loc loss 34.04425811767578\n",
      "cls loss 437.2261047363281  loc loss 32.55353927612305\n",
      "cls loss 587.38330078125  loc loss 40.02534103393555\n",
      "cls loss 901.3489990234375  loc loss 72.31708526611328\n",
      "cls loss 399.6245422363281  loc loss 19.253198623657227\n",
      "cls loss 519.5396118164062  loc loss 31.66687774658203\n",
      "cls loss 412.73126220703125  loc loss 22.628738403320312\n",
      "cls loss 451.9098205566406  loc loss 27.60950469970703\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 21., 21., 21.])\n",
      "cls loss 478.0669250488281  loc loss 28.292327880859375\n",
      "cls loss 445.2545166015625  loc loss 21.052701950073242\n",
      "cls loss 474.2259826660156  loc loss 31.18077850341797\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 35.])\n",
      "cls loss 618.3406372070312  loc loss 39.16897201538086\n",
      "cls loss 225.04840087890625  loc loss 12.493764877319336\n",
      "cls loss 371.6871643066406  loc loss 24.93412971496582\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 367.9236755371094  loc loss 16.795146942138672\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 38., 38.,  9., 38.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1.,  1.])\n",
      "cls loss 411.5009765625  loc loss 27.16852378845215\n",
      "cls loss 679.5120849609375  loc loss 43.76598358154297\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 2.,  1., 77., 31., 10., 10.,  1.,  4., 10.])\n",
      "cls loss 350.3665466308594  loc loss 16.80641746520996\n",
      "cls loss 645.850341796875  loc loss 38.281646728515625\n",
      "cls loss 1276.5142822265625  loc loss 75.15250396728516\n",
      "cls loss 413.63165283203125  loc loss 26.57037353515625\n",
      "cls loss 578.5538940429688  loc loss 42.4447135925293\n",
      "cls loss 427.7018127441406  loc loss 22.5462703704834\n",
      "cls loss 431.3951416015625  loc loss 20.582534790039062\n",
      "cls loss 619.8746948242188  loc loss 29.01935577392578\n",
      "cls loss 623.380859375  loc loss 32.59666442871094\n",
      "cls loss 551.7889404296875  loc loss 37.22935485839844\n",
      "cls loss 423.3010559082031  loc loss 20.364015579223633\n",
      "cls loss 459.1536560058594  loc loss 23.49646759033203\n",
      "cls loss 826.029296875  loc loss 51.357818603515625\n",
      "cls loss 708.8411254882812  loc loss 43.392906188964844\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1., 42., 42., 42., 42., 42., 42.,  1.,\n",
      "         1.,  1.,  1., 42.,  1.,  1., 42.,  1.])\n",
      "cls loss 392.3953552246094  loc loss 27.346355438232422\n",
      "cls loss 616.363037109375  loc loss 37.372352600097656\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.])\n",
      "cls loss 263.9554748535156  loc loss 15.871306419372559\n",
      "cls loss 602.41015625  loc loss 39.19102478027344\n",
      "cls loss 482.9801025390625  loc loss 33.719512939453125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([11.])\n",
      "cls loss 298.0003356933594  loc loss 16.983152389526367\n",
      "cls loss 373.0097961425781  loc loss 17.058923721313477\n",
      "cls loss 393.1667785644531  loc loss 17.226886749267578\n",
      "cls loss 603.2801513671875  loc loss 37.979068756103516\n",
      "cls loss 551.3285522460938  loc loss 29.16507339477539\n",
      "cls loss 513.100830078125  loc loss 35.058753967285156\n",
      "cls loss 763.0245361328125  loc loss 39.473175048828125\n",
      "cls loss 384.059326171875  loc loss 22.770423889160156\n",
      "cls loss 754.8026733398438  loc loss 53.74516677856445\n",
      "cls loss 375.802734375  loc loss 24.545259475708008\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 352.11944580078125  loc loss 24.479618072509766\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1., 38., 38., 42.])\n",
      "cls loss 451.33673095703125  loc loss 33.228267669677734\n",
      "cls loss 418.63531494140625  loc loss 24.422685623168945\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 363.47125244140625  loc loss 26.62861442565918\n",
      "cls loss 851.3743286132812  loc loss 58.393218994140625\n",
      "cls loss 519.876708984375  loc loss 33.791046142578125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10.,  3.,  3.,  6.,  8.,  8.,  1.,  1.,  1., 10.])\n",
      "cls loss 441.13116455078125  loc loss 22.720684051513672\n",
      "cls loss 275.27850341796875  loc loss 10.1322021484375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10.,  3.])\n",
      "cls loss 411.42230224609375  loc loss 22.965713500976562\n",
      "cls loss 247.11497497558594  loc loss 12.302842140197754\n",
      "cls loss 511.138916015625  loc loss 36.01374053955078\n",
      "cls loss 582.570068359375  loc loss 37.617958068847656\n",
      "cls loss 428.10186767578125  loc loss 25.53166961669922\n",
      "cls loss 306.3162536621094  loc loss 15.076991081237793\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 34.])\n",
      "cls loss 695.5101928710938  loc loss 44.19174575805664\n",
      "cls loss 752.17724609375  loc loss 63.64290237426758\n",
      "cls loss 486.14276123046875  loc loss 36.994102478027344\n",
      "cls loss 377.1056213378906  loc loss 27.112022399902344\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.,  1.])\n",
      "cls loss 436.7313232421875  loc loss 21.016551971435547\n",
      "cls loss 661.8067626953125  loc loss 51.25776290893555\n",
      "cls loss 991.3112182617188  loc loss 64.4693603515625\n",
      "cls loss 831.0166015625  loc loss 43.13840103149414\n",
      "cls loss 495.284423828125  loc loss 26.06993865966797\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 593.9959106445312  loc loss 34.09355545043945\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10.])\n",
      "cls loss 369.084716796875  loc loss 19.31047821044922\n",
      "cls loss 535.2547607421875  loc loss 26.354692459106445\n",
      "cls loss 485.9180603027344  loc loss 30.067134857177734\n",
      "cls loss 356.5118408203125  loc loss 21.516151428222656\n",
      "cls loss 454.471923828125  loc loss 30.307653427124023\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21.,\n",
      "        21.])\n",
      "cls loss 633.9541015625  loc loss 34.85490417480469\n",
      "cls loss 486.80877685546875  loc loss 29.738994598388672\n",
      "cls loss 317.790283203125  loc loss 14.637687683105469\n",
      "cls loss 666.27734375  loc loss 43.520687103271484\n",
      "cls loss 514.8857421875  loc loss 34.599369049072266\n",
      "cls loss 366.374267578125  loc loss 20.929210662841797\n",
      "cls loss 762.4884033203125  loc loss 49.371978759765625\n",
      "cls loss 922.5624389648438  loc loss 62.78388595581055\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15., 85.])\n",
      "cls loss 558.6873779296875  loc loss 36.619956970214844\n",
      "cls loss 589.4276733398438  loc loss 43.36822509765625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 596.6851196289062  loc loss 43.010498046875\n",
      "cls loss 537.0234985351562  loc loss 29.56236457824707\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 8., 8.])\n",
      "cls loss 347.083984375  loc loss 16.86121940612793\n",
      "cls loss 363.1054992675781  loc loss 25.892345428466797\n",
      "cls loss 460.7149658203125  loc loss 28.21692657470703\n",
      "cls loss 376.8858337402344  loc loss 21.35841178894043\n",
      "cls loss 438.3890380859375  loc loss 25.93865966796875\n",
      "cls loss 582.970703125  loc loss 36.156837463378906\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1., 35., 27., 27.,  1., 27.,  1.])\n",
      "cls loss 733.8017578125  loc loss 53.43516540527344\n",
      "cls loss 394.45843505859375  loc loss 25.213729858398438\n",
      "cls loss 445.4790954589844  loc loss 32.763999938964844\n",
      "cls loss 424.73614501953125  loc loss 37.53830337524414\n",
      "cls loss 385.2998962402344  loc loss 29.73797035217285\n",
      "cls loss 421.9291687011719  loc loss 33.4536247253418\n",
      "cls loss 424.74322509765625  loc loss 33.5010986328125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  2.,  2.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  2.,  2.])\n",
      "cls loss 248.08114624023438  loc loss 9.506237030029297\n",
      "cls loss 685.3128662109375  loc loss 42.13825988769531\n",
      "cls loss 476.8755187988281  loc loss 22.02166175842285\n",
      "cls loss 749.6617431640625  loc loss 54.94657897949219\n",
      "cls loss 318.2957763671875  loc loss 18.09608268737793\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 19., 19., 19., 16.])\n",
      "cls loss 332.9129638671875  loc loss 14.15891170501709\n",
      "cls loss 266.75299072265625  loc loss 11.111080169677734\n",
      "cls loss 413.59747314453125  loc loss 21.027606964111328\n",
      "cls loss 537.8324584960938  loc loss 35.58692932128906\n",
      "cls loss 280.5191345214844  loc loss 18.531038284301758\n",
      "cls loss 601.8812866210938  loc loss 45.98417663574219\n",
      "cls loss 431.0016174316406  loc loss 29.717559814453125\n",
      "cls loss 479.6161193847656  loc loss 30.62665367126465\n",
      "cls loss 610.3253784179688  loc loss 41.412845611572266\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 662.4801025390625  loc loss 28.952590942382812\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 844.599853515625  loc loss 72.90242767333984\n",
      "cls loss 1063.412353515625  loc loss 100.27722930908203\n",
      "cls loss 558.592529296875  loc loss 35.124229431152344\n",
      "cls loss 497.58282470703125  loc loss 32.17522430419922\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3.,  3.,  3.,  3.,  3., 10.])\n",
      "cls loss 276.505859375  loc loss 16.379228591918945\n",
      "cls loss 531.925048828125  loc loss 26.494415283203125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 1., 1., 1., 3., 3., 3., 3.])\n",
      "cls loss 410.0263366699219  loc loss 25.334129333496094\n",
      "cls loss 780.1624145507812  loc loss 50.48426818847656\n",
      "cls loss 611.974853515625  loc loss 40.27384567260742\n",
      "cls loss 403.0869140625  loc loss 23.888376235961914\n",
      "cls loss 622.9620971679688  loc loss 43.22101974487305\n",
      "cls loss 387.230224609375  loc loss 28.74557876586914\n",
      "cls loss 628.716064453125  loc loss 42.852535247802734\n",
      "cls loss 445.7245178222656  loc loss 42.6861686706543\n",
      "cls loss 486.8791809082031  loc loss 30.148653030395508\n",
      "cls loss 964.9669189453125  loc loss 79.46102142333984\n",
      "cls loss 644.82958984375  loc loss 46.043670654296875\n",
      "cls loss 448.7734375  loc loss 21.516124725341797\n",
      "cls loss 300.6468505859375  loc loss 12.756105422973633\n",
      "cls loss 346.4248352050781  loc loss 16.090511322021484\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3., 10., 10., 10., 10., 10., 10., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10., 10., 10., 10., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 11., 10., 10., 10., 10., 10.,  3.,  3.,  3.,  3.,  3.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 11., 10., 10., 10., 10., 10.,  3.,  3.,  3.,  3.,  3.])\n",
      "cls loss 325.5145263671875  loc loss 14.499937057495117\n",
      "cls loss 389.1431884765625  loc loss 18.19212532043457\n",
      "cls loss 325.251220703125  loc loss 19.46074104309082\n",
      "cls loss 332.282470703125  loc loss 14.473997116088867\n",
      "cls loss 381.638427734375  loc loss 30.41872215270996\n",
      "cls loss 313.3654479980469  loc loss 11.959933280944824\n",
      "cls loss 580.6451416015625  loc loss 39.45130920410156\n",
      "cls loss 498.13214111328125  loc loss 34.954524993896484\n",
      "cls loss 779.654541015625  loc loss 48.762725830078125\n",
      "cls loss 385.0755920410156  loc loss 28.114788055419922\n",
      "cls loss 695.7247314453125  loc loss 45.39537048339844\n",
      "cls loss 566.8455200195312  loc loss 37.226470947265625\n",
      "cls loss 524.7636108398438  loc loss 34.79838562011719\n",
      "cls loss 522.35791015625  loc loss 37.47380828857422\n",
      "cls loss 710.7296142578125  loc loss 47.40727615356445\n",
      "cls loss 725.027587890625  loc loss 43.33098220825195\n",
      "cls loss 342.2354736328125  loc loss 18.255023956298828\n",
      "cls loss 625.8424072265625  loc loss 45.42363357543945\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 10.,  1., 18.])\n",
      "cls loss 311.25006103515625  loc loss 20.509614944458008\n",
      "cls loss 378.98980712890625  loc loss 15.479552268981934\n",
      "cls loss 631.697265625  loc loss 32.8231315612793\n",
      "cls loss 886.1939086914062  loc loss 51.769474029541016\n",
      "cls loss 517.135986328125  loc loss 36.315101623535156\n",
      "cls loss 749.7991943359375  loc loss 39.746803283691406\n",
      "cls loss 529.7905883789062  loc loss 35.47176742553711\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.,  1.,  1.])\n",
      "cls loss 657.1447143554688  loc loss 42.70045471191406\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1., 38.,  1.])\n",
      "cls loss 626.2130126953125  loc loss 34.54214859008789\n",
      "cls loss 805.0313720703125  loc loss 58.5390625\n",
      "cls loss 436.4334411621094  loc loss 29.671350479125977\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 576.2685546875  loc loss 37.81827163696289\n",
      "cls loss 502.3931884765625  loc loss 30.787569046020508\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3., 10.,  8.,  3., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.])\n",
      "cls loss 595.2286376953125  loc loss 33.50801467895508\n",
      "cls loss 417.1056823730469  loc loss 25.710599899291992\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3.,  3., 11.,  3., 10., 10.,  3.,  3., 10.])\n",
      "cls loss 493.2939453125  loc loss 23.263181686401367\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3., 10., 10., 10.])\n",
      "cls loss 479.7553405761719  loc loss 30.377840042114258\n",
      "cls loss 426.8427734375  loc loss 22.93313217163086\n",
      "cls loss 506.24920654296875  loc loss 33.37252426147461\n",
      "cls loss 755.8062744140625  loc loss 43.953548431396484\n",
      "cls loss 495.22515869140625  loc loss 30.986068725585938\n",
      "cls loss 363.8592224121094  loc loss 30.543052673339844\n",
      "cls loss 483.2566833496094  loc loss 31.15338706970215\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 9.,  9., 85., 85.])\n",
      "cls loss 385.7960205078125  loc loss 21.54840850830078\n",
      "cls loss 456.41143798828125  loc loss 32.957435607910156\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 760.3975219726562  loc loss 52.848384857177734\n",
      "cls loss 663.615478515625  loc loss 31.192245483398438\n",
      "cls loss 711.6063232421875  loc loss 51.20623779296875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10., 10., 10., 10.])\n",
      "cls loss 450.9783935546875  loc loss 27.937519073486328\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([13.])\n",
      "cls loss 718.896728515625  loc loss 55.72926712036133\n",
      "cls loss 258.09564208984375  loc loss 13.493330955505371\n",
      "cls loss 337.9232177734375  loc loss 16.78262710571289\n",
      "cls loss 453.0858154296875  loc loss 23.776742935180664\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19.,  1.,  1.,  1., 19., 19.])\n",
      "cls loss 448.55718994140625  loc loss 29.72126007080078\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 360.4283752441406  loc loss 26.201168060302734\n",
      "cls loss 506.68035888671875  loc loss 36.23811721801758\n",
      "cls loss 388.4910583496094  loc loss 21.813478469848633\n",
      "cls loss 569.5107421875  loc loss 30.70461654663086\n",
      "cls loss 595.8933715820312  loc loss 45.26483917236328\n",
      "cls loss 491.4403991699219  loc loss 26.47970962524414\n",
      "cls loss 699.8758544921875  loc loss 50.2789306640625\n",
      "cls loss 284.0660400390625  loc loss 12.539397239685059\n",
      "cls loss 521.84521484375  loc loss 31.69857406616211\n",
      "cls loss 408.39898681640625  loc loss 20.16244125366211\n",
      "cls loss 444.301513671875  loc loss 23.21776580810547\n",
      "cls loss 552.8912963867188  loc loss 33.61844253540039\n",
      "cls loss 513.799072265625  loc loss 25.431547164916992\n",
      "cls loss 709.412109375  loc loss 46.186126708984375\n",
      "cls loss 455.12957763671875  loc loss 30.104921340942383\n",
      "cls loss 580.8423461914062  loc loss 41.24288558959961\n",
      "cls loss 889.3121948242188  loc loss 53.19940185546875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 456.3853759765625  loc loss 34.37689208984375\n",
      "cls loss 536.5272216796875  loc loss 31.66242027282715\n",
      "cls loss 614.0658569335938  loc loss 47.92817306518555\n",
      "cls loss 693.2749633789062  loc loss 48.44143295288086\n",
      "cls loss 850.9783935546875  loc loss 44.847381591796875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 5.])\n",
      "cls loss 250.10821533203125  loc loss 10.191112518310547\n",
      "cls loss 319.03570556640625  loc loss 14.38609790802002\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 13.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 6., 8., 8.])\n",
      "cls loss 266.10595703125  loc loss 14.15527057647705\n",
      "cls loss 356.70654296875  loc loss 17.457181930541992\n",
      "cls loss 672.5457153320312  loc loss 44.49105453491211\n",
      "cls loss 303.68646240234375  loc loss 14.893157005310059\n",
      "cls loss 512.209228515625  loc loss 39.45486068725586\n",
      "cls loss 790.833984375  loc loss 57.24873352050781\n",
      "cls loss 485.70184326171875  loc loss 35.6495361328125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([42., 42.,  1.,  1.,  1.,  1.,  1.,  1.,  1., 42., 42.])\n",
      "cls loss 555.8060302734375  loc loss 30.027353286743164\n",
      "cls loss 694.4727172851562  loc loss 53.18438720703125\n",
      "cls loss 606.58935546875  loc loss 44.559818267822266\n",
      "cls loss 410.88201904296875  loc loss 25.784082412719727\n",
      "cls loss 544.9950561523438  loc loss 31.301456451416016\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 742.08935546875  loc loss 48.913570404052734\n",
      "cls loss 616.415283203125  loc loss 41.77459716796875\n",
      "cls loss 378.38623046875  loc loss 21.61779022216797\n",
      "cls loss 311.7034912109375  loc loss 18.20965576171875\n",
      "cls loss 454.61248779296875  loc loss 26.530120849609375\n",
      "cls loss 606.8092041015625  loc loss 37.64610290527344\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15.])\n",
      "cls loss 311.4599609375  loc loss 12.23108959197998\n",
      "cls loss 509.40533447265625  loc loss 32.221012115478516\n",
      "cls loss 449.068359375  loc loss 29.670249938964844\n",
      "cls loss 792.8502197265625  loc loss 54.154388427734375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19.,  7.])\n",
      "cls loss 449.6463623046875  loc loss 23.494417190551758\n",
      "cls loss 829.9244995117188  loc loss 54.864654541015625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 706.385498046875  loc loss 36.03464889526367\n",
      "cls loss 597.9345703125  loc loss 43.382598876953125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([38., 38.,  1., 18.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1., 18., 18.,  1.])\n",
      "cls loss 461.7379150390625  loc loss 23.200607299804688\n",
      "cls loss 438.3412170410156  loc loss 20.875829696655273\n",
      "cls loss 802.21142578125  loc loss 57.047393798828125\n",
      "cls loss 616.8184204101562  loc loss 33.422367095947266\n",
      "cls loss 554.1290893554688  loc loss 28.801654815673828\n",
      "cls loss 333.52801513671875  loc loss 25.489456176757812\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.])\n",
      "cls loss 253.9180908203125  loc loss 9.214761734008789\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([32.])\n",
      "cls loss 510.53350830078125  loc loss 26.983081817626953\n",
      "cls loss 434.88653564453125  loc loss 31.166027069091797\n",
      "cls loss 568.810302734375  loc loss 44.500892639160156\n",
      "cls loss 491.9262390136719  loc loss 33.057491302490234\n",
      "cls loss 409.98724365234375  loc loss 25.911056518554688\n",
      "cls loss 683.4957275390625  loc loss 41.329505920410156\n",
      "cls loss 742.0517578125  loc loss 50.15480422973633\n",
      "cls loss 583.2284545898438  loc loss 37.9549446105957\n",
      "cls loss 474.60400390625  loc loss 27.542884826660156\n",
      "cls loss 745.1865234375  loc loss 47.219451904296875\n",
      "cls loss 496.314208984375  loc loss 25.399808883666992\n",
      "cls loss 805.4808349609375  loc loss 57.0092887878418\n",
      "cls loss 570.74658203125  loc loss 31.279510498046875\n",
      "cls loss 474.16192626953125  loc loss 34.86515808105469\n",
      "cls loss 355.9713439941406  loc loss 17.041378021240234\n",
      "cls loss 408.0799255371094  loc loss 24.665931701660156\n",
      "cls loss 597.664306640625  loc loss 38.57054138183594\n",
      "cls loss 624.54248046875  loc loss 43.13050842285156\n",
      "cls loss 361.67779541015625  loc loss 22.594518661499023\n",
      "cls loss 656.913330078125  loc loss 43.23711395263672\n",
      "cls loss 777.636474609375  loc loss 47.951171875\n",
      "cls loss 284.13861083984375  loc loss 19.178871154785156\n",
      "cls loss 761.8856811523438  loc loss 50.26167297363281\n",
      "cls loss 543.05078125  loc loss 40.953651428222656\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 737.6469116210938  loc loss 56.21990966796875\n",
      "cls loss 365.4423522949219  loc loss 13.3723783493042\n",
      "cls loss 543.9378662109375  loc loss 29.17855453491211\n",
      "cls loss 531.5191650390625  loc loss 34.941383361816406\n",
      "cls loss 440.2278137207031  loc loss 24.507049560546875\n",
      "cls loss 276.6299743652344  loc loss 13.508097648620605\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 9., 9., 1., 9., 9., 9., 9., 1., 9.])\n",
      "cls loss 941.416748046875  loc loss 75.5365982055664\n",
      "cls loss 561.9488525390625  loc loss 28.9514217376709\n",
      "cls loss 790.251953125  loc loss 65.30699920654297\n",
      "cls loss 340.30548095703125  loc loss 23.727842330932617\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 42., 42.])\n",
      "cls loss 583.48486328125  loc loss 43.09065628051758\n",
      "cls loss 633.5628662109375  loc loss 46.03348159790039\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  2.,  1.,  1.,  1., 38.,\n",
      "         1.,  1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 38., 38., 38.,  1., 38., 38., 38.,  1.,  1., 38.,  1.,\n",
      "         1.])\n",
      "cls loss 380.8645324707031  loc loss 27.95703125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  8.,  8.])\n",
      "cls loss 931.55419921875  loc loss 58.51983642578125\n",
      "cls loss 891.6513671875  loc loss 65.4186782836914\n",
      "cls loss 351.05548095703125  loc loss 20.008132934570312\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([4., 1., 1., 4.])\n",
      "cls loss 514.8851928710938  loc loss 33.820892333984375\n",
      "cls loss 620.9567260742188  loc loss 36.988285064697266\n",
      "cls loss 269.3727722167969  loc loss 13.097572326660156\n",
      "cls loss 362.7671203613281  loc loss 22.614320755004883\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([51.,  1.])\n",
      "cls loss 271.4760437011719  loc loss 10.810395240783691\n",
      "cls loss 369.54998779296875  loc loss 19.5458984375\n",
      "cls loss 633.4352416992188  loc loss 35.57538986206055\n",
      "cls loss 673.8086547851562  loc loss 47.71525573730469\n",
      "cls loss 901.1627807617188  loc loss 49.05836486816406\n",
      "cls loss 1099.0267333984375  loc loss 74.7022933959961\n",
      "cls loss 489.35955810546875  loc loss 29.08087730407715\n",
      "cls loss 699.5357666015625  loc loss 50.507789611816406\n",
      "cls loss 732.2993774414062  loc loss 51.78805160522461\n",
      "cls loss 583.3749389648438  loc loss 33.815982818603516\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  3.,  1.,  1.,  1.,  3.,  1.,  1.,\n",
      "         1.,  1.,  1.])\n",
      "cls loss 584.5098266601562  loc loss 27.235267639160156\n",
      "cls loss 678.5675659179688  loc loss 34.81499099731445\n",
      "cls loss 606.2420654296875  loc loss 32.37675857543945\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "cls loss 516.4429321289062  loc loss 30.008913040161133\n",
      "cls loss 300.5251770019531  loc loss 24.12974739074707\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3.])\n",
      "cls loss 246.32183837890625  loc loss 12.461809158325195\n",
      "cls loss 443.4088134765625  loc loss 29.356605529785156\n",
      "cls loss 364.4682922363281  loc loss 27.67379379272461\n",
      "cls loss 659.4998779296875  loc loss 44.09047317504883\n",
      "cls loss 447.56781005859375  loc loss 22.987802505493164\n",
      "cls loss 365.57720947265625  loc loss 25.348155975341797\n",
      "cls loss 1086.56201171875  loc loss 73.32730102539062\n",
      "cls loss 470.6394348144531  loc loss 36.31869125366211\n",
      "cls loss 361.2015380859375  loc loss 25.88675880432129\n",
      "cls loss 448.4534912109375  loc loss 25.988872528076172\n",
      "cls loss 409.5902099609375  loc loss 29.301319122314453\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 742.785400390625  loc loss 49.777164459228516\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  9., 64., 64., 64., 64., 64., 64., 64., 64., 64.,  9.,  9.,  9.,\n",
      "         9.])\n",
      "cls loss 396.6291198730469  loc loss 19.375762939453125\n",
      "cls loss 936.6866455078125  loc loss 75.18743896484375\n",
      "cls loss 506.6097412109375  loc loss 33.04592514038086\n",
      "cls loss 657.25830078125  loc loss 44.743568420410156\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.,  3.,  3.])\n",
      "cls loss 421.52117919921875  loc loss 23.006378173828125\n",
      "cls loss 456.8128662109375  loc loss 30.3098201751709\n",
      "cls loss 449.8052978515625  loc loss 32.073143005371094\n",
      "cls loss 472.29498291015625  loc loss 34.74085998535156\n",
      "cls loss 490.0102233886719  loc loss 38.61464309692383\n",
      "cls loss 507.24627685546875  loc loss 36.79745864868164\n",
      "cls loss 468.1531677246094  loc loss 36.07633972167969\n",
      "cls loss 517.741943359375  loc loss 30.115612030029297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 633.0863037109375  loc loss 42.17938232421875\n",
      "cls loss 518.0015869140625  loc loss 29.42127227783203\n",
      "cls loss 422.73321533203125  loc loss 18.970876693725586\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21.])\n",
      "cls loss 318.18292236328125  loc loss 17.787147521972656\n",
      "cls loss 441.70098876953125  loc loss 36.38471603393555\n",
      "cls loss 650.6004028320312  loc loss 44.38033676147461\n",
      "cls loss 377.72021484375  loc loss 20.87225341796875\n",
      "cls loss 509.85931396484375  loc loss 31.387557983398438\n",
      "cls loss 954.8900146484375  loc loss 50.789939880371094\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 42., 42.,  1.,  1.])\n",
      "cls loss 484.66845703125  loc loss 31.147640228271484\n",
      "cls loss 323.05462646484375  loc loss 22.86817741394043\n",
      "cls loss 462.3781433105469  loc loss 34.16383743286133\n",
      "cls loss 643.5076904296875  loc loss 51.32450866699219\n",
      "cls loss 411.8053283691406  loc loss 26.370222091674805\n",
      "cls loss 609.9559936523438  loc loss 46.04998779296875\n",
      "cls loss 584.8866577148438  loc loss 41.81955337524414\n",
      "cls loss 620.7569580078125  loc loss 36.480003356933594\n",
      "cls loss 489.45343017578125  loc loss 29.15713119506836\n",
      "cls loss 439.27978515625  loc loss 26.69768524169922\n",
      "cls loss 357.32763671875  loc loss 13.925307273864746\n",
      "cls loss 444.10443115234375  loc loss 28.96944808959961\n",
      "cls loss 679.6937255859375  loc loss 49.4927864074707\n",
      "cls loss 540.0899658203125  loc loss 33.134185791015625\n",
      "cls loss 497.9476318359375  loc loss 36.746402740478516\n",
      "cls loss 557.291748046875  loc loss 33.19415283203125\n",
      "cls loss 798.5972290039062  loc loss 56.9083137512207\n",
      "cls loss 593.509521484375  loc loss 43.657962799072266\n",
      "cls loss 682.4496459960938  loc loss 38.062679290771484\n",
      "cls loss 389.0523681640625  loc loss 19.486127853393555\n",
      "cls loss 560.4509887695312  loc loss 35.81391143798828\n",
      "cls loss 517.5693969726562  loc loss 30.652225494384766\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 5., 5., 5., 5., 5., 5.])\n",
      "cls loss 364.2867431640625  loc loss 24.55155372619629\n",
      "cls loss 451.21734619140625  loc loss 24.970327377319336\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([13.])\n",
      "cls loss 313.80218505859375  loc loss 18.828983306884766\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([44., 10.,  1.,  1.,  1.])\n",
      "cls loss 312.02545166015625  loc loss 19.131776809692383\n",
      "cls loss 602.5667724609375  loc loss 29.53671646118164\n",
      "cls loss 489.41107177734375  loc loss 27.488143920898438\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19., 19., 19., 19., 19., 19., 19.])\n",
      "cls loss 608.927734375  loc loss 31.23147201538086\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([56.])\n",
      "cls loss 1030.748291015625  loc loss 67.42176818847656\n",
      "cls loss 631.9432983398438  loc loss 48.625240325927734\n",
      "cls loss 804.70458984375  loc loss 55.536624908447266\n",
      "cls loss 794.0828857421875  loc loss 60.63142395019531\n",
      "cls loss 505.3108215332031  loc loss 27.75263214111328\n",
      "cls loss 788.4692993164062  loc loss 54.68690872192383\n",
      "cls loss 455.1405334472656  loc loss 29.72863006591797\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 36.])\n",
      "cls loss 554.611083984375  loc loss 30.185867309570312\n",
      "cls loss 502.6294860839844  loc loss 33.44221496582031\n",
      "cls loss 475.0690612792969  loc loss 28.62295150756836\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5.])\n",
      "cls loss 585.469482421875  loc loss 34.3387451171875\n",
      "cls loss 304.9129943847656  loc loss 16.218774795532227\n",
      "cls loss 719.5770874023438  loc loss 38.70969009399414\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "cls loss 615.99072265625  loc loss 40.14021301269531\n",
      "cls loss 597.3698120117188  loc loss 40.27739715576172\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 569.077880859375  loc loss 40.854976654052734\n",
      "cls loss 666.4911499023438  loc loss 47.157440185546875\n",
      "cls loss 556.9410400390625  loc loss 50.52294921875\n",
      "cls loss 402.0894775390625  loc loss 27.847312927246094\n",
      "cls loss 484.55303955078125  loc loss 35.33676528930664\n",
      "cls loss 515.276611328125  loc loss 32.06875991821289\n",
      "cls loss 788.4813232421875  loc loss 43.78279113769531\n",
      "cls loss 359.3115234375  loc loss 17.592533111572266\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 11., 15., 10., 10., 10., 10., 10.])\n",
      "cls loss 859.466796875  loc loss 50.996070861816406\n",
      "cls loss 452.525146484375  loc loss 32.31769943237305\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3.])\n",
      "cls loss 507.6498107910156  loc loss 33.71003341674805\n",
      "cls loss 474.6107177734375  loc loss 25.454059600830078\n",
      "cls loss 503.5576477050781  loc loss 24.350563049316406\n",
      "cls loss 640.2561645507812  loc loss 30.045377731323242\n",
      "cls loss 347.9400634765625  loc loss 16.324249267578125\n",
      "cls loss 497.309814453125  loc loss 32.77730178833008\n",
      "cls loss 554.5831909179688  loc loss 40.41333770751953\n",
      "cls loss 466.7396240234375  loc loss 34.937538146972656\n",
      "cls loss 1108.285400390625  loc loss 79.550048828125\n",
      "cls loss 777.5822143554688  loc loss 49.885536193847656\n",
      "cls loss 508.4491271972656  loc loss 35.49305725097656\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  9.,  9.,  9.,  6.,  6., 85., 85.,  8.,  1.,  1.,  1.,  1.,\n",
      "         6.,  6.])\n",
      "cls loss 337.8143310546875  loc loss 26.337047576904297\n",
      "cls loss 819.365966796875  loc loss 57.80604553222656\n",
      "cls loss 981.4517211914062  loc loss 60.41443634033203\n",
      "cls loss 666.5521850585938  loc loss 44.42124938964844\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10.,  3.,  3., 10.])\n",
      "cls loss 453.89288330078125  loc loss 23.823293685913086\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([7.])\n",
      "cls loss 551.08642578125  loc loss 36.36614990234375\n",
      "cls loss 566.7090454101562  loc loss 33.80466079711914\n",
      "cls loss 498.9051208496094  loc loss 41.731109619140625\n",
      "cls loss 720.164306640625  loc loss 58.77012634277344\n",
      "cls loss 507.8011474609375  loc loss 34.649269104003906\n",
      "cls loss 710.6866455078125  loc loss 46.1588134765625\n",
      "cls loss 883.8472900390625  loc loss 52.784828186035156\n",
      "cls loss 522.1765747070312  loc loss 36.35276412963867\n",
      "cls loss 573.25537109375  loc loss 40.596038818359375\n",
      "cls loss 482.04656982421875  loc loss 35.277626037597656\n",
      "cls loss 690.0326538085938  loc loss 55.12512969970703\n",
      "cls loss 554.7296142578125  loc loss 34.67250061035156\n",
      "cls loss 444.559326171875  loc loss 26.10361099243164\n",
      "cls loss 679.5  loc loss 51.024986267089844\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([62.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([62.])\n",
      "cls loss 314.7462463378906  loc loss 15.427505493164062\n",
      "cls loss 533.652099609375  loc loss 37.00831985473633\n",
      "cls loss 524.9500122070312  loc loss 33.645294189453125\n",
      "cls loss 358.0527648925781  loc loss 16.189851760864258\n",
      "cls loss 666.52392578125  loc loss 43.69371795654297\n",
      "cls loss 693.0135498046875  loc loss 38.1722526550293\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([28.])\n",
      "cls loss 753.521728515625  loc loss 39.99942398071289\n",
      "cls loss 655.4158935546875  loc loss 39.62510681152344\n",
      "cls loss 650.0718994140625  loc loss 42.21795654296875\n",
      "cls loss 650.5571899414062  loc loss 41.71088409423828\n",
      "cls loss 901.4149169921875  loc loss 60.20357131958008\n",
      "cls loss 507.478759765625  loc loss 32.00005340576172\n",
      "cls loss 636.5438232421875  loc loss 38.29387283325195\n",
      "cls loss 549.8438720703125  loc loss 45.528011322021484\n",
      "cls loss 892.5778198242188  loc loss 69.8952407836914\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([81.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 628.3399658203125  loc loss 25.383602142333984\n",
      "cls loss 465.4394226074219  loc loss 24.08978843688965\n",
      "cls loss 385.5288391113281  loc loss 25.36296272277832\n",
      "cls loss 336.8421630859375  loc loss 12.530244827270508\n",
      "cls loss 376.0105285644531  loc loss 25.296142578125\n",
      "cls loss 415.9122009277344  loc loss 25.337148666381836\n",
      "cls loss 492.3935546875  loc loss 30.038028717041016\n",
      "cls loss 640.924072265625  loc loss 49.970130920410156\n",
      "cls loss 709.4105224609375  loc loss 46.585514068603516\n",
      "cls loss 1324.259033203125  loc loss 87.66400146484375\n",
      "cls loss 533.3645629882812  loc loss 27.616411209106445\n",
      "cls loss 647.0147705078125  loc loss 45.01469039916992\n",
      "cls loss 456.914306640625  loc loss 28.046194076538086\n",
      "cls loss 596.440185546875  loc loss 33.7743034362793\n",
      "cls loss 520.3013305664062  loc loss 29.765310287475586\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([44., 44.])\n",
      "cls loss 479.2698974609375  loc loss 23.151674270629883\n",
      "cls loss 492.87176513671875  loc loss 33.52585983276367\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15.])\n",
      "cls loss 560.57763671875  loc loss 27.26083755493164\n",
      "cls loss 277.27197265625  loc loss 15.837312698364258\n",
      "cls loss 562.6856079101562  loc loss 32.46464538574219\n",
      "cls loss 315.5801086425781  loc loss 18.514991760253906\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([1., 3., 3.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 354.109130859375  loc loss 25.41786003112793\n",
      "cls loss 290.90936279296875  loc loss 12.251520156860352\n",
      "cls loss 535.5072021484375  loc loss 30.590808868408203\n",
      "cls loss 567.734619140625  loc loss 33.03742980957031\n",
      "cls loss 510.87890625  loc loss 33.40864944458008\n",
      "cls loss 522.366943359375  loc loss 28.200149536132812\n",
      "cls loss 416.5584716796875  loc loss 32.07915496826172\n",
      "cls loss 579.7876586914062  loc loss 37.884765625\n",
      "cls loss 425.0172119140625  loc loss 28.621700286865234\n",
      "cls loss 548.9638671875  loc loss 38.63512420654297\n",
      "cls loss 354.98883056640625  loc loss 21.323514938354492\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 662.3422241210938  loc loss 40.4874382019043\n",
      "cls loss 773.1492919921875  loc loss 36.815467834472656\n",
      "cls loss 671.1271362304688  loc loss 46.74507141113281\n",
      "cls loss 673.2384643554688  loc loss 51.25413513183594\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10., 10., 10.,  1.,  1.,  1.,  1.,  1.,  1.,  8.,  8.,\n",
      "         1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10., 10., 10.,  1.,  1.,  1.,  1.,  1.,  1.,  8.,  8.,\n",
      "         1.])\n",
      "cls loss 627.2847900390625  loc loss 29.096210479736328\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 3., 3., 3.])\n",
      "cls loss 531.13916015625  loc loss 33.008506774902344\n",
      "cls loss 375.92657470703125  loc loss 20.661375045776367\n",
      "cls loss 292.16558837890625  loc loss 13.935834884643555\n",
      "cls loss 493.41650390625  loc loss 37.19404220581055\n",
      "cls loss 379.4123840332031  loc loss 19.512569427490234\n",
      "cls loss 447.01373291015625  loc loss 29.152856826782227\n",
      "cls loss 494.7986755371094  loc loss 33.818115234375\n",
      "cls loss 697.595458984375  loc loss 47.99824905395508\n",
      "cls loss 587.614501953125  loc loss 28.765817642211914\n",
      "cls loss 570.9177856445312  loc loss 31.404550552368164\n",
      "cls loss 631.134765625  loc loss 41.689022064208984\n",
      "cls loss 448.4283447265625  loc loss 33.98018264770508\n",
      "cls loss 833.5421752929688  loc loss 61.691123962402344\n",
      "cls loss 420.07989501953125  loc loss 21.23653793334961\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 647.4542236328125  loc loss 39.55845260620117\n",
      "cls loss 322.1180419921875  loc loss 13.214824676513672\n",
      "cls loss 792.7164306640625  loc loss 49.188297271728516\n",
      "cls loss 412.6549072265625  loc loss 22.223556518554688\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 34.])\n",
      "cls loss 676.676513671875  loc loss 34.82767105102539\n",
      "cls loss 314.9513244628906  loc loss 20.16707420349121\n",
      "cls loss 584.1470336914062  loc loss 38.854713439941406\n",
      "cls loss 200.56619262695312  loc loss 15.197336196899414\n",
      "cls loss 511.8016357421875  loc loss 32.49877166748047\n",
      "cls loss 498.19854736328125  loc loss 40.11344528198242\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 38.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16., 16., 16.,  9.,  9.,  9., 16., 16., 16., 85.,  9.])\n",
      "cls loss 499.0085754394531  loc loss 32.9100456237793\n",
      "cls loss 570.678466796875  loc loss 44.047027587890625\n",
      "cls loss 767.8780517578125  loc loss 52.42182540893555\n",
      "cls loss 1106.303466796875  loc loss 73.88805389404297\n",
      "cls loss 347.4602966308594  loc loss 17.79568099975586\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3., 10.,  8.,  8., 10., 10., 10.,  3.,  3., 14.])\n",
      "cls loss 423.05889892578125  loc loss 19.810123443603516\n",
      "cls loss 756.2113037109375  loc loss 37.8533935546875\n",
      "cls loss 323.82708740234375  loc loss 11.684188842773438\n",
      "cls loss 478.700439453125  loc loss 20.47325325012207\n",
      "cls loss 635.1824951171875  loc loss 37.25877380371094\n",
      "cls loss 540.243896484375  loc loss 34.128971099853516\n",
      "cls loss 308.2707824707031  loc loss 15.95956039428711\n",
      "cls loss 347.90338134765625  loc loss 21.858266830444336\n",
      "cls loss 543.1570434570312  loc loss 34.7362060546875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42., 42.,  1.])\n",
      "cls loss 529.3912353515625  loc loss 37.256103515625\n",
      "cls loss 434.2591857910156  loc loss 25.569570541381836\n",
      "cls loss 575.0594482421875  loc loss 44.855133056640625\n",
      "cls loss 689.573486328125  loc loss 43.025508880615234\n",
      "cls loss 469.2564697265625  loc loss 30.294179916381836\n",
      "cls loss 583.539794921875  loc loss 40.91486358642578\n",
      "cls loss 378.83245849609375  loc loss 25.089210510253906\n",
      "cls loss 393.06121826171875  loc loss 27.173377990722656\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20.])\n",
      "cls loss 313.18072509765625  loc loss 17.297706604003906\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([11.])\n",
      "cls loss 398.25634765625  loc loss 19.821491241455078\n",
      "cls loss 277.0970458984375  loc loss 14.509100914001465\n",
      "cls loss 607.3570556640625  loc loss 46.63612365722656\n",
      "cls loss 284.4619140625  loc loss 12.664146423339844\n",
      "cls loss 591.4317016601562  loc loss 32.08064651489258\n",
      "cls loss 321.95758056640625  loc loss 20.065561294555664\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 35., 27.])\n",
      "cls loss 540.2242431640625  loc loss 33.53590774536133\n",
      "cls loss 586.5948486328125  loc loss 43.9757080078125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 403.87347412109375  loc loss 24.24484634399414\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([42.,  1.])\n",
      "cls loss 521.8478393554688  loc loss 36.38013458251953\n",
      "cls loss 485.27020263671875  loc loss 27.941753387451172\n",
      "cls loss 598.9432373046875  loc loss 36.099769592285156\n",
      "cls loss 723.8079833984375  loc loss 47.20505905151367\n",
      "cls loss 656.1019287109375  loc loss 39.31983947753906\n",
      "cls loss 447.9284973144531  loc loss 33.0709228515625\n",
      "cls loss 384.07342529296875  loc loss 29.114439010620117\n",
      "cls loss 254.426025390625  loc loss 11.592848777770996\n",
      "cls loss 457.432373046875  loc loss 24.840425491333008\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 1., 1.])\n",
      "cls loss 445.08099365234375  loc loss 24.085187911987305\n",
      "cls loss 488.6937561035156  loc loss 32.34138107299805\n",
      "cls loss 485.51446533203125  loc loss 30.645679473876953\n",
      "cls loss 396.24249267578125  loc loss 28.165929794311523\n",
      "cls loss 481.295166015625  loc loss 28.606109619140625\n",
      "cls loss 501.0662841796875  loc loss 37.20981979370117\n",
      "cls loss 691.5416870117188  loc loss 42.223594665527344\n",
      "cls loss 593.3690185546875  loc loss 45.811485290527344\n",
      "cls loss 566.1336059570312  loc loss 33.83186721801758\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 441.59906005859375  loc loss 30.05967903137207\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 525.055908203125  loc loss 25.871877670288086\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([81.])\n",
      "cls loss 635.5364990234375  loc loss 38.80072784423828\n",
      "cls loss 403.82745361328125  loc loss 26.858686447143555\n",
      "cls loss 284.33782958984375  loc loss 16.311735153198242\n",
      "cls loss 451.7208251953125  loc loss 23.596010208129883\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3.,  1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 19.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 19.])\n",
      "cls loss 580.28515625  loc loss 40.015419006347656\n",
      "cls loss 346.3895263671875  loc loss 17.72011375427246\n",
      "cls loss 360.93255615234375  loc loss 20.91666030883789\n",
      "cls loss 680.853759765625  loc loss 49.62474822998047\n",
      "cls loss 349.71484375  loc loss 21.777359008789062\n",
      "cls loss 435.0287170410156  loc loss 29.169261932373047\n",
      "cls loss 525.1829833984375  loc loss 35.157928466796875\n",
      "cls loss 417.9862060546875  loc loss 29.863828659057617\n",
      "cls loss 540.1041259765625  loc loss 31.599651336669922\n",
      "cls loss 608.7664794921875  loc loss 41.77893829345703\n",
      "cls loss 737.8374633789062  loc loss 66.13036346435547\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 81.])\n",
      "cls loss 542.2686157226562  loc loss 28.485576629638672\n",
      "cls loss 457.38079833984375  loc loss 26.385269165039062\n",
      "cls loss 528.8438720703125  loc loss 27.734384536743164\n",
      "cls loss 401.1290283203125  loc loss 19.637168884277344\n",
      "cls loss 358.7578125  loc loss 22.414384841918945\n",
      "cls loss 405.4456481933594  loc loss 30.018985748291016\n",
      "cls loss 332.8446350097656  loc loss 23.13616180419922\n",
      "cls loss 267.2842712402344  loc loss 17.099836349487305\n",
      "cls loss 357.0435791015625  loc loss 23.278440475463867\n",
      "cls loss 492.9068603515625  loc loss 29.828533172607422\n",
      "cls loss 403.0366516113281  loc loss 32.14387130737305\n",
      "cls loss 426.7615966796875  loc loss 33.65396499633789\n",
      "cls loss 263.0320129394531  loc loss 18.816171646118164\n",
      "cls loss 885.2357177734375  loc loss 62.98717498779297\n",
      "cls loss 562.80859375  loc loss 37.508506774902344\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 483.1513977050781  loc loss 25.10317611694336\n",
      "cls loss 525.4522094726562  loc loss 35.27302169799805\n",
      "cls loss 422.78399658203125  loc loss 25.540464401245117\n",
      "cls loss 614.7392578125  loc loss 40.50705337524414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 599.0961303710938  loc loss 37.62080764770508\n",
      "cls loss 540.544921875  loc loss 33.59752655029297\n",
      "cls loss 432.3779296875  loc loss 25.432781219482422\n",
      "cls loss 324.8310241699219  loc loss 20.237503051757812\n",
      "cls loss 496.09912109375  loc loss 29.36922836303711\n",
      "cls loss 523.9666748046875  loc loss 35.404502868652344\n",
      "cls loss 557.4729614257812  loc loss 31.031137466430664\n",
      "cls loss 692.6495971679688  loc loss 50.80534744262695\n",
      "cls loss 680.086669921875  loc loss 55.49469757080078\n",
      "cls loss 500.09796142578125  loc loss 35.929405212402344\n",
      "cls loss 673.1121215820312  loc loss 52.977752685546875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1., 38., 47.,  1.,  1.,  1.,  1.,  1., 62.])\n",
      "cls loss 484.18621826171875  loc loss 23.800918579101562\n",
      "cls loss 586.86376953125  loc loss 33.590492248535156\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 605.1494750976562  loc loss 35.387107849121094\n",
      "cls loss 642.9391479492188  loc loss 47.82366180419922\n",
      "cls loss 452.748779296875  loc loss 22.560970306396484\n",
      "cls loss 510.24896240234375  loc loss 41.873573303222656\n",
      "cls loss 472.5578918457031  loc loss 28.144750595092773\n",
      "cls loss 282.906005859375  loc loss 11.183516502380371\n",
      "cls loss 454.8922119140625  loc loss 25.748390197753906\n",
      "cls loss 391.57977294921875  loc loss 17.357765197753906\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1., 35.])\n",
      "cls loss 458.6295471191406  loc loss 22.9844970703125\n",
      "cls loss 625.4824829101562  loc loss 33.87922286987305\n",
      "cls loss 613.7568359375  loc loss 40.16896057128906\n",
      "cls loss 544.746337890625  loc loss 45.15879440307617\n",
      "cls loss 449.3810729980469  loc loss 35.21543884277344\n",
      "cls loss 588.9425048828125  loc loss 43.88264465332031\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 331.77874755859375  loc loss 19.110759735107422\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 480.5641784667969  loc loss 22.141645431518555\n",
      "cls loss 772.1500244140625  loc loss 40.597572326660156\n",
      "cls loss 931.0718994140625  loc loss 71.07488250732422\n",
      "cls loss 477.1124267578125  loc loss 24.436298370361328\n",
      "cls loss 419.87371826171875  loc loss 26.907058715820312\n",
      "cls loss 423.2578125  loc loss 23.0283260345459\n",
      "cls loss 448.361083984375  loc loss 28.54823112487793\n",
      "cls loss 412.0428466796875  loc loss 17.59943199157715\n",
      "cls loss 702.9166259765625  loc loss 48.7221794128418\n",
      "cls loss 576.4605102539062  loc loss 35.85987091064453\n",
      "cls loss 325.1436767578125  loc loss 20.601858139038086\n",
      "cls loss 566.98095703125  loc loss 31.323223114013672\n",
      "cls loss 673.9073486328125  loc loss 54.34461212158203\n",
      "cls loss 566.778076171875  loc loss 35.58892822265625\n",
      "cls loss 496.0673522949219  loc loss 26.86382293701172\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.])\n",
      "cls loss 465.75872802734375  loc loss 33.480690002441406\n",
      "cls loss 435.57537841796875  loc loss 31.897842407226562\n",
      "cls loss 578.8441162109375  loc loss 39.27451705932617\n",
      "cls loss 894.438232421875  loc loss 71.32530212402344\n",
      "cls loss 391.5478515625  loc loss 18.942794799804688\n",
      "cls loss 511.15032958984375  loc loss 31.086027145385742\n",
      "cls loss 405.9519958496094  loc loss 22.172266006469727\n",
      "cls loss 444.39935302734375  loc loss 27.252275466918945\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 21., 21., 21.])\n",
      "cls loss 468.4656066894531  loc loss 27.86693572998047\n",
      "cls loss 434.72491455078125  loc loss 20.756818771362305\n",
      "cls loss 467.31219482421875  loc loss 30.617263793945312\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 35.])\n",
      "cls loss 604.6444702148438  loc loss 38.02939987182617\n",
      "cls loss 220.19229125976562  loc loss 12.221025466918945\n",
      "cls loss 367.6669616699219  loc loss 24.552396774291992\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 361.415283203125  loc loss 16.407766342163086\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 38., 38.,  9., 38.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1.,  1.])\n",
      "cls loss 404.86279296875  loc loss 26.576162338256836\n",
      "cls loss 673.9400024414062  loc loss 42.87929916381836\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 2.,  1., 77., 31., 10., 10.,  1.,  4., 10.])\n",
      "cls loss 344.99652099609375  loc loss 16.415742874145508\n",
      "cls loss 636.7579345703125  loc loss 37.3646354675293\n",
      "cls loss 1260.83349609375  loc loss 73.52716064453125\n",
      "cls loss 403.6195373535156  loc loss 26.252479553222656\n",
      "cls loss 571.457275390625  loc loss 41.59113311767578\n",
      "cls loss 421.6660461425781  loc loss 21.89470100402832\n",
      "cls loss 424.25567626953125  loc loss 20.11447525024414\n",
      "cls loss 606.3118896484375  loc loss 28.656347274780273\n",
      "cls loss 613.8126220703125  loc loss 31.923812866210938\n",
      "cls loss 541.8385620117188  loc loss 36.62728500366211\n",
      "cls loss 417.25396728515625  loc loss 19.99660301208496\n",
      "cls loss 449.62164306640625  loc loss 23.101959228515625\n",
      "cls loss 814.7464599609375  loc loss 50.28007507324219\n",
      "cls loss 699.506591796875  loc loss 42.45246887207031\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1., 42., 42., 42., 42., 42., 42.,  1.,\n",
      "         1.,  1.,  1., 42.,  1.,  1., 42.,  1.])\n",
      "cls loss 386.4534912109375  loc loss 26.9874267578125\n",
      "cls loss 605.4520263671875  loc loss 36.50381088256836\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.])\n",
      "cls loss 259.8450927734375  loc loss 15.447965621948242\n",
      "cls loss 595.853515625  loc loss 38.40990447998047\n",
      "cls loss 473.90948486328125  loc loss 33.15116882324219\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([11.])\n",
      "cls loss 293.260986328125  loc loss 16.669082641601562\n",
      "cls loss 364.8130798339844  loc loss 16.744672775268555\n",
      "cls loss 383.71990966796875  loc loss 16.820722579956055\n",
      "cls loss 598.028076171875  loc loss 37.230953216552734\n",
      "cls loss 537.7692260742188  loc loss 28.53240203857422\n",
      "cls loss 506.1445617675781  loc loss 34.30481719970703\n",
      "cls loss 751.2109375  loc loss 38.5850944519043\n",
      "cls loss 375.92755126953125  loc loss 22.222387313842773\n",
      "cls loss 747.3128051757812  loc loss 52.670413970947266\n",
      "cls loss 369.50341796875  loc loss 24.03904151916504\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 347.9244689941406  loc loss 23.898597717285156\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1., 38., 38., 42.])\n",
      "cls loss 445.1194152832031  loc loss 32.5689582824707\n",
      "cls loss 413.87762451171875  loc loss 24.14122772216797\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 361.73748779296875  loc loss 26.148548126220703\n",
      "cls loss 841.41943359375  loc loss 57.336341857910156\n",
      "cls loss 512.4146118164062  loc loss 33.102317810058594\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10.,  3.,  3.,  6.,  8.,  8.,  1.,  1.,  1., 10.])\n",
      "cls loss 433.08331298828125  loc loss 22.151168823242188\n",
      "cls loss 270.76287841796875  loc loss 9.943918228149414\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10.,  3.])\n",
      "cls loss 403.1969299316406  loc loss 22.597211837768555\n",
      "cls loss 237.50881958007812  loc loss 12.130462646484375\n",
      "cls loss 503.7877502441406  loc loss 35.27497100830078\n",
      "cls loss 578.2138671875  loc loss 36.937034606933594\n",
      "cls loss 423.1145935058594  loc loss 25.089324951171875\n",
      "cls loss 303.64404296875  loc loss 14.869601249694824\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 34.])\n",
      "cls loss 686.9185180664062  loc loss 43.4395637512207\n",
      "cls loss 745.0968017578125  loc loss 62.50882339477539\n",
      "cls loss 478.21075439453125  loc loss 36.12255096435547\n",
      "cls loss 375.3954772949219  loc loss 26.63241958618164\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.,  1.])\n",
      "cls loss 430.3656005859375  loc loss 20.458532333374023\n",
      "cls loss 654.0170288085938  loc loss 50.35601806640625\n",
      "cls loss 972.9614868164062  loc loss 63.51166915893555\n",
      "cls loss 819.6473388671875  loc loss 42.42011260986328\n",
      "cls loss 488.0199890136719  loc loss 25.59294891357422\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 583.663818359375  loc loss 33.33480453491211\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10.])\n",
      "cls loss 361.81756591796875  loc loss 18.863338470458984\n",
      "cls loss 527.0860595703125  loc loss 25.91216468811035\n",
      "cls loss 476.43890380859375  loc loss 29.71436882019043\n",
      "cls loss 351.40216064453125  loc loss 20.969783782958984\n",
      "cls loss 450.468017578125  loc loss 29.671175003051758\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21.,\n",
      "        21.])\n",
      "cls loss 624.2698974609375  loc loss 34.28195571899414\n",
      "cls loss 478.1774597167969  loc loss 29.065176010131836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 314.10015869140625  loc loss 14.396574020385742\n",
      "cls loss 660.1340942382812  loc loss 42.83686447143555\n",
      "cls loss 507.7984619140625  loc loss 33.835723876953125\n",
      "cls loss 363.2243957519531  loc loss 20.306169509887695\n",
      "cls loss 749.357666015625  loc loss 48.288490295410156\n",
      "cls loss 904.9910888671875  loc loss 61.71377182006836\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15., 85.])\n",
      "cls loss 551.6728515625  loc loss 35.928436279296875\n",
      "cls loss 579.2968139648438  loc loss 42.616661071777344\n",
      "cls loss 590.3458862304688  loc loss 42.376304626464844\n",
      "cls loss 528.6923217773438  loc loss 29.0891170501709\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 8., 8.])\n",
      "cls loss 341.0740661621094  loc loss 16.32832908630371\n",
      "cls loss 357.9065856933594  loc loss 25.54264259338379\n",
      "cls loss 452.8180236816406  loc loss 27.70679473876953\n",
      "cls loss 370.7227783203125  loc loss 20.895536422729492\n",
      "cls loss 428.3158264160156  loc loss 25.308218002319336\n",
      "cls loss 575.8237915039062  loc loss 35.506248474121094\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1., 35., 27., 27.,  1., 27.,  1.])\n",
      "cls loss 722.887939453125  loc loss 52.406429290771484\n",
      "cls loss 390.8508605957031  loc loss 24.587440490722656\n",
      "cls loss 438.2440185546875  loc loss 32.184967041015625\n",
      "cls loss 418.4115295410156  loc loss 36.92817687988281\n",
      "cls loss 379.3974609375  loc loss 29.13371467590332\n",
      "cls loss 415.68719482421875  loc loss 32.74336242675781\n",
      "cls loss 419.98883056640625  loc loss 32.90114212036133\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  2.,  2.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  2.,  2.])\n",
      "cls loss 240.9390869140625  loc loss 9.290266036987305\n",
      "cls loss 677.4183959960938  loc loss 41.49997329711914\n",
      "cls loss 468.86248779296875  loc loss 21.46875762939453\n",
      "cls loss 739.4312744140625  loc loss 54.01713562011719\n",
      "cls loss 312.35296630859375  loc loss 17.64081573486328\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 19., 19., 19., 16.])\n",
      "cls loss 326.6888122558594  loc loss 13.844429969787598\n",
      "cls loss 261.36871337890625  loc loss 10.776971817016602\n",
      "cls loss 409.6470031738281  loc loss 20.704530715942383\n",
      "cls loss 532.4653930664062  loc loss 34.97970962524414\n",
      "cls loss 272.18572998046875  loc loss 18.119722366333008\n",
      "cls loss 594.8468017578125  loc loss 45.377559661865234\n",
      "cls loss 423.6770935058594  loc loss 29.13475227355957\n",
      "cls loss 470.6051025390625  loc loss 30.074792861938477\n",
      "cls loss 601.065673828125  loc loss 40.579200744628906\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 647.6153564453125  loc loss 28.506811141967773\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 835.175048828125  loc loss 71.58045959472656\n",
      "cls loss 1055.968505859375  loc loss 98.56515502929688\n",
      "cls loss 555.0532836914062  loc loss 34.20563888549805\n",
      "cls loss 491.8106994628906  loc loss 31.55846405029297\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3.,  3.,  3.,  3.,  3., 10.])\n",
      "cls loss 268.39532470703125  loc loss 16.093032836914062\n",
      "cls loss 527.326171875  loc loss 25.851852416992188\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 1., 1., 1., 3., 3., 3., 3.])\n",
      "cls loss 403.44036865234375  loc loss 24.49867820739746\n",
      "cls loss 772.0411987304688  loc loss 49.52435302734375\n",
      "cls loss 602.7489013671875  loc loss 39.50970458984375\n",
      "cls loss 395.0955810546875  loc loss 23.417922973632812\n",
      "cls loss 615.0218505859375  loc loss 42.369014739990234\n",
      "cls loss 380.47161865234375  loc loss 28.17721939086914\n",
      "cls loss 616.78125  loc loss 42.0502815246582\n",
      "cls loss 440.48504638671875  loc loss 42.07251739501953\n",
      "cls loss 480.6874084472656  loc loss 29.541589736938477\n",
      "cls loss 948.5174560546875  loc loss 77.93876647949219\n",
      "cls loss 635.5208740234375  loc loss 45.34889602661133\n",
      "cls loss 441.6683654785156  loc loss 21.14401626586914\n",
      "cls loss 293.6664733886719  loc loss 12.476884841918945\n",
      "cls loss 340.8795471191406  loc loss 15.82448959350586\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3., 10., 10., 10., 10., 10., 10., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10., 10., 10., 10., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 11., 10., 10., 10., 10., 10.,  3.,  3.,  3.,  3.,  3.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 11., 10., 10., 10., 10., 10.,  3.,  3.,  3.,  3.,  3.])\n",
      "cls loss 316.82696533203125  loc loss 14.112874984741211\n",
      "cls loss 381.2048645019531  loc loss 17.6602725982666\n",
      "cls loss 318.11639404296875  loc loss 18.888782501220703\n",
      "cls loss 327.55462646484375  loc loss 14.270233154296875\n",
      "cls loss 377.2846374511719  loc loss 29.882993698120117\n",
      "cls loss 308.48681640625  loc loss 11.767648696899414\n",
      "cls loss 575.1386108398438  loc loss 38.85833740234375\n",
      "cls loss 491.45111083984375  loc loss 34.11061477661133\n",
      "cls loss 770.709716796875  loc loss 47.93486404418945\n",
      "cls loss 382.42120361328125  loc loss 27.578899383544922\n",
      "cls loss 687.99462890625  loc loss 44.583465576171875\n",
      "cls loss 557.22607421875  loc loss 36.58356475830078\n",
      "cls loss 517.2703247070312  loc loss 34.17152786254883\n",
      "cls loss 513.9309692382812  loc loss 36.71394729614258\n",
      "cls loss 698.1793823242188  loc loss 46.622859954833984\n",
      "cls loss 713.7490234375  loc loss 42.56987762451172\n",
      "cls loss 337.0921630859375  loc loss 17.878353118896484\n",
      "cls loss 619.5577392578125  loc loss 44.543922424316406\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 10.,  1., 18.])\n",
      "cls loss 306.61016845703125  loc loss 20.085969924926758\n",
      "cls loss 378.09246826171875  loc loss 15.299003601074219\n",
      "cls loss 627.7658081054688  loc loss 32.51774597167969\n",
      "cls loss 874.0245361328125  loc loss 50.582847595214844\n",
      "cls loss 508.33172607421875  loc loss 35.64784240722656\n",
      "cls loss 736.3248901367188  loc loss 38.71266555786133\n",
      "cls loss 523.340087890625  loc loss 35.06016540527344\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.,  1.,  1.])\n",
      "cls loss 647.509765625  loc loss 41.82178497314453\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1., 38.,  1.])\n",
      "cls loss 610.2275390625  loc loss 33.76719665527344\n",
      "cls loss 790.92333984375  loc loss 57.736412048339844\n",
      "cls loss 431.4990234375  loc loss 29.139835357666016\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 570.45751953125  loc loss 37.11240005493164\n",
      "cls loss 494.7267150878906  loc loss 30.244192123413086\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3., 10.,  8.,  3., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.])\n",
      "cls loss 583.3021240234375  loc loss 32.793758392333984\n",
      "cls loss 407.85308837890625  loc loss 25.229825973510742\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3.,  3., 11.,  3., 10., 10.,  3.,  3., 10.])\n",
      "cls loss 482.02435302734375  loc loss 22.849082946777344\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3., 10., 10., 10.])\n",
      "cls loss 473.51019287109375  loc loss 29.62731170654297\n",
      "cls loss 417.8843688964844  loc loss 22.656940460205078\n",
      "cls loss 500.50885009765625  loc loss 32.78012466430664\n",
      "cls loss 742.6552734375  loc loss 42.81444549560547\n",
      "cls loss 488.86236572265625  loc loss 30.264179229736328\n",
      "cls loss 361.0069274902344  loc loss 29.94660186767578\n",
      "cls loss 477.97027587890625  loc loss 30.589719772338867\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 9.,  9., 85., 85.])\n",
      "cls loss 378.1452331542969  loc loss 21.088123321533203\n",
      "cls loss 451.07818603515625  loc loss 32.67790222167969\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 747.8204345703125  loc loss 51.847415924072266\n",
      "cls loss 651.4912109375  loc loss 30.63353729248047\n",
      "cls loss 701.1971435546875  loc loss 50.47010803222656\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10., 10., 10., 10.])\n",
      "cls loss 445.3704528808594  loc loss 27.47942543029785\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([13.])\n",
      "cls loss 705.301513671875  loc loss 54.82915115356445\n",
      "cls loss 251.7765655517578  loc loss 13.099535942077637\n",
      "cls loss 332.32208251953125  loc loss 16.4359073638916\n",
      "cls loss 444.0146179199219  loc loss 23.493656158447266\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19.,  1.,  1.,  1., 19., 19.])\n",
      "cls loss 440.9697265625  loc loss 29.241870880126953\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 354.73199462890625  loc loss 25.843738555908203\n",
      "cls loss 498.4850158691406  loc loss 35.76880645751953\n",
      "cls loss 383.9615783691406  loc loss 21.429948806762695\n",
      "cls loss 562.8297119140625  loc loss 30.050212860107422\n",
      "cls loss 587.71875  loc loss 44.50322341918945\n",
      "cls loss 483.4736022949219  loc loss 25.92616081237793\n",
      "cls loss 693.876708984375  loc loss 49.56001663208008\n",
      "cls loss 278.261962890625  loc loss 12.223207473754883\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 516.3104248046875  loc loss 31.2080135345459\n",
      "cls loss 401.76556396484375  loc loss 19.841123580932617\n",
      "cls loss 439.98516845703125  loc loss 23.037059783935547\n",
      "cls loss 548.262939453125  loc loss 32.944007873535156\n",
      "cls loss 506.2921447753906  loc loss 24.738054275512695\n",
      "cls loss 697.71142578125  loc loss 45.528961181640625\n",
      "cls loss 446.4495849609375  loc loss 29.399600982666016\n",
      "cls loss 571.485595703125  loc loss 40.83112335205078\n",
      "cls loss 871.9580688476562  loc loss 52.21235275268555\n",
      "cls loss 447.71826171875  loc loss 33.6592903137207\n",
      "cls loss 525.84423828125  loc loss 31.167755126953125\n",
      "cls loss 602.212158203125  loc loss 47.18722152709961\n",
      "cls loss 685.016845703125  loc loss 47.82683563232422\n",
      "cls loss 837.9435424804688  loc loss 44.056907653808594\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 5.])\n",
      "cls loss 243.72500610351562  loc loss 10.06607723236084\n",
      "cls loss 312.526611328125  loc loss 14.043886184692383\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 13.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 6., 8., 8.])\n",
      "cls loss 259.748046875  loc loss 13.897703170776367\n",
      "cls loss 352.154541015625  loc loss 17.095144271850586\n",
      "cls loss 660.85107421875  loc loss 43.56843566894531\n",
      "cls loss 298.3145751953125  loc loss 14.750741958618164\n",
      "cls loss 507.380615234375  loc loss 38.823551177978516\n",
      "cls loss 779.4197387695312  loc loss 56.397499084472656\n",
      "cls loss 480.12646484375  loc loss 34.925811767578125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([42., 42.,  1.,  1.,  1.,  1.,  1.,  1.,  1., 42., 42.])\n",
      "cls loss 548.310791015625  loc loss 29.36081314086914\n",
      "cls loss 683.9180297851562  loc loss 52.142784118652344\n",
      "cls loss 602.1751708984375  loc loss 43.518280029296875\n",
      "cls loss 402.45458984375  loc loss 25.349185943603516\n",
      "cls loss 533.933837890625  loc loss 30.40741539001465\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 734.5267333984375  loc loss 48.0203971862793\n",
      "cls loss 609.3651123046875  loc loss 41.196205139160156\n",
      "cls loss 372.2305603027344  loc loss 21.148948669433594\n",
      "cls loss 305.4882507324219  loc loss 17.98190689086914\n",
      "cls loss 444.25933837890625  loc loss 26.042407989501953\n",
      "cls loss 594.5320434570312  loc loss 36.7449836730957\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15.])\n",
      "cls loss 307.05047607421875  loc loss 11.787891387939453\n",
      "cls loss 504.3839111328125  loc loss 31.560489654541016\n",
      "cls loss 441.1785583496094  loc loss 29.148033142089844\n",
      "cls loss 779.9828491210938  loc loss 52.946163177490234\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19.,  7.])\n",
      "cls loss 440.76153564453125  loc loss 22.94356918334961\n",
      "cls loss 817.2416381835938  loc loss 54.017616271972656\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 699.670166015625  loc loss 35.28458786010742\n",
      "cls loss 588.9515380859375  loc loss 42.611732482910156\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([38., 38.,  1., 18.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1., 18., 18.,  1.])\n",
      "cls loss 450.4233093261719  loc loss 22.802227020263672\n",
      "cls loss 431.8229064941406  loc loss 20.41317367553711\n",
      "cls loss 793.0448608398438  loc loss 55.85711669921875\n",
      "cls loss 605.9161987304688  loc loss 32.884986877441406\n",
      "cls loss 542.6493530273438  loc loss 28.405611038208008\n",
      "cls loss 329.85626220703125  loc loss 25.085742950439453\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.])\n",
      "cls loss 246.907958984375  loc loss 9.052406311035156\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([32.])\n",
      "cls loss 504.779541015625  loc loss 26.739856719970703\n",
      "cls loss 429.43548583984375  loc loss 30.641563415527344\n",
      "cls loss 560.7223510742188  loc loss 43.69623565673828\n",
      "cls loss 484.968505859375  loc loss 32.44843292236328\n",
      "cls loss 404.26080322265625  loc loss 25.421350479125977\n",
      "cls loss 672.0546264648438  loc loss 40.404396057128906\n",
      "cls loss 734.0712280273438  loc loss 49.27946090698242\n",
      "cls loss 572.7909545898438  loc loss 37.2968635559082\n",
      "cls loss 466.7666931152344  loc loss 27.03957748413086\n",
      "cls loss 732.8158569335938  loc loss 46.42945861816406\n",
      "cls loss 490.0073547363281  loc loss 25.08429718017578\n",
      "cls loss 801.0451049804688  loc loss 55.93080520629883\n",
      "cls loss 563.26416015625  loc loss 30.774993896484375\n",
      "cls loss 466.1422119140625  loc loss 34.376163482666016\n",
      "cls loss 351.30572509765625  loc loss 16.668575286865234\n",
      "cls loss 401.10308837890625  loc loss 24.246795654296875\n",
      "cls loss 588.53564453125  loc loss 37.90382385253906\n",
      "cls loss 619.1861572265625  loc loss 42.28205490112305\n",
      "cls loss 356.24139404296875  loc loss 22.05651092529297\n",
      "cls loss 645.8177490234375  loc loss 42.486820220947266\n",
      "cls loss 767.595458984375  loc loss 47.39006423950195\n",
      "cls loss 279.79620361328125  loc loss 18.71974754333496\n",
      "cls loss 750.039306640625  loc loss 49.473426818847656\n",
      "cls loss 537.7779541015625  loc loss 40.01226043701172\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 728.5632934570312  loc loss 55.27720642089844\n",
      "cls loss 357.82135009765625  loc loss 13.149768829345703\n",
      "cls loss 530.771728515625  loc loss 28.598617553710938\n",
      "cls loss 520.890380859375  loc loss 34.241329193115234\n",
      "cls loss 432.31463623046875  loc loss 24.058141708374023\n",
      "cls loss 271.7032470703125  loc loss 13.238160133361816\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 9., 9., 1., 9., 9., 9., 9., 1., 9.])\n",
      "cls loss 928.4666137695312  loc loss 73.83528137207031\n",
      "cls loss 555.10009765625  loc loss 28.413612365722656\n",
      "cls loss 781.65576171875  loc loss 63.910587310791016\n",
      "cls loss 336.34832763671875  loc loss 23.435718536376953\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 42., 42.])\n",
      "cls loss 572.7215576171875  loc loss 42.37266540527344\n",
      "cls loss 621.961669921875  loc loss 45.2166633605957\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  2.,  1.,  1.,  1., 38.,\n",
      "         1.,  1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 38., 38., 38.,  1., 38., 38., 38.,  1.,  1., 38.,  1.,\n",
      "         1.])\n",
      "cls loss 374.1215515136719  loc loss 27.696998596191406\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  8.,  8.])\n",
      "cls loss 918.0819091796875  loc loss 57.69369125366211\n",
      "cls loss 876.281005859375  loc loss 64.94207763671875\n",
      "cls loss 345.81365966796875  loc loss 19.746379852294922\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([4., 1., 1., 4.])\n",
      "cls loss 508.2502136230469  loc loss 33.13945388793945\n",
      "cls loss 613.6012573242188  loc loss 36.23853302001953\n",
      "cls loss 265.1131896972656  loc loss 12.932693481445312\n",
      "cls loss 354.6131286621094  loc loss 22.1954402923584\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([51.,  1.])\n",
      "cls loss 266.8299255371094  loc loss 10.628825187683105\n",
      "cls loss 365.2922668457031  loc loss 19.265531539916992\n",
      "cls loss 625.4812622070312  loc loss 35.14364242553711\n",
      "cls loss 660.9383544921875  loc loss 46.6781120300293\n",
      "cls loss 887.2779541015625  loc loss 48.28839874267578\n",
      "cls loss 1086.9833984375  loc loss 73.4874496459961\n",
      "cls loss 480.32537841796875  loc loss 28.53604507446289\n",
      "cls loss 694.5277709960938  loc loss 49.95154571533203\n",
      "cls loss 724.0848388671875  loc loss 50.698570251464844\n",
      "cls loss 575.1915283203125  loc loss 33.31400680541992\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  3.,  1.,  1.,  1.,  3.,  1.,  1.,\n",
      "         1.,  1.,  1.])\n",
      "cls loss 578.786865234375  loc loss 26.60224723815918\n",
      "cls loss 667.4169921875  loc loss 34.12858581542969\n",
      "cls loss 593.1068115234375  loc loss 31.853689193725586\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "cls loss 508.6401672363281  loc loss 29.561908721923828\n",
      "cls loss 294.0681457519531  loc loss 23.668899536132812\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3.])\n",
      "cls loss 238.32168579101562  loc loss 12.284649848937988\n",
      "cls loss 435.37994384765625  loc loss 28.584985733032227\n",
      "cls loss 359.5646057128906  loc loss 27.115036010742188\n",
      "cls loss 653.1931762695312  loc loss 43.39086151123047\n",
      "cls loss 435.59417724609375  loc loss 22.665733337402344\n",
      "cls loss 359.8462219238281  loc loss 25.01759147644043\n",
      "cls loss 1073.154296875  loc loss 72.0456314086914\n",
      "cls loss 463.86700439453125  loc loss 35.74611282348633\n",
      "cls loss 359.2344665527344  loc loss 25.294612884521484\n",
      "cls loss 443.38818359375  loc loss 25.535459518432617\n",
      "cls loss 404.2259826660156  loc loss 28.84212875366211\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 732.7802734375  loc loss 48.896385192871094\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  9., 64., 64., 64., 64., 64., 64., 64., 64., 64.,  9.,  9.,  9.,\n",
      "         9.])\n",
      "cls loss 387.59765625  loc loss 18.826202392578125\n",
      "cls loss 925.3203735351562  loc loss 73.94345092773438\n",
      "cls loss 501.87652587890625  loc loss 32.62143325805664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 648.89892578125  loc loss 43.722373962402344\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.,  3.,  3.])\n",
      "cls loss 415.22698974609375  loc loss 22.434162139892578\n",
      "cls loss 448.8055419921875  loc loss 29.77973175048828\n",
      "cls loss 440.3540954589844  loc loss 31.369958877563477\n",
      "cls loss 463.6993103027344  loc loss 34.01105499267578\n",
      "cls loss 480.193359375  loc loss 37.88456344604492\n",
      "cls loss 502.1900634765625  loc loss 36.05147171020508\n",
      "cls loss 460.57684326171875  loc loss 35.24810791015625\n",
      "cls loss 509.18475341796875  loc loss 29.410945892333984\n",
      "cls loss 626.547119140625  loc loss 41.43563461303711\n",
      "cls loss 503.6185607910156  loc loss 28.91592788696289\n",
      "cls loss 410.34674072265625  loc loss 18.68238067626953\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21.])\n",
      "cls loss 313.312744140625  loc loss 17.54789924621582\n",
      "cls loss 437.50634765625  loc loss 35.88662338256836\n",
      "cls loss 645.1522827148438  loc loss 43.5932731628418\n",
      "cls loss 367.9572448730469  loc loss 20.30171775817871\n",
      "cls loss 501.31939697265625  loc loss 30.880882263183594\n",
      "cls loss 941.7299194335938  loc loss 49.85865783691406\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 42., 42.,  1.,  1.])\n",
      "cls loss 478.2093200683594  loc loss 30.627634048461914\n",
      "cls loss 319.2945556640625  loc loss 22.38681983947754\n",
      "cls loss 456.25408935546875  loc loss 33.425384521484375\n",
      "cls loss 632.00048828125  loc loss 50.560081481933594\n",
      "cls loss 404.49920654296875  loc loss 25.87689971923828\n",
      "cls loss 603.6383666992188  loc loss 45.36400604248047\n",
      "cls loss 576.44482421875  loc loss 40.95734405517578\n",
      "cls loss 608.5034790039062  loc loss 35.92189025878906\n",
      "cls loss 482.8974914550781  loc loss 28.542434692382812\n",
      "cls loss 428.9533386230469  loc loss 26.20415496826172\n",
      "cls loss 351.7934265136719  loc loss 13.618452072143555\n",
      "cls loss 440.1029357910156  loc loss 28.4608211517334\n",
      "cls loss 675.4058227539062  loc loss 48.22959899902344\n",
      "cls loss 532.5484619140625  loc loss 32.470367431640625\n",
      "cls loss 491.69219970703125  loc loss 36.066673278808594\n",
      "cls loss 549.1351318359375  loc loss 32.72769546508789\n",
      "cls loss 786.9588012695312  loc loss 56.2768669128418\n",
      "cls loss 587.0215454101562  loc loss 42.895355224609375\n",
      "cls loss 670.397216796875  loc loss 37.400718688964844\n",
      "cls loss 383.18218994140625  loc loss 19.102928161621094\n",
      "cls loss 553.2139892578125  loc loss 35.10174560546875\n",
      "cls loss 511.29193115234375  loc loss 30.004209518432617\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 5., 5., 5., 5., 5., 5.])\n",
      "cls loss 356.65631103515625  loc loss 24.00055694580078\n",
      "cls loss 445.3397216796875  loc loss 24.403318405151367\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([13.])\n",
      "cls loss 310.18524169921875  loc loss 18.385324478149414\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([44., 10.,  1.,  1.,  1.])\n",
      "cls loss 304.4269104003906  loc loss 18.863943099975586\n",
      "cls loss 589.776611328125  loc loss 28.95992088317871\n",
      "cls loss 481.78363037109375  loc loss 26.985332489013672\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19., 19., 19., 19., 19., 19., 19.])\n",
      "cls loss 594.844482421875  loc loss 30.576004028320312\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([56.])\n",
      "cls loss 1016.4008178710938  loc loss 66.5327377319336\n",
      "cls loss 625.091552734375  loc loss 47.81355285644531\n",
      "cls loss 797.0418701171875  loc loss 54.5533447265625\n",
      "cls loss 782.7725830078125  loc loss 59.6202278137207\n",
      "cls loss 500.1151123046875  loc loss 27.29041862487793\n",
      "cls loss 783.382568359375  loc loss 53.62053680419922\n",
      "cls loss 451.02972412109375  loc loss 29.409297943115234\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 36.])\n",
      "cls loss 546.619384765625  loc loss 29.58951759338379\n",
      "cls loss 497.4865417480469  loc loss 32.765106201171875\n",
      "cls loss 468.12835693359375  loc loss 28.097492218017578\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5.])\n",
      "cls loss 573.4268798828125  loc loss 33.73468780517578\n",
      "cls loss 297.794921875  loc loss 15.8651123046875\n",
      "cls loss 711.28125  loc loss 38.042293548583984\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "cls loss 606.8290405273438  loc loss 39.380653381347656\n",
      "cls loss 585.1516723632812  loc loss 39.5811767578125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 563.31494140625  loc loss 40.18440246582031\n",
      "cls loss 657.38720703125  loc loss 46.2844123840332\n",
      "cls loss 550.8807373046875  loc loss 49.53741455078125\n",
      "cls loss 398.2166748046875  loc loss 27.403743743896484\n",
      "cls loss 473.5444641113281  loc loss 34.618064880371094\n",
      "cls loss 506.0434265136719  loc loss 31.473785400390625\n",
      "cls loss 776.4029541015625  loc loss 42.84135818481445\n",
      "cls loss 353.333740234375  loc loss 17.263463973999023\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 11., 15., 10., 10., 10., 10., 10.])\n",
      "cls loss 845.206298828125  loc loss 49.924407958984375\n",
      "cls loss 444.9268798828125  loc loss 31.96756362915039\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3.])\n",
      "cls loss 497.37640380859375  loc loss 33.23044204711914\n",
      "cls loss 466.5868835449219  loc loss 24.84276580810547\n",
      "cls loss 494.2729187011719  loc loss 23.886676788330078\n",
      "cls loss 631.20849609375  loc loss 29.375244140625\n",
      "cls loss 340.45343017578125  loc loss 16.009544372558594\n",
      "cls loss 491.8474426269531  loc loss 32.344810485839844\n",
      "cls loss 550.6759033203125  loc loss 39.475608825683594\n",
      "cls loss 461.4552001953125  loc loss 34.36091995239258\n",
      "cls loss 1094.3875732421875  loc loss 77.92829895019531\n",
      "cls loss 765.5941772460938  loc loss 49.06085205078125\n",
      "cls loss 500.87445068359375  loc loss 34.80302047729492\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  9.,  9.,  9.,  6.,  6., 85., 85.,  8.,  1.,  1.,  1.,  1.,\n",
      "         6.,  6.])\n",
      "cls loss 331.55767822265625  loc loss 26.060680389404297\n",
      "cls loss 805.771484375  loc loss 56.92628860473633\n",
      "cls loss 969.8763427734375  loc loss 59.32218551635742\n",
      "cls loss 655.8370361328125  loc loss 43.79985046386719\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10.,  3.,  3., 10.])\n",
      "cls loss 448.0735168457031  loc loss 23.253042221069336\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([7.])\n",
      "cls loss 539.7750244140625  loc loss 35.440452575683594\n",
      "cls loss 555.802001953125  loc loss 33.100399017333984\n",
      "cls loss 493.53070068359375  loc loss 41.2740478515625\n",
      "cls loss 713.0515747070312  loc loss 58.00307846069336\n",
      "cls loss 497.7453308105469  loc loss 33.927555084228516\n",
      "cls loss 701.5987548828125  loc loss 45.314693450927734\n",
      "cls loss 872.357421875  loc loss 51.715980529785156\n",
      "cls loss 516.037353515625  loc loss 35.64189910888672\n",
      "cls loss 566.5021362304688  loc loss 40.121070861816406\n",
      "cls loss 472.5313720703125  loc loss 34.62333679199219\n",
      "cls loss 686.2764892578125  loc loss 54.212772369384766\n",
      "cls loss 546.1856689453125  loc loss 34.009796142578125\n",
      "cls loss 438.7849426269531  loc loss 25.72426986694336\n",
      "cls loss 670.1309814453125  loc loss 50.226531982421875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([62.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([62.])\n",
      "cls loss 311.7763366699219  loc loss 15.119730949401855\n",
      "cls loss 521.2529296875  loc loss 36.26185607910156\n",
      "cls loss 515.42431640625  loc loss 32.916404724121094\n",
      "cls loss 351.30865478515625  loc loss 15.959527015686035\n",
      "cls loss 655.596435546875  loc loss 42.866764068603516\n",
      "cls loss 687.3350830078125  loc loss 37.43696975708008\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([28.])\n",
      "cls loss 747.9513549804688  loc loss 39.26444625854492\n",
      "cls loss 645.2275390625  loc loss 38.909706115722656\n",
      "cls loss 640.16162109375  loc loss 41.764617919921875\n",
      "cls loss 641.6068725585938  loc loss 40.822425842285156\n",
      "cls loss 887.2276000976562  loc loss 59.14195251464844\n",
      "cls loss 501.2162780761719  loc loss 31.371417999267578\n",
      "cls loss 631.8565673828125  loc loss 37.699974060058594\n",
      "cls loss 540.6051025390625  loc loss 44.645751953125\n",
      "cls loss 881.48388671875  loc loss 68.9454574584961\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([81.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 616.6117553710938  loc loss 24.98149871826172\n",
      "cls loss 456.3380126953125  loc loss 23.793498992919922\n",
      "cls loss 373.89837646484375  loc loss 24.94069480895996\n",
      "cls loss 328.35137939453125  loc loss 12.288748741149902\n",
      "cls loss 366.8954162597656  loc loss 25.00225067138672\n",
      "cls loss 407.21661376953125  loc loss 24.985071182250977\n",
      "cls loss 483.04656982421875  loc loss 29.492950439453125\n",
      "cls loss 632.2784423828125  loc loss 49.26054000854492\n",
      "cls loss 703.451171875  loc loss 45.67288589477539\n",
      "cls loss 1299.960693359375  loc loss 85.91899108886719\n",
      "cls loss 524.0306396484375  loc loss 27.119293212890625\n",
      "cls loss 635.7786865234375  loc loss 44.539886474609375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 449.2546691894531  loc loss 27.752315521240234\n",
      "cls loss 590.8855590820312  loc loss 33.32200622558594\n",
      "cls loss 511.10052490234375  loc loss 29.223817825317383\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([44., 44.])\n",
      "cls loss 471.75732421875  loc loss 22.66343116760254\n",
      "cls loss 488.5410461425781  loc loss 32.826541900634766\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15.])\n",
      "cls loss 548.3272705078125  loc loss 26.65555191040039\n",
      "cls loss 270.9653015136719  loc loss 15.554535865783691\n",
      "cls loss 549.7069091796875  loc loss 31.86886978149414\n",
      "cls loss 308.0553894042969  loc loss 18.03230857849121\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([1., 3., 3.])\n",
      "cls loss 348.6537780761719  loc loss 24.784664154052734\n",
      "cls loss 282.3436279296875  loc loss 12.056239128112793\n",
      "cls loss 523.1861572265625  loc loss 30.173301696777344\n",
      "cls loss 558.5255126953125  loc loss 32.37933349609375\n",
      "cls loss 502.51312255859375  loc loss 32.97333908081055\n",
      "cls loss 504.88665771484375  loc loss 27.549293518066406\n",
      "cls loss 411.26263427734375  loc loss 31.585514068603516\n",
      "cls loss 575.056640625  loc loss 37.13765335083008\n",
      "cls loss 416.1790771484375  loc loss 28.058706283569336\n",
      "cls loss 543.576171875  loc loss 37.97648239135742\n",
      "cls loss 353.2440185546875  loc loss 20.83201026916504\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 654.8020629882812  loc loss 39.80515670776367\n",
      "cls loss 766.5640869140625  loc loss 36.062828063964844\n",
      "cls loss 662.41650390625  loc loss 46.02471923828125\n",
      "cls loss 665.852294921875  loc loss 50.76903533935547\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10., 10., 10.,  1.,  1.,  1.,  1.,  1.,  1.,  8.,  8.,\n",
      "         1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10., 10., 10.,  1.,  1.,  1.,  1.,  1.,  1.,  8.,  8.,\n",
      "         1.])\n",
      "cls loss 613.3597412109375  loc loss 28.49217414855957\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 3., 3., 3.])\n",
      "cls loss 521.6685180664062  loc loss 32.34941101074219\n",
      "cls loss 370.7793273925781  loc loss 20.41823959350586\n",
      "cls loss 285.8634948730469  loc loss 13.6369047164917\n",
      "cls loss 485.1998291015625  loc loss 36.558380126953125\n",
      "cls loss 374.31781005859375  loc loss 18.93752670288086\n",
      "cls loss 439.68505859375  loc loss 28.732589721679688\n",
      "cls loss 490.13677978515625  loc loss 33.192230224609375\n",
      "cls loss 689.52392578125  loc loss 47.10919952392578\n",
      "cls loss 580.588134765625  loc loss 28.340755462646484\n",
      "cls loss 563.37158203125  loc loss 30.853158950805664\n",
      "cls loss 616.223388671875  loc loss 40.983970642089844\n",
      "cls loss 437.5657653808594  loc loss 33.37255859375\n",
      "cls loss 818.730712890625  loc loss 60.83942794799805\n",
      "cls loss 410.26312255859375  loc loss 20.668048858642578\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 636.9664306640625  loc loss 38.91612243652344\n",
      "cls loss 315.4391174316406  loc loss 12.875003814697266\n",
      "cls loss 777.3748168945312  loc loss 48.1728630065918\n",
      "cls loss 401.2715148925781  loc loss 21.96379280090332\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 34.])\n",
      "cls loss 663.4217529296875  loc loss 34.12263107299805\n",
      "cls loss 310.9039001464844  loc loss 19.820085525512695\n",
      "cls loss 580.42236328125  loc loss 38.08311080932617\n",
      "cls loss 198.4266357421875  loc loss 14.935628890991211\n",
      "cls loss 502.8777770996094  loc loss 31.72714614868164\n",
      "cls loss 489.0132751464844  loc loss 39.5458984375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 38.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16., 16., 16.,  9.,  9.,  9., 16., 16., 16., 85.,  9.])\n",
      "cls loss 491.0489807128906  loc loss 32.43418502807617\n",
      "cls loss 561.8182373046875  loc loss 43.27199935913086\n",
      "cls loss 754.340576171875  loc loss 51.12792205810547\n",
      "cls loss 1093.986328125  loc loss 72.44388580322266\n",
      "cls loss 340.6700134277344  loc loss 17.531085968017578\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3., 10.,  8.,  8., 10., 10., 10.,  3.,  3., 14.])\n",
      "cls loss 410.47418212890625  loc loss 19.373109817504883\n",
      "cls loss 739.20849609375  loc loss 37.26369857788086\n",
      "cls loss 318.0049743652344  loc loss 11.41639518737793\n",
      "cls loss 472.2431640625  loc loss 20.110166549682617\n",
      "cls loss 624.285888671875  loc loss 36.61061096191406\n",
      "cls loss 532.509521484375  loc loss 33.3270263671875\n",
      "cls loss 302.5068359375  loc loss 15.657842636108398\n",
      "cls loss 343.14849853515625  loc loss 21.38835334777832\n",
      "cls loss 538.12744140625  loc loss 33.99862289428711\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42., 42.,  1.])\n",
      "cls loss 524.8837890625  loc loss 36.55173873901367\n",
      "cls loss 425.60015869140625  loc loss 25.10742950439453\n",
      "cls loss 568.426513671875  loc loss 44.160457611083984\n",
      "cls loss 682.4526977539062  loc loss 42.096466064453125\n",
      "cls loss 461.6954345703125  loc loss 29.749431610107422\n",
      "cls loss 573.3712768554688  loc loss 40.40049743652344\n",
      "cls loss 373.224365234375  loc loss 24.789382934570312\n",
      "cls loss 387.16229248046875  loc loss 26.770160675048828\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20.])\n",
      "cls loss 304.47027587890625  loc loss 17.039958953857422\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([11.])\n",
      "cls loss 390.7775573730469  loc loss 19.3778133392334\n",
      "cls loss 269.86419677734375  loc loss 14.2161283493042\n",
      "cls loss 597.9144287109375  loc loss 45.7886962890625\n",
      "cls loss 279.5626220703125  loc loss 12.485617637634277\n",
      "cls loss 585.6580200195312  loc loss 31.538551330566406\n",
      "cls loss 318.83856201171875  loc loss 19.77110481262207\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 35., 27.])\n",
      "cls loss 534.5316162109375  loc loss 32.64548873901367\n",
      "cls loss 582.69189453125  loc loss 43.31501388549805\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 397.6320495605469  loc loss 23.68488121032715\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([42.,  1.])\n",
      "cls loss 510.83380126953125  loc loss 35.527984619140625\n",
      "cls loss 479.2373352050781  loc loss 27.40180778503418\n",
      "cls loss 586.0297241210938  loc loss 35.59127426147461\n",
      "cls loss 717.7366943359375  loc loss 46.2774658203125\n",
      "cls loss 647.6331176757812  loc loss 38.464805603027344\n",
      "cls loss 440.8197326660156  loc loss 32.31980895996094\n",
      "cls loss 377.8643798828125  loc loss 28.515235900878906\n",
      "cls loss 248.53515625  loc loss 11.329950332641602\n",
      "cls loss 448.39483642578125  loc loss 24.33592987060547\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 1., 1.])\n",
      "cls loss 436.720947265625  loc loss 23.898645401000977\n",
      "cls loss 482.9328308105469  loc loss 31.720029830932617\n",
      "cls loss 477.1563720703125  loc loss 30.02303695678711\n",
      "cls loss 391.98016357421875  loc loss 27.582002639770508\n",
      "cls loss 474.87493896484375  loc loss 28.21103858947754\n",
      "cls loss 496.80938720703125  loc loss 36.45103454589844\n",
      "cls loss 684.4602661132812  loc loss 41.558143615722656\n",
      "cls loss 586.532470703125  loc loss 44.99718475341797\n",
      "cls loss 556.51025390625  loc loss 33.26427459716797\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 435.5075378417969  loc loss 29.466325759887695\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 518.758056640625  loc loss 25.42305564880371\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([81.])\n",
      "cls loss 625.7864990234375  loc loss 37.97283172607422\n",
      "cls loss 396.6685791015625  loc loss 26.42751693725586\n",
      "cls loss 281.0290832519531  loc loss 15.970075607299805\n",
      "cls loss 444.958251953125  loc loss 23.21843910217285\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3.,  1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 19.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 19.])\n",
      "cls loss 569.0164184570312  loc loss 39.48496627807617\n",
      "cls loss 339.98358154296875  loc loss 17.586652755737305\n",
      "cls loss 355.59765625  loc loss 20.400970458984375\n",
      "cls loss 670.93994140625  loc loss 48.887107849121094\n",
      "cls loss 343.6720275878906  loc loss 21.36409568786621\n",
      "cls loss 426.9736022949219  loc loss 28.46556854248047\n",
      "cls loss 520.800048828125  loc loss 34.59441375732422\n",
      "cls loss 414.4481201171875  loc loss 29.327377319335938\n",
      "cls loss 532.8756103515625  loc loss 30.94620132446289\n",
      "cls loss 603.3570556640625  loc loss 41.030757904052734\n",
      "cls loss 730.239990234375  loc loss 64.95719146728516\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 81.])\n",
      "cls loss 535.88232421875  loc loss 27.909700393676758\n",
      "cls loss 451.804443359375  loc loss 25.818878173828125\n",
      "cls loss 520.2442626953125  loc loss 27.271358489990234\n",
      "cls loss 395.04754638671875  loc loss 19.431713104248047\n",
      "cls loss 351.7067565917969  loc loss 22.05511474609375\n",
      "cls loss 390.5986328125  loc loss 29.626976013183594\n",
      "cls loss 324.38006591796875  loc loss 22.72483253479004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 262.0684509277344  loc loss 16.83623504638672\n",
      "cls loss 350.8456115722656  loc loss 22.842296600341797\n",
      "cls loss 483.31536865234375  loc loss 29.25347137451172\n",
      "cls loss 398.4199523925781  loc loss 31.670801162719727\n",
      "cls loss 421.19921875  loc loss 32.93367004394531\n",
      "cls loss 259.4156494140625  loc loss 18.333765029907227\n",
      "cls loss 874.5516357421875  loc loss 61.919769287109375\n",
      "cls loss 551.6263427734375  loc loss 36.63911819458008\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 475.2966613769531  loc loss 24.52597999572754\n",
      "cls loss 520.53271484375  loc loss 34.6653938293457\n",
      "cls loss 415.17822265625  loc loss 25.2158203125\n",
      "cls loss 609.6865234375  loc loss 40.18212890625\n",
      "cls loss 589.6185913085938  loc loss 36.84074783325195\n",
      "cls loss 535.544677734375  loc loss 32.93608093261719\n",
      "cls loss 424.7973937988281  loc loss 25.12503433227539\n",
      "cls loss 319.23822021484375  loc loss 19.96828269958496\n",
      "cls loss 488.642822265625  loc loss 28.736177444458008\n",
      "cls loss 519.4118041992188  loc loss 34.92583465576172\n",
      "cls loss 549.6765747070312  loc loss 30.429309844970703\n",
      "cls loss 682.4521484375  loc loss 49.737491607666016\n",
      "cls loss 673.0032958984375  loc loss 54.753807067871094\n",
      "cls loss 491.73101806640625  loc loss 35.31224822998047\n",
      "cls loss 667.584228515625  loc loss 52.40420913696289\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1., 38., 47.,  1.,  1.,  1.,  1.,  1., 62.])\n",
      "cls loss 478.3121337890625  loc loss 23.321735382080078\n",
      "cls loss 577.2468872070312  loc loss 33.32364273071289\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 601.9666748046875  loc loss 34.8887825012207\n",
      "cls loss 634.5526123046875  loc loss 47.15159606933594\n",
      "cls loss 444.2399597167969  loc loss 22.13541603088379\n",
      "cls loss 504.5101318359375  loc loss 41.23183059692383\n",
      "cls loss 468.13311767578125  loc loss 27.645315170288086\n",
      "cls loss 277.6459045410156  loc loss 10.95621109008789\n",
      "cls loss 443.5824279785156  loc loss 25.222856521606445\n",
      "cls loss 383.9292907714844  loc loss 17.036848068237305\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1., 35.])\n",
      "cls loss 444.25860595703125  loc loss 22.70956039428711\n",
      "cls loss 618.0700073242188  loc loss 33.1872673034668\n",
      "cls loss 605.9796142578125  loc loss 39.54711151123047\n",
      "cls loss 535.9957275390625  loc loss 44.3782958984375\n",
      "cls loss 444.26513671875  loc loss 34.59604263305664\n",
      "cls loss 584.0894775390625  loc loss 43.382484436035156\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 327.6263427734375  loc loss 18.82513999938965\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 474.21820068359375  loc loss 21.59716033935547\n",
      "cls loss 763.8994140625  loc loss 39.970333099365234\n",
      "cls loss 915.48828125  loc loss 70.18341064453125\n",
      "cls loss 468.0928955078125  loc loss 24.069229125976562\n",
      "cls loss 414.5152587890625  loc loss 26.417888641357422\n",
      "cls loss 415.50701904296875  loc loss 22.456939697265625\n",
      "cls loss 436.27313232421875  loc loss 27.594114303588867\n",
      "cls loss 399.55194091796875  loc loss 17.22640609741211\n",
      "cls loss 691.85107421875  loc loss 47.75591278076172\n",
      "cls loss 570.2076416015625  loc loss 35.32863998413086\n",
      "cls loss 315.8533630371094  loc loss 20.337757110595703\n",
      "cls loss 560.2224731445312  loc loss 30.819393157958984\n",
      "cls loss 665.1502685546875  loc loss 53.55046463012695\n",
      "cls loss 558.3936767578125  loc loss 35.14997482299805\n",
      "cls loss 484.49774169921875  loc loss 26.461729049682617\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.])\n",
      "cls loss 458.58917236328125  loc loss 32.920291900634766\n",
      "cls loss 433.60504150390625  loc loss 31.281810760498047\n",
      "cls loss 570.321044921875  loc loss 38.545780181884766\n",
      "cls loss 886.09619140625  loc loss 70.3955078125\n",
      "cls loss 383.6773986816406  loc loss 18.66097640991211\n",
      "cls loss 501.900634765625  loc loss 30.558765411376953\n",
      "cls loss 399.41265869140625  loc loss 21.726402282714844\n",
      "cls loss 435.86480712890625  loc loss 26.87177848815918\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 21., 21., 21.])\n",
      "cls loss 458.6884460449219  loc loss 27.435779571533203\n",
      "cls loss 424.10003662109375  loc loss 20.443910598754883\n",
      "cls loss 459.43963623046875  loc loss 30.088342666625977\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 35.])\n",
      "cls loss 590.55419921875  loc loss 37.024600982666016\n",
      "cls loss 215.6116943359375  loc loss 11.957779884338379\n",
      "cls loss 363.616943359375  loc loss 24.146644592285156\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 353.828857421875  loc loss 16.066057205200195\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 38., 38.,  9., 38.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1.,  1.])\n",
      "cls loss 398.2579650878906  loc loss 26.001371383666992\n",
      "cls loss 667.3055419921875  loc loss 41.9962272644043\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 2.,  1., 77., 31., 10., 10.,  1.,  4., 10.])\n",
      "cls loss 339.3675537109375  loc loss 16.065086364746094\n",
      "cls loss 627.3781127929688  loc loss 36.420654296875\n",
      "cls loss 1245.302978515625  loc loss 71.84492492675781\n",
      "cls loss 392.68902587890625  loc loss 25.93381118774414\n",
      "cls loss 562.6781616210938  loc loss 40.75959396362305\n",
      "cls loss 414.7096252441406  loc loss 21.26559829711914\n",
      "cls loss 414.84783935546875  loc loss 19.638519287109375\n",
      "cls loss 590.973876953125  loc loss 28.29004669189453\n",
      "cls loss 601.9671020507812  loc loss 31.282550811767578\n",
      "cls loss 530.1749267578125  loc loss 36.024681091308594\n",
      "cls loss 411.0033874511719  loc loss 19.636844635009766\n",
      "cls loss 438.68206787109375  loc loss 22.721202850341797\n",
      "cls loss 803.5657958984375  loc loss 49.24870300292969\n",
      "cls loss 689.9302978515625  loc loss 41.607261657714844\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1., 42., 42., 42., 42., 42., 42.,  1.,\n",
      "         1.,  1.,  1., 42.,  1.,  1., 42.,  1.])\n",
      "cls loss 380.48992919921875  loc loss 26.6636962890625\n",
      "cls loss 594.297119140625  loc loss 35.618621826171875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.])\n",
      "cls loss 255.15245056152344  loc loss 15.032191276550293\n",
      "cls loss 587.6837158203125  loc loss 37.64347457885742\n",
      "cls loss 463.26416015625  loc loss 32.54621887207031\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([11.])\n",
      "cls loss 287.4804992675781  loc loss 16.422710418701172\n",
      "cls loss 355.36248779296875  loc loss 16.416133880615234\n",
      "cls loss 372.4420166015625  loc loss 16.414575576782227\n",
      "cls loss 591.232177734375  loc loss 36.51494216918945\n",
      "cls loss 522.1121215820312  loc loss 27.922677993774414\n",
      "cls loss 497.8558349609375  loc loss 33.64081954956055\n",
      "cls loss 738.2210083007812  loc loss 37.70991516113281\n",
      "cls loss 367.9006652832031  loc loss 21.70846176147461\n",
      "cls loss 740.1568603515625  loc loss 51.5939826965332\n",
      "cls loss 364.1327209472656  loc loss 23.57855224609375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 343.78704833984375  loc loss 23.334287643432617\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1., 38., 38., 42.])\n",
      "cls loss 438.87005615234375  loc loss 31.944509506225586\n",
      "cls loss 409.3817138671875  loc loss 23.852041244506836\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 359.81329345703125  loc loss 25.705547332763672\n",
      "cls loss 829.7866821289062  loc loss 56.311309814453125\n",
      "cls loss 505.3250732421875  loc loss 32.49226379394531\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10.,  3.,  3.,  6.,  8.,  8.,  1.,  1.,  1., 10.])\n",
      "cls loss 424.74334716796875  loc loss 21.582843780517578\n",
      "cls loss 265.56781005859375  loc loss 9.750460624694824\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10.,  3.])\n",
      "cls loss 393.7783508300781  loc loss 22.221343994140625\n",
      "cls loss 226.94723510742188  loc loss 11.940132141113281\n",
      "cls loss 495.7646484375  loc loss 34.53526306152344\n",
      "cls loss 573.988525390625  loc loss 36.29532241821289\n",
      "cls loss 417.98675537109375  loc loss 24.65082359313965\n",
      "cls loss 301.33953857421875  loc loss 14.64290714263916\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 34.])\n",
      "cls loss 679.2152709960938  loc loss 42.683807373046875\n",
      "cls loss 737.5108032226562  loc loss 61.40220260620117\n",
      "cls loss 469.89617919921875  loc loss 35.28804016113281\n",
      "cls loss 373.45977783203125  loc loss 26.16362762451172\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.,  1.])\n",
      "cls loss 422.51141357421875  loc loss 19.926177978515625\n",
      "cls loss 645.24951171875  loc loss 49.50868225097656\n",
      "cls loss 954.7277221679688  loc loss 62.59430694580078\n",
      "cls loss 805.4999389648438  loc loss 41.79733657836914\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 480.85296630859375  loc loss 25.152587890625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 572.9269409179688  loc loss 32.61982727050781\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10.])\n",
      "cls loss 354.57916259765625  loc loss 18.443735122680664\n",
      "cls loss 518.4239501953125  loc loss 25.495899200439453\n",
      "cls loss 467.97930908203125  loc loss 29.355514526367188\n",
      "cls loss 346.19647216796875  loc loss 20.437854766845703\n",
      "cls loss 445.8536682128906  loc loss 29.00470733642578\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21.,\n",
      "        21.])\n",
      "cls loss 611.28515625  loc loss 33.71383285522461\n",
      "cls loss 468.94683837890625  loc loss 28.378257751464844\n",
      "cls loss 309.88037109375  loc loss 14.172720909118652\n",
      "cls loss 652.8936157226562  loc loss 42.19244384765625\n",
      "cls loss 500.7041320800781  loc loss 33.11677932739258\n",
      "cls loss 359.11712646484375  loc loss 19.714536666870117\n",
      "cls loss 735.3909912109375  loc loss 47.27265167236328\n",
      "cls loss 885.464599609375  loc loss 60.679893493652344\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15., 85.])\n",
      "cls loss 545.8922119140625  loc loss 35.24456024169922\n",
      "cls loss 568.6386108398438  loc loss 41.90511703491211\n",
      "cls loss 583.2846069335938  loc loss 41.69232177734375\n",
      "cls loss 518.3582763671875  loc loss 28.62906265258789\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 8., 8.])\n",
      "cls loss 335.1097106933594  loc loss 15.804640769958496\n",
      "cls loss 351.8506164550781  loc loss 25.19019317626953\n",
      "cls loss 444.8486633300781  loc loss 27.17017936706543\n",
      "cls loss 365.44976806640625  loc loss 20.4366455078125\n",
      "cls loss 417.11322021484375  loc loss 24.714197158813477\n",
      "cls loss 568.7891845703125  loc loss 34.8563232421875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1., 35., 27., 27.,  1., 27.,  1.])\n",
      "cls loss 712.2601928710938  loc loss 51.558937072753906\n",
      "cls loss 386.24981689453125  loc loss 23.959054946899414\n",
      "cls loss 432.4980773925781  loc loss 31.612998962402344\n",
      "cls loss 411.7959899902344  loc loss 36.35989761352539\n",
      "cls loss 373.15411376953125  loc loss 28.52507781982422\n",
      "cls loss 410.1257019042969  loc loss 32.04888153076172\n",
      "cls loss 415.2840576171875  loc loss 32.31673812866211\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  2.,  2.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  2.,  2.])\n",
      "cls loss 233.2572021484375  loc loss 9.088000297546387\n",
      "cls loss 668.0849609375  loc loss 40.850975036621094\n",
      "cls loss 460.1924133300781  loc loss 20.918987274169922\n",
      "cls loss 729.4912109375  loc loss 53.127281188964844\n",
      "cls loss 305.5162353515625  loc loss 17.19085693359375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 19., 19., 19., 16.])\n",
      "cls loss 320.3623352050781  loc loss 13.539260864257812\n",
      "cls loss 255.54824829101562  loc loss 10.459085464477539\n",
      "cls loss 405.5274658203125  loc loss 20.378376007080078\n",
      "cls loss 527.2080078125  loc loss 34.41147994995117\n",
      "cls loss 261.196533203125  loc loss 17.707475662231445\n",
      "cls loss 587.91015625  loc loss 44.8125\n",
      "cls loss 417.1954040527344  loc loss 28.557327270507812\n",
      "cls loss 461.4997253417969  loc loss 29.565277099609375\n",
      "cls loss 590.870849609375  loc loss 39.772743225097656\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 631.452880859375  loc loss 28.05019760131836\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 824.0715942382812  loc loss 70.27396392822266\n",
      "cls loss 1048.549072265625  loc loss 96.87188720703125\n",
      "cls loss 550.1471557617188  loc loss 33.348243713378906\n",
      "cls loss 486.1011657714844  loc loss 30.91558074951172\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3.,  3.,  3.,  3.,  3., 10.])\n",
      "cls loss 260.8840026855469  loc loss 15.768694877624512\n",
      "cls loss 522.526123046875  loc loss 25.24930191040039\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 1., 1., 1., 3., 3., 3., 3.])\n",
      "cls loss 396.850830078125  loc loss 23.704572677612305\n",
      "cls loss 763.7071533203125  loc loss 48.698455810546875\n",
      "cls loss 594.9644775390625  loc loss 38.73030471801758\n",
      "cls loss 388.7675476074219  loc loss 22.982898712158203\n",
      "cls loss 607.590576171875  loc loss 41.55705642700195\n",
      "cls loss 373.9314880371094  loc loss 27.6378173828125\n",
      "cls loss 603.5506591796875  loc loss 41.3069953918457\n",
      "cls loss 435.7847595214844  loc loss 41.50230026245117\n",
      "cls loss 472.5668640136719  loc loss 28.937030792236328\n",
      "cls loss 931.222412109375  loc loss 76.4998550415039\n",
      "cls loss 625.3047485351562  loc loss 44.74076843261719\n",
      "cls loss 433.4286193847656  loc loss 20.769559860229492\n",
      "cls loss 286.322021484375  loc loss 12.210888862609863\n",
      "cls loss 334.4347229003906  loc loss 15.586621284484863\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3., 10., 10., 10., 10., 10., 10., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10., 10., 10., 10., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 11., 10., 10., 10., 10., 10.,  3.,  3.,  3.,  3.,  3.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 11., 10., 10., 10., 10., 10.,  3.,  3.,  3.,  3.,  3.])\n",
      "cls loss 306.65618896484375  loc loss 13.723925590515137\n",
      "cls loss 373.6769104003906  loc loss 17.13473129272461\n",
      "cls loss 311.58587646484375  loc loss 18.381380081176758\n",
      "cls loss 323.899169921875  loc loss 14.076108932495117\n",
      "cls loss 373.73321533203125  loc loss 29.353069305419922\n",
      "cls loss 303.1654052734375  loc loss 11.60489559173584\n",
      "cls loss 568.9794311523438  loc loss 38.27107238769531\n",
      "cls loss 485.87493896484375  loc loss 33.32130813598633\n",
      "cls loss 760.343017578125  loc loss 47.14839172363281\n",
      "cls loss 378.7079162597656  loc loss 27.0849609375\n",
      "cls loss 678.926025390625  loc loss 43.81203842163086\n",
      "cls loss 546.7952880859375  loc loss 35.992332458496094\n",
      "cls loss 509.74481201171875  loc loss 33.591793060302734\n",
      "cls loss 505.2738037109375  loc loss 36.01629638671875\n",
      "cls loss 685.652587890625  loc loss 45.78461456298828\n",
      "cls loss 701.8580322265625  loc loss 41.823673248291016\n",
      "cls loss 331.15045166015625  loc loss 17.5068359375\n",
      "cls loss 612.2327880859375  loc loss 43.61343765258789\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 10.,  1., 18.])\n",
      "cls loss 301.13482666015625  loc loss 19.67873764038086\n",
      "cls loss 376.5260009765625  loc loss 15.133788108825684\n",
      "cls loss 624.6624755859375  loc loss 32.192840576171875\n",
      "cls loss 861.3693237304688  loc loss 49.48151779174805\n",
      "cls loss 499.7676696777344  loc loss 34.99106979370117\n",
      "cls loss 724.195068359375  loc loss 37.7613525390625\n",
      "cls loss 516.838134765625  loc loss 34.5933952331543\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.,  1.,  1.])\n",
      "cls loss 637.2621459960938  loc loss 40.929012298583984\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1., 38.,  1.])\n",
      "cls loss 591.8453979492188  loc loss 33.023895263671875\n",
      "cls loss 776.6668701171875  loc loss 57.045963287353516\n",
      "cls loss 426.0072021484375  loc loss 28.623682022094727\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 564.609130859375  loc loss 36.45023727416992\n",
      "cls loss 486.8610534667969  loc loss 29.695146560668945\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3., 10.,  8.,  3., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.])\n",
      "cls loss 569.994140625  loc loss 32.134971618652344\n",
      "cls loss 396.5721130371094  loc loss 24.757535934448242\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3.,  3., 11.,  3., 10., 10.,  3.,  3., 10.])\n",
      "cls loss 469.17559814453125  loc loss 22.426280975341797\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3., 10., 10., 10.])\n",
      "cls loss 467.24029541015625  loc loss 28.87297248840332\n",
      "cls loss 408.45404052734375  loc loss 22.411861419677734\n",
      "cls loss 494.9022216796875  loc loss 32.16908645629883\n",
      "cls loss 729.8638916015625  loc loss 41.71577072143555\n",
      "cls loss 481.2955322265625  loc loss 29.56597137451172\n",
      "cls loss 357.93939208984375  loc loss 29.356210708618164\n",
      "cls loss 471.7337951660156  loc loss 30.031780242919922\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 9.,  9., 85., 85.])\n",
      "cls loss 370.4450988769531  loc loss 20.642215728759766\n",
      "cls loss 445.64862060546875  loc loss 32.37394332885742\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 734.2161865234375  loc loss 50.76739501953125\n",
      "cls loss 638.6907958984375  loc loss 30.1215763092041\n",
      "cls loss 690.6137084960938  loc loss 49.79719161987305\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10., 10., 10., 10.])\n",
      "cls loss 438.29736328125  loc loss 27.022079467773438\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([13.])\n",
      "cls loss 690.9278564453125  loc loss 53.92892837524414\n",
      "cls loss 244.13999938964844  loc loss 12.689311981201172\n",
      "cls loss 326.12603759765625  loc loss 16.04244041442871\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 434.7698059082031  loc loss 23.20905876159668\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19.,  1.,  1.,  1., 19., 19.])\n",
      "cls loss 435.03729248046875  loc loss 28.679519653320312\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 349.369873046875  loc loss 25.478626251220703\n",
      "cls loss 489.73345947265625  loc loss 35.32417297363281\n",
      "cls loss 379.74090576171875  loc loss 21.103147506713867\n",
      "cls loss 555.051513671875  loc loss 29.39569854736328\n",
      "cls loss 579.682373046875  loc loss 43.77423095703125\n",
      "cls loss 473.8870544433594  loc loss 25.38901138305664\n",
      "cls loss 687.017822265625  loc loss 48.71895217895508\n",
      "cls loss 272.12872314453125  loc loss 11.924102783203125\n",
      "cls loss 509.5819396972656  loc loss 30.748497009277344\n",
      "cls loss 394.8232116699219  loc loss 19.536531448364258\n",
      "cls loss 434.62786865234375  loc loss 22.92003631591797\n",
      "cls loss 543.9118041992188  loc loss 32.37552261352539\n",
      "cls loss 497.620849609375  loc loss 24.125028610229492\n",
      "cls loss 687.698486328125  loc loss 44.87440872192383\n",
      "cls loss 438.841796875  loc loss 28.730573654174805\n",
      "cls loss 563.435302734375  loc loss 40.36577606201172\n",
      "cls loss 853.0462646484375  loc loss 51.22694396972656\n",
      "cls loss 438.7418212890625  loc loss 32.95459747314453\n",
      "cls loss 515.6572265625  loc loss 30.690889358520508\n",
      "cls loss 591.3011474609375  loc loss 46.48163986206055\n",
      "cls loss 675.5547485351562  loc loss 47.23738479614258\n",
      "cls loss 823.8837890625  loc loss 43.38859558105469\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 5.])\n",
      "cls loss 236.4644012451172  loc loss 9.93133544921875\n",
      "cls loss 305.9281311035156  loc loss 13.689865112304688\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 13.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 6., 8., 8.])\n",
      "cls loss 252.89523315429688  loc loss 13.641496658325195\n",
      "cls loss 344.21875  loc loss 16.741512298583984\n",
      "cls loss 648.234130859375  loc loss 42.59807205200195\n",
      "cls loss 291.73956298828125  loc loss 14.631307601928711\n",
      "cls loss 502.41033935546875  loc loss 38.25382995605469\n",
      "cls loss 769.12060546875  loc loss 55.51846694946289\n",
      "cls loss 474.3712158203125  loc loss 34.223052978515625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([42., 42.,  1.,  1.,  1.,  1.,  1.,  1.,  1., 42., 42.])\n",
      "cls loss 540.0526733398438  loc loss 28.681129455566406\n",
      "cls loss 671.7474365234375  loc loss 51.09522247314453\n",
      "cls loss 596.5752563476562  loc loss 42.537906646728516\n",
      "cls loss 393.9676818847656  loc loss 24.911277770996094\n",
      "cls loss 522.8695068359375  loc loss 29.59342384338379\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 727.0579833984375  loc loss 47.22318649291992\n",
      "cls loss 600.904052734375  loc loss 40.68165588378906\n",
      "cls loss 366.03228759765625  loc loss 20.69428825378418\n",
      "cls loss 299.405029296875  loc loss 17.729198455810547\n",
      "cls loss 432.3466796875  loc loss 25.522844314575195\n",
      "cls loss 581.6795654296875  loc loss 35.85365676879883\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15.])\n",
      "cls loss 301.68634033203125  loc loss 11.369620323181152\n",
      "cls loss 498.764404296875  loc loss 30.894023895263672\n",
      "cls loss 431.9637451171875  loc loss 28.63909912109375\n",
      "cls loss 766.1898803710938  loc loss 51.78273010253906\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19.,  7.])\n",
      "cls loss 428.67230224609375  loc loss 22.41617774963379\n",
      "cls loss 804.9952392578125  loc loss 53.14448165893555\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 692.9151611328125  loc loss 34.59056091308594\n",
      "cls loss 580.799072265625  loc loss 41.81858825683594\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([38., 38.,  1., 18.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1., 18., 18.,  1.])\n",
      "cls loss 439.26416015625  loc loss 22.42501449584961\n",
      "cls loss 425.28631591796875  loc loss 19.945215225219727\n",
      "cls loss 783.6965942382812  loc loss 54.68928527832031\n",
      "cls loss 593.0263671875  loc loss 32.401832580566406\n",
      "cls loss 529.6920166015625  loc loss 28.057289123535156\n",
      "cls loss 324.9873046875  loc loss 24.688369750976562\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.])\n",
      "cls loss 238.63197326660156  loc loss 8.892619132995605\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([32.])\n",
      "cls loss 498.69158935546875  loc loss 26.492252349853516\n",
      "cls loss 423.6661376953125  loc loss 30.076091766357422\n",
      "cls loss 551.504638671875  loc loss 42.8865966796875\n",
      "cls loss 478.6914978027344  loc loss 31.811599731445312\n",
      "cls loss 399.2132568359375  loc loss 24.989131927490234\n",
      "cls loss 661.3712158203125  loc loss 39.517208099365234\n",
      "cls loss 726.2235107421875  loc loss 48.338287353515625\n",
      "cls loss 562.4607543945312  loc loss 36.69390869140625\n",
      "cls loss 458.214111328125  loc loss 26.50766372680664\n",
      "cls loss 719.4466552734375  loc loss 45.603538513183594\n",
      "cls loss 482.9421081542969  loc loss 24.725934982299805\n",
      "cls loss 794.71337890625  loc loss 54.877559661865234\n",
      "cls loss 554.1567993164062  loc loss 30.30711555480957\n",
      "cls loss 457.1785888671875  loc loss 33.893455505371094\n",
      "cls loss 346.32867431640625  loc loss 16.268089294433594\n",
      "cls loss 393.17718505859375  loc loss 23.843490600585938\n",
      "cls loss 579.35546875  loc loss 37.24509048461914\n",
      "cls loss 612.5303344726562  loc loss 41.471336364746094\n",
      "cls loss 350.2942199707031  loc loss 21.53978729248047\n",
      "cls loss 633.625  loc loss 41.76612091064453\n",
      "cls loss 757.9100341796875  loc loss 46.633766174316406\n",
      "cls loss 276.0194091796875  loc loss 18.23027801513672\n",
      "cls loss 737.397705078125  loc loss 48.73456954956055\n",
      "cls loss 533.1893920898438  loc loss 39.03773498535156\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 719.585693359375  loc loss 54.313480377197266\n",
      "cls loss 350.14697265625  loc loss 12.915736198425293\n",
      "cls loss 516.596923828125  loc loss 27.995487213134766\n",
      "cls loss 510.0025329589844  loc loss 33.57097625732422\n",
      "cls loss 422.6570129394531  loc loss 23.5824031829834\n",
      "cls loss 264.4196472167969  loc loss 12.999547004699707\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 9., 9., 1., 9., 9., 9., 9., 1., 9.])\n",
      "cls loss 915.9633178710938  loc loss 72.30313110351562\n",
      "cls loss 546.185791015625  loc loss 27.89153480529785\n",
      "cls loss 773.1874389648438  loc loss 62.613895416259766\n",
      "cls loss 332.45599365234375  loc loss 23.16425132751465\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 42., 42.])\n",
      "cls loss 562.5149536132812  loc loss 41.661651611328125\n",
      "cls loss 609.1404418945312  loc loss 44.4248046875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  2.,  1.,  1.,  1., 38.,\n",
      "         1.,  1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 38., 38., 38.,  1., 38., 38., 38.,  1.,  1., 38.,  1.,\n",
      "         1.])\n",
      "cls loss 368.1785888671875  loc loss 27.377193450927734\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  8.,  8.])\n",
      "cls loss 902.0960693359375  loc loss 56.90099334716797\n",
      "cls loss 862.3582763671875  loc loss 64.5166015625\n",
      "cls loss 340.265869140625  loc loss 19.531177520751953\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([4., 1., 1., 4.])\n",
      "cls loss 500.95281982421875  loc loss 32.45378875732422\n",
      "cls loss 604.2574462890625  loc loss 35.55186080932617\n",
      "cls loss 259.78607177734375  loc loss 12.768464088439941\n",
      "cls loss 345.983154296875  loc loss 21.79715919494629\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([51.,  1.])\n",
      "cls loss 261.0523681640625  loc loss 10.464524269104004\n",
      "cls loss 359.7008972167969  loc loss 19.05240821838379\n",
      "cls loss 616.5958862304688  loc loss 34.840850830078125\n",
      "cls loss 646.0723266601562  loc loss 45.66896438598633\n",
      "cls loss 876.4771118164062  loc loss 47.5593376159668\n",
      "cls loss 1075.4638671875  loc loss 72.29024505615234\n",
      "cls loss 471.0198974609375  loc loss 28.064796447753906\n",
      "cls loss 685.1624145507812  loc loss 49.404296875\n",
      "cls loss 715.6641845703125  loc loss 49.56691360473633\n",
      "cls loss 565.6346435546875  loc loss 32.89951705932617\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  3.,  1.,  1.,  1.,  3.,  1.,  1.,\n",
      "         1.,  1.,  1.])\n",
      "cls loss 573.3355712890625  loc loss 26.028221130371094\n",
      "cls loss 657.8609619140625  loc loss 33.498687744140625\n",
      "cls loss 582.1465454101562  loc loss 31.372852325439453\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "cls loss 500.01104736328125  loc loss 29.157352447509766\n",
      "cls loss 285.8310546875  loc loss 23.202281951904297\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3.])\n",
      "cls loss 229.5186767578125  loc loss 12.113682746887207\n",
      "cls loss 425.7178955078125  loc loss 27.839689254760742\n",
      "cls loss 354.138916015625  loc loss 26.569358825683594\n",
      "cls loss 647.7282104492188  loc loss 42.68251037597656\n",
      "cls loss 419.125244140625  loc loss 22.380084991455078\n",
      "cls loss 353.47589111328125  loc loss 24.707279205322266\n",
      "cls loss 1056.8408203125  loc loss 70.87007141113281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 456.5403137207031  loc loss 35.2201042175293\n",
      "cls loss 357.55975341796875  loc loss 24.763286590576172\n",
      "cls loss 439.396240234375  loc loss 25.146039962768555\n",
      "cls loss 401.2370910644531  loc loss 28.410579681396484\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 724.0445556640625  loc loss 48.077178955078125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  9., 64., 64., 64., 64., 64., 64., 64., 64., 64.,  9.,  9.,  9.,\n",
      "         9.])\n",
      "cls loss 378.9682312011719  loc loss 18.32707977294922\n",
      "cls loss 914.2618408203125  loc loss 72.78959655761719\n",
      "cls loss 495.7185974121094  loc loss 32.203880310058594\n",
      "cls loss 639.315185546875  loc loss 42.75675964355469\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.,  3.,  3.])\n",
      "cls loss 406.21636962890625  loc loss 21.88373565673828\n",
      "cls loss 439.74310302734375  loc loss 29.30388832092285\n",
      "cls loss 430.4173583984375  loc loss 30.705406188964844\n",
      "cls loss 455.0550537109375  loc loss 33.27067947387695\n",
      "cls loss 470.5357666015625  loc loss 37.20316696166992\n",
      "cls loss 497.10888671875  loc loss 35.37250518798828\n",
      "cls loss 453.5799560546875  loc loss 34.47859191894531\n",
      "cls loss 499.41778564453125  loc loss 28.71463394165039\n",
      "cls loss 619.4722900390625  loc loss 40.73564147949219\n",
      "cls loss 488.2502136230469  loc loss 28.424612045288086\n",
      "cls loss 397.2728271484375  loc loss 18.378503799438477\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21.])\n",
      "cls loss 307.7940673828125  loc loss 17.31072235107422\n",
      "cls loss 431.0574645996094  loc loss 35.38685607910156\n",
      "cls loss 637.457763671875  loc loss 42.785194396972656\n",
      "cls loss 356.4247741699219  loc loss 19.79424285888672\n",
      "cls loss 493.31634521484375  loc loss 30.41151237487793\n",
      "cls loss 927.7293701171875  loc loss 48.94544982910156\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 42., 42.,  1.,  1.])\n",
      "cls loss 473.39532470703125  loc loss 30.06903648376465\n",
      "cls loss 315.803955078125  loc loss 21.900339126586914\n",
      "cls loss 450.3675537109375  loc loss 32.73772048950195\n",
      "cls loss 621.1629028320312  loc loss 49.779258728027344\n",
      "cls loss 397.3478698730469  loc loss 25.383874893188477\n",
      "cls loss 598.0267333984375  loc loss 44.653526306152344\n",
      "cls loss 567.3015747070312  loc loss 40.16623306274414\n",
      "cls loss 594.6428833007812  loc loss 35.40435791015625\n",
      "cls loss 474.54595947265625  loc loss 27.964326858520508\n",
      "cls loss 415.65509033203125  loc loss 25.64653778076172\n",
      "cls loss 344.0862731933594  loc loss 13.374576568603516\n",
      "cls loss 435.9676208496094  loc loss 27.99104881286621\n",
      "cls loss 669.7568359375  loc loss 47.03343963623047\n",
      "cls loss 524.3313598632812  loc loss 31.815956115722656\n",
      "cls loss 485.73223876953125  loc loss 35.3675537109375\n",
      "cls loss 540.5680541992188  loc loss 32.277191162109375\n",
      "cls loss 775.3945922851562  loc loss 55.64212417602539\n",
      "cls loss 580.3228149414062  loc loss 42.137657165527344\n",
      "cls loss 658.3999633789062  loc loss 36.78216552734375\n",
      "cls loss 378.46856689453125  loc loss 18.73996353149414\n",
      "cls loss 545.7693481445312  loc loss 34.409576416015625\n",
      "cls loss 504.8799743652344  loc loss 29.343992233276367\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 5., 5., 5., 5., 5., 5.])\n",
      "cls loss 349.4469909667969  loc loss 23.48601531982422\n",
      "cls loss 438.89385986328125  loc loss 23.90704345703125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([13.])\n",
      "cls loss 305.79046630859375  loc loss 17.973966598510742\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([44., 10.,  1.,  1.,  1.])\n",
      "cls loss 296.3710021972656  loc loss 18.57950210571289\n",
      "cls loss 572.7357788085938  loc loss 28.39457130432129\n",
      "cls loss 472.34466552734375  loc loss 26.443458557128906\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19., 19., 19., 19., 19., 19., 19.])\n",
      "cls loss 575.9585571289062  loc loss 29.942241668701172\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([56.])\n",
      "cls loss 1002.2778930664062  loc loss 65.62998962402344\n",
      "cls loss 618.2457885742188  loc loss 47.00759506225586\n",
      "cls loss 789.3154296875  loc loss 53.61697006225586\n",
      "cls loss 774.3231201171875  loc loss 58.64541244506836\n",
      "cls loss 496.6899108886719  loc loss 26.841787338256836\n",
      "cls loss 779.0010986328125  loc loss 52.61614227294922\n",
      "cls loss 447.4384765625  loc loss 29.095985412597656\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 36.])\n",
      "cls loss 539.9580078125  loc loss 28.96627426147461\n",
      "cls loss 490.12103271484375  loc loss 32.13240432739258\n",
      "cls loss 460.380859375  loc loss 27.681291580200195\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5.])\n",
      "cls loss 557.0946044921875  loc loss 33.120445251464844\n",
      "cls loss 290.8148193359375  loc loss 15.52798080444336\n",
      "cls loss 701.2064208984375  loc loss 37.35539627075195\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "cls loss 596.90283203125  loc loss 38.65113830566406\n",
      "cls loss 572.334716796875  loc loss 38.87696075439453\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 557.9854736328125  loc loss 39.429283142089844\n",
      "cls loss 649.130615234375  loc loss 45.44966125488281\n",
      "cls loss 545.9468383789062  loc loss 48.559844970703125\n",
      "cls loss 394.69305419921875  loc loss 26.938175201416016\n",
      "cls loss 463.6331787109375  loc loss 33.93193435668945\n",
      "cls loss 495.6675109863281  loc loss 30.896089553833008\n",
      "cls loss 764.1748046875  loc loss 41.933937072753906\n",
      "cls loss 347.31280517578125  loc loss 16.963193893432617\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 11., 15., 10., 10., 10., 10., 10.])\n",
      "cls loss 825.58740234375  loc loss 48.915069580078125\n",
      "cls loss 437.68084716796875  loc loss 31.594621658325195\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3.])\n",
      "cls loss 487.29132080078125  loc loss 32.69248580932617\n",
      "cls loss 456.20703125  loc loss 24.276586532592773\n",
      "cls loss 484.0309143066406  loc loss 23.477828979492188\n",
      "cls loss 620.6430053710938  loc loss 28.73101043701172\n",
      "cls loss 331.4594421386719  loc loss 15.698237419128418\n",
      "cls loss 485.18231201171875  loc loss 31.861101150512695\n",
      "cls loss 546.301025390625  loc loss 38.58353042602539\n",
      "cls loss 456.3076171875  loc loss 33.742408752441406\n",
      "cls loss 1079.07080078125  loc loss 76.28043365478516\n",
      "cls loss 752.29150390625  loc loss 48.24443817138672\n",
      "cls loss 492.5595703125  loc loss 34.15033721923828\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  9.,  9.,  9.,  6.,  6., 85., 85.,  8.,  1.,  1.,  1.,  1.,\n",
      "         6.,  6.])\n",
      "cls loss 325.80523681640625  loc loss 25.80130958557129\n",
      "cls loss 792.56689453125  loc loss 56.03651428222656\n",
      "cls loss 956.8345336914062  loc loss 58.25410079956055\n",
      "cls loss 644.243896484375  loc loss 43.25829315185547\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10.,  3.,  3., 10.])\n",
      "cls loss 440.86328125  loc loss 22.728368759155273\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([7.])\n",
      "cls loss 526.8009033203125  loc loss 34.60681915283203\n",
      "cls loss 542.9161376953125  loc loss 32.38385772705078\n",
      "cls loss 488.2618408203125  loc loss 40.83049774169922\n",
      "cls loss 704.8538818359375  loc loss 57.187599182128906\n",
      "cls loss 486.2181396484375  loc loss 33.25111770629883\n",
      "cls loss 692.776611328125  loc loss 44.54971694946289\n",
      "cls loss 860.6256103515625  loc loss 50.70233154296875\n",
      "cls loss 510.9510803222656  loc loss 34.92488098144531\n",
      "cls loss 559.6153564453125  loc loss 39.593727111816406\n",
      "cls loss 462.70947265625  loc loss 33.9966926574707\n",
      "cls loss 682.7545166015625  loc loss 53.21326446533203\n",
      "cls loss 537.2757568359375  loc loss 33.37055969238281\n",
      "cls loss 433.31231689453125  loc loss 25.363780975341797\n",
      "cls loss 659.6195068359375  loc loss 49.42094421386719\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([62.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([62.])\n",
      "cls loss 309.267578125  loc loss 14.829874038696289\n",
      "cls loss 508.29949951171875  loc loss 35.560787200927734\n",
      "cls loss 504.6614990234375  loc loss 32.21826171875\n",
      "cls loss 343.125  loc loss 15.727779388427734\n",
      "cls loss 642.988525390625  loc loss 42.055625915527344\n",
      "cls loss 680.0054931640625  loc loss 36.755271911621094\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([28.])\n",
      "cls loss 743.2364501953125  loc loss 38.512786865234375\n",
      "cls loss 633.2039794921875  loc loss 38.25498962402344\n",
      "cls loss 630.0958251953125  loc loss 41.2438850402832\n",
      "cls loss 632.680419921875  loc loss 39.946624755859375\n",
      "cls loss 873.30224609375  loc loss 58.003082275390625\n",
      "cls loss 495.91363525390625  loc loss 30.76267433166504\n",
      "cls loss 627.012451171875  loc loss 37.158233642578125\n",
      "cls loss 531.0186767578125  loc loss 43.75724411010742\n",
      "cls loss 868.87451171875  loc loss 67.97579956054688\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([81.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 603.4627685546875  loc loss 24.534420013427734\n",
      "cls loss 446.7948913574219  loc loss 23.45546531677246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 360.85614013671875  loc loss 24.580923080444336\n",
      "cls loss 318.6159973144531  loc loss 12.088897705078125\n",
      "cls loss 356.96392822265625  loc loss 24.696733474731445\n",
      "cls loss 397.5135498046875  loc loss 24.66124725341797\n",
      "cls loss 469.05328369140625  loc loss 28.939170837402344\n",
      "cls loss 619.5540161132812  loc loss 48.545021057128906\n",
      "cls loss 695.6195068359375  loc loss 44.74836730957031\n",
      "cls loss 1273.6177978515625  loc loss 84.22962951660156\n",
      "cls loss 514.3596801757812  loc loss 26.596691131591797\n",
      "cls loss 624.8712158203125  loc loss 44.060569763183594\n",
      "cls loss 443.6175537109375  loc loss 27.471200942993164\n",
      "cls loss 586.4558715820312  loc loss 32.906681060791016\n",
      "cls loss 503.06658935546875  loc loss 28.71602439880371\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([44., 44.])\n",
      "cls loss 464.45477294921875  loc loss 22.173418045043945\n",
      "cls loss 483.33673095703125  loc loss 32.16773986816406\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15.])\n",
      "cls loss 534.03955078125  loc loss 26.056167602539062\n",
      "cls loss 262.47540283203125  loc loss 15.257476806640625\n",
      "cls loss 534.1798095703125  loc loss 31.252723693847656\n",
      "cls loss 299.6781005859375  loc loss 17.56184959411621\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([1., 3., 3.])\n",
      "cls loss 342.447021484375  loc loss 24.19721794128418\n",
      "cls loss 272.03509521484375  loc loss 11.878183364868164\n",
      "cls loss 509.0185241699219  loc loss 29.803239822387695\n",
      "cls loss 548.099609375  loc loss 31.729116439819336\n",
      "cls loss 493.5474548339844  loc loss 32.48505783081055\n",
      "cls loss 482.7518615722656  loc loss 26.911846160888672\n",
      "cls loss 406.6387634277344  loc loss 31.028684616088867\n",
      "cls loss 570.76513671875  loc loss 36.446144104003906\n",
      "cls loss 408.664794921875  loc loss 27.497058868408203\n",
      "cls loss 539.8892822265625  loc loss 37.33906173706055\n",
      "cls loss 352.21551513671875  loc loss 20.3632755279541\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 644.468505859375  loc loss 39.07996368408203\n",
      "cls loss 757.9127197265625  loc loss 35.31144332885742\n",
      "cls loss 652.3702392578125  loc loss 45.325775146484375\n",
      "cls loss 656.797607421875  loc loss 50.29777145385742\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10., 10., 10.,  1.,  1.,  1.,  1.,  1.,  1.,  8.,  8.,\n",
      "         1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10., 10., 10.,  1.,  1.,  1.,  1.,  1.,  1.,  8.,  8.,\n",
      "         1.])\n",
      "cls loss 598.744384765625  loc loss 27.90714454650879\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 3., 3., 3.])\n",
      "cls loss 511.5196838378906  loc loss 31.680410385131836\n",
      "cls loss 364.3124084472656  loc loss 20.226099014282227\n",
      "cls loss 280.26824951171875  loc loss 13.350869178771973\n",
      "cls loss 477.7441711425781  loc loss 35.934444427490234\n",
      "cls loss 371.01605224609375  loc loss 18.388824462890625\n",
      "cls loss 431.72515869140625  loc loss 28.295703887939453\n",
      "cls loss 484.6952209472656  loc loss 32.67947006225586\n",
      "cls loss 681.06396484375  loc loss 46.25632095336914\n",
      "cls loss 573.0679321289062  loc loss 27.93906021118164\n",
      "cls loss 553.658203125  loc loss 30.361865997314453\n",
      "cls loss 599.630126953125  loc loss 40.35108947753906\n",
      "cls loss 426.2383117675781  loc loss 32.717586517333984\n",
      "cls loss 802.4813232421875  loc loss 59.92816162109375\n",
      "cls loss 399.288818359375  loc loss 20.11640739440918\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 625.7919921875  loc loss 38.27173614501953\n",
      "cls loss 307.54046630859375  loc loss 12.551711082458496\n",
      "cls loss 760.8025512695312  loc loss 47.246421813964844\n",
      "cls loss 388.9813537597656  loc loss 21.707733154296875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 34.])\n",
      "cls loss 647.2635498046875  loc loss 33.4334831237793\n",
      "cls loss 305.64154052734375  loc loss 19.498132705688477\n",
      "cls loss 576.8143310546875  loc loss 37.34517288208008\n",
      "cls loss 196.33200073242188  loc loss 14.66814136505127\n",
      "cls loss 493.77581787109375  loc loss 31.0025634765625\n",
      "cls loss 478.4520568847656  loc loss 38.96160125732422\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 38.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16., 16., 16.,  9.,  9.,  9., 16., 16., 16., 85.,  9.])\n",
      "cls loss 483.8415832519531  loc loss 31.946144104003906\n",
      "cls loss 552.8218994140625  loc loss 42.53818130493164\n",
      "cls loss 739.70947265625  loc loss 49.89684295654297\n",
      "cls loss 1082.2861328125  loc loss 71.06756591796875\n",
      "cls loss 333.0047302246094  loc loss 17.249826431274414\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3., 10.,  8.,  8., 10., 10., 10.,  3.,  3., 14.])\n",
      "cls loss 393.5025634765625  loc loss 18.94979476928711\n",
      "cls loss 718.073974609375  loc loss 36.66869354248047\n",
      "cls loss 312.1380615234375  loc loss 11.146148681640625\n",
      "cls loss 465.9959716796875  loc loss 19.767131805419922\n",
      "cls loss 613.1845703125  loc loss 36.00353240966797\n",
      "cls loss 524.2265625  loc loss 32.534461975097656\n",
      "cls loss 296.2486877441406  loc loss 15.374195098876953\n",
      "cls loss 339.9699401855469  loc loss 20.882732391357422\n",
      "cls loss 533.0474243164062  loc loss 33.30615234375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42., 42.,  1.])\n",
      "cls loss 521.3699951171875  loc loss 35.85163879394531\n",
      "cls loss 415.77069091796875  loc loss 24.6654052734375\n",
      "cls loss 562.3970336914062  loc loss 43.47612380981445\n",
      "cls loss 674.1029052734375  loc loss 41.21371841430664\n",
      "cls loss 453.8148193359375  loc loss 29.229490280151367\n",
      "cls loss 562.569580078125  loc loss 39.890380859375\n",
      "cls loss 366.68634033203125  loc loss 24.460060119628906\n",
      "cls loss 380.63934326171875  loc loss 26.413394927978516\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20.])\n",
      "cls loss 293.82806396484375  loc loss 16.797361373901367\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([11.])\n",
      "cls loss 383.03668212890625  loc loss 18.911373138427734\n",
      "cls loss 261.46685791015625  loc loss 13.95371150970459\n",
      "cls loss 586.525634765625  loc loss 44.968387603759766\n",
      "cls loss 273.5140380859375  loc loss 12.292472839355469\n",
      "cls loss 578.86572265625  loc loss 31.06769371032715\n",
      "cls loss 314.82958984375  loc loss 19.440364837646484\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 35., 27.])\n",
      "cls loss 527.8377685546875  loc loss 31.834638595581055\n",
      "cls loss 577.669189453125  loc loss 42.711727142333984\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 391.50177001953125  loc loss 23.09450912475586\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([42.,  1.])\n",
      "cls loss 500.39752197265625  loc loss 34.712677001953125\n",
      "cls loss 473.72686767578125  loc loss 26.916513442993164\n",
      "cls loss 573.0946044921875  loc loss 35.09196090698242\n",
      "cls loss 710.4071044921875  loc loss 45.3492546081543\n",
      "cls loss 638.29052734375  loc loss 37.726531982421875\n",
      "cls loss 432.3458251953125  loc loss 31.575836181640625\n",
      "cls loss 371.20465087890625  loc loss 27.916078567504883\n",
      "cls loss 240.94512939453125  loc loss 11.077779769897461\n",
      "cls loss 437.6866455078125  loc loss 23.869213104248047\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 1., 1.])\n",
      "cls loss 426.21002197265625  loc loss 23.736352920532227\n",
      "cls loss 476.1745910644531  loc loss 31.127262115478516\n",
      "cls loss 467.9979248046875  loc loss 29.424123764038086\n",
      "cls loss 387.02679443359375  loc loss 27.038612365722656\n",
      "cls loss 468.11224365234375  loc loss 27.83761215209961\n",
      "cls loss 493.2652282714844  loc loss 35.69066619873047\n",
      "cls loss 678.5068359375  loc loss 40.90464401245117\n",
      "cls loss 579.9752197265625  loc loss 44.21513366699219\n",
      "cls loss 546.4326782226562  loc loss 32.72101593017578\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 429.1080627441406  loc loss 28.915029525756836\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 512.3295288085938  loc loss 25.014663696289062\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([81.])\n",
      "cls loss 615.9058837890625  loc loss 37.14267349243164\n",
      "cls loss 388.6075439453125  loc loss 26.033905029296875\n",
      "cls loss 277.3310241699219  loc loss 15.633567810058594\n",
      "cls loss 436.489990234375  loc loss 22.871990203857422\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3.,  1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 19.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 19.])\n",
      "cls loss 557.7890014648438  loc loss 38.97343826293945\n",
      "cls loss 333.1695556640625  loc loss 17.440841674804688\n",
      "cls loss 349.164794921875  loc loss 19.89669418334961\n",
      "cls loss 661.422119140625  loc loss 48.17289733886719\n",
      "cls loss 337.53778076171875  loc loss 20.950164794921875\n",
      "cls loss 419.64093017578125  loc loss 27.74126434326172\n",
      "cls loss 516.9390869140625  loc loss 33.996620178222656\n",
      "cls loss 410.9756774902344  loc loss 28.796480178833008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 525.7371826171875  loc loss 30.334074020385742\n",
      "cls loss 598.5089721679688  loc loss 40.28990173339844\n",
      "cls loss 721.74169921875  loc loss 63.937339782714844\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 81.])\n",
      "cls loss 528.7706298828125  loc loss 27.355655670166016\n",
      "cls loss 445.9764404296875  loc loss 25.268280029296875\n",
      "cls loss 510.3498229980469  loc loss 26.82108497619629\n",
      "cls loss 387.7159423828125  loc loss 19.19095230102539\n",
      "cls loss 343.01483154296875  loc loss 21.68189811706543\n",
      "cls loss 375.7557373046875  loc loss 29.251428604125977\n",
      "cls loss 314.68572998046875  loc loss 22.282928466796875\n",
      "cls loss 256.35699462890625  loc loss 16.5653133392334\n",
      "cls loss 344.7384033203125  loc loss 22.397111892700195\n",
      "cls loss 471.9607238769531  loc loss 28.687639236450195\n",
      "cls loss 394.4571533203125  loc loss 31.174583435058594\n",
      "cls loss 415.794677734375  loc loss 32.24874496459961\n",
      "cls loss 255.5755615234375  loc loss 17.84649658203125\n",
      "cls loss 863.3799438476562  loc loss 60.7133674621582\n",
      "cls loss 539.0094604492188  loc loss 35.760467529296875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 467.52423095703125  loc loss 23.95975112915039\n",
      "cls loss 516.4481201171875  loc loss 34.09016036987305\n",
      "cls loss 407.8736267089844  loc loss 24.884666442871094\n",
      "cls loss 604.934814453125  loc loss 39.8565788269043\n",
      "cls loss 579.8429565429688  loc loss 36.06257247924805\n",
      "cls loss 529.819580078125  loc loss 32.27778625488281\n",
      "cls loss 415.80328369140625  loc loss 24.854297637939453\n",
      "cls loss 313.8785705566406  loc loss 19.70145034790039\n",
      "cls loss 480.5247497558594  loc loss 28.14055633544922\n",
      "cls loss 514.1697387695312  loc loss 34.449363708496094\n",
      "cls loss 539.3316650390625  loc loss 29.8863582611084\n",
      "cls loss 671.4578857421875  loc loss 48.69637680053711\n",
      "cls loss 666.3818359375  loc loss 53.98289489746094\n",
      "cls loss 482.7355651855469  loc loss 34.758583068847656\n",
      "cls loss 661.0390625  loc loss 51.85158157348633\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1., 38., 47.,  1.,  1.,  1.,  1.,  1., 62.])\n",
      "cls loss 472.1673889160156  loc loss 22.868741989135742\n",
      "cls loss 565.8865356445312  loc loss 33.08002471923828\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 597.3220825195312  loc loss 34.396385192871094\n",
      "cls loss 625.904541015625  loc loss 46.48773193359375\n",
      "cls loss 434.8531494140625  loc loss 21.692493438720703\n",
      "cls loss 499.8564147949219  loc loss 40.58554458618164\n",
      "cls loss 464.25640869140625  loc loss 27.222923278808594\n",
      "cls loss 272.5878601074219  loc loss 10.733551025390625\n",
      "cls loss 431.40069580078125  loc loss 24.753799438476562\n",
      "cls loss 374.42645263671875  loc loss 16.705642700195312\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1., 35.])\n",
      "cls loss 427.5064392089844  loc loss 22.449508666992188\n",
      "cls loss 610.2625122070312  loc loss 32.52627944946289\n",
      "cls loss 597.656005859375  loc loss 38.92937088012695\n",
      "cls loss 526.6312255859375  loc loss 43.59741973876953\n",
      "cls loss 436.7841491699219  loc loss 33.95277786254883\n",
      "cls loss 577.5689086914062  loc loss 42.89909744262695\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 323.8150634765625  loc loss 18.564111709594727\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 468.7001647949219  loc loss 21.078678131103516\n",
      "cls loss 755.732666015625  loc loss 39.35188293457031\n",
      "cls loss 899.2181396484375  loc loss 69.25546264648438\n",
      "cls loss 459.73114013671875  loc loss 23.714502334594727\n",
      "cls loss 408.670654296875  loc loss 25.936861038208008\n",
      "cls loss 408.1524658203125  loc loss 21.9025821685791\n",
      "cls loss 424.0943908691406  loc loss 26.689455032348633\n",
      "cls loss 385.8692932128906  loc loss 16.835296630859375\n",
      "cls loss 680.0276489257812  loc loss 46.826473236083984\n",
      "cls loss 563.7229614257812  loc loss 34.76344299316406\n",
      "cls loss 303.0644836425781  loc loss 20.051597595214844\n",
      "cls loss 553.5469360351562  loc loss 30.348148345947266\n",
      "cls loss 656.057861328125  loc loss 52.741512298583984\n",
      "cls loss 547.7437744140625  loc loss 34.67409896850586\n",
      "cls loss 472.9244079589844  loc loss 26.080984115600586\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.])\n",
      "cls loss 450.61248779296875  loc loss 32.41694259643555\n",
      "cls loss 431.57794189453125  loc loss 30.669435501098633\n",
      "cls loss 562.0831298828125  loc loss 37.69611358642578\n",
      "cls loss 876.7918090820312  loc loss 69.39798736572266\n",
      "cls loss 375.7013244628906  loc loss 18.37505340576172\n",
      "cls loss 491.6436462402344  loc loss 30.058429718017578\n",
      "cls loss 392.3875732421875  loc loss 21.310604095458984\n",
      "cls loss 425.533935546875  loc loss 26.50514793395996\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 21., 21., 21.])\n",
      "cls loss 448.0072937011719  loc loss 26.968355178833008\n",
      "cls loss 413.634521484375  loc loss 20.1346378326416\n",
      "cls loss 449.0347900390625  loc loss 29.553672790527344\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 35.])\n",
      "cls loss 576.632080078125  loc loss 36.08574676513672\n",
      "cls loss 211.339599609375  loc loss 11.702154159545898\n",
      "cls loss 359.11309814453125  loc loss 23.720794677734375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 345.9024963378906  loc loss 15.699040412902832\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 38., 38.,  9., 38.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1.,  1.])\n",
      "cls loss 392.08758544921875  loc loss 25.454126358032227\n",
      "cls loss 659.4219970703125  loc loss 41.150455474853516\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 2.,  1., 77., 31., 10., 10.,  1.,  4., 10.])\n",
      "cls loss 333.70965576171875  loc loss 15.688299179077148\n",
      "cls loss 618.2440185546875  loc loss 35.620269775390625\n",
      "cls loss 1230.0296630859375  loc loss 70.3474349975586\n",
      "cls loss 381.74249267578125  loc loss 25.610599517822266\n",
      "cls loss 551.8173828125  loc loss 39.93014907836914\n",
      "cls loss 406.89794921875  loc loss 20.619430541992188\n",
      "cls loss 403.20086669921875  loc loss 19.19583511352539\n",
      "cls loss 574.0305786132812  loc loss 27.929838180541992\n",
      "cls loss 587.461669921875  loc loss 30.653270721435547\n",
      "cls loss 515.8118896484375  loc loss 35.3887825012207\n",
      "cls loss 404.3519592285156  loc loss 19.292827606201172\n",
      "cls loss 426.3276062011719  loc loss 22.377239227294922\n",
      "cls loss 790.6874389648438  loc loss 48.244380950927734\n",
      "cls loss 680.2630615234375  loc loss 40.806400299072266\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1., 42., 42., 42., 42., 42., 42.,  1.,\n",
      "         1.,  1.,  1., 42.,  1.,  1., 42.,  1.])\n",
      "cls loss 374.65692138671875  loc loss 26.37961769104004\n",
      "cls loss 582.6759033203125  loc loss 34.782779693603516\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.])\n",
      "cls loss 249.84933471679688  loc loss 14.607211112976074\n",
      "cls loss 578.6124267578125  loc loss 36.948387145996094\n",
      "cls loss 451.30694580078125  loc loss 31.922109603881836\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([11.])\n",
      "cls loss 280.3681640625  loc loss 16.129119873046875\n",
      "cls loss 343.60723876953125  loc loss 16.075942993164062\n",
      "cls loss 359.81158447265625  loc loss 16.007009506225586\n",
      "cls loss 582.613037109375  loc loss 35.74144744873047\n",
      "cls loss 503.99139404296875  loc loss 27.307981491088867\n",
      "cls loss 489.4704895019531  loc loss 32.9525146484375\n",
      "cls loss 723.2410888671875  loc loss 36.89581298828125\n",
      "cls loss 360.306396484375  loc loss 21.232568740844727\n",
      "cls loss 733.1987915039062  loc loss 50.566104888916016\n",
      "cls loss 358.772216796875  loc loss 23.072715759277344\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 339.3348388671875  loc loss 22.753829956054688\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1., 38., 38., 42.])\n",
      "cls loss 432.661865234375  loc loss 31.386220932006836\n",
      "cls loss 404.75628662109375  loc loss 23.579622268676758\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 357.28997802734375  loc loss 25.256305694580078\n",
      "cls loss 816.4588623046875  loc loss 55.38234329223633\n",
      "cls loss 498.07513427734375  loc loss 31.89651107788086\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10.,  3.,  3.,  6.,  8.,  8.,  1.,  1.,  1., 10.])\n",
      "cls loss 415.94610595703125  loc loss 21.03171157836914\n",
      "cls loss 259.47607421875  loc loss 9.578163146972656\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10.,  3.])\n",
      "cls loss 384.09039306640625  loc loss 21.867372512817383\n",
      "cls loss 216.01126098632812  loc loss 11.72742748260498\n",
      "cls loss 487.5257568359375  loc loss 33.782615661621094\n",
      "cls loss 568.447265625  loc loss 35.641971588134766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 411.78009033203125  loc loss 24.203567504882812\n",
      "cls loss 296.3079833984375  loc loss 14.447280883789062\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 34.])\n",
      "cls loss 673.1171875  loc loss 41.970523834228516\n",
      "cls loss 729.720703125  loc loss 60.14673614501953\n",
      "cls loss 462.74169921875  loc loss 34.521766662597656\n",
      "cls loss 370.8326721191406  loc loss 25.70889663696289\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.,  1.])\n",
      "cls loss 413.22076416015625  loc loss 19.453920364379883\n",
      "cls loss 636.4047241210938  loc loss 48.662715911865234\n",
      "cls loss 937.9638061523438  loc loss 61.70365905761719\n",
      "cls loss 789.73876953125  loc loss 41.159645080566406\n",
      "cls loss 474.1114501953125  loc loss 24.68758773803711\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 561.193603515625  loc loss 31.8392391204834\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10.])\n",
      "cls loss 347.986572265625  loc loss 18.00231170654297\n",
      "cls loss 509.939697265625  loc loss 25.06706428527832\n",
      "cls loss 460.2789306640625  loc loss 28.948747634887695\n",
      "cls loss 340.800537109375  loc loss 19.880401611328125\n",
      "cls loss 440.1787109375  loc loss 28.386865615844727\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21.,\n",
      "        21.])\n",
      "cls loss 594.881591796875  loc loss 33.14131164550781\n",
      "cls loss 459.13372802734375  loc loss 27.71723747253418\n",
      "cls loss 304.7864074707031  loc loss 13.94450855255127\n",
      "cls loss 645.063720703125  loc loss 41.526084899902344\n",
      "cls loss 493.6327819824219  loc loss 32.379310607910156\n",
      "cls loss 355.3821105957031  loc loss 19.18270492553711\n",
      "cls loss 720.881103515625  loc loss 46.263893127441406\n",
      "cls loss 865.221923828125  loc loss 59.64208984375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15., 85.])\n",
      "cls loss 541.40673828125  loc loss 34.586124420166016\n",
      "cls loss 557.818359375  loc loss 41.17045593261719\n",
      "cls loss 575.1451416015625  loc loss 41.048545837402344\n",
      "cls loss 506.6150817871094  loc loss 28.20549201965332\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 8., 8.])\n",
      "cls loss 327.8747863769531  loc loss 15.29981517791748\n",
      "cls loss 344.99346923828125  loc loss 24.842056274414062\n",
      "cls loss 435.7620544433594  loc loss 26.67236328125\n",
      "cls loss 360.8969421386719  loc loss 19.984573364257812\n",
      "cls loss 406.4332275390625  loc loss 24.09693145751953\n",
      "cls loss 562.31591796875  loc loss 34.220558166503906\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1., 35., 27., 27.,  1., 27.,  1.])\n",
      "cls loss 702.03662109375  loc loss 50.624271392822266\n",
      "cls loss 381.20452880859375  loc loss 23.39339828491211\n",
      "cls loss 427.66015625  loc loss 31.087854385375977\n",
      "cls loss 404.3142395019531  loc loss 35.74469757080078\n",
      "cls loss 366.410400390625  loc loss 27.871313095092773\n",
      "cls loss 404.7144775390625  loc loss 31.371198654174805\n",
      "cls loss 409.83111572265625  loc loss 31.787694931030273\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  2.,  2.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  2.,  2.])\n",
      "cls loss 224.8852996826172  loc loss 8.906848907470703\n",
      "cls loss 656.9940185546875  loc loss 40.19815444946289\n",
      "cls loss 449.9720764160156  loc loss 20.383054733276367\n",
      "cls loss 718.4677124023438  loc loss 52.249881744384766\n",
      "cls loss 297.8356628417969  loc loss 16.77718734741211\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 19., 19., 19., 16.])\n",
      "cls loss 313.77227783203125  loc loss 13.249714851379395\n",
      "cls loss 249.01913452148438  loc loss 10.185635566711426\n",
      "cls loss 400.5922546386719  loc loss 20.036245346069336\n",
      "cls loss 521.1890258789062  loc loss 33.81829833984375\n",
      "cls loss 247.8552703857422  loc loss 17.292816162109375\n",
      "cls loss 580.812744140625  loc loss 44.160682678222656\n",
      "cls loss 411.9878845214844  loc loss 27.99431800842285\n",
      "cls loss 453.11669921875  loc loss 29.056652069091797\n",
      "cls loss 579.379638671875  loc loss 38.95912170410156\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 614.8631591796875  loc loss 27.604398727416992\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 811.08740234375  loc loss 69.02465057373047\n",
      "cls loss 1040.06787109375  loc loss 95.3101806640625\n",
      "cls loss 543.8519287109375  loc loss 32.5042839050293\n",
      "cls loss 480.41839599609375  loc loss 30.309520721435547\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3.,  3.,  3.,  3.,  3., 10.])\n",
      "cls loss 253.92947387695312  loc loss 15.433538436889648\n",
      "cls loss 517.498291015625  loc loss 24.650108337402344\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 1., 1., 1., 3., 3., 3., 3.])\n",
      "cls loss 391.20159912109375  loc loss 22.958322525024414\n",
      "cls loss 756.3522338867188  loc loss 47.863677978515625\n",
      "cls loss 588.7540283203125  loc loss 37.927581787109375\n",
      "cls loss 382.90301513671875  loc loss 22.570911407470703\n",
      "cls loss 600.34423828125  loc loss 40.861690521240234\n",
      "cls loss 367.54473876953125  loc loss 27.050085067749023\n",
      "cls loss 589.09716796875  loc loss 40.620452880859375\n",
      "cls loss 430.9116516113281  loc loss 40.885597229003906\n",
      "cls loss 462.55364990234375  loc loss 28.383338928222656\n",
      "cls loss 915.377197265625  loc loss 75.11433410644531\n",
      "cls loss 614.9920654296875  loc loss 44.12881851196289\n",
      "cls loss 424.63592529296875  loc loss 20.397594451904297\n",
      "cls loss 279.1339111328125  loc loss 11.942232131958008\n",
      "cls loss 328.10858154296875  loc loss 15.343374252319336\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3., 10., 10., 10., 10., 10., 10., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10., 10., 10., 10., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 11., 10., 10., 10., 10., 10.,  3.,  3.,  3.,  3.,  3.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 11., 10., 10., 10., 10., 10.,  3.,  3.,  3.,  3.,  3.])\n",
      "cls loss 295.1455993652344  loc loss 13.32809066772461\n",
      "cls loss 366.09033203125  loc loss 16.69609260559082\n",
      "cls loss 305.6614685058594  loc loss 17.8947811126709\n",
      "cls loss 320.6723327636719  loc loss 13.855826377868652\n",
      "cls loss 370.55401611328125  loc loss 28.81951904296875\n",
      "cls loss 296.7186279296875  loc loss 11.449057579040527\n",
      "cls loss 562.102783203125  loc loss 37.674686431884766\n",
      "cls loss 480.890869140625  loc loss 32.5264892578125\n",
      "cls loss 749.2078247070312  loc loss 46.40186309814453\n",
      "cls loss 374.1593017578125  loc loss 26.60171890258789\n",
      "cls loss 668.0513916015625  loc loss 43.05262756347656\n",
      "cls loss 534.9628295898438  loc loss 35.38007354736328\n",
      "cls loss 502.24298095703125  loc loss 32.984764099121094\n",
      "cls loss 496.8009948730469  loc loss 35.32160186767578\n",
      "cls loss 672.0722045898438  loc loss 44.96136474609375\n",
      "cls loss 687.5821533203125  loc loss 41.16075897216797\n",
      "cls loss 324.52020263671875  loc loss 17.111164093017578\n",
      "cls loss 604.48486328125  loc loss 42.64158248901367\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 10.,  1., 18.])\n",
      "cls loss 295.4574890136719  loc loss 19.31157875061035\n",
      "cls loss 374.1999816894531  loc loss 14.966066360473633\n",
      "cls loss 621.8232421875  loc loss 31.908653259277344\n",
      "cls loss 848.312255859375  loc loss 48.492149353027344\n",
      "cls loss 491.4584045410156  loc loss 34.391685485839844\n",
      "cls loss 712.1406860351562  loc loss 36.8916130065918\n",
      "cls loss 509.71002197265625  loc loss 34.175418853759766\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.,  1.,  1.])\n",
      "cls loss 625.9934692382812  loc loss 40.096134185791016\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1., 38.,  1.])\n",
      "cls loss 572.4166259765625  loc loss 32.32394027709961\n",
      "cls loss 762.393310546875  loc loss 56.30169677734375\n",
      "cls loss 420.38775634765625  loc loss 28.13756561279297\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 558.84619140625  loc loss 35.79043197631836\n",
      "cls loss 478.7973327636719  loc loss 29.200298309326172\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3., 10.,  8.,  3., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.])\n",
      "cls loss 556.2666015625  loc loss 31.49949836730957\n",
      "cls loss 383.4884948730469  loc loss 24.371326446533203\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3.,  3., 11.,  3., 10., 10.,  3.,  3., 10.])\n",
      "cls loss 455.69427490234375  loc loss 22.07537841796875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3., 10., 10., 10.])\n",
      "cls loss 460.51568603515625  loc loss 28.142913818359375\n",
      "cls loss 398.2962341308594  loc loss 22.14702033996582\n",
      "cls loss 488.80450439453125  loc loss 31.628170013427734\n",
      "cls loss 716.5978393554688  loc loss 40.761878967285156\n",
      "cls loss 474.03448486328125  loc loss 28.899375915527344\n",
      "cls loss 354.6017761230469  loc loss 28.767654418945312\n",
      "cls loss 464.97869873046875  loc loss 29.506364822387695\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 9.,  9., 85., 85.])\n",
      "cls loss 362.78509521484375  loc loss 20.241674423217773\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 440.6575012207031  loc loss 32.087379455566406\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 720.271484375  loc loss 49.759700775146484\n",
      "cls loss 626.3663330078125  loc loss 29.575544357299805\n",
      "cls loss 679.9539184570312  loc loss 49.12506866455078\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10., 10., 10., 10.])\n",
      "cls loss 429.9788818359375  loc loss 26.63774299621582\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([13.])\n",
      "cls loss 676.6395263671875  loc loss 53.06444549560547\n",
      "cls loss 235.5459442138672  loc loss 12.292476654052734\n",
      "cls loss 319.11614990234375  loc loss 15.664904594421387\n",
      "cls loss 424.123291015625  loc loss 22.943012237548828\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19.,  1.,  1.,  1., 19., 19.])\n",
      "cls loss 429.7216491699219  loc loss 28.201406478881836\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 345.4617919921875  loc loss 25.125272750854492\n",
      "cls loss 481.7219543457031  loc loss 34.8343505859375\n",
      "cls loss 375.6331481933594  loc loss 20.841629028320312\n",
      "cls loss 545.990966796875  loc loss 28.780479431152344\n",
      "cls loss 571.653076171875  loc loss 43.02540969848633\n",
      "cls loss 462.0819091796875  loc loss 24.843427658081055\n",
      "cls loss 679.6425170898438  loc loss 47.90864562988281\n",
      "cls loss 265.2664794921875  loc loss 11.640411376953125\n",
      "cls loss 500.2704772949219  loc loss 30.25261878967285\n",
      "cls loss 388.0528259277344  loc loss 19.28076934814453\n",
      "cls loss 427.8770751953125  loc loss 22.789600372314453\n",
      "cls loss 539.5136108398438  loc loss 31.789688110351562\n",
      "cls loss 487.384765625  loc loss 23.581018447875977\n",
      "cls loss 678.0308837890625  loc loss 44.199920654296875\n",
      "cls loss 432.449462890625  loc loss 28.078832626342773\n",
      "cls loss 556.4049072265625  loc loss 39.85812759399414\n",
      "cls loss 833.7289428710938  loc loss 50.26491928100586\n",
      "cls loss 429.21795654296875  loc loss 32.261295318603516\n",
      "cls loss 507.06646728515625  loc loss 30.218135833740234\n",
      "cls loss 581.3283081054688  loc loss 45.81954574584961\n",
      "cls loss 665.6478881835938  loc loss 46.73267364501953\n",
      "cls loss 809.9161376953125  loc loss 42.77775573730469\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 5.])\n",
      "cls loss 228.15606689453125  loc loss 9.78329849243164\n",
      "cls loss 298.9434814453125  loc loss 13.329537391662598\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 13.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 6., 8., 8.])\n",
      "cls loss 245.35069274902344  loc loss 13.35988712310791\n",
      "cls loss 333.90533447265625  loc loss 16.441932678222656\n",
      "cls loss 634.396484375  loc loss 41.641021728515625\n",
      "cls loss 283.52392578125  loc loss 14.518471717834473\n",
      "cls loss 496.94940185546875  loc loss 37.63661193847656\n",
      "cls loss 759.0538330078125  loc loss 54.67533874511719\n",
      "cls loss 468.20599365234375  loc loss 33.548553466796875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([42., 42.,  1.,  1.,  1.,  1.,  1.,  1.,  1., 42., 42.])\n",
      "cls loss 531.060546875  loc loss 28.060810089111328\n",
      "cls loss 659.883544921875  loc loss 50.10533905029297\n",
      "cls loss 591.1875610351562  loc loss 41.56950378417969\n",
      "cls loss 386.3272705078125  loc loss 24.511878967285156\n",
      "cls loss 512.2799072265625  loc loss 28.834712982177734\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 719.0383911132812  loc loss 46.46741485595703\n",
      "cls loss 591.176513671875  loc loss 40.17705535888672\n",
      "cls loss 358.8076477050781  loc loss 20.281822204589844\n",
      "cls loss 293.8993225097656  loc loss 17.550251007080078\n",
      "cls loss 419.1299743652344  loc loss 25.062210083007812\n",
      "cls loss 569.9559326171875  loc loss 34.96457290649414\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15.])\n",
      "cls loss 295.18170166015625  loc loss 10.95528793334961\n",
      "cls loss 492.03155517578125  loc loss 30.21710968017578\n",
      "cls loss 421.5122985839844  loc loss 28.10493278503418\n",
      "cls loss 752.936279296875  loc loss 50.660770416259766\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19.,  7.])\n",
      "cls loss 412.7486572265625  loc loss 21.929109573364258\n",
      "cls loss 793.0498657226562  loc loss 52.29487609863281\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 686.6468505859375  loc loss 33.954345703125\n",
      "cls loss 572.925537109375  loc loss 41.04838943481445\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([38., 38.,  1., 18.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1., 18., 18.,  1.])\n",
      "cls loss 427.3908386230469  loc loss 22.02923583984375\n",
      "cls loss 417.7625427246094  loc loss 19.474695205688477\n",
      "cls loss 772.5360107421875  loc loss 53.60686111450195\n",
      "cls loss 578.767578125  loc loss 31.896276473999023\n",
      "cls loss 515.3115234375  loc loss 27.68403434753418\n",
      "cls loss 319.1707458496094  loc loss 24.237520217895508\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.])\n",
      "cls loss 230.13150024414062  loc loss 8.734256744384766\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([32.])\n",
      "cls loss 492.01617431640625  loc loss 26.219825744628906\n",
      "cls loss 417.63238525390625  loc loss 29.504287719726562\n",
      "cls loss 541.2296752929688  loc loss 42.06055450439453\n",
      "cls loss 472.2888488769531  loc loss 31.258533477783203\n",
      "cls loss 393.5827941894531  loc loss 24.4700927734375\n",
      "cls loss 649.7635498046875  loc loss 38.63572311401367\n",
      "cls loss 717.6962890625  loc loss 47.52362060546875\n",
      "cls loss 552.71728515625  loc loss 36.17344665527344\n",
      "cls loss 449.3897705078125  loc loss 25.992298126220703\n",
      "cls loss 706.9176025390625  loc loss 44.85962677001953\n",
      "cls loss 477.01641845703125  loc loss 24.37184715270996\n",
      "cls loss 788.7269897460938  loc loss 53.85942459106445\n",
      "cls loss 544.3284912109375  loc loss 29.862375259399414\n",
      "cls loss 447.35302734375  loc loss 33.407962799072266\n",
      "cls loss 340.58355712890625  loc loss 15.896418571472168\n",
      "cls loss 384.8023681640625  loc loss 23.48050308227539\n",
      "cls loss 570.4498291015625  loc loss 36.63486862182617\n",
      "cls loss 604.3140869140625  loc loss 40.68799591064453\n",
      "cls loss 344.35296630859375  loc loss 21.07991600036621\n",
      "cls loss 620.9774780273438  loc loss 41.06367492675781\n",
      "cls loss 748.5648193359375  loc loss 45.916831970214844\n",
      "cls loss 272.6236877441406  loc loss 17.80141830444336\n",
      "cls loss 724.7283935546875  loc loss 47.969764709472656\n",
      "cls loss 528.8265380859375  loc loss 38.07019805908203\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 709.6222534179688  loc loss 53.431556701660156\n",
      "cls loss 342.1466369628906  loc loss 12.713579177856445\n",
      "cls loss 503.0019836425781  loc loss 27.44538116455078\n",
      "cls loss 500.31732177734375  loc loss 32.928565979003906\n",
      "cls loss 413.1737365722656  loc loss 23.17137336730957\n",
      "cls loss 255.51138305664062  loc loss 12.793170928955078\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 9., 9., 1., 9., 9., 9., 9., 1., 9.])\n",
      "cls loss 902.220703125  loc loss 70.95960998535156\n",
      "cls loss 535.0795288085938  loc loss 27.405105590820312\n",
      "cls loss 765.67431640625  loc loss 61.31334686279297\n",
      "cls loss 328.15252685546875  loc loss 22.923795700073242\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 42., 42.])\n",
      "cls loss 552.3721313476562  loc loss 40.98817443847656\n",
      "cls loss 594.439697265625  loc loss 43.67643356323242\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  2.,  1.,  1.,  1., 38.,\n",
      "         1.,  1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 38., 38., 38.,  1., 38., 38., 38.,  1.,  1., 38.,  1.,\n",
      "         1.])\n",
      "cls loss 361.44415283203125  loc loss 26.95037841796875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  8.,  8.])\n",
      "cls loss 882.2598876953125  loc loss 56.03251647949219\n",
      "cls loss 850.5977783203125  loc loss 64.0448226928711\n",
      "cls loss 334.8048095703125  loc loss 19.294567108154297\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([4., 1., 1., 4.])\n",
      "cls loss 494.1181640625  loc loss 31.752822875976562\n",
      "cls loss 594.2168579101562  loc loss 34.85809326171875\n",
      "cls loss 253.64041137695312  loc loss 12.543600082397461\n",
      "cls loss 337.136962890625  loc loss 21.30274200439453\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([51.,  1.])\n",
      "cls loss 253.84500122070312  loc loss 10.256596565246582\n",
      "cls loss 352.47088623046875  loc loss 18.78458595275879\n",
      "cls loss 606.7147216796875  loc loss 34.31715393066406\n",
      "cls loss 629.4833984375  loc loss 44.61071014404297\n",
      "cls loss 867.5916748046875  loc loss 46.84731674194336\n",
      "cls loss 1063.5640869140625  loc loss 71.15850830078125\n",
      "cls loss 460.32843017578125  loc loss 27.63675880432129\n",
      "cls loss 670.880615234375  loc loss 48.72258377075195\n",
      "cls loss 706.3988647460938  loc loss 48.40705871582031\n",
      "cls loss 555.3497924804688  loc loss 32.30328369140625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  3.,  1.,  1.,  1.,  3.,  1.,  1.,\n",
      "         1.,  1.,  1.])\n",
      "cls loss 568.696533203125  loc loss 25.432071685791016\n",
      "cls loss 650.48779296875  loc loss 32.8756103515625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 573.5758056640625  loc loss 31.000951766967773\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "cls loss 489.67523193359375  loc loss 28.814138412475586\n",
      "cls loss 276.30560302734375  loc loss 22.768735885620117\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3.])\n",
      "cls loss 220.68240356445312  loc loss 11.943706512451172\n",
      "cls loss 414.20758056640625  loc loss 27.130287170410156\n",
      "cls loss 348.16387939453125  loc loss 25.978256225585938\n",
      "cls loss 642.761962890625  loc loss 41.89297866821289\n",
      "cls loss 397.7783203125  loc loss 22.042991638183594\n",
      "cls loss 347.0962219238281  loc loss 24.42652702331543\n",
      "cls loss 1039.832763671875  loc loss 69.59686279296875\n",
      "cls loss 448.1435852050781  loc loss 34.72636032104492\n",
      "cls loss 354.01220703125  loc loss 24.26248550415039\n",
      "cls loss 433.12530517578125  loc loss 24.685379028320312\n",
      "cls loss 397.9623107910156  loc loss 27.94739532470703\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 714.2059326171875  loc loss 47.23271560668945\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  9., 64., 64., 64., 64., 64., 64., 64., 64., 64.,  9.,  9.,  9.,\n",
      "         9.])\n",
      "cls loss 369.21746826171875  loc loss 17.77545166015625\n",
      "cls loss 905.184814453125  loc loss 71.67958068847656\n",
      "cls loss 489.20245361328125  loc loss 31.809600830078125\n",
      "cls loss 627.8626098632812  loc loss 41.763458251953125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.,  3.,  3.])\n",
      "cls loss 395.6377868652344  loc loss 21.376819610595703\n",
      "cls loss 429.6324462890625  loc loss 28.845975875854492\n",
      "cls loss 421.4736328125  loc loss 30.078691482543945\n",
      "cls loss 446.5769958496094  loc loss 32.56278610229492\n",
      "cls loss 461.8195495605469  loc loss 36.555908203125\n",
      "cls loss 492.3292236328125  loc loss 34.73324203491211\n",
      "cls loss 447.66558837890625  loc loss 33.73560333251953\n",
      "cls loss 489.44482421875  loc loss 28.056026458740234\n",
      "cls loss 611.3611450195312  loc loss 40.078121185302734\n",
      "cls loss 472.664306640625  loc loss 27.957294464111328\n",
      "cls loss 383.84771728515625  loc loss 18.06475830078125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21.])\n",
      "cls loss 301.39373779296875  loc loss 17.042409896850586\n",
      "cls loss 423.44775390625  loc loss 34.84768295288086\n",
      "cls loss 628.7368774414062  loc loss 41.9696044921875\n",
      "cls loss 343.1972351074219  loc loss 19.29142189025879\n",
      "cls loss 486.5124816894531  loc loss 29.98407554626465\n",
      "cls loss 913.6251220703125  loc loss 48.03201675415039\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 42., 42.,  1.,  1.])\n",
      "cls loss 469.9652099609375  loc loss 29.512451171875\n",
      "cls loss 312.4419860839844  loc loss 21.485023498535156\n",
      "cls loss 444.15069580078125  loc loss 31.953018188476562\n",
      "cls loss 610.0714111328125  loc loss 48.989967346191406\n",
      "cls loss 390.52734375  loc loss 24.9388427734375\n",
      "cls loss 591.997314453125  loc loss 43.92586898803711\n",
      "cls loss 557.4193115234375  loc loss 39.49643325805664\n",
      "cls loss 578.1900634765625  loc loss 34.87042999267578\n",
      "cls loss 464.31854248046875  loc loss 27.471818923950195\n",
      "cls loss 399.6761779785156  loc loss 25.112333297729492\n",
      "cls loss 334.66241455078125  loc loss 13.141209602355957\n",
      "cls loss 431.12994384765625  loc loss 27.46994972229004\n",
      "cls loss 662.4293212890625  loc loss 45.849098205566406\n",
      "cls loss 516.474609375  loc loss 31.152982711791992\n",
      "cls loss 478.084228515625  loc loss 34.717247009277344\n",
      "cls loss 531.3948974609375  loc loss 31.8061580657959\n",
      "cls loss 764.33251953125  loc loss 55.06616973876953\n",
      "cls loss 573.2271728515625  loc loss 41.504852294921875\n",
      "cls loss 645.9579467773438  loc loss 36.17694091796875\n",
      "cls loss 373.713134765625  loc loss 18.373573303222656\n",
      "cls loss 537.8494873046875  loc loss 33.81788635253906\n",
      "cls loss 497.5987854003906  loc loss 28.80707550048828\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 5., 5., 5., 5., 5., 5.])\n",
      "cls loss 342.3998718261719  loc loss 22.996875762939453\n",
      "cls loss 432.0750732421875  loc loss 23.41034507751465\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([13.])\n",
      "cls loss 301.02587890625  loc loss 17.561555862426758\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([44., 10.,  1.,  1.,  1.])\n",
      "cls loss 287.24786376953125  loc loss 18.356536865234375\n",
      "cls loss 552.1368408203125  loc loss 27.84952163696289\n",
      "cls loss 462.06378173828125  loc loss 25.936721801757812\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19., 19., 19., 19., 19., 19., 19.])\n",
      "cls loss 554.3419189453125  loc loss 29.333053588867188\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([56.])\n",
      "cls loss 989.2789306640625  loc loss 64.76611328125\n",
      "cls loss 612.4696044921875  loc loss 46.28076171875\n",
      "cls loss 781.1085205078125  loc loss 52.756649017333984\n",
      "cls loss 765.33447265625  loc loss 57.72157287597656\n",
      "cls loss 492.3539123535156  loc loss 26.438413619995117\n",
      "cls loss 772.193603515625  loc loss 51.613304138183594\n",
      "cls loss 443.03399658203125  loc loss 28.790390014648438\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 36.])\n",
      "cls loss 534.7861328125  loc loss 28.36504364013672\n",
      "cls loss 481.852783203125  loc loss 31.537811279296875\n",
      "cls loss 452.0897216796875  loc loss 27.186275482177734\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5.])\n",
      "cls loss 540.290771484375  loc loss 32.49644088745117\n",
      "cls loss 284.286865234375  loc loss 15.217232704162598\n",
      "cls loss 689.5219116210938  loc loss 36.68479537963867\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "cls loss 585.8927612304688  loc loss 37.954803466796875\n",
      "cls loss 557.728759765625  loc loss 38.177146911621094\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 553.830322265625  loc loss 38.73502731323242\n",
      "cls loss 640.9268798828125  loc loss 44.60631561279297\n",
      "cls loss 540.9237060546875  loc loss 47.610992431640625\n",
      "cls loss 390.4710693359375  loc loss 26.44905662536621\n",
      "cls loss 454.3338928222656  loc loss 33.27738571166992\n",
      "cls loss 485.0245056152344  loc loss 30.337478637695312\n",
      "cls loss 752.302734375  loc loss 41.05622100830078\n",
      "cls loss 341.1886901855469  loc loss 16.675148010253906\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 11., 15., 10., 10., 10., 10., 10.])\n",
      "cls loss 800.2208862304688  loc loss 47.98378372192383\n",
      "cls loss 429.9230041503906  loc loss 31.230623245239258\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3.])\n",
      "cls loss 476.2183837890625  loc loss 32.23701095581055\n",
      "cls loss 443.68402099609375  loc loss 23.71170425415039\n",
      "cls loss 474.5006408691406  loc loss 23.098342895507812\n",
      "cls loss 608.6690673828125  loc loss 28.10044288635254\n",
      "cls loss 320.6248474121094  loc loss 15.38233757019043\n",
      "cls loss 478.7024230957031  loc loss 31.422931671142578\n",
      "cls loss 540.4588012695312  loc loss 37.71527099609375\n",
      "cls loss 451.4840087890625  loc loss 33.14016342163086\n",
      "cls loss 1064.3551025390625  loc loss 74.64984130859375\n",
      "cls loss 737.702880859375  loc loss 47.41761779785156\n",
      "cls loss 483.9080810546875  loc loss 33.52656936645508\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  9.,  9.,  9.,  6.,  6., 85., 85.,  8.,  1.,  1.,  1.,  1.,\n",
      "         6.,  6.])\n",
      "cls loss 320.195068359375  loc loss 25.517623901367188\n",
      "cls loss 779.781494140625  loc loss 55.147682189941406\n",
      "cls loss 941.8836059570312  loc loss 57.253875732421875\n",
      "cls loss 631.2657470703125  loc loss 42.68634796142578\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10.,  3.,  3., 10.])\n",
      "cls loss 432.30126953125  loc loss 22.246450424194336\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([7.])\n",
      "cls loss 514.32080078125  loc loss 33.792022705078125\n",
      "cls loss 529.6100463867188  loc loss 31.70533561706543\n",
      "cls loss 483.66229248046875  loc loss 40.40479278564453\n",
      "cls loss 697.2327880859375  loc loss 56.42576599121094\n",
      "cls loss 473.7344665527344  loc loss 32.54155349731445\n",
      "cls loss 682.99658203125  loc loss 43.764549255371094\n",
      "cls loss 849.8341064453125  loc loss 49.75889205932617\n",
      "cls loss 506.08642578125  loc loss 34.29405212402344\n",
      "cls loss 552.483154296875  loc loss 39.18718338012695\n",
      "cls loss 452.87554931640625  loc loss 33.31852722167969\n",
      "cls loss 678.5442504882812  loc loss 52.308135986328125\n",
      "cls loss 527.391357421875  loc loss 32.80790710449219\n",
      "cls loss 427.33544921875  loc loss 24.991525650024414\n",
      "cls loss 648.5491943359375  loc loss 48.64397430419922\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([62.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([62.])\n",
      "cls loss 307.35498046875  loc loss 14.593870162963867\n",
      "cls loss 495.4688720703125  loc loss 34.90277862548828\n",
      "cls loss 492.2822570800781  loc loss 31.52286148071289\n",
      "cls loss 333.7193603515625  loc loss 15.493631362915039\n",
      "cls loss 629.6842041015625  loc loss 41.2194938659668\n",
      "cls loss 671.0806884765625  loc loss 36.09337615966797\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([28.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 740.3619995117188  loc loss 37.827476501464844\n",
      "cls loss 620.4519653320312  loc loss 37.613319396972656\n",
      "cls loss 620.4071044921875  loc loss 40.7193489074707\n",
      "cls loss 623.0982055664062  loc loss 39.149375915527344\n",
      "cls loss 858.77978515625  loc loss 56.923980712890625\n",
      "cls loss 491.371337890625  loc loss 30.23178482055664\n",
      "cls loss 621.1190185546875  loc loss 36.64093017578125\n",
      "cls loss 521.472412109375  loc loss 42.89371871948242\n",
      "cls loss 855.4599609375  loc loss 67.04634857177734\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([81.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 588.43505859375  loc loss 24.113998413085938\n",
      "cls loss 436.5321044921875  loc loss 23.122346878051758\n",
      "cls loss 347.55633544921875  loc loss 24.230587005615234\n",
      "cls loss 308.8083801269531  loc loss 11.927289962768555\n",
      "cls loss 347.15313720703125  loc loss 24.401281356811523\n",
      "cls loss 388.629638671875  loc loss 24.318296432495117\n",
      "cls loss 450.9327697753906  loc loss 28.381290435791016\n",
      "cls loss 603.571044921875  loc loss 47.90546417236328\n",
      "cls loss 687.7229614257812  loc loss 43.915611267089844\n",
      "cls loss 1247.9820556640625  loc loss 82.5965576171875\n",
      "cls loss 504.257080078125  loc loss 26.086746215820312\n",
      "cls loss 613.7785034179688  loc loss 43.57511901855469\n",
      "cls loss 438.0656433105469  loc loss 27.214712142944336\n",
      "cls loss 583.3449096679688  loc loss 32.50481414794922\n",
      "cls loss 494.8880615234375  loc loss 28.22233772277832\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([44., 44.])\n",
      "cls loss 455.257080078125  loc loss 21.73143768310547\n",
      "cls loss 475.5793762207031  loc loss 31.506446838378906\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15.])\n",
      "cls loss 518.28662109375  loc loss 25.532875061035156\n",
      "cls loss 253.031494140625  loc loss 15.008028984069824\n",
      "cls loss 517.4884033203125  loc loss 30.645341873168945\n",
      "cls loss 291.74981689453125  loc loss 17.126794815063477\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([1., 3., 3.])\n",
      "cls loss 335.982421875  loc loss 23.56001853942871\n",
      "cls loss 262.03021240234375  loc loss 11.701549530029297\n",
      "cls loss 494.462646484375  loc loss 29.44102668762207\n",
      "cls loss 536.857177734375  loc loss 31.076000213623047\n",
      "cls loss 484.49505615234375  loc loss 32.03125762939453\n",
      "cls loss 458.3686218261719  loc loss 26.356643676757812\n",
      "cls loss 402.3474426269531  loc loss 30.491504669189453\n",
      "cls loss 565.0413818359375  loc loss 35.75809860229492\n",
      "cls loss 401.20111083984375  loc loss 26.955610275268555\n",
      "cls loss 537.64013671875  loc loss 36.72968673706055\n",
      "cls loss 352.96588134765625  loc loss 19.931869506835938\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 633.7889404296875  loc loss 38.370880126953125\n",
      "cls loss 748.4068603515625  loc loss 34.59650421142578\n",
      "cls loss 642.0479736328125  loc loss 44.59129333496094\n",
      "cls loss 646.169189453125  loc loss 49.793155670166016\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10., 10., 10.,  1.,  1.,  1.,  1.,  1.,  1.,  8.,  8.,\n",
      "         1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10., 10., 10.,  1.,  1.,  1.,  1.,  1.,  1.,  8.,  8.,\n",
      "         1.])\n",
      "cls loss 581.844482421875  loc loss 27.323015213012695\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 3., 3., 3.])\n",
      "cls loss 500.3692626953125  loc loss 31.058053970336914\n",
      "cls loss 356.1453857421875  loc loss 20.051105499267578\n",
      "cls loss 274.3934020996094  loc loss 13.100692749023438\n",
      "cls loss 470.4736328125  loc loss 35.38527297973633\n",
      "cls loss 367.5534362792969  loc loss 17.835147857666016\n",
      "cls loss 424.17083740234375  loc loss 27.88005828857422\n",
      "cls loss 479.97662353515625  loc loss 32.14639663696289\n",
      "cls loss 671.8489990234375  loc loss 45.49911880493164\n",
      "cls loss 565.4707641601562  loc loss 27.602312088012695\n",
      "cls loss 542.5350341796875  loc loss 29.88803482055664\n",
      "cls loss 582.3621826171875  loc loss 39.638404846191406\n",
      "cls loss 413.99176025390625  loc loss 32.11516189575195\n",
      "cls loss 785.7474975585938  loc loss 59.06007385253906\n",
      "cls loss 387.3246154785156  loc loss 19.677919387817383\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 614.5013427734375  loc loss 37.64210510253906\n",
      "cls loss 298.900390625  loc loss 12.251617431640625\n",
      "cls loss 745.0741577148438  loc loss 46.37010192871094\n",
      "cls loss 377.3397216796875  loc loss 21.48276138305664\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 34.])\n",
      "cls loss 628.4686279296875  loc loss 32.77107238769531\n",
      "cls loss 299.1839599609375  loc loss 19.190601348876953\n",
      "cls loss 572.591064453125  loc loss 36.58809280395508\n",
      "cls loss 194.31764221191406  loc loss 14.412429809570312\n",
      "cls loss 484.8182373046875  loc loss 30.325885772705078\n",
      "cls loss 467.4696350097656  loc loss 38.410667419433594\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 38.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16., 16., 16.,  9.,  9.,  9., 16., 16., 16., 85.,  9.])\n",
      "cls loss 477.42822265625  loc loss 31.45166015625\n",
      "cls loss 543.1475830078125  loc loss 41.87640380859375\n",
      "cls loss 724.7076416015625  loc loss 48.76413345336914\n",
      "cls loss 1071.666259765625  loc loss 69.75357818603516\n",
      "cls loss 324.32061767578125  loc loss 16.95952033996582\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3., 10.,  8.,  8., 10., 10., 10.,  3.,  3., 14.])\n",
      "cls loss 372.9383544921875  loc loss 18.494354248046875\n",
      "cls loss 691.5535888671875  loc loss 36.110530853271484\n",
      "cls loss 304.0706787109375  loc loss 10.874720573425293\n",
      "cls loss 458.37493896484375  loc loss 19.43012237548828\n",
      "cls loss 601.4560546875  loc loss 35.436588287353516\n",
      "cls loss 514.541015625  loc loss 31.818103790283203\n",
      "cls loss 289.45904541015625  loc loss 15.056053161621094\n",
      "cls loss 338.27191162109375  loc loss 20.331424713134766\n",
      "cls loss 530.9911499023438  loc loss 32.576778411865234\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42., 42.,  1.])\n",
      "cls loss 517.8331298828125  loc loss 35.18671417236328\n",
      "cls loss 406.72283935546875  loc loss 24.25046730041504\n",
      "cls loss 556.09326171875  loc loss 42.78229522705078\n",
      "cls loss 664.0166625976562  loc loss 40.4044075012207\n",
      "cls loss 445.96728515625  loc loss 28.690122604370117\n",
      "cls loss 552.230712890625  loc loss 39.314430236816406\n",
      "cls loss 358.7882080078125  loc loss 24.146757125854492\n",
      "cls loss 373.32122802734375  loc loss 26.033267974853516\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20.])\n",
      "cls loss 282.1259765625  loc loss 16.591590881347656\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([11.])\n",
      "cls loss 375.5926208496094  loc loss 18.460969924926758\n",
      "cls loss 251.7851104736328  loc loss 13.737577438354492\n",
      "cls loss 574.0126953125  loc loss 44.08157730102539\n",
      "cls loss 266.2841491699219  loc loss 12.065488815307617\n",
      "cls loss 570.55126953125  loc loss 30.554006576538086\n",
      "cls loss 310.4751892089844  loc loss 19.11859130859375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 35., 27.])\n",
      "cls loss 521.1511840820312  loc loss 31.010347366333008\n",
      "cls loss 571.1034545898438  loc loss 42.1125602722168\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 385.75396728515625  loc loss 22.46343994140625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([42.,  1.])\n",
      "cls loss 490.82220458984375  loc loss 33.91946792602539\n",
      "cls loss 467.6932373046875  loc loss 26.42133903503418\n",
      "cls loss 560.100830078125  loc loss 34.542503356933594\n",
      "cls loss 702.3533935546875  loc loss 44.376834869384766\n",
      "cls loss 628.07958984375  loc loss 36.97949981689453\n",
      "cls loss 423.2896423339844  loc loss 30.842891693115234\n",
      "cls loss 364.30615234375  loc loss 27.335241317749023\n",
      "cls loss 232.20481872558594  loc loss 10.822961807250977\n",
      "cls loss 426.2565002441406  loc loss 23.373889923095703\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 1., 1.])\n",
      "cls loss 414.6966552734375  loc loss 23.589099884033203\n",
      "cls loss 468.7078552246094  loc loss 30.555320739746094\n",
      "cls loss 458.74420166015625  loc loss 28.816558837890625\n",
      "cls loss 381.2026062011719  loc loss 26.483699798583984\n",
      "cls loss 460.91632080078125  loc loss 27.51400375366211\n",
      "cls loss 489.6870422363281  loc loss 34.92179870605469\n",
      "cls loss 673.990966796875  loc loss 40.219364166259766\n",
      "cls loss 574.0463256835938  loc loss 43.456539154052734\n",
      "cls loss 535.830078125  loc loss 32.22602844238281\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 421.791259765625  loc loss 28.36831283569336\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 505.50665283203125  loc loss 24.583919525146484\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([81.])\n",
      "cls loss 606.6964111328125  loc loss 36.37031936645508\n",
      "cls loss 380.295654296875  loc loss 25.665925979614258\n",
      "cls loss 273.2059020996094  loc loss 15.285054206848145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 426.823486328125  loc loss 22.57023048400879\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3.,  1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 19.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 19.])\n",
      "cls loss 547.4974365234375  loc loss 38.45233917236328\n",
      "cls loss 325.8696594238281  loc loss 17.309772491455078\n",
      "cls loss 341.5474548339844  loc loss 19.397855758666992\n",
      "cls loss 651.926513671875  loc loss 47.49546813964844\n",
      "cls loss 331.05633544921875  loc loss 20.547794342041016\n",
      "cls loss 413.6380615234375  loc loss 27.027606964111328\n",
      "cls loss 513.829833984375  loc loss 33.380035400390625\n",
      "cls loss 406.47412109375  loc loss 28.25950813293457\n",
      "cls loss 518.1722412109375  loc loss 29.70229721069336\n",
      "cls loss 592.9263916015625  loc loss 39.523948669433594\n",
      "cls loss 713.1144409179688  loc loss 62.959129333496094\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 81.])\n",
      "cls loss 520.435791015625  loc loss 26.793224334716797\n",
      "cls loss 440.8533630371094  loc loss 24.70958137512207\n",
      "cls loss 499.69287109375  loc loss 26.408885955810547\n",
      "cls loss 379.43695068359375  loc loss 18.96577262878418\n",
      "cls loss 334.18670654296875  loc loss 21.31303596496582\n",
      "cls loss 362.8015441894531  loc loss 28.838483810424805\n",
      "cls loss 304.35809326171875  loc loss 21.85066032409668\n",
      "cls loss 250.29989624023438  loc loss 16.295703887939453\n",
      "cls loss 339.6298828125  loc loss 21.983901977539062\n",
      "cls loss 460.2311096191406  loc loss 28.119659423828125\n",
      "cls loss 390.563232421875  loc loss 30.72831916809082\n",
      "cls loss 410.58587646484375  loc loss 31.584217071533203\n",
      "cls loss 251.674072265625  loc loss 17.427061080932617\n",
      "cls loss 851.9900512695312  loc loss 59.53549575805664\n",
      "cls loss 525.0330200195312  loc loss 34.88334655761719\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 460.2518615722656  loc loss 23.385906219482422\n",
      "cls loss 512.6980590820312  loc loss 33.5343017578125\n",
      "cls loss 400.71875  loc loss 24.57579803466797\n",
      "cls loss 600.5929565429688  loc loss 39.545188903808594\n",
      "cls loss 570.0819702148438  loc loss 35.31662368774414\n",
      "cls loss 522.845458984375  loc loss 31.654834747314453\n",
      "cls loss 405.6843566894531  loc loss 24.553667068481445\n",
      "cls loss 308.976806640625  loc loss 19.41786003112793\n",
      "cls loss 471.6461181640625  loc loss 27.55289077758789\n",
      "cls loss 508.41436767578125  loc loss 33.99706268310547\n",
      "cls loss 526.8489990234375  loc loss 29.348278045654297\n",
      "cls loss 660.5121459960938  loc loss 47.70924758911133\n",
      "cls loss 659.630615234375  loc loss 53.231327056884766\n",
      "cls loss 474.4300231933594  loc loss 34.174015045166016\n",
      "cls loss 655.715087890625  loc loss 51.28781509399414\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1., 38., 47.,  1.,  1.,  1.,  1.,  1., 62.])\n",
      "cls loss 466.0224609375  loc loss 22.431339263916016\n",
      "cls loss 553.9029541015625  loc loss 32.837276458740234\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 591.9700927734375  loc loss 33.9053840637207\n",
      "cls loss 616.828125  loc loss 45.84945297241211\n",
      "cls loss 425.2742614746094  loc loss 21.258649826049805\n",
      "cls loss 495.95458984375  loc loss 39.91054916381836\n",
      "cls loss 460.7886962890625  loc loss 26.83108901977539\n",
      "cls loss 267.724853515625  loc loss 10.541975021362305\n",
      "cls loss 418.8772888183594  loc loss 24.262649536132812\n",
      "cls loss 363.94586181640625  loc loss 16.38968276977539\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1., 35.])\n",
      "cls loss 409.81805419921875  loc loss 22.200557708740234\n",
      "cls loss 601.908935546875  loc loss 31.878084182739258\n",
      "cls loss 588.3908081054688  loc loss 38.33118438720703\n",
      "cls loss 517.2822875976562  loc loss 42.80187225341797\n",
      "cls loss 427.3878173828125  loc loss 33.35676574707031\n",
      "cls loss 569.576416015625  loc loss 42.39785385131836\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 320.0426940917969  loc loss 18.30013084411621\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 464.9839782714844  loc loss 20.58725357055664\n",
      "cls loss 748.1498413085938  loc loss 38.7254638671875\n",
      "cls loss 883.1845092773438  loc loss 68.44612884521484\n",
      "cls loss 452.47625732421875  loc loss 23.345247268676758\n",
      "cls loss 402.0994873046875  loc loss 25.451871871948242\n",
      "cls loss 400.741943359375  loc loss 21.353546142578125\n",
      "cls loss 413.2057189941406  loc loss 25.851655960083008\n",
      "cls loss 372.6773986816406  loc loss 16.45516586303711\n",
      "cls loss 667.7318115234375  loc loss 45.97197341918945\n",
      "cls loss 556.83056640625  loc loss 34.23505401611328\n",
      "cls loss 287.9764099121094  loc loss 19.741443634033203\n",
      "cls loss 546.7928466796875  loc loss 29.86027717590332\n",
      "cls loss 647.443603515625  loc loss 51.97807312011719\n",
      "cls loss 535.0450439453125  loc loss 34.20936584472656\n",
      "cls loss 461.6221618652344  loc loss 25.728700637817383\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.])\n",
      "cls loss 442.3634033203125  loc loss 31.901227951049805\n",
      "cls loss 429.44268798828125  loc loss 30.037216186523438\n",
      "cls loss 554.2982177734375  loc loss 36.88467788696289\n",
      "cls loss 867.3492431640625  loc loss 68.39647674560547\n",
      "cls loss 368.0404968261719  loc loss 18.071102142333984\n",
      "cls loss 480.7200012207031  loc loss 29.573822021484375\n",
      "cls loss 384.73773193359375  loc loss 20.878681182861328\n",
      "cls loss 413.4322204589844  loc loss 26.1337890625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 21., 21., 21.])\n",
      "cls loss 436.6041259765625  loc loss 26.541257858276367\n",
      "cls loss 403.9846496582031  loc loss 19.84261703491211\n",
      "cls loss 437.03143310546875  loc loss 29.03875732421875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 35.])\n",
      "cls loss 563.236328125  loc loss 35.19257736206055\n",
      "cls loss 207.67160034179688  loc loss 11.428439140319824\n",
      "cls loss 354.71966552734375  loc loss 23.281845092773438\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 339.1141357421875  loc loss 15.325844764709473\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 38., 38.,  9., 38.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1.,  1.])\n",
      "cls loss 386.72418212890625  loc loss 24.95949935913086\n",
      "cls loss 650.1383056640625  loc loss 40.343955993652344\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 2.,  1., 77., 31., 10., 10.,  1.,  4., 10.])\n",
      "cls loss 327.9608459472656  loc loss 15.314236640930176\n",
      "cls loss 608.9639282226562  loc loss 34.84449768066406\n",
      "cls loss 1215.7467041015625  loc loss 68.86165618896484\n",
      "cls loss 371.97491455078125  loc loss 25.293100357055664\n",
      "cls loss 539.0341186523438  loc loss 39.1341552734375\n",
      "cls loss 398.58740234375  loc loss 20.024946212768555\n",
      "cls loss 391.14776611328125  loc loss 18.742740631103516\n",
      "cls loss 554.685791015625  loc loss 27.549928665161133\n",
      "cls loss 570.0682373046875  loc loss 30.032236099243164\n",
      "cls loss 499.67071533203125  loc loss 34.79474639892578\n",
      "cls loss 396.97991943359375  loc loss 18.933664321899414\n",
      "cls loss 413.1097412109375  loc loss 22.052589416503906\n",
      "cls loss 775.1658935546875  loc loss 47.22079849243164\n",
      "cls loss 671.1245727539062  loc loss 40.06618881225586\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1., 42., 42., 42., 42., 42., 42.,  1.,\n",
      "         1.,  1.,  1., 42.,  1.,  1., 42.,  1.])\n",
      "cls loss 369.32623291015625  loc loss 26.077579498291016\n",
      "cls loss 570.6692504882812  loc loss 33.93213653564453\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.])\n",
      "cls loss 244.9783935546875  loc loss 14.203895568847656\n",
      "cls loss 569.2411499023438  loc loss 36.24086380004883\n",
      "cls loss 438.86138916015625  loc loss 31.306982040405273\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([11.])\n",
      "cls loss 273.44927978515625  loc loss 15.856145858764648\n",
      "cls loss 331.4818420410156  loc loss 15.732145309448242\n",
      "cls loss 348.52142333984375  loc loss 15.653112411499023\n",
      "cls loss 572.8724365234375  loc loss 34.99355697631836\n",
      "cls loss 483.658935546875  loc loss 26.70227813720703\n",
      "cls loss 480.72064208984375  loc loss 32.2933349609375\n",
      "cls loss 705.113525390625  loc loss 36.11033630371094\n",
      "cls loss 352.8631896972656  loc loss 20.792688369750977\n",
      "cls loss 726.0467529296875  loc loss 49.57915496826172\n",
      "cls loss 352.85284423828125  loc loss 22.579824447631836\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 334.4199523925781  loc loss 22.261369705200195\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1., 38., 38., 42.])\n",
      "cls loss 427.73455810546875  loc loss 30.833660125732422\n",
      "cls loss 399.09796142578125  loc loss 23.307371139526367\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 353.890869140625  loc loss 24.819713592529297\n",
      "cls loss 801.9554443359375  loc loss 54.408607482910156\n",
      "cls loss 490.617919921875  loc loss 31.339813232421875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10.,  3.,  3.,  6.,  8.,  8.,  1.,  1.,  1., 10.])\n",
      "cls loss 406.82965087890625  loc loss 20.481948852539062\n",
      "cls loss 253.09173583984375  loc loss 9.389751434326172\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10.,  3.])\n",
      "cls loss 374.03179931640625  loc loss 21.537057876586914\n",
      "cls loss 205.27719116210938  loc loss 11.532768249511719\n",
      "cls loss 478.7776794433594  loc loss 33.0613899230957\n",
      "cls loss 561.589599609375  loc loss 35.04473876953125\n",
      "cls loss 404.93670654296875  loc loss 23.788833618164062\n",
      "cls loss 289.4708251953125  loc loss 14.273024559020996\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 34.])\n",
      "cls loss 667.3548583984375  loc loss 41.312744140625\n",
      "cls loss 722.3418579101562  loc loss 58.871036529541016\n",
      "cls loss 457.7860107421875  loc loss 33.7778434753418\n",
      "cls loss 367.70855712890625  loc loss 25.265178680419922\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.,  1.])\n",
      "cls loss 404.360107421875  loc loss 18.980419158935547\n",
      "cls loss 627.612548828125  loc loss 47.869293212890625\n",
      "cls loss 924.0886840820312  loc loss 60.8765754699707\n",
      "cls loss 774.1983032226562  loc loss 40.525978088378906\n",
      "cls loss 467.193359375  loc loss 24.243410110473633\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 548.188720703125  loc loss 31.09290885925293\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10.])\n",
      "cls loss 341.531982421875  loc loss 17.589725494384766\n",
      "cls loss 500.9823913574219  loc loss 24.70638656616211\n",
      "cls loss 452.75531005859375  loc loss 28.52421760559082\n",
      "cls loss 334.26788330078125  loc loss 19.344661712646484\n",
      "cls loss 432.98504638671875  loc loss 27.7191162109375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21.,\n",
      "        21.])\n",
      "cls loss 575.0574951171875  loc loss 32.56038284301758\n",
      "cls loss 448.8587951660156  loc loss 27.089231491088867\n",
      "cls loss 299.10357666015625  loc loss 13.693912506103516\n",
      "cls loss 636.96142578125  loc loss 40.890228271484375\n",
      "cls loss 486.31146240234375  loc loss 31.69487762451172\n",
      "cls loss 352.88446044921875  loc loss 18.672456741333008\n",
      "cls loss 708.2083740234375  loc loss 45.277000427246094\n",
      "cls loss 846.089111328125  loc loss 58.670310974121094\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15., 85.])\n",
      "cls loss 536.9337158203125  loc loss 33.89002990722656\n",
      "cls loss 547.3614501953125  loc loss 40.424110412597656\n",
      "cls loss 565.501220703125  loc loss 40.416595458984375\n",
      "cls loss 494.549072265625  loc loss 27.823514938354492\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 8., 8.])\n",
      "cls loss 319.693359375  loc loss 14.837912559509277\n",
      "cls loss 337.3010559082031  loc loss 24.498794555664062\n",
      "cls loss 425.803955078125  loc loss 26.15618133544922\n",
      "cls loss 356.10125732421875  loc loss 19.561433792114258\n",
      "cls loss 396.81427001953125  loc loss 23.523473739624023\n",
      "cls loss 555.5462646484375  loc loss 33.60810470581055\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1., 35., 27., 27.,  1., 27.,  1.])\n",
      "cls loss 689.2659912109375  loc loss 49.78076171875\n",
      "cls loss 376.15423583984375  loc loss 22.817493438720703\n",
      "cls loss 422.89068603515625  loc loss 30.582653045654297\n",
      "cls loss 396.1194763183594  loc loss 35.13953399658203\n",
      "cls loss 359.8064270019531  loc loss 27.17894172668457\n",
      "cls loss 399.25946044921875  loc loss 30.70113182067871\n",
      "cls loss 405.2253723144531  loc loss 31.26031494140625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  2.,  2.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  2.,  2.])\n",
      "cls loss 217.6077880859375  loc loss 8.760713577270508\n",
      "cls loss 646.7305297851562  loc loss 39.59037780761719\n",
      "cls loss 439.57904052734375  loc loss 19.859697341918945\n",
      "cls loss 707.1699829101562  loc loss 51.409339904785156\n",
      "cls loss 289.0369873046875  loc loss 16.395965576171875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 19., 19., 19., 16.])\n",
      "cls loss 305.76763916015625  loc loss 12.954996109008789\n",
      "cls loss 242.0130615234375  loc loss 9.935491561889648\n",
      "cls loss 394.623291015625  loc loss 19.684593200683594\n",
      "cls loss 514.7861938476562  loc loss 33.23909378051758\n",
      "cls loss 232.77024841308594  loc loss 16.896865844726562\n",
      "cls loss 572.5460205078125  loc loss 43.47539138793945\n",
      "cls loss 407.3585510253906  loc loss 27.43178367614746\n",
      "cls loss 444.83221435546875  loc loss 28.606719970703125\n",
      "cls loss 568.170166015625  loc loss 38.17775344848633\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 600.8533935546875  loc loss 27.17950439453125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 798.510986328125  loc loss 67.83660888671875\n",
      "cls loss 1030.471435546875  loc loss 93.73837280273438\n",
      "cls loss 538.375  loc loss 31.733400344848633\n",
      "cls loss 474.7169494628906  loc loss 29.682775497436523\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3.,  3.,  3.,  3.,  3., 10.])\n",
      "cls loss 246.7264404296875  loc loss 15.092548370361328\n",
      "cls loss 510.5345458984375  loc loss 24.13074493408203\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 1., 1., 1., 3., 3., 3., 3.])\n",
      "cls loss 385.7214660644531  loc loss 22.234615325927734\n",
      "cls loss 749.072509765625  loc loss 47.0995979309082\n",
      "cls loss 583.660888671875  loc loss 37.16876983642578\n",
      "cls loss 377.92071533203125  loc loss 22.19219970703125\n",
      "cls loss 592.9639892578125  loc loss 40.249996185302734\n",
      "cls loss 361.77142333984375  loc loss 26.519424438476562\n",
      "cls loss 576.0667114257812  loc loss 39.90574264526367\n",
      "cls loss 426.9017333984375  loc loss 40.28606033325195\n",
      "cls loss 451.70703125  loc loss 27.888717651367188\n",
      "cls loss 901.77392578125  loc loss 73.7776107788086\n",
      "cls loss 604.4862060546875  loc loss 43.58056640625\n",
      "cls loss 415.015380859375  loc loss 20.00592803955078\n",
      "cls loss 271.49505615234375  loc loss 11.691496849060059\n",
      "cls loss 321.568359375  loc loss 15.1058349609375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3., 10., 10., 10., 10., 10., 10., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10., 10., 10., 10., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 11., 10., 10., 10., 10., 10.,  3.,  3.,  3.,  3.,  3.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 11., 10., 10., 10., 10., 10.,  3.,  3.,  3.,  3.,  3.])\n",
      "cls loss 282.25921630859375  loc loss 12.950139999389648\n",
      "cls loss 357.47467041015625  loc loss 16.23312759399414\n",
      "cls loss 298.9498291015625  loc loss 17.498348236083984\n",
      "cls loss 316.20831298828125  loc loss 13.635704040527344\n",
      "cls loss 366.2413330078125  loc loss 28.292369842529297\n",
      "cls loss 289.92987060546875  loc loss 11.312418937683105\n",
      "cls loss 554.4777221679688  loc loss 37.04523468017578\n",
      "cls loss 476.6510009765625  loc loss 31.749080657958984\n",
      "cls loss 738.1174926757812  loc loss 45.689308166503906\n",
      "cls loss 369.56640625  loc loss 26.11170196533203\n",
      "cls loss 656.2122802734375  loc loss 42.24757766723633\n",
      "cls loss 522.2997436523438  loc loss 34.84901809692383\n",
      "cls loss 495.6246643066406  loc loss 32.36167526245117\n",
      "cls loss 489.1982421875  loc loss 34.64836883544922\n",
      "cls loss 658.3025512695312  loc loss 44.095951080322266\n",
      "cls loss 670.9869384765625  loc loss 40.44776153564453\n",
      "cls loss 317.4195556640625  loc loss 16.758670806884766\n",
      "cls loss 595.2911376953125  loc loss 41.72450256347656\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 10.,  1., 18.])\n",
      "cls loss 288.8275146484375  loc loss 18.94251251220703\n",
      "cls loss 368.320556640625  loc loss 14.764749526977539\n",
      "cls loss 616.5472412109375  loc loss 31.56900405883789\n",
      "cls loss 834.1666870117188  loc loss 47.53235626220703\n",
      "cls loss 484.11419677734375  loc loss 33.74591064453125\n",
      "cls loss 701.6903076171875  loc loss 36.02250671386719\n",
      "cls loss 503.1661682128906  loc loss 33.73519515991211\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.,  1.,  1.])\n",
      "cls loss 614.9078369140625  loc loss 39.25691604614258\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1., 38.,  1.])\n",
      "cls loss 552.987060546875  loc loss 31.655357360839844\n",
      "cls loss 749.09814453125  loc loss 55.58367919921875\n",
      "cls loss 414.324462890625  loc loss 27.635761260986328\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 553.4400634765625  loc loss 35.16240310668945\n",
      "cls loss 470.8809509277344  loc loss 28.683130264282227\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3., 10.,  8.,  3., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.])\n",
      "cls loss 542.941162109375  loc loss 30.919963836669922\n",
      "cls loss 370.363037109375  loc loss 23.960773468017578\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3.,  3., 11.,  3., 10., 10.,  3.,  3., 10.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 442.7531433105469  loc loss 21.733989715576172\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3., 10., 10., 10.])\n",
      "cls loss 453.4913024902344  loc loss 27.391422271728516\n",
      "cls loss 387.36053466796875  loc loss 21.9420223236084\n",
      "cls loss 481.6087646484375  loc loss 31.16419792175293\n",
      "cls loss 702.8587036132812  loc loss 39.84963607788086\n",
      "cls loss 466.48193359375  loc loss 28.283185958862305\n",
      "cls loss 350.5534362792969  loc loss 28.24089241027832\n",
      "cls loss 457.61669921875  loc loss 28.984535217285156\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 9.,  9., 85., 85.])\n",
      "cls loss 356.08782958984375  loc loss 19.835309982299805\n",
      "cls loss 436.6541442871094  loc loss 31.81060791015625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 706.6300048828125  loc loss 48.873477935791016\n",
      "cls loss 614.163818359375  loc loss 29.106739044189453\n",
      "cls loss 670.0888671875  loc loss 48.44841003417969\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10., 10., 10., 10.])\n",
      "cls loss 422.0087890625  loc loss 26.261642456054688\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([13.])\n",
      "cls loss 664.0496826171875  loc loss 52.19148635864258\n",
      "cls loss 226.51263427734375  loc loss 11.947176933288574\n",
      "cls loss 311.2948303222656  loc loss 15.28173828125\n",
      "cls loss 412.8866882324219  loc loss 22.62540626525879\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19.,  1.,  1.,  1., 19., 19.])\n",
      "cls loss 423.68414306640625  loc loss 27.633338928222656\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 341.71844482421875  loc loss 24.81904411315918\n",
      "cls loss 474.41339111328125  loc loss 34.42674255371094\n",
      "cls loss 371.3625793457031  loc loss 20.586551666259766\n",
      "cls loss 536.5599975585938  loc loss 28.24100112915039\n",
      "cls loss 564.403564453125  loc loss 42.270103454589844\n",
      "cls loss 449.41961669921875  loc loss 24.310943603515625\n",
      "cls loss 672.3408813476562  loc loss 47.14373016357422\n",
      "cls loss 257.8935852050781  loc loss 11.417011260986328\n",
      "cls loss 488.8251647949219  loc loss 29.7376708984375\n",
      "cls loss 380.5601806640625  loc loss 19.038719177246094\n",
      "cls loss 419.6430969238281  loc loss 22.648548126220703\n",
      "cls loss 534.8988647460938  loc loss 31.31020736694336\n",
      "cls loss 476.0113525390625  loc loss 23.03799057006836\n",
      "cls loss 666.7536010742188  loc loss 43.473182678222656\n",
      "cls loss 426.9048767089844  loc loss 27.453296661376953\n",
      "cls loss 549.1514892578125  loc loss 39.27802276611328\n",
      "cls loss 814.3302001953125  loc loss 49.15353012084961\n",
      "cls loss 420.11126708984375  loc loss 31.664794921875\n",
      "cls loss 499.57904052734375  loc loss 29.80530548095703\n",
      "cls loss 572.3308715820312  loc loss 45.14385986328125\n",
      "cls loss 656.801025390625  loc loss 46.22954177856445\n",
      "cls loss 794.9525146484375  loc loss 42.204471588134766\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 5.])\n",
      "cls loss 219.75680541992188  loc loss 9.634575843811035\n",
      "cls loss 292.1373291015625  loc loss 12.966127395629883\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 13.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 6., 8., 8.])\n",
      "cls loss 237.90773010253906  loc loss 13.077168464660645\n",
      "cls loss 322.7520751953125  loc loss 16.138782501220703\n",
      "cls loss 619.7352294921875  loc loss 40.67090606689453\n",
      "cls loss 273.98443603515625  loc loss 14.365878105163574\n",
      "cls loss 491.15704345703125  loc loss 37.01581954956055\n",
      "cls loss 747.4490966796875  loc loss 53.785301208496094\n",
      "cls loss 461.88739013671875  loc loss 32.92313003540039\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([42., 42.,  1.,  1.,  1.,  1.,  1.,  1.,  1., 42., 42.])\n",
      "cls loss 521.3516845703125  loc loss 27.509124755859375\n",
      "cls loss 650.031494140625  loc loss 49.115257263183594\n",
      "cls loss 586.9642333984375  loc loss 40.65189743041992\n",
      "cls loss 380.32745361328125  loc loss 24.082401275634766\n",
      "cls loss 503.52813720703125  loc loss 28.04930877685547\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 710.7471313476562  loc loss 45.70967483520508\n",
      "cls loss 580.7583618164062  loc loss 39.59684753417969\n",
      "cls loss 351.4588928222656  loc loss 19.90282440185547\n",
      "cls loss 289.17822265625  loc loss 17.356311798095703\n",
      "cls loss 405.946533203125  loc loss 24.621530532836914\n",
      "cls loss 559.6370239257812  loc loss 34.19777297973633\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15.])\n",
      "cls loss 288.0651550292969  loc loss 10.59512996673584\n",
      "cls loss 483.7333984375  loc loss 29.518264770507812\n",
      "cls loss 410.83544921875  loc loss 27.552474975585938\n",
      "cls loss 739.2649536132812  loc loss 49.50666809082031\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19.,  7.])\n",
      "cls loss 393.8703308105469  loc loss 21.444538116455078\n",
      "cls loss 779.6876220703125  loc loss 51.4796257019043\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 679.95263671875  loc loss 33.416900634765625\n",
      "cls loss 565.5347900390625  loc loss 40.3291130065918\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([38., 38.,  1., 18.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1., 18., 18.,  1.])\n",
      "cls loss 416.0719299316406  loc loss 21.634368896484375\n",
      "cls loss 409.76593017578125  loc loss 19.03154182434082\n",
      "cls loss 759.886962890625  loc loss 52.48284912109375\n",
      "cls loss 565.400634765625  loc loss 31.397886276245117\n",
      "cls loss 499.71783447265625  loc loss 27.346315383911133\n",
      "cls loss 312.72467041015625  loc loss 23.72494888305664\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.])\n",
      "cls loss 221.5025634765625  loc loss 8.610088348388672\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([32.])\n",
      "cls loss 484.85650634765625  loc loss 25.91673469543457\n",
      "cls loss 410.8219299316406  loc loss 28.96619415283203\n",
      "cls loss 530.48388671875  loc loss 41.23666000366211\n",
      "cls loss 465.11566162109375  loc loss 30.685243606567383\n",
      "cls loss 387.1870422363281  loc loss 24.002079010009766\n",
      "cls loss 639.0859375  loc loss 37.76441955566406\n",
      "cls loss 709.63232421875  loc loss 46.75315475463867\n",
      "cls loss 543.717529296875  loc loss 35.63089370727539\n",
      "cls loss 440.6875  loc loss 25.56093406677246\n",
      "cls loss 694.9191284179688  loc loss 44.1016845703125\n",
      "cls loss 472.14337158203125  loc loss 24.008113861083984\n",
      "cls loss 783.8828735351562  loc loss 52.82707214355469\n",
      "cls loss 534.7967529296875  loc loss 29.398427963256836\n",
      "cls loss 437.426025390625  loc loss 32.86183547973633\n",
      "cls loss 334.3974609375  loc loss 15.559003829956055\n",
      "cls loss 376.798828125  loc loss 23.200485229492188\n",
      "cls loss 561.3204956054688  loc loss 36.071712493896484\n",
      "cls loss 594.8097534179688  loc loss 40.00056838989258\n",
      "cls loss 337.81915283203125  loc loss 20.64730453491211\n",
      "cls loss 609.046142578125  loc loss 40.40953826904297\n",
      "cls loss 738.944091796875  loc loss 45.2830696105957\n",
      "cls loss 269.3846740722656  loc loss 17.350088119506836\n",
      "cls loss 712.811279296875  loc loss 47.20106506347656\n",
      "cls loss 524.7109985351562  loc loss 37.175926208496094\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 700.0962524414062  loc loss 52.675209045410156\n",
      "cls loss 335.3311462402344  loc loss 12.516489028930664\n",
      "cls loss 492.3662414550781  loc loss 26.972929000854492\n",
      "cls loss 492.1142578125  loc loss 32.40378952026367\n",
      "cls loss 403.14801025390625  loc loss 22.824806213378906\n",
      "cls loss 246.10968017578125  loc loss 12.609119415283203\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 9., 9., 1., 9., 9., 9., 9., 1., 9.])\n",
      "cls loss 887.7344970703125  loc loss 69.46353912353516\n",
      "cls loss 523.171142578125  loc loss 26.898902893066406\n",
      "cls loss 758.4996337890625  loc loss 60.08856964111328\n",
      "cls loss 323.44683837890625  loc loss 22.69144058227539\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 42., 42.])\n",
      "cls loss 543.0057373046875  loc loss 40.411827087402344\n",
      "cls loss 579.3499755859375  loc loss 42.98950958251953\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  2.,  1.,  1.,  1., 38.,\n",
      "         1.,  1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 38., 38., 38.,  1., 38., 38., 38.,  1.,  1., 38.,  1.,\n",
      "         1.])\n",
      "cls loss 354.091552734375  loc loss 26.436925888061523\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  8.,  8.])\n",
      "cls loss 862.48388671875  loc loss 55.17064666748047\n",
      "cls loss 840.9488525390625  loc loss 63.411224365234375\n",
      "cls loss 328.3328552246094  loc loss 19.07457160949707\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([4., 1., 1., 4.])\n",
      "cls loss 487.57354736328125  loc loss 31.086719512939453\n",
      "cls loss 584.582275390625  loc loss 34.206153869628906\n",
      "cls loss 247.00311279296875  loc loss 12.302414894104004\n",
      "cls loss 328.2425537109375  loc loss 20.76560401916504\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([51.,  1.])\n",
      "cls loss 245.76271057128906  loc loss 10.02401351928711\n",
      "cls loss 343.78021240234375  loc loss 18.445018768310547\n",
      "cls loss 596.7347412109375  loc loss 33.72285079956055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 612.883544921875  loc loss 43.53349685668945\n",
      "cls loss 858.9893188476562  loc loss 46.14423751831055\n",
      "cls loss 1052.0252685546875  loc loss 70.05022430419922\n",
      "cls loss 449.23809814453125  loc loss 27.19617462158203\n",
      "cls loss 654.7030029296875  loc loss 48.10350036621094\n",
      "cls loss 697.617919921875  loc loss 47.31858825683594\n",
      "cls loss 545.956787109375  loc loss 31.624752044677734\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  3.,  1.,  1.,  1.,  3.,  1.,  1.,\n",
      "         1.,  1.,  1.])\n",
      "cls loss 565.31396484375  loc loss 24.877763748168945\n",
      "cls loss 644.7349853515625  loc loss 32.284706115722656\n",
      "cls loss 568.5635986328125  loc loss 30.55068588256836\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "cls loss 478.98309326171875  loc loss 28.43661880493164\n",
      "cls loss 266.6968994140625  loc loss 22.371280670166016\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3.])\n",
      "cls loss 211.9586181640625  loc loss 11.798447608947754\n",
      "cls loss 402.156005859375  loc loss 26.46354866027832\n",
      "cls loss 342.115966796875  loc loss 25.311687469482422\n",
      "cls loss 638.486572265625  loc loss 41.01236343383789\n",
      "cls loss 374.0741882324219  loc loss 21.731693267822266\n",
      "cls loss 341.281982421875  loc loss 24.209697723388672\n",
      "cls loss 1022.45166015625  loc loss 68.25813293457031\n",
      "cls loss 438.23907470703125  loc loss 34.264591217041016\n",
      "cls loss 347.94696044921875  loc loss 23.767587661743164\n",
      "cls loss 425.83447265625  loc loss 24.168954849243164\n",
      "cls loss 395.0289611816406  loc loss 27.515216827392578\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 705.2132568359375  loc loss 46.325443267822266\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  9., 64., 64., 64., 64., 64., 64., 64., 64., 64.,  9.,  9.,  9.,\n",
      "         9.])\n",
      "cls loss 360.4645080566406  loc loss 17.202409744262695\n",
      "cls loss 899.7730712890625  loc loss 70.47461700439453\n",
      "cls loss 483.0722961425781  loc loss 31.450077056884766\n",
      "cls loss 615.2106323242188  loc loss 40.78338623046875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.,  3.,  3.])\n",
      "cls loss 384.9352722167969  loc loss 20.908605575561523\n",
      "cls loss 418.7518615722656  loc loss 28.3625545501709\n",
      "cls loss 412.6219482421875  loc loss 29.453357696533203\n",
      "cls loss 437.6565856933594  loc loss 31.924102783203125\n",
      "cls loss 454.439697265625  loc loss 36.013145446777344\n",
      "cls loss 487.386474609375  loc loss 34.111324310302734\n",
      "cls loss 441.7821044921875  loc loss 33.0683479309082\n",
      "cls loss 479.7127685546875  loc loss 27.42342758178711\n",
      "cls loss 602.6612548828125  loc loss 39.435150146484375\n",
      "cls loss 458.448974609375  loc loss 27.546836853027344\n",
      "cls loss 372.2838134765625  loc loss 17.78517723083496\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21.])\n",
      "cls loss 294.88494873046875  loc loss 16.76732063293457\n",
      "cls loss 416.4166259765625  loc loss 34.31816101074219\n",
      "cls loss 618.5618896484375  loc loss 41.1431884765625\n",
      "cls loss 329.6639709472656  loc loss 18.75494384765625\n",
      "cls loss 479.5724792480469  loc loss 29.6409912109375\n",
      "cls loss 899.5784912109375  loc loss 47.14748001098633\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 42., 42.,  1.,  1.])\n",
      "cls loss 467.1824035644531  loc loss 28.966064453125\n",
      "cls loss 308.92572021484375  loc loss 21.094593048095703\n",
      "cls loss 437.94842529296875  loc loss 31.146963119506836\n",
      "cls loss 598.751953125  loc loss 48.292015075683594\n",
      "cls loss 384.2052001953125  loc loss 24.478347778320312\n",
      "cls loss 586.4283447265625  loc loss 43.215423583984375\n",
      "cls loss 547.9927978515625  loc loss 38.84479904174805\n",
      "cls loss 560.3475341796875  loc loss 34.33735275268555\n",
      "cls loss 452.8209533691406  loc loss 27.009674072265625\n",
      "cls loss 383.09417724609375  loc loss 24.59698486328125\n",
      "cls loss 324.003662109375  loc loss 12.860209465026855\n",
      "cls loss 426.19427490234375  loc loss 26.998455047607422\n",
      "cls loss 653.61767578125  loc loss 44.696624755859375\n",
      "cls loss 509.034423828125  loc loss 30.426259994506836\n",
      "cls loss 468.7855529785156  loc loss 33.99409484863281\n",
      "cls loss 523.2947387695312  loc loss 31.382143020629883\n",
      "cls loss 754.1817626953125  loc loss 54.439208984375\n",
      "cls loss 565.6058349609375  loc loss 40.96318817138672\n",
      "cls loss 632.1433715820312  loc loss 35.59344482421875\n",
      "cls loss 367.8861389160156  loc loss 18.005876541137695\n",
      "cls loss 528.8390502929688  loc loss 33.243282318115234\n",
      "cls loss 489.494384765625  loc loss 28.32168960571289\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 5., 5., 5., 5., 5., 5.])\n",
      "cls loss 334.939453125  loc loss 22.523029327392578\n",
      "cls loss 424.0355224609375  loc loss 22.952117919921875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([13.])\n",
      "cls loss 295.60137939453125  loc loss 17.17046356201172\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([44., 10.,  1.,  1.,  1.])\n",
      "cls loss 278.2635803222656  loc loss 18.158870697021484\n",
      "cls loss 529.3497314453125  loc loss 27.39982032775879\n",
      "cls loss 451.31781005859375  loc loss 25.440494537353516\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19., 19., 19., 19., 19., 19., 19.])\n",
      "cls loss 531.9268798828125  loc loss 28.67306137084961\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([56.])\n",
      "cls loss 977.20458984375  loc loss 63.9622688293457\n",
      "cls loss 607.212646484375  loc loss 45.66200637817383\n",
      "cls loss 772.8794555664062  loc loss 51.91336441040039\n",
      "cls loss 755.0234375  loc loss 56.849021911621094\n",
      "cls loss 486.4989013671875  loc loss 26.07511329650879\n",
      "cls loss 763.276611328125  loc loss 50.62469482421875\n",
      "cls loss 438.02056884765625  loc loss 28.500652313232422\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 36.])\n",
      "cls loss 531.5657348632812  loc loss 27.79659080505371\n",
      "cls loss 472.5063781738281  loc loss 31.015003204345703\n",
      "cls loss 444.2668151855469  loc loss 26.69597816467285\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5.])\n",
      "cls loss 524.11669921875  loc loss 31.923744201660156\n",
      "cls loss 278.1795654296875  loc loss 14.946840286254883\n",
      "cls loss 675.6415405273438  loc loss 36.065486907958984\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "cls loss 573.1842041015625  loc loss 37.271575927734375\n",
      "cls loss 542.7522583007812  loc loss 37.59683609008789\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 549.9561767578125  loc loss 38.11250686645508\n",
      "cls loss 632.1102294921875  loc loss 43.79860305786133\n",
      "cls loss 535.227294921875  loc loss 46.60123062133789\n",
      "cls loss 385.3138732910156  loc loss 25.93386459350586\n",
      "cls loss 446.09942626953125  loc loss 32.730892181396484\n",
      "cls loss 475.6684875488281  loc loss 29.83486557006836\n",
      "cls loss 741.8760375976562  loc loss 40.32191848754883\n",
      "cls loss 335.144775390625  loc loss 16.41792869567871\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 11., 15., 10., 10., 10., 10., 10.])\n",
      "cls loss 773.032958984375  loc loss 47.098228454589844\n",
      "cls loss 423.0437316894531  loc loss 30.826675415039062\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3.])\n",
      "cls loss 463.9560852050781  loc loss 31.782638549804688\n",
      "cls loss 429.30560302734375  loc loss 23.210803985595703\n",
      "cls loss 464.9915771484375  loc loss 22.726863861083984\n",
      "cls loss 594.7279052734375  loc loss 27.48672103881836\n",
      "cls loss 308.0183410644531  loc loss 15.048832893371582\n",
      "cls loss 472.1885986328125  loc loss 30.928194046020508\n",
      "cls loss 532.154052734375  loc loss 36.89092254638672\n",
      "cls loss 446.96917724609375  loc loss 32.519813537597656\n",
      "cls loss 1050.573486328125  loc loss 73.12335205078125\n",
      "cls loss 723.6605834960938  loc loss 46.660858154296875\n",
      "cls loss 476.36627197265625  loc loss 32.99043273925781\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  9.,  9.,  9.,  6.,  6., 85., 85.,  8.,  1.,  1.,  1.,  1.,\n",
      "         6.,  6.])\n",
      "cls loss 314.5376892089844  loc loss 25.196592330932617\n",
      "cls loss 767.98681640625  loc loss 54.345550537109375\n",
      "cls loss 924.9285278320312  loc loss 56.39365005493164\n",
      "cls loss 617.9493408203125  loc loss 42.183902740478516\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10.,  3.,  3., 10.])\n",
      "cls loss 422.2352294921875  loc loss 21.804840087890625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([7.])\n",
      "cls loss 504.05718994140625  loc loss 33.015262603759766\n",
      "cls loss 516.59130859375  loc loss 31.041370391845703\n",
      "cls loss 479.77362060546875  loc loss 39.986568450927734\n",
      "cls loss 692.4796142578125  loc loss 55.67352294921875\n",
      "cls loss 461.2552490234375  loc loss 31.856483459472656\n",
      "cls loss 671.4721069335938  loc loss 43.02020263671875\n",
      "cls loss 839.2539672851562  loc loss 48.89509201049805\n",
      "cls loss 501.3222351074219  loc loss 33.65333557128906\n",
      "cls loss 545.4164428710938  loc loss 38.763763427734375\n",
      "cls loss 443.530029296875  loc loss 32.70863342285156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 673.270751953125  loc loss 51.44584274291992\n",
      "cls loss 517.274658203125  loc loss 32.261661529541016\n",
      "cls loss 421.04840087890625  loc loss 24.626073837280273\n",
      "cls loss 636.1039428710938  loc loss 47.83824157714844\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([62.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([62.])\n",
      "cls loss 305.087890625  loc loss 14.363794326782227\n",
      "cls loss 483.24273681640625  loc loss 34.277099609375\n",
      "cls loss 478.98638916015625  loc loss 30.816436767578125\n",
      "cls loss 323.52392578125  loc loss 15.287376403808594\n",
      "cls loss 616.7234497070312  loc loss 40.4614143371582\n",
      "cls loss 660.1805419921875  loc loss 35.45035934448242\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([28.])\n",
      "cls loss 737.9912109375  loc loss 37.161163330078125\n",
      "cls loss 607.8880004882812  loc loss 36.997657775878906\n",
      "cls loss 609.4681396484375  loc loss 40.1487922668457\n",
      "cls loss 613.859130859375  loc loss 38.34254455566406\n",
      "cls loss 843.8292236328125  loc loss 55.860321044921875\n",
      "cls loss 487.0813903808594  loc loss 29.720386505126953\n",
      "cls loss 615.317626953125  loc loss 36.06048583984375\n",
      "cls loss 512.352294921875  loc loss 42.05105209350586\n",
      "cls loss 841.759033203125  loc loss 66.14000701904297\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([81.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 572.8875732421875  loc loss 23.7260799407959\n",
      "cls loss 426.0878601074219  loc loss 22.774093627929688\n",
      "cls loss 334.4658203125  loc loss 23.895666122436523\n",
      "cls loss 299.60906982421875  loc loss 11.808667182922363\n",
      "cls loss 337.47161865234375  loc loss 24.136062622070312\n",
      "cls loss 382.1436767578125  loc loss 23.97662353515625\n",
      "cls loss 432.2126770019531  loc loss 27.853416442871094\n",
      "cls loss 587.3036499023438  loc loss 47.19358825683594\n",
      "cls loss 680.3433227539062  loc loss 43.01613235473633\n",
      "cls loss 1224.1904296875  loc loss 81.0204849243164\n",
      "cls loss 493.54693603515625  loc loss 25.536195755004883\n",
      "cls loss 601.973876953125  loc loss 43.13510513305664\n",
      "cls loss 431.14361572265625  loc loss 26.956867218017578\n",
      "cls loss 578.1620483398438  loc loss 32.09049606323242\n",
      "cls loss 486.56158447265625  loc loss 27.741741180419922\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([44., 44.])\n",
      "cls loss 445.37469482421875  loc loss 21.278799057006836\n",
      "cls loss 467.42486572265625  loc loss 30.84092903137207\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15.])\n",
      "cls loss 503.3667297363281  loc loss 25.062877655029297\n",
      "cls loss 244.15371704101562  loc loss 14.721370697021484\n",
      "cls loss 501.3990478515625  loc loss 30.07074737548828\n",
      "cls loss 284.9574890136719  loc loss 16.717086791992188\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([1., 3., 3.])\n",
      "cls loss 329.2947998046875  loc loss 22.953195571899414\n",
      "cls loss 253.1155242919922  loc loss 11.537616729736328\n",
      "cls loss 480.31451416015625  loc loss 29.15581703186035\n",
      "cls loss 525.5420532226562  loc loss 30.415437698364258\n",
      "cls loss 475.82659912109375  loc loss 31.613658905029297\n",
      "cls loss 434.06695556640625  loc loss 25.785839080810547\n",
      "cls loss 397.74688720703125  loc loss 29.947751998901367\n",
      "cls loss 557.150390625  loc loss 35.090293884277344\n",
      "cls loss 394.4043273925781  loc loss 26.456270217895508\n",
      "cls loss 533.7356567382812  loc loss 36.07548141479492\n",
      "cls loss 351.81976318359375  loc loss 19.553234100341797\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 622.0860595703125  loc loss 37.689910888671875\n",
      "cls loss 738.703369140625  loc loss 33.888736724853516\n",
      "cls loss 632.3621215820312  loc loss 43.885066986083984\n",
      "cls loss 634.8950805664062  loc loss 49.25321578979492\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10., 10., 10.,  1.,  1.,  1.,  1.,  1.,  1.,  8.,  8.,\n",
      "         1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10., 10., 10.,  1.,  1.,  1.,  1.,  1.,  1.,  8.,  8.,\n",
      "         1.])\n",
      "cls loss 563.3968505859375  loc loss 26.789932250976562\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 3., 3., 3.])\n",
      "cls loss 489.32733154296875  loc loss 30.476308822631836\n",
      "cls loss 347.4068603515625  loc loss 19.894865036010742\n",
      "cls loss 268.4039611816406  loc loss 12.85993766784668\n",
      "cls loss 463.338623046875  loc loss 34.76289749145508\n",
      "cls loss 363.5611572265625  loc loss 17.300445556640625\n",
      "cls loss 418.18719482421875  loc loss 27.466758728027344\n",
      "cls loss 474.2249755859375  loc loss 31.665321350097656\n",
      "cls loss 661.8685302734375  loc loss 44.827903747558594\n",
      "cls loss 558.4959716796875  loc loss 27.302005767822266\n",
      "cls loss 531.9404296875  loc loss 29.533374786376953\n",
      "cls loss 566.1725463867188  loc loss 38.99176025390625\n",
      "cls loss 402.349853515625  loc loss 31.557838439941406\n",
      "cls loss 770.3428344726562  loc loss 58.2530517578125\n",
      "cls loss 375.34423828125  loc loss 19.2691650390625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 604.34033203125  loc loss 37.014041900634766\n",
      "cls loss 290.79296875  loc loss 12.001853942871094\n",
      "cls loss 730.02734375  loc loss 45.57063293457031\n",
      "cls loss 365.7467041015625  loc loss 21.270856857299805\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 34.])\n",
      "cls loss 606.8951416015625  loc loss 32.13578796386719\n",
      "cls loss 291.831787109375  loc loss 18.88141441345215\n",
      "cls loss 566.59375  loc loss 35.91101837158203\n",
      "cls loss 191.49520874023438  loc loss 14.16988754272461\n",
      "cls loss 475.444091796875  loc loss 29.68169593811035\n",
      "cls loss 458.41290283203125  loc loss 37.881874084472656\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 38.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16., 16., 16.,  9.,  9.,  9., 16., 16., 16., 85.,  9.])\n",
      "cls loss 472.33538818359375  loc loss 30.97408103942871\n",
      "cls loss 532.741943359375  loc loss 41.21892166137695\n",
      "cls loss 710.0804443359375  loc loss 47.70036697387695\n",
      "cls loss 1062.3717041015625  loc loss 68.48274230957031\n",
      "cls loss 315.4360046386719  loc loss 16.661762237548828\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3., 10.,  8.,  8., 10., 10., 10.,  3.,  3., 14.])\n",
      "cls loss 351.58935546875  loc loss 18.122480392456055\n",
      "cls loss 662.1865234375  loc loss 35.61231231689453\n",
      "cls loss 293.750244140625  loc loss 10.648423194885254\n",
      "cls loss 448.8224182128906  loc loss 19.09743881225586\n",
      "cls loss 588.856689453125  loc loss 34.90229415893555\n",
      "cls loss 504.20355224609375  loc loss 31.123706817626953\n",
      "cls loss 282.60382080078125  loc loss 14.774310111999512\n",
      "cls loss 337.2434387207031  loc loss 19.807146072387695\n",
      "cls loss 531.3148193359375  loc loss 31.91547393798828\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42., 42.,  1.])\n",
      "cls loss 514.2670288085938  loc loss 34.56025695800781\n",
      "cls loss 399.0255126953125  loc loss 23.83306884765625\n",
      "cls loss 548.82373046875  loc loss 42.18940353393555\n",
      "cls loss 652.2808837890625  loc loss 39.60148239135742\n",
      "cls loss 438.88037109375  loc loss 28.176311492919922\n",
      "cls loss 542.59130859375  loc loss 38.85316848754883\n",
      "cls loss 350.0768127441406  loc loss 23.80535125732422\n",
      "cls loss 365.78021240234375  loc loss 25.620845794677734\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20.])\n",
      "cls loss 271.00823974609375  loc loss 16.368412017822266\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([11.])\n",
      "cls loss 369.03143310546875  loc loss 18.026546478271484\n",
      "cls loss 241.74722290039062  loc loss 13.487197875976562\n",
      "cls loss 561.047607421875  loc loss 43.24378204345703\n",
      "cls loss 258.75067138671875  loc loss 11.844413757324219\n",
      "cls loss 560.6757202148438  loc loss 30.075273513793945\n",
      "cls loss 306.1994934082031  loc loss 18.780311584472656\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 35., 27.])\n",
      "cls loss 514.8975219726562  loc loss 30.26034164428711\n",
      "cls loss 563.7949829101562  loc loss 41.56327438354492\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 379.70208740234375  loc loss 21.862977981567383\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([42.,  1.])\n",
      "cls loss 481.4750061035156  loc loss 33.16033172607422\n",
      "cls loss 462.3782653808594  loc loss 25.98882293701172\n",
      "cls loss 549.305419921875  loc loss 34.01318359375\n",
      "cls loss 693.5052490234375  loc loss 43.44257354736328\n",
      "cls loss 616.7125244140625  loc loss 36.29369354248047\n",
      "cls loss 414.08807373046875  loc loss 30.148984909057617\n",
      "cls loss 357.04425048828125  loc loss 26.75803565979004\n",
      "cls loss 223.4617919921875  loc loss 10.568212509155273\n",
      "cls loss 415.67437744140625  loc loss 22.884994506835938\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 1., 1.])\n",
      "cls loss 403.448974609375  loc loss 23.415700912475586\n",
      "cls loss 460.123046875  loc loss 30.024417877197266\n",
      "cls loss 449.8807067871094  loc loss 28.19453239440918\n",
      "cls loss 373.9388427734375  loc loss 25.978124618530273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 452.30303955078125  loc loss 27.2108211517334\n",
      "cls loss 485.08367919921875  loc loss 34.181968688964844\n",
      "cls loss 669.5176391601562  loc loss 39.542293548583984\n",
      "cls loss 568.1032104492188  loc loss 42.80081558227539\n",
      "cls loss 525.3604736328125  loc loss 31.72355842590332\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 413.6083984375  loc loss 27.876829147338867\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 499.4416809082031  loc loss 24.200544357299805\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([81.])\n",
      "cls loss 598.05517578125  loc loss 35.541866302490234\n",
      "cls loss 371.71624755859375  loc loss 25.306270599365234\n",
      "cls loss 268.923828125  loc loss 14.963111877441406\n",
      "cls loss 416.74591064453125  loc loss 22.246065139770508\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3.,  1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 19.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 19.])\n",
      "cls loss 539.4735107421875  loc loss 37.9286994934082\n",
      "cls loss 318.7248229980469  loc loss 17.16744041442871\n",
      "cls loss 333.799560546875  loc loss 18.944719314575195\n",
      "cls loss 642.0281372070312  loc loss 46.83994674682617\n",
      "cls loss 324.51641845703125  loc loss 20.18149185180664\n",
      "cls loss 408.58343505859375  loc loss 26.32038116455078\n",
      "cls loss 510.263427734375  loc loss 32.792476654052734\n",
      "cls loss 400.4346923828125  loc loss 27.7159423828125\n",
      "cls loss 510.34954833984375  loc loss 29.07678985595703\n",
      "cls loss 586.7329711914062  loc loss 38.791038513183594\n",
      "cls loss 705.8494873046875  loc loss 62.00446319580078\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 81.])\n",
      "cls loss 510.59832763671875  loc loss 26.238067626953125\n",
      "cls loss 436.1594543457031  loc loss 24.20557975769043\n",
      "cls loss 488.38433837890625  loc loss 26.072690963745117\n",
      "cls loss 371.0003662109375  loc loss 18.753032684326172\n",
      "cls loss 325.6799011230469  loc loss 20.95025634765625\n",
      "cls loss 352.4418029785156  loc loss 28.4431095123291\n",
      "cls loss 294.00732421875  loc loss 21.404130935668945\n",
      "cls loss 244.33714294433594  loc loss 16.04371452331543\n",
      "cls loss 335.15203857421875  loc loss 21.610668182373047\n",
      "cls loss 449.23797607421875  loc loss 27.593656539916992\n",
      "cls loss 386.678955078125  loc loss 30.262611389160156\n",
      "cls loss 405.4410400390625  loc loss 30.97079086303711\n",
      "cls loss 247.298828125  loc loss 17.060380935668945\n",
      "cls loss 840.709716796875  loc loss 58.325843811035156\n",
      "cls loss 510.1816711425781  loc loss 34.09621047973633\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 453.1619873046875  loc loss 22.835826873779297\n",
      "cls loss 508.05645751953125  loc loss 32.970611572265625\n",
      "cls loss 394.2913818359375  loc loss 24.24001121520996\n",
      "cls loss 595.6497802734375  loc loss 39.21165466308594\n",
      "cls loss 560.2039794921875  loc loss 34.60031509399414\n",
      "cls loss 514.6151733398438  loc loss 31.078296661376953\n",
      "cls loss 395.42437744140625  loc loss 24.2701473236084\n",
      "cls loss 305.1888732910156  loc loss 19.165733337402344\n",
      "cls loss 462.62213134765625  loc loss 26.991872787475586\n",
      "cls loss 503.12310791015625  loc loss 33.58513641357422\n",
      "cls loss 513.8462524414062  loc loss 28.811174392700195\n",
      "cls loss 648.4537353515625  loc loss 46.73357391357422\n",
      "cls loss 651.583740234375  loc loss 52.43677520751953\n",
      "cls loss 467.080322265625  loc loss 33.5571403503418\n",
      "cls loss 651.2288208007812  loc loss 50.74124526977539\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1., 38., 47.,  1.,  1.,  1.,  1.,  1., 62.])\n",
      "cls loss 459.00372314453125  loc loss 22.01912498474121\n",
      "cls loss 542.3013305664062  loc loss 32.60356140136719\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 586.8355712890625  loc loss 33.456703186035156\n",
      "cls loss 607.7987670898438  loc loss 45.2109260559082\n",
      "cls loss 417.5129699707031  loc loss 20.810958862304688\n",
      "cls loss 492.20465087890625  loc loss 39.2516975402832\n",
      "cls loss 456.93927001953125  loc loss 26.399778366088867\n",
      "cls loss 263.06341552734375  loc loss 10.396618843078613\n",
      "cls loss 407.03118896484375  loc loss 23.815372467041016\n",
      "cls loss 353.0380859375  loc loss 16.137617111206055\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1., 35.])\n",
      "cls loss 392.645751953125  loc loss 21.969440460205078\n",
      "cls loss 592.8286743164062  loc loss 31.279903411865234\n",
      "cls loss 578.4872436523438  loc loss 37.76001739501953\n",
      "cls loss 507.70843505859375  loc loss 42.04817199707031\n",
      "cls loss 417.4385986328125  loc loss 32.73807907104492\n",
      "cls loss 560.9849853515625  loc loss 41.89573287963867\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 316.030517578125  loc loss 18.024328231811523\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 461.77923583984375  loc loss 20.148082733154297\n",
      "cls loss 740.0731201171875  loc loss 38.117671966552734\n",
      "cls loss 868.2167358398438  loc loss 67.6186752319336\n",
      "cls loss 446.3721923828125  loc loss 22.97846794128418\n",
      "cls loss 394.86859130859375  loc loss 24.948823928833008\n",
      "cls loss 393.49859619140625  loc loss 20.818443298339844\n",
      "cls loss 404.89996337890625  loc loss 25.079566955566406\n",
      "cls loss 362.4407043457031  loc loss 16.072158813476562\n",
      "cls loss 656.1383056640625  loc loss 45.07952117919922\n",
      "cls loss 549.995361328125  loc loss 33.64422607421875\n",
      "cls loss 273.3543701171875  loc loss 19.427337646484375\n",
      "cls loss 539.120361328125  loc loss 29.400257110595703\n",
      "cls loss 639.0936279296875  loc loss 51.190826416015625\n",
      "cls loss 522.16455078125  loc loss 33.7818489074707\n",
      "cls loss 450.11480712890625  loc loss 25.393041610717773\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.])\n",
      "cls loss 433.9101257324219  loc loss 31.421186447143555\n",
      "cls loss 426.7982177734375  loc loss 29.367528915405273\n",
      "cls loss 546.927978515625  loc loss 35.96809005737305\n",
      "cls loss 858.5084228515625  loc loss 67.36323547363281\n",
      "cls loss 360.57867431640625  loc loss 17.730398178100586\n",
      "cls loss 469.56756591796875  loc loss 29.01361083984375\n",
      "cls loss 377.1551513671875  loc loss 20.477685928344727\n",
      "cls loss 401.0177917480469  loc loss 25.78404426574707\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 21., 21., 21.])\n",
      "cls loss 425.05865478515625  loc loss 26.09626579284668\n",
      "cls loss 394.8155822753906  loc loss 19.56942367553711\n",
      "cls loss 425.42181396484375  loc loss 28.46451187133789\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 35.])\n",
      "cls loss 551.0572509765625  loc loss 34.325565338134766\n",
      "cls loss 204.4835205078125  loc loss 11.167153358459473\n",
      "cls loss 350.1406555175781  loc loss 22.8201847076416\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 334.0870056152344  loc loss 14.957300186157227\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 38., 38.,  9., 38.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1.,  1.])\n",
      "cls loss 381.95355224609375  loc loss 24.444250106811523\n",
      "cls loss 640.1983642578125  loc loss 39.529083251953125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 2.,  1., 77., 31., 10., 10.,  1.,  4., 10.])\n",
      "cls loss 322.026611328125  loc loss 14.964954376220703\n",
      "cls loss 599.4661254882812  loc loss 34.10677719116211\n",
      "cls loss 1202.0709228515625  loc loss 67.50433349609375\n",
      "cls loss 363.9539794921875  loc loss 24.968740463256836\n",
      "cls loss 525.1421508789062  loc loss 38.36708450317383\n",
      "cls loss 390.0440979003906  loc loss 19.417715072631836\n",
      "cls loss 379.4393310546875  loc loss 18.35451889038086\n",
      "cls loss 535.9878540039062  loc loss 27.195106506347656\n",
      "cls loss 552.226806640625  loc loss 29.413930892944336\n",
      "cls loss 483.6878662109375  loc loss 34.17902374267578\n",
      "cls loss 389.63287353515625  loc loss 18.619400024414062\n",
      "cls loss 400.89984130859375  loc loss 21.718563079833984\n",
      "cls loss 758.47509765625  loc loss 46.26466751098633\n",
      "cls loss 662.5491943359375  loc loss 39.33555603027344\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1., 42., 42., 42., 42., 42., 42.,  1.,\n",
      "         1.,  1.,  1., 42.,  1.,  1., 42.,  1.])\n",
      "cls loss 364.0965881347656  loc loss 25.796092987060547\n",
      "cls loss 558.9430541992188  loc loss 33.11579513549805\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.])\n",
      "cls loss 240.478271484375  loc loss 13.855188369750977\n",
      "cls loss 559.4517822265625  loc loss 35.54667663574219\n",
      "cls loss 426.2575378417969  loc loss 30.755834579467773\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([11.])\n",
      "cls loss 266.73614501953125  loc loss 15.582530975341797\n",
      "cls loss 318.8237609863281  loc loss 15.406450271606445\n",
      "cls loss 338.17095947265625  loc loss 15.326107025146484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 561.998779296875  loc loss 34.25267028808594\n",
      "cls loss 464.71575927734375  loc loss 26.093029022216797\n",
      "cls loss 473.1722106933594  loc loss 31.576416015625\n",
      "cls loss 687.3797607421875  loc loss 35.359230041503906\n",
      "cls loss 347.0599670410156  loc loss 20.360538482666016\n",
      "cls loss 719.9581298828125  loc loss 48.576202392578125\n",
      "cls loss 347.76171875  loc loss 22.105915069580078\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 329.3566589355469  loc loss 21.782493591308594\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1., 38., 38., 42.])\n",
      "cls loss 423.41876220703125  loc loss 30.328523635864258\n",
      "cls loss 392.91961669921875  loc loss 23.04318618774414\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 349.277099609375  loc loss 24.40205955505371\n",
      "cls loss 787.0623779296875  loc loss 53.43364715576172\n",
      "cls loss 482.90655517578125  loc loss 30.760021209716797\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10.,  3.,  3.,  6.,  8.,  8.,  1.,  1.,  1., 10.])\n",
      "cls loss 396.8030090332031  loc loss 19.98284339904785\n",
      "cls loss 246.9361572265625  loc loss 9.227980613708496\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10.,  3.])\n",
      "cls loss 364.25823974609375  loc loss 21.207359313964844\n",
      "cls loss 195.89291381835938  loc loss 11.34827709197998\n",
      "cls loss 469.4596862792969  loc loss 32.367313385009766\n",
      "cls loss 553.3663330078125  loc loss 34.46000289916992\n",
      "cls loss 396.8923645019531  loc loss 23.37532615661621\n",
      "cls loss 280.0312805175781  loc loss 14.09698486328125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 34.])\n",
      "cls loss 659.2354125976562  loc loss 40.64399719238281\n",
      "cls loss 715.4652099609375  loc loss 57.55690002441406\n",
      "cls loss 455.43963623046875  loc loss 33.0988883972168\n",
      "cls loss 364.90789794921875  loc loss 24.825883865356445\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.,  1.])\n",
      "cls loss 398.046630859375  loc loss 18.51940155029297\n",
      "cls loss 619.876953125  loc loss 47.11393737792969\n",
      "cls loss 912.87744140625  loc loss 59.94742202758789\n",
      "cls loss 760.8800048828125  loc loss 39.94941329956055\n",
      "cls loss 459.0208740234375  loc loss 23.80392074584961\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 534.1710205078125  loc loss 30.29660415649414\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10.])\n",
      "cls loss 332.9093017578125  loc loss 17.163827896118164\n",
      "cls loss 490.4146728515625  loc loss 24.341224670410156\n",
      "cls loss 445.55450439453125  loc loss 28.058494567871094\n",
      "cls loss 326.1905822753906  loc loss 18.828645706176758\n",
      "cls loss 425.1553955078125  loc loss 27.091068267822266\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21.,\n",
      "        21.])\n",
      "cls loss 554.7862548828125  loc loss 32.03892135620117\n",
      "cls loss 439.47564697265625  loc loss 26.501296997070312\n",
      "cls loss 293.3581237792969  loc loss 13.460817337036133\n",
      "cls loss 628.57373046875  loc loss 40.246185302734375\n",
      "cls loss 478.7422180175781  loc loss 30.988245010375977\n",
      "cls loss 350.9345703125  loc loss 18.1606388092041\n",
      "cls loss 698.0992431640625  loc loss 44.28375244140625\n",
      "cls loss 828.3372802734375  loc loss 57.65848159790039\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15., 85.])\n",
      "cls loss 532.2277221679688  loc loss 33.21473693847656\n",
      "cls loss 536.628662109375  loc loss 39.65586471557617\n",
      "cls loss 555.744140625  loc loss 39.793636322021484\n",
      "cls loss 482.0057373046875  loc loss 27.463220596313477\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 8., 8.])\n",
      "cls loss 312.27142333984375  loc loss 14.407135009765625\n",
      "cls loss 329.79632568359375  loc loss 24.139434814453125\n",
      "cls loss 415.94476318359375  loc loss 25.644954681396484\n",
      "cls loss 351.6722412109375  loc loss 19.16427993774414\n",
      "cls loss 387.834716796875  loc loss 22.932907104492188\n",
      "cls loss 549.63623046875  loc loss 32.9869499206543\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1., 35., 27., 27.,  1., 27.,  1.])\n",
      "cls loss 676.1561889648438  loc loss 49.00848388671875\n",
      "cls loss 371.1698913574219  loc loss 22.253646850585938\n",
      "cls loss 416.8062744140625  loc loss 30.067062377929688\n",
      "cls loss 387.94854736328125  loc loss 34.596744537353516\n",
      "cls loss 354.1977233886719  loc loss 26.550640106201172\n",
      "cls loss 393.776123046875  loc loss 30.10563850402832\n",
      "cls loss 400.73651123046875  loc loss 30.76058006286621\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  2.,  2.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  2.,  2.])\n",
      "cls loss 211.55227661132812  loc loss 8.634079933166504\n",
      "cls loss 638.4780883789062  loc loss 38.98980712890625\n",
      "cls loss 429.48583984375  loc loss 19.404403686523438\n",
      "cls loss 698.4295654296875  loc loss 50.57841873168945\n",
      "cls loss 280.0434265136719  loc loss 16.011436462402344\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 19., 19., 19., 16.])\n",
      "cls loss 297.21044921875  loc loss 12.669946670532227\n",
      "cls loss 235.116455078125  loc loss 9.728864669799805\n",
      "cls loss 387.9315490722656  loc loss 19.380657196044922\n",
      "cls loss 508.083251953125  loc loss 32.67931365966797\n",
      "cls loss 218.58932495117188  loc loss 16.48571014404297\n",
      "cls loss 564.0201416015625  loc loss 42.818965911865234\n",
      "cls loss 403.7007141113281  loc loss 26.910383224487305\n",
      "cls loss 437.19830322265625  loc loss 28.139883041381836\n",
      "cls loss 558.407958984375  loc loss 37.37812042236328\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 588.833251953125  loc loss 26.737606048583984\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 787.7965087890625  loc loss 66.65737915039062\n",
      "cls loss 1020.6142578125  loc loss 92.23297882080078\n",
      "cls loss 532.44677734375  loc loss 30.978450775146484\n",
      "cls loss 468.99114990234375  loc loss 29.07054901123047\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3.,  3.,  3.,  3.,  3., 10.])\n",
      "cls loss 239.53897094726562  loc loss 14.788503646850586\n",
      "cls loss 502.1507568359375  loc loss 23.63232421875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 1., 1., 1., 3., 3., 3., 3.])\n",
      "cls loss 380.4364013671875  loc loss 21.48362922668457\n",
      "cls loss 741.1054077148438  loc loss 46.32594680786133\n",
      "cls loss 579.05615234375  loc loss 36.43307876586914\n",
      "cls loss 374.1539306640625  loc loss 21.85118865966797\n",
      "cls loss 585.689697265625  loc loss 39.66691207885742\n",
      "cls loss 356.32275390625  loc loss 25.9987735748291\n",
      "cls loss 564.500244140625  loc loss 39.215728759765625\n",
      "cls loss 423.021728515625  loc loss 39.72517395019531\n",
      "cls loss 440.6683654785156  loc loss 27.381921768188477\n",
      "cls loss 890.0213623046875  loc loss 72.42791748046875\n",
      "cls loss 594.820068359375  loc loss 43.05668258666992\n",
      "cls loss 406.2549133300781  loc loss 19.63016128540039\n",
      "cls loss 264.5969543457031  loc loss 11.448813438415527\n",
      "cls loss 315.25048828125  loc loss 14.941877365112305\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3., 10., 10., 10., 10., 10., 10., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10., 10., 10., 10., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 11., 10., 10., 10., 10., 10.,  3.,  3.,  3.,  3.,  3.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 11., 10., 10., 10., 10., 10.,  3.,  3.,  3.,  3.,  3.])\n",
      "cls loss 270.1824645996094  loc loss 12.602148056030273\n",
      "cls loss 349.3895263671875  loc loss 15.749509811401367\n",
      "cls loss 292.4110412597656  loc loss 17.09469223022461\n",
      "cls loss 310.43475341796875  loc loss 13.41330337524414\n",
      "cls loss 360.8952941894531  loc loss 27.801664352416992\n",
      "cls loss 283.14495849609375  loc loss 11.176773071289062\n",
      "cls loss 546.1080932617188  loc loss 36.445003509521484\n",
      "cls loss 473.53448486328125  loc loss 31.03446388244629\n",
      "cls loss 727.6036376953125  loc loss 44.95709991455078\n",
      "cls loss 365.18695068359375  loc loss 25.664587020874023\n",
      "cls loss 644.795166015625  loc loss 41.453887939453125\n",
      "cls loss 509.4078063964844  loc loss 34.320159912109375\n",
      "cls loss 489.622802734375  loc loss 31.729711532592773\n",
      "cls loss 482.25372314453125  loc loss 34.06645584106445\n",
      "cls loss 644.7832641601562  loc loss 43.21883010864258\n",
      "cls loss 653.0294799804688  loc loss 39.73953628540039\n",
      "cls loss 310.4354248046875  loc loss 16.44268798828125\n",
      "cls loss 585.176025390625  loc loss 40.82530212402344\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 10.,  1., 18.])\n",
      "cls loss 281.71185302734375  loc loss 18.560665130615234\n",
      "cls loss 360.0002746582031  loc loss 14.56070327758789\n",
      "cls loss 610.348876953125  loc loss 31.171443939208984\n",
      "cls loss 819.0443115234375  loc loss 46.59983444213867\n",
      "cls loss 477.647216796875  loc loss 33.00771713256836\n",
      "cls loss 692.9691772460938  loc loss 35.22258377075195\n",
      "cls loss 497.7770080566406  loc loss 33.23382568359375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.,  1.,  1.])\n",
      "cls loss 604.60986328125  loc loss 38.49338150024414\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1., 38.,  1.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 534.601806640625  loc loss 31.022197723388672\n",
      "cls loss 736.4691162109375  loc loss 54.863670349121094\n",
      "cls loss 407.87786865234375  loc loss 27.15188217163086\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 547.8331909179688  loc loss 34.52311706542969\n",
      "cls loss 462.37371826171875  loc loss 28.14892578125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3., 10.,  8.,  3., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.])\n",
      "cls loss 530.157958984375  loc loss 30.27061653137207\n",
      "cls loss 358.37017822265625  loc loss 23.593603134155273\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3.,  3., 11.,  3., 10., 10.,  3.,  3., 10.])\n",
      "cls loss 431.16583251953125  loc loss 21.31691551208496\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3., 10., 10., 10.])\n",
      "cls loss 446.56121826171875  loc loss 26.67803192138672\n",
      "cls loss 377.5032043457031  loc loss 21.81808853149414\n",
      "cls loss 475.21441650390625  loc loss 30.831453323364258\n",
      "cls loss 690.62744140625  loc loss 38.943138122558594\n",
      "cls loss 458.2086181640625  loc loss 27.64898681640625\n",
      "cls loss 346.25201416015625  loc loss 27.69040870666504\n",
      "cls loss 449.0284423828125  loc loss 28.429256439208984\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 9.,  9., 85., 85.])\n",
      "cls loss 350.23956298828125  loc loss 19.47044563293457\n",
      "cls loss 433.4497375488281  loc loss 31.513946533203125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 694.7496337890625  loc loss 48.051116943359375\n",
      "cls loss 601.9850463867188  loc loss 28.745088577270508\n",
      "cls loss 661.839111328125  loc loss 47.94761657714844\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10., 10., 10., 10.])\n",
      "cls loss 415.28277587890625  loc loss 25.960193634033203\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([13.])\n",
      "cls loss 653.0020751953125  loc loss 51.3204345703125\n",
      "cls loss 217.1844940185547  loc loss 11.573065757751465\n",
      "cls loss 302.8355712890625  loc loss 14.936395645141602\n",
      "cls loss 401.1943359375  loc loss 22.309032440185547\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19.,  1.,  1.,  1., 19., 19.])\n",
      "cls loss 416.132568359375  loc loss 27.036083221435547\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 336.99920654296875  loc loss 24.578994750976562\n",
      "cls loss 468.15167236328125  loc loss 34.117835998535156\n",
      "cls loss 367.03564453125  loc loss 20.436321258544922\n",
      "cls loss 527.4974365234375  loc loss 27.768321990966797\n",
      "cls loss 557.6004028320312  loc loss 41.64151382446289\n",
      "cls loss 436.7486572265625  loc loss 23.81235122680664\n",
      "cls loss 664.820556640625  loc loss 46.30083465576172\n",
      "cls loss 250.31614685058594  loc loss 11.174222946166992\n",
      "cls loss 476.3082275390625  loc loss 29.215574264526367\n",
      "cls loss 371.74102783203125  loc loss 18.892372131347656\n",
      "cls loss 409.99163818359375  loc loss 22.666730880737305\n",
      "cls loss 530.2467041015625  loc loss 30.988492965698242\n",
      "cls loss 465.1741943359375  loc loss 22.629714965820312\n",
      "cls loss 655.1375732421875  loc loss 42.77878189086914\n",
      "cls loss 421.3694763183594  loc loss 26.84676742553711\n",
      "cls loss 541.2462768554688  loc loss 38.743507385253906\n",
      "cls loss 795.828857421875  loc loss 48.10127639770508\n",
      "cls loss 412.2281799316406  loc loss 31.008502960205078\n",
      "cls loss 493.2038879394531  loc loss 29.402589797973633\n",
      "cls loss 563.921142578125  loc loss 44.549015045166016\n",
      "cls loss 649.0936889648438  loc loss 45.75444030761719\n",
      "cls loss 779.0201416015625  loc loss 41.674930572509766\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 5.])\n",
      "cls loss 212.14846801757812  loc loss 9.508505821228027\n",
      "cls loss 285.92047119140625  loc loss 12.614295959472656\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 13.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 6., 8., 8.])\n",
      "cls loss 231.08343505859375  loc loss 12.783276557922363\n",
      "cls loss 311.9665832519531  loc loss 15.800817489624023\n",
      "cls loss 605.2266845703125  loc loss 39.705196380615234\n",
      "cls loss 263.872314453125  loc loss 14.230475425720215\n",
      "cls loss 485.7200622558594  loc loss 36.39778518676758\n",
      "cls loss 736.2052001953125  loc loss 52.940757751464844\n",
      "cls loss 456.1449279785156  loc loss 32.27267837524414\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([42., 42.,  1.,  1.,  1.,  1.,  1.,  1.,  1., 42., 42.])\n",
      "cls loss 511.94415283203125  loc loss 26.967121124267578\n",
      "cls loss 643.0216064453125  loc loss 48.14216613769531\n",
      "cls loss 582.826904296875  loc loss 39.76724624633789\n",
      "cls loss 375.2013244628906  loc loss 23.681941986083984\n",
      "cls loss 495.4140625  loc loss 27.354873657226562\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 702.7007446289062  loc loss 45.01960754394531\n",
      "cls loss 569.82861328125  loc loss 39.06466293334961\n",
      "cls loss 344.43548583984375  loc loss 19.529741287231445\n",
      "cls loss 285.1632080078125  loc loss 17.140655517578125\n",
      "cls loss 393.521728515625  loc loss 24.150981903076172\n",
      "cls loss 550.51513671875  loc loss 33.50184631347656\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15.])\n",
      "cls loss 280.9476318359375  loc loss 10.267783164978027\n",
      "cls loss 474.14898681640625  loc loss 28.82632827758789\n",
      "cls loss 401.5711669921875  loc loss 27.010221481323242\n",
      "cls loss 725.6220092773438  loc loss 48.333194732666016\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19.,  7.])\n",
      "cls loss 375.5591735839844  loc loss 21.05931282043457\n",
      "cls loss 765.279541015625  loc loss 50.57341384887695\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 672.0179443359375  loc loss 32.925071716308594\n",
      "cls loss 558.8023071289062  loc loss 39.597572326660156\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([38., 38.,  1., 18.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1., 18., 18.,  1.])\n",
      "cls loss 405.396728515625  loc loss 21.226455688476562\n",
      "cls loss 401.52362060546875  loc loss 18.631622314453125\n",
      "cls loss 746.744873046875  loc loss 51.43961715698242\n",
      "cls loss 554.27001953125  loc loss 30.905569076538086\n",
      "cls loss 483.6336669921875  loc loss 27.021095275878906\n",
      "cls loss 305.90557861328125  loc loss 23.206045150756836\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.])\n",
      "cls loss 212.41139221191406  loc loss 8.40500545501709\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([32.])\n",
      "cls loss 477.64312744140625  loc loss 25.60404396057129\n",
      "cls loss 403.3548583984375  loc loss 28.404830932617188\n",
      "cls loss 519.8563232421875  loc loss 40.47395324707031\n",
      "cls loss 457.63177490234375  loc loss 30.147178649902344\n",
      "cls loss 380.535888671875  loc loss 23.544822692871094\n",
      "cls loss 629.5947265625  loc loss 37.003238677978516\n",
      "cls loss 703.0003051757812  loc loss 45.93095016479492\n",
      "cls loss 536.2722778320312  loc loss 35.12989807128906\n",
      "cls loss 432.4825134277344  loc loss 25.098899841308594\n",
      "cls loss 682.4036254882812  loc loss 43.34459686279297\n",
      "cls loss 467.2718811035156  loc loss 23.649812698364258\n",
      "cls loss 779.5076904296875  loc loss 51.941226959228516\n",
      "cls loss 525.3956298828125  loc loss 28.982784271240234\n",
      "cls loss 427.8060302734375  loc loss 32.386043548583984\n",
      "cls loss 328.06268310546875  loc loss 15.24951171875\n",
      "cls loss 369.75079345703125  loc loss 22.93449592590332\n",
      "cls loss 552.5560913085938  loc loss 35.53958511352539\n",
      "cls loss 585.4695434570312  loc loss 39.38262939453125\n",
      "cls loss 331.775634765625  loc loss 20.25051498413086\n",
      "cls loss 598.0438232421875  loc loss 39.767574310302734\n",
      "cls loss 728.162841796875  loc loss 44.67763137817383\n",
      "cls loss 266.4251403808594  loc loss 16.920080184936523\n",
      "cls loss 701.2017822265625  loc loss 46.58674621582031\n",
      "cls loss 520.5820922851562  loc loss 36.312931060791016\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 690.45556640625  loc loss 52.00551986694336\n",
      "cls loss 329.22296142578125  loc loss 12.285244941711426\n",
      "cls loss 484.6189880371094  loc loss 26.526620864868164\n",
      "cls loss 485.597412109375  loc loss 31.91872787475586\n",
      "cls loss 394.60821533203125  loc loss 22.47827911376953\n",
      "cls loss 237.3249969482422  loc loss 12.424503326416016\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 9., 9., 1., 9., 9., 9., 9., 1., 9.])\n",
      "cls loss 875.1097412109375  loc loss 68.11154174804688\n",
      "cls loss 512.05615234375  loc loss 26.432567596435547\n",
      "cls loss 752.1150512695312  loc loss 58.968544006347656\n",
      "cls loss 318.7325134277344  loc loss 22.459562301635742\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 42., 42.])\n",
      "cls loss 534.3045043945312  loc loss 39.80356216430664\n",
      "cls loss 565.0423583984375  loc loss 42.240577697753906\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  2.,  1.,  1.,  1., 38.,\n",
      "         1.,  1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 38., 38., 38.,  1., 38., 38., 38.,  1.,  1., 38.,  1.,\n",
      "         1.])\n",
      "cls loss 346.38604736328125  loc loss 26.033071517944336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  8.,  8.])\n",
      "cls loss 842.4697875976562  loc loss 54.348846435546875\n",
      "cls loss 831.4766845703125  loc loss 62.90884780883789\n",
      "cls loss 321.3810119628906  loc loss 18.874536514282227\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([4., 1., 1., 4.])\n",
      "cls loss 482.1514587402344  loc loss 30.501937866210938\n",
      "cls loss 576.4283447265625  loc loss 33.54841613769531\n",
      "cls loss 240.80941772460938  loc loss 12.07219123840332\n",
      "cls loss 319.4632568359375  loc loss 20.310359954833984\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([51.,  1.])\n",
      "cls loss 237.45040893554688  loc loss 9.809232711791992\n",
      "cls loss 334.3350830078125  loc loss 18.12322998046875\n",
      "cls loss 587.3072509765625  loc loss 33.29650115966797\n",
      "cls loss 597.549560546875  loc loss 42.63976287841797\n",
      "cls loss 851.662353515625  loc loss 45.48781204223633\n",
      "cls loss 1040.61572265625  loc loss 68.98112487792969\n",
      "cls loss 437.75921630859375  loc loss 26.785900115966797\n",
      "cls loss 637.8544921875  loc loss 47.579437255859375\n",
      "cls loss 687.5687866210938  loc loss 46.36505889892578\n",
      "cls loss 534.9669799804688  loc loss 31.029052734375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  3.,  1.,  1.,  1.,  3.,  1.,  1.,\n",
      "         1.,  1.,  1.])\n",
      "cls loss 560.598388671875  loc loss 24.32182502746582\n",
      "cls loss 638.4508056640625  loc loss 31.665019989013672\n",
      "cls loss 565.4404907226562  loc loss 30.001007080078125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "cls loss 470.70098876953125  loc loss 28.037765502929688\n",
      "cls loss 258.8770751953125  loc loss 21.940692901611328\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3.])\n",
      "cls loss 204.87921142578125  loc loss 11.689071655273438\n",
      "cls loss 389.8513488769531  loc loss 25.867841720581055\n",
      "cls loss 336.135986328125  loc loss 24.620967864990234\n",
      "cls loss 633.2821044921875  loc loss 40.157875061035156\n",
      "cls loss 351.74456787109375  loc loss 21.480228424072266\n",
      "cls loss 336.00189208984375  loc loss 24.04140281677246\n",
      "cls loss 1005.0093994140625  loc loss 66.90022277832031\n",
      "cls loss 427.994140625  loc loss 33.803226470947266\n",
      "cls loss 340.22882080078125  loc loss 23.293018341064453\n",
      "cls loss 416.79913330078125  loc loss 23.68305206298828\n",
      "cls loss 390.230712890625  loc loss 27.06547737121582\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 694.6766357421875  loc loss 45.39604568481445\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  9., 64., 64., 64., 64., 64., 64., 64., 64., 64.,  9.,  9.,  9.,\n",
      "         9.])\n",
      "cls loss 351.885498046875  loc loss 16.601871490478516\n",
      "cls loss 896.550048828125  loc loss 69.32823944091797\n",
      "cls loss 477.8447265625  loc loss 31.10590934753418\n",
      "cls loss 603.3858032226562  loc loss 39.84017562866211\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.,  3.,  3.])\n",
      "cls loss 374.80975341796875  loc loss 20.468751907348633\n",
      "cls loss 408.2130126953125  loc loss 27.884845733642578\n",
      "cls loss 405.08966064453125  loc loss 28.880786895751953\n",
      "cls loss 429.20751953125  loc loss 31.388004302978516\n",
      "cls loss 448.9467468261719  loc loss 35.57792282104492\n",
      "cls loss 482.1396484375  loc loss 33.55827331542969\n",
      "cls loss 435.80535888671875  loc loss 32.40591049194336\n",
      "cls loss 470.2944030761719  loc loss 26.84693145751953\n",
      "cls loss 592.7554321289062  loc loss 38.78878402709961\n",
      "cls loss 444.9544372558594  loc loss 27.24108123779297\n",
      "cls loss 361.9647216796875  loc loss 17.50556182861328\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21.])\n",
      "cls loss 288.4119873046875  loc loss 16.51398277282715\n",
      "cls loss 409.7289123535156  loc loss 33.86856460571289\n",
      "cls loss 608.7344360351562  loc loss 40.371665954589844\n",
      "cls loss 319.0325927734375  loc loss 18.21261978149414\n",
      "cls loss 473.1116943359375  loc loss 29.283613204956055\n",
      "cls loss 887.34326171875  loc loss 46.33209991455078\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 42., 42.,  1.,  1.])\n",
      "cls loss 464.51617431640625  loc loss 28.46904754638672\n",
      "cls loss 305.0731201171875  loc loss 20.7503662109375\n",
      "cls loss 432.2730407714844  loc loss 30.32590675354004\n",
      "cls loss 587.1892700195312  loc loss 47.66991424560547\n",
      "cls loss 378.4413757324219  loc loss 23.98200035095215\n",
      "cls loss 579.3546142578125  loc loss 42.478057861328125\n",
      "cls loss 538.9359130859375  loc loss 38.13394546508789\n",
      "cls loss 541.883056640625  loc loss 33.79051208496094\n",
      "cls loss 441.2118225097656  loc loss 26.569047927856445\n",
      "cls loss 367.77215576171875  loc loss 24.1024112701416\n",
      "cls loss 313.96343994140625  loc loss 12.607836723327637\n",
      "cls loss 421.3720703125  loc loss 26.541780471801758\n",
      "cls loss 644.16259765625  loc loss 43.6021614074707\n",
      "cls loss 502.1294250488281  loc loss 29.6392765045166\n",
      "cls loss 459.98345947265625  loc loss 33.36212921142578\n",
      "cls loss 516.0183715820312  loc loss 30.904457092285156\n",
      "cls loss 743.8341064453125  loc loss 53.77822494506836\n",
      "cls loss 558.2374267578125  loc loss 40.37443542480469\n",
      "cls loss 618.7324829101562  loc loss 35.04943084716797\n",
      "cls loss 361.70062255859375  loc loss 17.714595794677734\n",
      "cls loss 519.490234375  loc loss 32.83832931518555\n",
      "cls loss 481.2993469238281  loc loss 27.937931060791016\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 5., 5., 5., 5., 5., 5.])\n",
      "cls loss 326.914306640625  loc loss 21.989315032958984\n",
      "cls loss 415.473876953125  loc loss 22.464630126953125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([13.])\n",
      "cls loss 290.296875  loc loss 16.795944213867188\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([44., 10.,  1.,  1.,  1.])\n",
      "cls loss 270.5215759277344  loc loss 17.99006462097168\n",
      "cls loss 507.73028564453125  loc loss 26.96002769470215\n",
      "cls loss 441.101806640625  loc loss 24.95362091064453\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19., 19., 19., 19., 19., 19., 19.])\n",
      "cls loss 511.499267578125  loc loss 28.08686065673828\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([56.])\n",
      "cls loss 965.6432495117188  loc loss 63.265052795410156\n",
      "cls loss 601.939697265625  loc loss 44.96413040161133\n",
      "cls loss 765.0865478515625  loc loss 51.073707580566406\n",
      "cls loss 744.7777099609375  loc loss 55.985992431640625\n",
      "cls loss 479.182373046875  loc loss 25.71835708618164\n",
      "cls loss 753.6392211914062  loc loss 49.69593048095703\n",
      "cls loss 432.239990234375  loc loss 28.24683380126953\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 36.])\n",
      "cls loss 529.3245239257812  loc loss 27.294034957885742\n",
      "cls loss 462.7779541015625  loc loss 30.465572357177734\n",
      "cls loss 436.61053466796875  loc loss 26.254487991333008\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5.])\n",
      "cls loss 508.88568115234375  loc loss 31.337383270263672\n",
      "cls loss 272.5216369628906  loc loss 14.701338768005371\n",
      "cls loss 660.649658203125  loc loss 35.3714485168457\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "cls loss 559.9780883789062  loc loss 36.64203643798828\n",
      "cls loss 529.5487060546875  loc loss 36.99908447265625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 546.3713989257812  loc loss 37.471858978271484\n",
      "cls loss 623.2380981445312  loc loss 42.9599723815918\n",
      "cls loss 529.016357421875  loc loss 45.711517333984375\n",
      "cls loss 379.730712890625  loc loss 25.44317626953125\n",
      "cls loss 438.57470703125  loc loss 32.10633087158203\n",
      "cls loss 467.6529846191406  loc loss 29.30563735961914\n",
      "cls loss 732.9397583007812  loc loss 39.59864044189453\n",
      "cls loss 329.0048522949219  loc loss 16.152435302734375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 11., 15., 10., 10., 10., 10., 10.])\n",
      "cls loss 745.802001953125  loc loss 46.31244659423828\n",
      "cls loss 417.0029602050781  loc loss 30.42917251586914\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3.])\n",
      "cls loss 452.6177978515625  loc loss 31.287578582763672\n",
      "cls loss 416.26666259765625  loc loss 22.71209144592285\n",
      "cls loss 456.427001953125  loc loss 22.402681350708008\n",
      "cls loss 580.5402221679688  loc loss 26.85574722290039\n",
      "cls loss 295.55230712890625  loc loss 14.759866714477539\n",
      "cls loss 465.6361999511719  loc loss 30.492374420166016\n",
      "cls loss 522.5587158203125  loc loss 36.159812927246094\n",
      "cls loss 441.99652099609375  loc loss 31.85021209716797\n",
      "cls loss 1038.587158203125  loc loss 71.56240844726562\n",
      "cls loss 710.7150268554688  loc loss 45.89977264404297\n",
      "cls loss 469.2431335449219  loc loss 32.49845886230469\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  9.,  9.,  9.,  6.,  6., 85., 85.,  8.,  1.,  1.,  1.,  1.,\n",
      "         6.,  6.])\n",
      "cls loss 308.8743896484375  loc loss 24.950096130371094\n",
      "cls loss 757.1431274414062  loc loss 53.4511833190918\n",
      "cls loss 907.4749145507812  loc loss 55.45936584472656\n",
      "cls loss 604.3738403320312  loc loss 41.62493133544922\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10.,  3.,  3., 10.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 411.2333984375  loc loss 21.39031219482422\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([7.])\n",
      "cls loss 495.24102783203125  loc loss 32.27082061767578\n",
      "cls loss 506.0048828125  loc loss 30.377033233642578\n",
      "cls loss 477.9074401855469  loc loss 39.5465087890625\n",
      "cls loss 691.1536865234375  loc loss 55.023372650146484\n",
      "cls loss 450.5709533691406  loc loss 31.130708694458008\n",
      "cls loss 658.73486328125  loc loss 42.30194091796875\n",
      "cls loss 828.532958984375  loc loss 48.07709884643555\n",
      "cls loss 496.2967224121094  loc loss 33.10038757324219\n",
      "cls loss 538.2510986328125  loc loss 38.36288070678711\n",
      "cls loss 434.3915100097656  loc loss 32.05769348144531\n",
      "cls loss 667.3990478515625  loc loss 50.709503173828125\n",
      "cls loss 507.8143005371094  loc loss 31.808313369750977\n",
      "cls loss 415.0008850097656  loc loss 24.256078720092773\n",
      "cls loss 624.70166015625  loc loss 47.038978576660156\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([62.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([62.])\n",
      "cls loss 302.1643371582031  loc loss 14.136542320251465\n",
      "cls loss 472.7763671875  loc loss 33.678009033203125\n",
      "cls loss 466.4082946777344  loc loss 30.171030044555664\n",
      "cls loss 313.04913330078125  loc loss 15.075986862182617\n",
      "cls loss 605.1109619140625  loc loss 39.76813888549805\n",
      "cls loss 647.2349243164062  loc loss 34.88188934326172\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([28.])\n",
      "cls loss 735.796875  loc loss 36.55872344970703\n",
      "cls loss 596.1522216796875  loc loss 36.45943069458008\n",
      "cls loss 598.2337036132812  loc loss 39.624610900878906\n",
      "cls loss 605.1697998046875  loc loss 37.60423278808594\n",
      "cls loss 828.9965209960938  loc loss 54.76421356201172\n",
      "cls loss 481.9295654296875  loc loss 29.222745895385742\n",
      "cls loss 609.5984497070312  loc loss 35.51213455200195\n",
      "cls loss 504.35009765625  loc loss 41.28594207763672\n",
      "cls loss 829.89453125  loc loss 65.35367584228516\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([81.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 557.8353881835938  loc loss 23.371835708618164\n",
      "cls loss 415.6173095703125  loc loss 22.468135833740234\n",
      "cls loss 322.35174560546875  loc loss 23.516361236572266\n",
      "cls loss 290.87432861328125  loc loss 11.692623138427734\n",
      "cls loss 327.93798828125  loc loss 23.799150466918945\n",
      "cls loss 377.1452941894531  loc loss 23.622665405273438\n",
      "cls loss 415.8372497558594  loc loss 27.327909469604492\n",
      "cls loss 572.7230224609375  loc loss 46.56922912597656\n",
      "cls loss 674.37451171875  loc loss 42.222965240478516\n",
      "cls loss 1202.5947265625  loc loss 79.48580932617188\n",
      "cls loss 484.230712890625  loc loss 24.984615325927734\n",
      "cls loss 591.8680419921875  loc loss 42.7235221862793\n",
      "cls loss 424.69439697265625  loc loss 26.703462600708008\n",
      "cls loss 570.7708129882812  loc loss 31.5607852935791\n",
      "cls loss 477.305908203125  loc loss 27.316837310791016\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([44., 44.])\n",
      "cls loss 434.3811950683594  loc loss 20.866899490356445\n",
      "cls loss 458.51220703125  loc loss 30.22167205810547\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15.])\n",
      "cls loss 489.2130126953125  loc loss 24.65422248840332\n",
      "cls loss 235.92166137695312  loc loss 14.439383506774902\n",
      "cls loss 486.6361999511719  loc loss 29.582212448120117\n",
      "cls loss 279.12774658203125  loc loss 16.287763595581055\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([1., 3., 3.])\n",
      "cls loss 322.55426025390625  loc loss 22.355154037475586\n",
      "cls loss 245.23974609375  loc loss 11.325573921203613\n",
      "cls loss 467.27813720703125  loc loss 28.872671127319336\n",
      "cls loss 515.0995483398438  loc loss 29.77651596069336\n",
      "cls loss 467.30108642578125  loc loss 31.161808013916016\n",
      "cls loss 413.7171936035156  loc loss 25.258678436279297\n",
      "cls loss 393.0279541015625  loc loss 29.414825439453125\n",
      "cls loss 547.8399658203125  loc loss 34.48586654663086\n",
      "cls loss 388.7093200683594  loc loss 26.025667190551758\n",
      "cls loss 528.1909790039062  loc loss 35.48366165161133\n",
      "cls loss 349.31005859375  loc loss 19.18874740600586\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 610.9625244140625  loc loss 37.03028869628906\n",
      "cls loss 728.8419799804688  loc loss 33.1946907043457\n",
      "cls loss 623.0408935546875  loc loss 43.18796920776367\n",
      "cls loss 623.6566772460938  loc loss 48.74665069580078\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10., 10., 10.,  1.,  1.,  1.,  1.,  1.,  1.,  8.,  8.,\n",
      "         1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10., 10., 10.,  1.,  1.,  1.,  1.,  1.,  1.,  8.,  8.,\n",
      "         1.])\n",
      "cls loss 544.8165283203125  loc loss 26.263792037963867\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 3., 3., 3.])\n",
      "cls loss 479.7982482910156  loc loss 29.89089012145996\n",
      "cls loss 338.90960693359375  loc loss 19.699691772460938\n",
      "cls loss 261.8738098144531  loc loss 12.623600006103516\n",
      "cls loss 457.0434875488281  loc loss 34.179603576660156\n",
      "cls loss 359.15771484375  loc loss 16.8099422454834\n",
      "cls loss 413.4809875488281  loc loss 27.059093475341797\n",
      "cls loss 468.298828125  loc loss 31.26795196533203\n",
      "cls loss 651.520751953125  loc loss 44.1461067199707\n",
      "cls loss 552.3017578125  loc loss 27.03810691833496\n",
      "cls loss 522.4189453125  loc loss 29.144166946411133\n",
      "cls loss 550.7332763671875  loc loss 38.1845588684082\n",
      "cls loss 392.51776123046875  loc loss 30.97771453857422\n",
      "cls loss 757.3492431640625  loc loss 57.37694549560547\n",
      "cls loss 364.49359130859375  loc loss 18.90146827697754\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 596.4466552734375  loc loss 36.4018440246582\n",
      "cls loss 284.2376708984375  loc loss 11.753996849060059\n",
      "cls loss 714.9481811523438  loc loss 44.79069137573242\n",
      "cls loss 355.7952880859375  loc loss 20.97267723083496\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 34.])\n",
      "cls loss 587.6177978515625  loc loss 31.454208374023438\n",
      "cls loss 285.0638427734375  loc loss 18.573867797851562\n",
      "cls loss 559.380126953125  loc loss 35.21905517578125\n",
      "cls loss 188.69284057617188  loc loss 13.94039535522461\n",
      "cls loss 466.234619140625  loc loss 28.99612808227539\n",
      "cls loss 451.58758544921875  loc loss 37.41435241699219\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 38.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16., 16., 16.,  9.,  9.,  9., 16., 16., 16., 85.,  9.])\n",
      "cls loss 467.75360107421875  loc loss 30.5355167388916\n",
      "cls loss 522.36279296875  loc loss 40.66107177734375\n",
      "cls loss 696.6468505859375  loc loss 46.718589782714844\n",
      "cls loss 1053.74462890625  loc loss 67.19818878173828\n",
      "cls loss 306.90618896484375  loc loss 16.35838508605957\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3., 10.,  8.,  8., 10., 10., 10.,  3.,  3., 14.])\n",
      "cls loss 333.01568603515625  loc loss 17.775989532470703\n",
      "cls loss 634.740478515625  loc loss 35.134056091308594\n",
      "cls loss 283.8774108886719  loc loss 10.481115341186523\n",
      "cls loss 440.07489013671875  loc loss 18.82404327392578\n",
      "cls loss 577.167724609375  loc loss 34.44801330566406\n",
      "cls loss 494.44415283203125  loc loss 30.519773483276367\n",
      "cls loss 276.0484619140625  loc loss 14.552739143371582\n",
      "cls loss 335.6303405761719  loc loss 19.36996078491211\n",
      "cls loss 531.62744140625  loc loss 31.312053680419922\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42., 42.,  1.])\n",
      "cls loss 510.4308776855469  loc loss 33.90727233886719\n",
      "cls loss 392.615234375  loc loss 23.467058181762695\n",
      "cls loss 541.1982421875  loc loss 41.69408416748047\n",
      "cls loss 639.6885986328125  loc loss 38.825897216796875\n",
      "cls loss 432.76434326171875  loc loss 27.723180770874023\n",
      "cls loss 533.6819458007812  loc loss 38.46931838989258\n",
      "cls loss 341.1349182128906  loc loss 23.479721069335938\n",
      "cls loss 357.8863220214844  loc loss 25.308134078979492\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20.])\n",
      "cls loss 262.1068115234375  loc loss 16.12660026550293\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([11.])\n",
      "cls loss 363.3488464355469  loc loss 17.638425827026367\n",
      "cls loss 232.22915649414062  loc loss 13.314668655395508\n",
      "cls loss 549.38232421875  loc loss 42.52158737182617\n",
      "cls loss 251.28057861328125  loc loss 11.642535209655762\n",
      "cls loss 549.782958984375  loc loss 29.749469757080078\n",
      "cls loss 301.62158203125  loc loss 18.46109390258789\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 35., 27.])\n",
      "cls loss 509.1282958984375  loc loss 29.584325790405273\n",
      "cls loss 556.8209838867188  loc loss 41.10020446777344\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 374.261474609375  loc loss 21.25994873046875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([42.,  1.])\n",
      "cls loss 472.654541015625  loc loss 32.44029998779297\n",
      "cls loss 457.5635681152344  loc loss 25.558975219726562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 540.06884765625  loc loss 33.463321685791016\n",
      "cls loss 684.6893920898438  loc loss 42.524208068847656\n",
      "cls loss 604.8916625976562  loc loss 35.66128921508789\n",
      "cls loss 405.9458923339844  loc loss 29.479244232177734\n",
      "cls loss 349.5987548828125  loc loss 26.174306869506836\n",
      "cls loss 215.83924865722656  loc loss 10.348132133483887\n",
      "cls loss 407.0125732421875  loc loss 22.43602180480957\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 1., 1.])\n",
      "cls loss 393.79937744140625  loc loss 23.306724548339844\n",
      "cls loss 451.59161376953125  loc loss 29.51845932006836\n",
      "cls loss 441.9093933105469  loc loss 27.581501007080078\n",
      "cls loss 366.61358642578125  loc loss 25.45845603942871\n",
      "cls loss 444.19732666015625  loc loss 26.873249053955078\n",
      "cls loss 479.82513427734375  loc loss 33.49399185180664\n",
      "cls loss 664.3988037109375  loc loss 38.91246032714844\n",
      "cls loss 562.1869506835938  loc loss 42.110931396484375\n",
      "cls loss 514.487548828125  loc loss 31.228694915771484\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 404.50958251953125  loc loss 27.45101547241211\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 493.6712646484375  loc loss 23.81064796447754\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([81.])\n",
      "cls loss 589.4714965820312  loc loss 34.7138671875\n",
      "cls loss 362.92218017578125  loc loss 24.907913208007812\n",
      "cls loss 263.89581298828125  loc loss 14.653118133544922\n",
      "cls loss 406.82647705078125  loc loss 21.917959213256836\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3.,  1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 19.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 19.])\n",
      "cls loss 533.3335571289062  loc loss 37.361995697021484\n",
      "cls loss 311.9534912109375  loc loss 17.020051956176758\n",
      "cls loss 327.3056335449219  loc loss 18.505939483642578\n",
      "cls loss 632.1759643554688  loc loss 46.20859146118164\n",
      "cls loss 318.6062927246094  loc loss 19.8414306640625\n",
      "cls loss 404.0817565917969  loc loss 25.642988204956055\n",
      "cls loss 505.9004211425781  loc loss 32.23622131347656\n",
      "cls loss 393.49102783203125  loc loss 27.196338653564453\n",
      "cls loss 502.420166015625  loc loss 28.455686569213867\n",
      "cls loss 580.0422973632812  loc loss 38.10478973388672\n",
      "cls loss 699.3062744140625  loc loss 61.056060791015625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 81.])\n",
      "cls loss 500.5198669433594  loc loss 25.646484375\n",
      "cls loss 431.9290466308594  loc loss 23.731584548950195\n",
      "cls loss 476.6890869140625  loc loss 25.820270538330078\n",
      "cls loss 362.45709228515625  loc loss 18.557886123657227\n",
      "cls loss 317.9935302734375  loc loss 20.626094818115234\n",
      "cls loss 344.52557373046875  loc loss 28.087297439575195\n",
      "cls loss 284.5230712890625  loc loss 21.001903533935547\n",
      "cls loss 239.08827209472656  loc loss 15.87039566040039\n",
      "cls loss 330.54913330078125  loc loss 21.26844024658203\n",
      "cls loss 439.8263854980469  loc loss 27.0853328704834\n",
      "cls loss 382.24176025390625  loc loss 29.818199157714844\n",
      "cls loss 400.45294189453125  loc loss 30.266231536865234\n",
      "cls loss 242.97042846679688  loc loss 16.657629013061523\n",
      "cls loss 829.5726318359375  loc loss 57.18165969848633\n",
      "cls loss 495.39569091796875  loc loss 33.30155563354492\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 445.7228698730469  loc loss 22.327116012573242\n",
      "cls loss 502.72430419921875  loc loss 32.426429748535156\n",
      "cls loss 388.50677490234375  loc loss 23.93879508972168\n",
      "cls loss 590.5401611328125  loc loss 38.946224212646484\n",
      "cls loss 550.65283203125  loc loss 33.939579010009766\n",
      "cls loss 506.8638916015625  loc loss 30.496671676635742\n",
      "cls loss 385.65484619140625  loc loss 23.971193313598633\n",
      "cls loss 301.97662353515625  loc loss 18.87409210205078\n",
      "cls loss 453.73272705078125  loc loss 26.458568572998047\n",
      "cls loss 498.24468994140625  loc loss 33.186832427978516\n",
      "cls loss 501.84954833984375  loc loss 28.319091796875\n",
      "cls loss 635.0997314453125  loc loss 45.860008239746094\n",
      "cls loss 643.4999389648438  loc loss 51.767127990722656\n",
      "cls loss 460.06256103515625  loc loss 33.05155563354492\n",
      "cls loss 646.64794921875  loc loss 50.244503021240234\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1., 38., 47.,  1.,  1.,  1.,  1.,  1., 62.])\n",
      "cls loss 451.36944580078125  loc loss 21.595182418823242\n",
      "cls loss 531.6610717773438  loc loss 32.38668441772461\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 580.5197143554688  loc loss 32.958885192871094\n",
      "cls loss 599.7625732421875  loc loss 44.63117980957031\n",
      "cls loss 411.4417724609375  loc loss 20.371837615966797\n",
      "cls loss 488.294921875  loc loss 38.63745880126953\n",
      "cls loss 453.0887451171875  loc loss 26.010263442993164\n",
      "cls loss 258.7491455078125  loc loss 10.279024124145508\n",
      "cls loss 397.1168212890625  loc loss 23.380821228027344\n",
      "cls loss 342.5662841796875  loc loss 15.891290664672852\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1., 35.])\n",
      "cls loss 379.08172607421875  loc loss 21.73558807373047\n",
      "cls loss 583.971923828125  loc loss 30.708412170410156\n",
      "cls loss 568.9329833984375  loc loss 37.23031997680664\n",
      "cls loss 499.3360595703125  loc loss 41.26900863647461\n",
      "cls loss 408.1838073730469  loc loss 32.16926574707031\n",
      "cls loss 551.9239501953125  loc loss 41.426116943359375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 311.35321044921875  loc loss 17.769432067871094\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 457.18243408203125  loc loss 19.7471923828125\n",
      "cls loss 730.5687255859375  loc loss 37.574668884277344\n",
      "cls loss 854.7073974609375  loc loss 66.86647033691406\n",
      "cls loss 440.9042053222656  loc loss 22.591655731201172\n",
      "cls loss 387.5792541503906  loc loss 24.398622512817383\n",
      "cls loss 387.7428283691406  loc loss 20.293516159057617\n",
      "cls loss 399.41375732421875  loc loss 24.361343383789062\n",
      "cls loss 354.8173828125  loc loss 15.68134593963623\n",
      "cls loss 646.0335693359375  loc loss 44.28697204589844\n",
      "cls loss 543.6220703125  loc loss 33.06813430786133\n",
      "cls loss 261.3018798828125  loc loss 19.103933334350586\n",
      "cls loss 531.146728515625  loc loss 28.935256958007812\n",
      "cls loss 631.54052734375  loc loss 50.425376892089844\n",
      "cls loss 511.21826171875  loc loss 33.39339065551758\n",
      "cls loss 439.4610900878906  loc loss 25.0531005859375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.])\n",
      "cls loss 425.8586730957031  loc loss 30.93962860107422\n",
      "cls loss 423.55706787109375  loc loss 28.7780818939209\n",
      "cls loss 539.8353271484375  loc loss 35.15540313720703\n",
      "cls loss 850.7427978515625  loc loss 66.37934875488281\n",
      "cls loss 353.4237365722656  loc loss 17.402889251708984\n",
      "cls loss 458.4551696777344  loc loss 28.44727325439453\n",
      "cls loss 369.60955810546875  loc loss 20.087289810180664\n",
      "cls loss 389.6927795410156  loc loss 25.399864196777344\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 21., 21., 21.])\n",
      "cls loss 414.86297607421875  loc loss 25.700965881347656\n",
      "cls loss 387.06158447265625  loc loss 19.276777267456055\n",
      "cls loss 415.7201232910156  loc loss 27.905590057373047\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 35.])\n",
      "cls loss 541.0314331054688  loc loss 33.52946853637695\n",
      "cls loss 202.18096923828125  loc loss 10.929966926574707\n",
      "cls loss 346.0128173828125  loc loss 22.355934143066406\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 330.0  loc loss 14.575047492980957\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 38., 38.,  9., 38.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1.,  1.])\n",
      "cls loss 377.62835693359375  loc loss 23.995874404907227\n",
      "cls loss 629.591064453125  loc loss 38.81647491455078\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 2.,  1., 77., 31., 10., 10.,  1.,  4., 10.])\n",
      "cls loss 315.3406982421875  loc loss 14.598895072937012\n",
      "cls loss 588.948486328125  loc loss 33.4134521484375\n",
      "cls loss 1187.3897705078125  loc loss 66.21165466308594\n",
      "cls loss 357.64990234375  loc loss 24.679662704467773\n",
      "cls loss 512.4178466796875  loc loss 37.60673141479492\n",
      "cls loss 381.4580078125  loc loss 18.787038803100586\n",
      "cls loss 369.024169921875  loc loss 17.996387481689453\n",
      "cls loss 520.9684448242188  loc loss 26.851640701293945\n",
      "cls loss 536.708984375  loc loss 28.817533493041992\n",
      "cls loss 469.80731201171875  loc loss 33.57649230957031\n",
      "cls loss 382.7474670410156  loc loss 18.274490356445312\n",
      "cls loss 390.4954833984375  loc loss 21.3912296295166\n",
      "cls loss 740.57763671875  loc loss 45.32719421386719\n",
      "cls loss 654.728515625  loc loss 38.5013542175293\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1., 42., 42., 42., 42., 42., 42.,  1.,\n",
      "         1.,  1.,  1., 42.,  1.,  1., 42.,  1.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 359.8927001953125  loc loss 25.49603843688965\n",
      "cls loss 548.3014526367188  loc loss 32.37189865112305\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.])\n",
      "cls loss 236.76480102539062  loc loss 13.542750358581543\n",
      "cls loss 550.392822265625  loc loss 34.87840270996094\n",
      "cls loss 415.01019287109375  loc loss 30.235595703125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([11.])\n",
      "cls loss 260.583984375  loc loss 15.31330680847168\n",
      "cls loss 307.4361572265625  loc loss 15.134777069091797\n",
      "cls loss 329.18621826171875  loc loss 14.999387741088867\n",
      "cls loss 551.6312255859375  loc loss 33.57432174682617\n",
      "cls loss 449.27337646484375  loc loss 25.50174903869629\n",
      "cls loss 467.4314270019531  loc loss 30.906797409057617\n",
      "cls loss 672.782958984375  loc loss 34.63271713256836\n",
      "cls loss 343.05859375  loc loss 19.943099975585938\n",
      "cls loss 714.8016357421875  loc loss 47.54622268676758\n",
      "cls loss 342.5799865722656  loc loss 21.61507225036621\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 323.80181884765625  loc loss 21.320064544677734\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1., 38., 38., 42.])\n",
      "cls loss 419.033447265625  loc loss 29.83154296875\n",
      "cls loss 386.7652587890625  loc loss 22.790454864501953\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 344.4810791015625  loc loss 23.951313018798828\n",
      "cls loss 773.26806640625  loc loss 52.461307525634766\n",
      "cls loss 475.1329040527344  loc loss 30.19318389892578\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10.,  3.,  3.,  6.,  8.,  8.,  1.,  1.,  1., 10.])\n",
      "cls loss 386.3662109375  loc loss 19.46735191345215\n",
      "cls loss 241.51715087890625  loc loss 9.074913024902344\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10.,  3.])\n",
      "cls loss 355.1201171875  loc loss 20.900711059570312\n",
      "cls loss 187.77008056640625  loc loss 11.175223350524902\n",
      "cls loss 459.8140869140625  loc loss 31.744333267211914\n",
      "cls loss 544.880859375  loc loss 33.94375991821289\n",
      "cls loss 389.0948486328125  loc loss 22.992910385131836\n",
      "cls loss 270.47314453125  loc loss 13.945793151855469\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 34.])\n",
      "cls loss 649.861328125  loc loss 39.96709060668945\n",
      "cls loss 709.4263916015625  loc loss 56.25120544433594\n",
      "cls loss 454.1578369140625  loc loss 32.443359375\n",
      "cls loss 362.8902893066406  loc loss 24.4067325592041\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.,  1.])\n",
      "cls loss 393.1988525390625  loc loss 18.058134078979492\n",
      "cls loss 614.0859375  loc loss 46.44461441040039\n",
      "cls loss 902.3876953125  loc loss 59.147884368896484\n",
      "cls loss 749.20751953125  loc loss 39.37626647949219\n",
      "cls loss 450.31671142578125  loc loss 23.402013778686523\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 520.5621948242188  loc loss 29.560104370117188\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10.])\n",
      "cls loss 324.8128662109375  loc loss 16.785608291625977\n",
      "cls loss 479.9564514160156  loc loss 23.888912200927734\n",
      "cls loss 438.61700439453125  loc loss 27.571884155273438\n",
      "cls loss 317.54913330078125  loc loss 18.344993591308594\n",
      "cls loss 417.2093505859375  loc loss 26.469249725341797\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21.,\n",
      "        21.])\n",
      "cls loss 535.8646850585938  loc loss 31.549510955810547\n",
      "cls loss 431.17669677734375  loc loss 25.872316360473633\n",
      "cls loss 287.994384765625  loc loss 13.23057746887207\n",
      "cls loss 620.8966064453125  loc loss 39.67582321166992\n",
      "cls loss 471.19757080078125  loc loss 30.298416137695312\n",
      "cls loss 349.3292236328125  loc loss 17.723339080810547\n",
      "cls loss 690.109130859375  loc loss 43.31098175048828\n",
      "cls loss 813.5172729492188  loc loss 56.67124938964844\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15., 85.])\n",
      "cls loss 528.076171875  loc loss 32.53705596923828\n",
      "cls loss 526.8536376953125  loc loss 38.92616271972656\n",
      "cls loss 546.0012817382812  loc loss 39.24481964111328\n",
      "cls loss 469.48236083984375  loc loss 27.186058044433594\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 8., 8.])\n",
      "cls loss 305.29168701171875  loc loss 13.983874320983887\n",
      "cls loss 322.30548095703125  loc loss 23.754199981689453\n",
      "cls loss 406.69952392578125  loc loss 25.11484146118164\n",
      "cls loss 347.22186279296875  loc loss 18.790401458740234\n",
      "cls loss 381.07354736328125  loc loss 22.391704559326172\n",
      "cls loss 544.1318359375  loc loss 32.397483825683594\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1., 35., 27., 27.,  1., 27.,  1.])\n",
      "cls loss 662.5963134765625  loc loss 48.115447998046875\n",
      "cls loss 366.9208984375  loc loss 21.710285186767578\n",
      "cls loss 410.9309387207031  loc loss 29.583539962768555\n",
      "cls loss 381.50067138671875  loc loss 33.987525939941406\n",
      "cls loss 350.1122131347656  loc loss 25.872291564941406\n",
      "cls loss 388.4248046875  loc loss 29.50006103515625\n",
      "cls loss 396.3084411621094  loc loss 30.250200271606445\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  2.,  2.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  2.,  2.])\n",
      "cls loss 206.1479034423828  loc loss 8.533137321472168\n",
      "cls loss 630.703857421875  loc loss 38.35359191894531\n",
      "cls loss 418.5186462402344  loc loss 18.936418533325195\n",
      "cls loss 689.7105712890625  loc loss 49.766353607177734\n",
      "cls loss 272.02410888671875  loc loss 15.66182804107666\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 19., 19., 19., 16.])\n",
      "cls loss 288.92498779296875  loc loss 12.37728500366211\n",
      "cls loss 229.26837158203125  loc loss 9.536005020141602\n",
      "cls loss 381.3019714355469  loc loss 19.06557273864746\n",
      "cls loss 501.35699462890625  loc loss 32.1085090637207\n",
      "cls loss 207.81626892089844  loc loss 16.1009464263916\n",
      "cls loss 555.38134765625  loc loss 42.11235809326172\n",
      "cls loss 400.48089599609375  loc loss 26.41708755493164\n",
      "cls loss 429.8993225097656  loc loss 27.657934188842773\n",
      "cls loss 549.5733642578125  loc loss 36.656009674072266\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 577.456298828125  loc loss 26.334060668945312\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 777.9917602539062  loc loss 65.50672912597656\n",
      "cls loss 1009.921875  loc loss 90.70353698730469\n",
      "cls loss 526.7431640625  loc loss 30.231271743774414\n",
      "cls loss 462.77642822265625  loc loss 28.480224609375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3.,  3.,  3.,  3.,  3., 10.])\n",
      "cls loss 233.13168334960938  loc loss 14.44411849975586\n",
      "cls loss 493.76275634765625  loc loss 23.169315338134766\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 1., 1., 1., 3., 3., 3., 3.])\n",
      "cls loss 375.8717041015625  loc loss 20.84438133239746\n",
      "cls loss 732.3817138671875  loc loss 45.55406951904297\n",
      "cls loss 574.4063720703125  loc loss 35.74993133544922\n",
      "cls loss 370.67889404296875  loc loss 21.491785049438477\n",
      "cls loss 578.5860595703125  loc loss 39.09272003173828\n",
      "cls loss 351.085693359375  loc loss 25.50969886779785\n",
      "cls loss 555.076904296875  loc loss 38.55538558959961\n",
      "cls loss 419.35052490234375  loc loss 39.161643981933594\n",
      "cls loss 430.21026611328125  loc loss 26.9456787109375\n",
      "cls loss 879.0355224609375  loc loss 71.19110107421875\n",
      "cls loss 585.7352294921875  loc loss 42.568695068359375\n",
      "cls loss 398.236572265625  loc loss 19.255878448486328\n",
      "cls loss 258.4491882324219  loc loss 11.240196228027344\n",
      "cls loss 309.7908935546875  loc loss 14.745027542114258\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3., 10., 10., 10., 10., 10., 10., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10., 10., 10., 10., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 11., 10., 10., 10., 10., 10.,  3.,  3.,  3.,  3.,  3.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 11., 10., 10., 10., 10., 10.,  3.,  3.,  3.,  3.,  3.])\n",
      "cls loss 259.84002685546875  loc loss 12.235065460205078\n",
      "cls loss 342.6807861328125  loc loss 15.320521354675293\n",
      "cls loss 286.3517761230469  loc loss 16.74509620666504\n",
      "cls loss 303.9480895996094  loc loss 13.185333251953125\n",
      "cls loss 354.99005126953125  loc loss 27.333789825439453\n",
      "cls loss 276.49603271484375  loc loss 11.030610084533691\n",
      "cls loss 537.7726440429688  loc loss 35.82505798339844\n",
      "cls loss 471.31500244140625  loc loss 30.269248962402344\n",
      "cls loss 718.33447265625  loc loss 44.27584457397461\n",
      "cls loss 361.1373291015625  loc loss 25.22869873046875\n",
      "cls loss 634.7008056640625  loc loss 40.70003128051758\n",
      "cls loss 497.6089172363281  loc loss 33.784812927246094\n",
      "cls loss 483.8861083984375  loc loss 31.068647384643555\n",
      "cls loss 475.33331298828125  loc loss 33.41814041137695\n",
      "cls loss 632.0455932617188  loc loss 42.33734893798828\n",
      "cls loss 634.6857299804688  loc loss 39.041133880615234\n",
      "cls loss 303.6729736328125  loc loss 16.15713882446289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 575.3331298828125  loc loss 39.93742752075195\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 10.,  1., 18.])\n",
      "cls loss 275.2480163574219  loc loss 18.20896339416504\n",
      "cls loss 351.55267333984375  loc loss 14.341638565063477\n",
      "cls loss 604.8263549804688  loc loss 30.710330963134766\n",
      "cls loss 805.1756591796875  loc loss 45.565773010253906\n",
      "cls loss 472.32000732421875  loc loss 32.19953536987305\n",
      "cls loss 685.3982543945312  loc loss 34.43158721923828\n",
      "cls loss 493.5903625488281  loc loss 32.750282287597656\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.,  1.,  1.])\n",
      "cls loss 595.8236083984375  loc loss 37.75189208984375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1., 38.,  1.])\n",
      "cls loss 517.731689453125  loc loss 30.424203872680664\n",
      "cls loss 725.1394653320312  loc loss 54.12481689453125\n",
      "cls loss 400.97796630859375  loc loss 26.70902442932129\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 542.0587768554688  loc loss 33.885597229003906\n",
      "cls loss 452.9776611328125  loc loss 27.606544494628906\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3., 10.,  8.,  3., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.])\n",
      "cls loss 517.9721069335938  loc loss 29.67582893371582\n",
      "cls loss 347.8792419433594  loc loss 23.245811462402344\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3.,  3., 11.,  3., 10., 10.,  3.,  3., 10.])\n",
      "cls loss 420.7390441894531  loc loss 20.963027954101562\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3., 10., 10., 10.])\n",
      "cls loss 440.47381591796875  loc loss 25.965328216552734\n",
      "cls loss 368.8340759277344  loc loss 21.672292709350586\n",
      "cls loss 470.2874755859375  loc loss 30.480648040771484\n",
      "cls loss 680.719482421875  loc loss 38.2020378112793\n",
      "cls loss 450.98797607421875  loc loss 27.084667205810547\n",
      "cls loss 342.28167724609375  loc loss 27.090065002441406\n",
      "cls loss 440.4873962402344  loc loss 27.788484573364258\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 9.,  9., 85., 85.])\n",
      "cls loss 345.25860595703125  loc loss 19.06866455078125\n",
      "cls loss 430.9831237792969  loc loss 31.191091537475586\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 684.43115234375  loc loss 47.245819091796875\n",
      "cls loss 590.890380859375  loc loss 28.35285758972168\n",
      "cls loss 654.643310546875  loc loss 47.4560432434082\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10., 10., 10., 10.])\n",
      "cls loss 409.23272705078125  loc loss 25.722579956054688\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([13.])\n",
      "cls loss 643.2290649414062  loc loss 50.521854400634766\n",
      "cls loss 207.94131469726562  loc loss 11.226682662963867\n",
      "cls loss 294.61346435546875  loc loss 14.560600280761719\n",
      "cls loss 390.9156799316406  loc loss 21.925247192382812\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19.,  1.,  1.,  1., 19., 19.])\n",
      "cls loss 409.2137451171875  loc loss 26.44112777709961\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 332.99810791015625  loc loss 24.32101821899414\n",
      "cls loss 462.9847412109375  loc loss 33.81973648071289\n",
      "cls loss 363.6414794921875  loc loss 20.345739364624023\n",
      "cls loss 519.6080932617188  loc loss 27.420124053955078\n",
      "cls loss 550.5880737304688  loc loss 41.10480499267578\n",
      "cls loss 424.9869689941406  loc loss 23.397663116455078\n",
      "cls loss 656.510009765625  loc loss 45.44844436645508\n",
      "cls loss 242.98773193359375  loc loss 10.943254470825195\n",
      "cls loss 463.77685546875  loc loss 28.66574478149414\n",
      "cls loss 362.58392333984375  loc loss 18.77483558654785\n",
      "cls loss 400.5130615234375  loc loss 22.747875213623047\n",
      "cls loss 525.4044189453125  loc loss 30.71722984313965\n",
      "cls loss 455.408203125  loc loss 22.29106330871582\n",
      "cls loss 643.0340576171875  loc loss 42.14586639404297\n",
      "cls loss 415.6846618652344  loc loss 26.299625396728516\n",
      "cls loss 534.3607177734375  loc loss 38.14455795288086\n",
      "cls loss 780.1024169921875  loc loss 47.075462341308594\n",
      "cls loss 405.42767333984375  loc loss 30.4262638092041\n",
      "cls loss 487.3454284667969  loc loss 29.06082534790039\n",
      "cls loss 556.529052734375  loc loss 44.066837310791016\n",
      "cls loss 642.7039794921875  loc loss 45.4105110168457\n",
      "cls loss 763.3493041992188  loc loss 41.25566101074219\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 5.])\n",
      "cls loss 205.48831176757812  loc loss 9.373486518859863\n",
      "cls loss 280.10260009765625  loc loss 12.2730712890625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 13.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 6., 8., 8.])\n",
      "cls loss 224.58010864257812  loc loss 12.52171802520752\n",
      "cls loss 301.900146484375  loc loss 15.502537727355957\n",
      "cls loss 590.8908081054688  loc loss 38.798370361328125\n",
      "cls loss 254.32061767578125  loc loss 14.078216552734375\n",
      "cls loss 481.175048828125  loc loss 35.78833770751953\n",
      "cls loss 724.0345458984375  loc loss 52.106292724609375\n",
      "cls loss 451.15679931640625  loc loss 31.678543090820312\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([42., 42.,  1.,  1.,  1.,  1.,  1.,  1.,  1., 42., 42.])\n",
      "cls loss 503.0916748046875  loc loss 26.443185806274414\n",
      "cls loss 637.927734375  loc loss 47.179996490478516\n",
      "cls loss 580.2844848632812  loc loss 38.978843688964844\n",
      "cls loss 371.7214050292969  loc loss 23.276508331298828\n",
      "cls loss 488.79345703125  loc loss 26.650182723999023\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 695.2806396484375  loc loss 44.343040466308594\n",
      "cls loss 559.7649536132812  loc loss 38.482879638671875\n",
      "cls loss 338.1575622558594  loc loss 19.193904876708984\n",
      "cls loss 281.41009521484375  loc loss 16.949079513549805\n",
      "cls loss 382.6785888671875  loc loss 23.715505599975586\n",
      "cls loss 541.8785400390625  loc loss 32.8631477355957\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15.])\n",
      "cls loss 273.8465881347656  loc loss 9.963760375976562\n",
      "cls loss 464.4300842285156  loc loss 28.144887924194336\n",
      "cls loss 393.2305908203125  loc loss 26.479719161987305\n",
      "cls loss 712.5115356445312  loc loss 47.249385833740234\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19.,  7.])\n",
      "cls loss 360.630859375  loc loss 20.682371139526367\n",
      "cls loss 750.494384765625  loc loss 49.75857925415039\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 663.6361083984375  loc loss 32.45762634277344\n",
      "cls loss 553.1204223632812  loc loss 38.92210388183594\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([38., 38.,  1., 18.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1., 18., 18.,  1.])\n",
      "cls loss 396.0944519042969  loc loss 20.848440170288086\n",
      "cls loss 393.59429931640625  loc loss 18.26412010192871\n",
      "cls loss 735.8356323242188  loc loss 50.462364196777344\n",
      "cls loss 545.8187255859375  loc loss 30.450851440429688\n",
      "cls loss 468.2066345214844  loc loss 26.687488555908203\n",
      "cls loss 299.607666015625  loc loss 22.758014678955078\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.])\n",
      "cls loss 204.33212280273438  loc loss 8.2369384765625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([32.])\n",
      "cls loss 470.79180908203125  loc loss 25.25440216064453\n",
      "cls loss 395.9277648925781  loc loss 27.85765838623047\n",
      "cls loss 509.800537109375  loc loss 39.639923095703125\n",
      "cls loss 449.86602783203125  loc loss 29.633468627929688\n",
      "cls loss 373.9642333984375  loc loss 23.057701110839844\n",
      "cls loss 619.4432373046875  loc loss 36.28063201904297\n",
      "cls loss 697.6407470703125  loc loss 45.20335388183594\n",
      "cls loss 529.8837890625  loc loss 34.667755126953125\n",
      "cls loss 425.8625183105469  loc loss 24.66166877746582\n",
      "cls loss 671.7404174804688  loc loss 42.69793701171875\n",
      "cls loss 462.96514892578125  loc loss 23.26584243774414\n",
      "cls loss 776.0225830078125  loc loss 51.009979248046875\n",
      "cls loss 517.615234375  loc loss 28.565141677856445\n",
      "cls loss 418.980224609375  loc loss 31.94498062133789\n",
      "cls loss 322.06475830078125  loc loss 14.95026969909668\n",
      "cls loss 363.4904479980469  loc loss 22.773418426513672\n",
      "cls loss 543.4140625  loc loss 35.09258270263672\n",
      "cls loss 576.6651611328125  loc loss 38.83774185180664\n",
      "cls loss 326.1273193359375  loc loss 19.919578552246094\n",
      "cls loss 588.0554809570312  loc loss 39.198280334472656\n",
      "cls loss 716.520263671875  loc loss 44.07265853881836\n",
      "cls loss 263.35296630859375  loc loss 16.52074432373047\n",
      "cls loss 690.2874755859375  loc loss 45.93644714355469\n",
      "cls loss 516.2207641601562  loc loss 35.590816497802734\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 681.3189697265625  loc loss 51.34067916870117\n",
      "cls loss 323.99810791015625  loc loss 12.082715034484863\n",
      "cls loss 478.6363220214844  loc loss 26.117691040039062\n",
      "cls loss 481.3721923828125  loc loss 31.465497970581055\n",
      "cls loss 387.86309814453125  loc loss 22.19053840637207\n",
      "cls loss 230.035400390625  loc loss 12.269272804260254\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 9., 9., 1., 9., 9., 9., 9., 1., 9.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 865.2701416015625  loc loss 66.72918701171875\n",
      "cls loss 502.523193359375  loc loss 26.01310920715332\n",
      "cls loss 746.0986328125  loc loss 57.98505401611328\n",
      "cls loss 314.2630615234375  loc loss 22.273054122924805\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 42., 42.])\n",
      "cls loss 526.1820068359375  loc loss 39.31931686401367\n",
      "cls loss 552.3443603515625  loc loss 41.53496551513672\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  2.,  1.,  1.,  1., 38.,\n",
      "         1.,  1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 38., 38., 38.,  1., 38., 38., 38.,  1.,  1., 38.,  1.,\n",
      "         1.])\n",
      "cls loss 338.082275390625  loc loss 25.53417205810547\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  8.,  8.])\n",
      "cls loss 822.962646484375  loc loss 53.50222396850586\n",
      "cls loss 821.5804443359375  loc loss 62.309757232666016\n",
      "cls loss 314.5069885253906  loc loss 18.663984298706055\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([4., 1., 1., 4.])\n",
      "cls loss 478.576171875  loc loss 29.97091293334961\n",
      "cls loss 570.703125  loc loss 32.99729537963867\n",
      "cls loss 235.3685760498047  loc loss 11.811492919921875\n",
      "cls loss 311.0992431640625  loc loss 19.795408248901367\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([51.,  1.])\n",
      "cls loss 229.40225219726562  loc loss 9.56219482421875\n",
      "cls loss 324.58758544921875  loc loss 17.7961483001709\n",
      "cls loss 579.075439453125  loc loss 32.71883010864258\n",
      "cls loss 584.24951171875  loc loss 41.69683837890625\n",
      "cls loss 846.0616455078125  loc loss 44.83055877685547\n",
      "cls loss 1029.2119140625  loc loss 68.13672637939453\n",
      "cls loss 426.6295166015625  loc loss 26.47698974609375\n",
      "cls loss 621.4686889648438  loc loss 47.052066802978516\n",
      "cls loss 676.783203125  loc loss 45.52782440185547\n",
      "cls loss 521.3707275390625  loc loss 30.31243324279785\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  3.,  1.,  1.,  1.,  3.,  1.,  1.,\n",
      "         1.,  1.,  1.])\n",
      "cls loss 554.5571899414062  loc loss 23.928747177124023\n",
      "cls loss 631.751953125  loc loss 31.089967727661133\n",
      "cls loss 562.904052734375  loc loss 29.446332931518555\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "cls loss 466.09661865234375  loc loss 27.723857879638672\n",
      "cls loss 253.7592010498047  loc loss 21.596559524536133\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3.])\n",
      "cls loss 200.01943969726562  loc loss 11.564963340759277\n",
      "cls loss 378.59039306640625  loc loss 25.383424758911133\n",
      "cls loss 330.5872802734375  loc loss 23.936071395874023\n",
      "cls loss 626.4892578125  loc loss 39.34510040283203\n",
      "cls loss 332.95269775390625  loc loss 21.319734573364258\n",
      "cls loss 331.3253173828125  loc loss 23.993558883666992\n",
      "cls loss 988.6817016601562  loc loss 65.7377700805664\n",
      "cls loss 418.4849853515625  loc loss 33.352378845214844\n",
      "cls loss 332.3777770996094  loc loss 22.875385284423828\n",
      "cls loss 406.9878845214844  loc loss 23.2939510345459\n",
      "cls loss 382.3195495605469  loc loss 26.74214744567871\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 681.6156005859375  loc loss 44.58202362060547\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  9., 64., 64., 64., 64., 64., 64., 64., 64., 64.,  9.,  9.,  9.,\n",
      "         9.])\n",
      "cls loss 342.7866516113281  loc loss 16.141101837158203\n",
      "cls loss 896.12158203125  loc loss 68.33297729492188\n",
      "cls loss 474.2790222167969  loc loss 30.77728843688965\n",
      "cls loss 593.4727783203125  loc loss 38.98714828491211\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.,  3.,  3.])\n",
      "cls loss 365.38330078125  loc loss 20.054258346557617\n",
      "cls loss 398.8944091796875  loc loss 27.564390182495117\n",
      "cls loss 399.24017333984375  loc loss 28.371047973632812\n",
      "cls loss 421.79449462890625  loc loss 30.94005012512207\n",
      "cls loss 445.3910827636719  loc loss 35.31210708618164\n",
      "cls loss 477.1229248046875  loc loss 33.07456970214844\n",
      "cls loss 429.920654296875  loc loss 31.781492233276367\n",
      "cls loss 460.95068359375  loc loss 26.28409767150879\n",
      "cls loss 582.1156005859375  loc loss 38.10327911376953\n",
      "cls loss 432.4780578613281  loc loss 26.89904022216797\n",
      "cls loss 352.0869140625  loc loss 17.23200798034668\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21.])\n",
      "cls loss 282.02252197265625  loc loss 16.288742065429688\n",
      "cls loss 403.7576904296875  loc loss 33.47642517089844\n",
      "cls loss 599.81884765625  loc loss 39.676910400390625\n",
      "cls loss 312.2850646972656  loc loss 17.667314529418945\n",
      "cls loss 467.93829345703125  loc loss 28.915760040283203\n",
      "cls loss 876.0339965820312  loc loss 45.64506149291992\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 42., 42.,  1.,  1.])\n",
      "cls loss 462.21820068359375  loc loss 27.924209594726562\n",
      "cls loss 301.53369140625  loc loss 20.396955490112305\n",
      "cls loss 427.56396484375  loc loss 29.54891586303711\n",
      "cls loss 576.5487060546875  loc loss 47.192832946777344\n",
      "cls loss 372.93524169921875  loc loss 23.46788215637207\n",
      "cls loss 571.403076171875  loc loss 41.767948150634766\n",
      "cls loss 530.5050048828125  loc loss 37.36124801635742\n",
      "cls loss 524.942626953125  loc loss 33.27680969238281\n",
      "cls loss 430.372314453125  loc loss 26.084632873535156\n",
      "cls loss 354.6460876464844  loc loss 23.615631103515625\n",
      "cls loss 304.89593505859375  loc loss 12.358234405517578\n",
      "cls loss 416.66375732421875  loc loss 26.213314056396484\n",
      "cls loss 635.30712890625  loc loss 42.54093551635742\n",
      "cls loss 496.44268798828125  loc loss 28.884845733642578\n",
      "cls loss 452.62921142578125  loc loss 32.70988082885742\n",
      "cls loss 510.1153564453125  loc loss 30.401485443115234\n",
      "cls loss 734.91064453125  loc loss 53.148712158203125\n",
      "cls loss 552.56982421875  loc loss 39.79844284057617\n",
      "cls loss 607.8641357421875  loc loss 34.49626922607422\n",
      "cls loss 355.9881591796875  loc loss 17.424787521362305\n",
      "cls loss 510.51116943359375  loc loss 32.424110412597656\n",
      "cls loss 472.7469482421875  loc loss 27.590110778808594\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 5., 5., 5., 5., 5., 5.])\n",
      "cls loss 319.126708984375  loc loss 21.38163185119629\n",
      "cls loss 406.6148681640625  loc loss 21.992294311523438\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([13.])\n",
      "cls loss 284.7584533691406  loc loss 16.35955047607422\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([44., 10.,  1.,  1.,  1.])\n",
      "cls loss 264.15380859375  loc loss 17.772371292114258\n",
      "cls loss 488.67803955078125  loc loss 26.572309494018555\n",
      "cls loss 432.01385498046875  loc loss 24.501306533813477\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19., 19., 19., 19., 19., 19., 19.])\n",
      "cls loss 494.01361083984375  loc loss 27.656917572021484\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([56.])\n",
      "cls loss 953.283203125  loc loss 62.566551208496094\n",
      "cls loss 596.6002807617188  loc loss 44.372684478759766\n",
      "cls loss 758.8231201171875  loc loss 50.284873962402344\n",
      "cls loss 736.2164306640625  loc loss 55.14649200439453\n",
      "cls loss 474.005126953125  loc loss 25.302875518798828\n",
      "cls loss 745.7714233398438  loc loss 48.675254821777344\n",
      "cls loss 426.1362609863281  loc loss 27.952848434448242\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 36.])\n",
      "cls loss 526.8449096679688  loc loss 26.83613395690918\n",
      "cls loss 452.8018493652344  loc loss 29.968212127685547\n",
      "cls loss 428.84906005859375  loc loss 25.808555603027344\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5.])\n",
      "cls loss 493.81732177734375  loc loss 30.854463577270508\n",
      "cls loss 266.8068542480469  loc loss 14.49303150177002\n",
      "cls loss 644.88916015625  loc loss 34.654563903808594\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "cls loss 548.06298828125  loc loss 35.891151428222656\n",
      "cls loss 519.1450805664062  loc loss 36.38373565673828\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 542.5533447265625  loc loss 36.91796112060547\n",
      "cls loss 615.4124755859375  loc loss 42.19756317138672\n",
      "cls loss 523.0260620117188  loc loss 44.897674560546875\n",
      "cls loss 374.0244445800781  loc loss 24.89638328552246\n",
      "cls loss 431.6612548828125  loc loss 31.433427810668945\n",
      "cls loss 460.76361083984375  loc loss 28.79444122314453\n",
      "cls loss 725.341552734375  loc loss 38.90284729003906\n",
      "cls loss 323.0058898925781  loc loss 15.900577545166016\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 11., 15., 10., 10., 10., 10., 10.])\n",
      "cls loss 722.254150390625  loc loss 45.61111831665039\n",
      "cls loss 411.79119873046875  loc loss 30.037036895751953\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3.])\n",
      "cls loss 442.205810546875  loc loss 30.797142028808594\n",
      "cls loss 405.0846252441406  loc loss 22.188798904418945\n",
      "cls loss 448.9038391113281  loc loss 22.090303421020508\n",
      "cls loss 567.1179809570312  loc loss 26.17322540283203\n",
      "cls loss 284.4588623046875  loc loss 14.397870063781738\n",
      "cls loss 458.52490234375  loc loss 30.008590698242188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 513.5885009765625  loc loss 35.45456314086914\n",
      "cls loss 436.5455322265625  loc loss 31.143756866455078\n",
      "cls loss 1027.619873046875  loc loss 70.00503540039062\n",
      "cls loss 698.979248046875  loc loss 45.22123718261719\n",
      "cls loss 461.79266357421875  loc loss 31.965755462646484\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  9.,  9.,  9.,  6.,  6., 85., 85.,  8.,  1.,  1.,  1.,  1.,\n",
      "         6.,  6.])\n",
      "cls loss 303.76690673828125  loc loss 24.760831832885742\n",
      "cls loss 747.9404296875  loc loss 52.62754440307617\n",
      "cls loss 892.596435546875  loc loss 54.59514236450195\n",
      "cls loss 591.7205810546875  loc loss 41.077266693115234\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10.,  3.,  3., 10.])\n",
      "cls loss 400.3538818359375  loc loss 20.9970645904541\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([7.])\n",
      "cls loss 486.49774169921875  loc loss 31.601625442504883\n",
      "cls loss 495.67950439453125  loc loss 29.706172943115234\n",
      "cls loss 475.66162109375  loc loss 39.17255783081055\n",
      "cls loss 691.3739013671875  loc loss 54.39291763305664\n",
      "cls loss 441.58685302734375  loc loss 30.45713996887207\n",
      "cls loss 646.4099731445312  loc loss 41.601844787597656\n",
      "cls loss 818.42626953125  loc loss 47.26310348510742\n",
      "cls loss 491.82275390625  loc loss 32.51793670654297\n",
      "cls loss 532.0577392578125  loc loss 37.9537353515625\n",
      "cls loss 425.83221435546875  loc loss 31.515588760375977\n",
      "cls loss 661.1661987304688  loc loss 50.085086822509766\n",
      "cls loss 498.5404357910156  loc loss 31.478492736816406\n",
      "cls loss 407.1050109863281  loc loss 23.963272094726562\n",
      "cls loss 614.040283203125  loc loss 46.129547119140625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([62.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([62.])\n",
      "cls loss 298.0836181640625  loc loss 13.87999439239502\n",
      "cls loss 463.68865966796875  loc loss 33.12137222290039\n",
      "cls loss 455.57049560546875  loc loss 29.530241012573242\n",
      "cls loss 303.7118835449219  loc loss 14.907939910888672\n",
      "cls loss 595.668212890625  loc loss 39.180450439453125\n",
      "cls loss 633.3931884765625  loc loss 34.37461853027344\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([28.])\n",
      "cls loss 732.8899536132812  loc loss 36.12151336669922\n",
      "cls loss 584.4425659179688  loc loss 35.98503875732422\n",
      "cls loss 586.5933227539062  loc loss 39.10472106933594\n",
      "cls loss 596.9110107421875  loc loss 36.86233139038086\n",
      "cls loss 814.9725952148438  loc loss 53.728553771972656\n",
      "cls loss 476.6504821777344  loc loss 28.783447265625\n",
      "cls loss 605.061279296875  loc loss 35.055633544921875\n",
      "cls loss 498.1012268066406  loc loss 40.57265090942383\n",
      "cls loss 820.8167724609375  loc loss 64.7078857421875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([81.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 543.84130859375  loc loss 23.068490982055664\n",
      "cls loss 406.4981689453125  loc loss 22.164949417114258\n",
      "cls loss 311.704345703125  loc loss 23.128795623779297\n",
      "cls loss 282.6487731933594  loc loss 11.65816879272461\n",
      "cls loss 318.6523132324219  loc loss 23.441478729248047\n",
      "cls loss 373.02532958984375  loc loss 23.29106903076172\n",
      "cls loss 402.76123046875  loc loss 26.801708221435547\n",
      "cls loss 560.8965454101562  loc loss 45.92147445678711\n",
      "cls loss 669.2471923828125  loc loss 41.37315368652344\n",
      "cls loss 1182.8758544921875  loc loss 78.08145904541016\n",
      "cls loss 475.95013427734375  loc loss 24.4461727142334\n",
      "cls loss 582.60205078125  loc loss 42.414363861083984\n",
      "cls loss 417.57415771484375  loc loss 26.38928985595703\n",
      "cls loss 562.1361083984375  loc loss 31.007474899291992\n",
      "cls loss 468.10284423828125  loc loss 26.844524383544922\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([44., 44.])\n",
      "cls loss 422.6724548339844  loc loss 20.452966690063477\n",
      "cls loss 450.04925537109375  loc loss 29.577579498291016\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15.])\n",
      "cls loss 475.6390075683594  loc loss 24.237760543823242\n",
      "cls loss 229.32460021972656  loc loss 14.184106826782227\n",
      "cls loss 474.26556396484375  loc loss 29.147613525390625\n",
      "cls loss 274.57281494140625  loc loss 15.864654541015625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([1., 3., 3.])\n",
      "cls loss 316.3751220703125  loc loss 21.752676010131836\n",
      "cls loss 238.34652709960938  loc loss 11.083955764770508\n",
      "cls loss 455.65765380859375  loc loss 28.53936767578125\n",
      "cls loss 506.14373779296875  loc loss 29.108104705810547\n",
      "cls loss 458.8960266113281  loc loss 30.764423370361328\n",
      "cls loss 398.0136413574219  loc loss 24.81240463256836\n",
      "cls loss 388.354248046875  loc loss 28.87851333618164\n",
      "cls loss 538.3568115234375  loc loss 33.902496337890625\n",
      "cls loss 383.33880615234375  loc loss 25.63047981262207\n",
      "cls loss 521.21240234375  loc loss 34.887962341308594\n",
      "cls loss 346.80462646484375  loc loss 18.858369827270508\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 600.9654541015625  loc loss 36.3232421875\n",
      "cls loss 719.27099609375  loc loss 32.521575927734375\n",
      "cls loss 614.4573364257812  loc loss 42.517364501953125\n",
      "cls loss 612.385986328125  loc loss 48.32318115234375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10., 10., 10.,  1.,  1.,  1.,  1.,  1.,  1.,  8.,  8.,\n",
      "         1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10., 10., 10.,  1.,  1.,  1.,  1.,  1.,  1.,  8.,  8.,\n",
      "         1.])\n",
      "cls loss 527.8682250976562  loc loss 25.815202713012695\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 3., 3., 3.])\n",
      "cls loss 472.0149841308594  loc loss 29.35286521911621\n",
      "cls loss 330.6678466796875  loc loss 19.55756950378418\n",
      "cls loss 255.014404296875  loc loss 12.410987854003906\n",
      "cls loss 451.53045654296875  loc loss 33.60602569580078\n",
      "cls loss 354.2080993652344  loc loss 16.32411003112793\n",
      "cls loss 409.830810546875  loc loss 26.62006187438965\n",
      "cls loss 463.17877197265625  loc loss 30.845115661621094\n",
      "cls loss 641.7433471679688  loc loss 43.445377349853516\n",
      "cls loss 546.4797973632812  loc loss 26.766006469726562\n",
      "cls loss 513.6830444335938  loc loss 28.734140396118164\n",
      "cls loss 537.3330078125  loc loss 37.46400833129883\n",
      "cls loss 384.0987548828125  loc loss 30.45021629333496\n",
      "cls loss 746.2900390625  loc loss 56.48992919921875\n",
      "cls loss 354.806640625  loc loss 18.576139450073242\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 590.326171875  loc loss 35.7326774597168\n",
      "cls loss 278.4190673828125  loc loss 11.531909942626953\n",
      "cls loss 700.0978393554688  loc loss 44.09918212890625\n",
      "cls loss 347.5203857421875  loc loss 20.68785858154297\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 34.])\n",
      "cls loss 571.3692016601562  loc loss 30.79035758972168\n",
      "cls loss 279.21563720703125  loc loss 18.2668514251709\n",
      "cls loss 552.6153564453125  loc loss 34.51509475708008\n",
      "cls loss 186.2545166015625  loc loss 13.699051856994629\n",
      "cls loss 457.7810974121094  loc loss 28.32425308227539\n",
      "cls loss 445.64410400390625  loc loss 37.019378662109375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 38.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16., 16., 16.,  9.,  9.,  9., 16., 16., 16., 85.,  9.])\n",
      "cls loss 463.0218505859375  loc loss 30.08099937438965\n",
      "cls loss 512.6992797851562  loc loss 40.1053466796875\n",
      "cls loss 684.7681274414062  loc loss 45.76031494140625\n",
      "cls loss 1045.078125  loc loss 66.00202178955078\n",
      "cls loss 298.70074462890625  loc loss 16.04056167602539\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3., 10.,  8.,  8., 10., 10., 10.,  3.,  3., 14.])\n",
      "cls loss 318.8244934082031  loc loss 17.433929443359375\n",
      "cls loss 610.619140625  loc loss 34.67466354370117\n",
      "cls loss 274.8475341796875  loc loss 10.280914306640625\n",
      "cls loss 432.598876953125  loc loss 18.550880432128906\n",
      "cls loss 567.7469482421875  loc loss 33.986061096191406\n",
      "cls loss 486.0616149902344  loc loss 29.931127548217773\n",
      "cls loss 270.25054931640625  loc loss 14.3123140335083\n",
      "cls loss 333.8763427734375  loc loss 18.90735626220703\n",
      "cls loss 531.6436157226562  loc loss 30.651376724243164\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42., 42.,  1.])\n",
      "cls loss 506.56365966796875  loc loss 33.16078567504883\n",
      "cls loss 386.84619140625  loc loss 23.13267707824707\n",
      "cls loss 533.7467041015625  loc loss 41.146419525146484\n",
      "cls loss 627.0367431640625  loc loss 38.097537994384766\n",
      "cls loss 427.3595275878906  loc loss 27.249374389648438\n",
      "cls loss 526.0240478515625  loc loss 38.0604248046875\n",
      "cls loss 332.85736083984375  loc loss 23.191204071044922\n",
      "cls loss 350.5600891113281  loc loss 25.073930740356445\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20.])\n",
      "cls loss 255.52288818359375  loc loss 15.89073657989502\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([11.])\n",
      "cls loss 358.449462890625  loc loss 17.205320358276367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 224.27159118652344  loc loss 13.133960723876953\n",
      "cls loss 539.480712890625  loc loss 41.73542404174805\n",
      "cls loss 244.7083740234375  loc loss 11.47075366973877\n",
      "cls loss 538.8579711914062  loc loss 29.350772857666016\n",
      "cls loss 296.47161865234375  loc loss 18.148080825805664\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 35., 27.])\n",
      "cls loss 503.59124755859375  loc loss 28.90104866027832\n",
      "cls loss 550.657958984375  loc loss 40.671207427978516\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 369.10406494140625  loc loss 20.750686645507812\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([42.,  1.])\n",
      "cls loss 464.4499816894531  loc loss 31.787696838378906\n",
      "cls loss 453.5799560546875  loc loss 25.1481990814209\n",
      "cls loss 532.25390625  loc loss 33.01293182373047\n",
      "cls loss 676.6888427734375  loc loss 41.56727600097656\n",
      "cls loss 593.473388671875  loc loss 34.95283126831055\n",
      "cls loss 398.59503173828125  loc loss 28.76276969909668\n",
      "cls loss 342.6047668457031  loc loss 25.597631454467773\n",
      "cls loss 209.8622589111328  loc loss 10.092182159423828\n",
      "cls loss 400.29510498046875  loc loss 22.055362701416016\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 1., 1.])\n",
      "cls loss 385.62060546875  loc loss 23.132360458374023\n",
      "cls loss 443.4655456542969  loc loss 29.04556655883789\n",
      "cls loss 434.356689453125  loc loss 27.028369903564453\n",
      "cls loss 359.09002685546875  loc loss 25.039997100830078\n",
      "cls loss 436.2728271484375  loc loss 26.635751724243164\n",
      "cls loss 473.74853515625  loc loss 32.84821701049805\n",
      "cls loss 658.8670043945312  loc loss 38.29096603393555\n",
      "cls loss 556.8013305664062  loc loss 41.451820373535156\n",
      "cls loss 504.94500732421875  loc loss 30.819766998291016\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 395.97900390625  loc loss 27.00203514099121\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 489.3603515625  loc loss 23.477888107299805\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([81.])\n",
      "cls loss 581.5372314453125  loc loss 33.88431167602539\n",
      "cls loss 354.8267822265625  loc loss 24.63687515258789\n",
      "cls loss 259.1787109375  loc loss 14.339709281921387\n",
      "cls loss 397.58538818359375  loc loss 21.67571449279785\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3.,  1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 19.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 19.])\n",
      "cls loss 527.9891967773438  loc loss 36.87593078613281\n",
      "cls loss 305.4849853515625  loc loss 16.862598419189453\n",
      "cls loss 321.6911315917969  loc loss 18.146493911743164\n",
      "cls loss 623.010986328125  loc loss 45.5760498046875\n",
      "cls loss 313.08648681640625  loc loss 19.488037109375\n",
      "cls loss 399.4613342285156  loc loss 24.970977783203125\n",
      "cls loss 501.34722900390625  loc loss 31.62466812133789\n",
      "cls loss 386.9572448730469  loc loss 26.639568328857422\n",
      "cls loss 494.65301513671875  loc loss 27.874168395996094\n",
      "cls loss 572.954833984375  loc loss 37.41206741333008\n",
      "cls loss 693.6054077148438  loc loss 60.144527435302734\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 81.])\n",
      "cls loss 491.7423095703125  loc loss 25.092193603515625\n",
      "cls loss 428.2667236328125  loc loss 23.281553268432617\n",
      "cls loss 465.54412841796875  loc loss 25.450782775878906\n",
      "cls loss 354.57806396484375  loc loss 18.333908081054688\n",
      "cls loss 311.0848693847656  loc loss 20.26498794555664\n",
      "cls loss 338.7044677734375  loc loss 27.686901092529297\n",
      "cls loss 275.98626708984375  loc loss 20.649599075317383\n",
      "cls loss 234.65243530273438  loc loss 15.69913387298584\n",
      "cls loss 325.09075927734375  loc loss 20.96933937072754\n",
      "cls loss 431.29931640625  loc loss 26.62503433227539\n",
      "cls loss 377.802734375  loc loss 29.354293823242188\n",
      "cls loss 395.57257080078125  loc loss 29.535804748535156\n",
      "cls loss 238.58714294433594  loc loss 16.282806396484375\n",
      "cls loss 818.6717529296875  loc loss 55.919830322265625\n",
      "cls loss 481.700927734375  loc loss 32.54334259033203\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 437.40093994140625  loc loss 21.853744506835938\n",
      "cls loss 496.78460693359375  loc loss 31.87520980834961\n",
      "cls loss 383.46710205078125  loc loss 23.657554626464844\n",
      "cls loss 584.857421875  loc loss 38.71818161010742\n",
      "cls loss 542.1116943359375  loc loss 33.30190658569336\n",
      "cls loss 499.4396057128906  loc loss 29.981077194213867\n",
      "cls loss 376.4482727050781  loc loss 23.700593948364258\n",
      "cls loss 298.7121276855469  loc loss 18.581378936767578\n",
      "cls loss 445.3477783203125  loc loss 25.933441162109375\n",
      "cls loss 493.731689453125  loc loss 32.76921081542969\n",
      "cls loss 490.62469482421875  loc loss 27.836259841918945\n",
      "cls loss 622.218505859375  loc loss 44.93965148925781\n",
      "cls loss 636.09033203125  loc loss 51.015647888183594\n",
      "cls loss 453.54473876953125  loc loss 32.59329605102539\n",
      "cls loss 642.782958984375  loc loss 49.82929992675781\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1., 38., 47.,  1.,  1.,  1.,  1.,  1., 62.])\n",
      "cls loss 443.50286865234375  loc loss 21.239694595336914\n",
      "cls loss 522.0676879882812  loc loss 32.252281188964844\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 573.514892578125  loc loss 32.50015640258789\n",
      "cls loss 592.775146484375  loc loss 44.0300407409668\n",
      "cls loss 406.4659423828125  loc loss 19.875640869140625\n",
      "cls loss 484.1814270019531  loc loss 37.95851516723633\n",
      "cls loss 449.22479248046875  loc loss 25.640222549438477\n",
      "cls loss 254.91897583007812  loc loss 10.175954818725586\n",
      "cls loss 388.923095703125  loc loss 23.032737731933594\n",
      "cls loss 333.34564208984375  loc loss 15.748929977416992\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1., 35.])\n",
      "cls loss 368.68829345703125  loc loss 21.547945022583008\n",
      "cls loss 575.650390625  loc loss 30.2315616607666\n",
      "cls loss 559.904541015625  loc loss 36.76749038696289\n",
      "cls loss 492.52734375  loc loss 40.556312561035156\n",
      "cls loss 400.6278076171875  loc loss 31.628433227539062\n",
      "cls loss 543.8854370117188  loc loss 40.883399963378906\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 306.07574462890625  loc loss 17.55858039855957\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 451.35272216796875  loc loss 19.40892219543457\n",
      "cls loss 720.2447509765625  loc loss 37.052608489990234\n",
      "cls loss 842.8245849609375  loc loss 66.31260681152344\n",
      "cls loss 435.4234924316406  loc loss 22.234905242919922\n",
      "cls loss 380.42474365234375  loc loss 23.858814239501953\n",
      "cls loss 383.4046630859375  loc loss 19.82900619506836\n",
      "cls loss 395.90289306640625  loc loss 23.69902801513672\n",
      "cls loss 349.323486328125  loc loss 15.301582336425781\n",
      "cls loss 637.658203125  loc loss 43.5842399597168\n",
      "cls loss 538.1039428710938  loc loss 32.45066833496094\n",
      "cls loss 252.66796875  loc loss 18.712793350219727\n",
      "cls loss 523.0654296875  loc loss 28.517824172973633\n",
      "cls loss 624.8343505859375  loc loss 49.68192672729492\n",
      "cls loss 501.6756896972656  loc loss 33.02206039428711\n",
      "cls loss 429.80841064453125  loc loss 24.74501609802246\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.])\n",
      "cls loss 418.68017578125  loc loss 30.54844093322754\n",
      "cls loss 419.90875244140625  loc loss 28.164508819580078\n",
      "cls loss 533.5411376953125  loc loss 34.30229187011719\n",
      "cls loss 843.82177734375  loc loss 65.35693359375\n",
      "cls loss 346.30145263671875  loc loss 17.122936248779297\n",
      "cls loss 448.0010681152344  loc loss 27.97573471069336\n",
      "cls loss 362.292236328125  loc loss 19.684385299682617\n",
      "cls loss 380.1750793457031  loc loss 25.050073623657227\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 21., 21., 21.])\n",
      "cls loss 405.8883056640625  loc loss 25.300920486450195\n",
      "cls loss 380.80828857421875  loc loss 19.0137996673584\n",
      "cls loss 407.89239501953125  loc loss 27.268569946289062\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 35.])\n",
      "cls loss 532.460693359375  loc loss 32.83395004272461\n",
      "cls loss 200.06011962890625  loc loss 10.684103965759277\n",
      "cls loss 342.6971435546875  loc loss 21.891395568847656\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 326.085693359375  loc loss 14.231695175170898\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 38., 38.,  9., 38.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1.,  1.])\n",
      "cls loss 373.82354736328125  loc loss 23.564985275268555\n",
      "cls loss 620.0614013671875  loc loss 38.108009338378906\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 2.,  1., 77., 31., 10., 10.,  1.,  4., 10.])\n",
      "cls loss 308.57647705078125  loc loss 14.234672546386719\n",
      "cls loss 577.6395263671875  loc loss 32.84100341796875\n",
      "cls loss 1173.0347900390625  loc loss 65.07011413574219\n",
      "cls loss 352.1136169433594  loc loss 24.372406005859375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 501.5584716796875  loc loss 36.89401626586914\n",
      "cls loss 372.6068115234375  loc loss 18.240285873413086\n",
      "cls loss 358.5869140625  loc loss 17.617708206176758\n",
      "cls loss 507.9065246582031  loc loss 26.506629943847656\n",
      "cls loss 522.407470703125  loc loss 28.241790771484375\n",
      "cls loss 459.093505859375  loc loss 32.949893951416016\n",
      "cls loss 377.1145935058594  loc loss 18.011629104614258\n",
      "cls loss 382.34722900390625  loc loss 21.08951187133789\n",
      "cls loss 723.190185546875  loc loss 44.4647216796875\n",
      "cls loss 647.77783203125  loc loss 37.74679183959961\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1., 42., 42., 42., 42., 42., 42.,  1.,\n",
      "         1.,  1.,  1., 42.,  1.,  1., 42.,  1.])\n",
      "cls loss 356.34954833984375  loc loss 25.261821746826172\n",
      "cls loss 539.07763671875  loc loss 31.639741897583008\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.])\n",
      "cls loss 233.57546997070312  loc loss 13.241792678833008\n",
      "cls loss 542.2223510742188  loc loss 34.31024169921875\n",
      "cls loss 405.5980529785156  loc loss 29.740779876708984\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([11.])\n",
      "cls loss 254.7787322998047  loc loss 15.025885581970215\n",
      "cls loss 297.21881103515625  loc loss 14.825824737548828\n",
      "cls loss 320.2469482421875  loc loss 14.722321510314941\n",
      "cls loss 542.3262939453125  loc loss 32.89963912963867\n",
      "cls loss 437.1468811035156  loc loss 24.977357864379883\n",
      "cls loss 462.21185302734375  loc loss 30.24860954284668\n",
      "cls loss 660.1849365234375  loc loss 34.01744079589844\n",
      "cls loss 340.0238037109375  loc loss 19.585102081298828\n",
      "cls loss 710.3780517578125  loc loss 46.57635498046875\n",
      "cls loss 339.03424072265625  loc loss 21.161733627319336\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 319.1435546875  loc loss 20.835283279418945\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1., 38., 38., 42.])\n",
      "cls loss 415.3096923828125  loc loss 29.329227447509766\n",
      "cls loss 381.3856201171875  loc loss 22.524864196777344\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 339.68280029296875  loc loss 23.54242706298828\n",
      "cls loss 760.8712158203125  loc loss 51.497589111328125\n",
      "cls loss 467.8308410644531  loc loss 29.62659454345703\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10.,  3.,  3.,  6.,  8.,  8.,  1.,  1.,  1., 10.])\n",
      "cls loss 376.02508544921875  loc loss 18.97390365600586\n",
      "cls loss 236.59634399414062  loc loss 8.959113121032715\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10.,  3.])\n",
      "cls loss 346.932373046875  loc loss 20.56351089477539\n",
      "cls loss 180.54928588867188  loc loss 11.000272750854492\n",
      "cls loss 449.1189880371094  loc loss 31.07810401916504\n",
      "cls loss 535.947021484375  loc loss 33.39805603027344\n",
      "cls loss 381.58392333984375  loc loss 22.619678497314453\n",
      "cls loss 261.2799987792969  loc loss 13.80586051940918\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 34.])\n",
      "cls loss 638.80517578125  loc loss 39.33875274658203\n",
      "cls loss 704.3599243164062  loc loss 54.94218063354492\n",
      "cls loss 453.2353515625  loc loss 31.860952377319336\n",
      "cls loss 361.3742980957031  loc loss 24.037813186645508\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.,  1.])\n",
      "cls loss 389.7486572265625  loc loss 17.63315773010254\n",
      "cls loss 610.764892578125  loc loss 45.69590377807617\n",
      "cls loss 892.2720947265625  loc loss 58.244361877441406\n",
      "cls loss 738.870361328125  loc loss 38.88914489746094\n",
      "cls loss 441.50732421875  loc loss 22.965818405151367\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 507.2828063964844  loc loss 28.85087776184082\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10.])\n",
      "cls loss 316.95721435546875  loc loss 16.40565299987793\n",
      "cls loss 469.25311279296875  loc loss 23.355941772460938\n",
      "cls loss 432.1505126953125  loc loss 27.0263729095459\n",
      "cls loss 308.8623962402344  loc loss 17.892087936401367\n",
      "cls loss 409.8483581542969  loc loss 25.88084602355957\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21.,\n",
      "        21.])\n",
      "cls loss 518.7637939453125  loc loss 31.052330017089844\n",
      "cls loss 423.96917724609375  loc loss 25.303754806518555\n",
      "cls loss 282.985107421875  loc loss 13.003642082214355\n",
      "cls loss 613.571533203125  loc loss 39.111854553222656\n",
      "cls loss 463.7470703125  loc loss 29.61432647705078\n",
      "cls loss 347.639404296875  loc loss 17.345561981201172\n",
      "cls loss 683.3931884765625  loc loss 42.42328643798828\n",
      "cls loss 801.04345703125  loc loss 55.682151794433594\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15., 85.])\n",
      "cls loss 524.0568237304688  loc loss 31.850095748901367\n",
      "cls loss 518.7183837890625  loc loss 38.20725631713867\n",
      "cls loss 536.9259033203125  loc loss 38.77894592285156\n",
      "cls loss 457.855712890625  loc loss 26.943212509155273\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 8., 8.])\n",
      "cls loss 299.91680908203125  loc loss 13.538566589355469\n",
      "cls loss 315.2225036621094  loc loss 23.42688751220703\n",
      "cls loss 398.69622802734375  loc loss 24.515169143676758\n",
      "cls loss 342.3861083984375  loc loss 18.475812911987305\n",
      "cls loss 375.3531494140625  loc loss 21.778385162353516\n",
      "cls loss 538.532958984375  loc loss 31.832401275634766\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1., 35., 27., 27.,  1., 27.,  1.])\n",
      "cls loss 648.6614990234375  loc loss 47.32049560546875\n",
      "cls loss 363.01495361328125  loc loss 21.21139144897461\n",
      "cls loss 405.1997985839844  loc loss 29.114147186279297\n",
      "cls loss 376.941650390625  loc loss 33.41687774658203\n",
      "cls loss 346.94097900390625  loc loss 25.19614601135254\n",
      "cls loss 384.6304016113281  loc loss 28.97757339477539\n",
      "cls loss 392.693115234375  loc loss 29.722347259521484\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  2.,  2.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  2.,  2.])\n",
      "cls loss 202.12620544433594  loc loss 8.446486473083496\n",
      "cls loss 623.0701904296875  loc loss 37.793861389160156\n",
      "cls loss 407.76666259765625  loc loss 18.53061294555664\n",
      "cls loss 679.9359130859375  loc loss 48.94335174560547\n",
      "cls loss 265.33441162109375  loc loss 15.290291786193848\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 19., 19., 19., 16.])\n",
      "cls loss 281.5225830078125  loc loss 12.088645935058594\n",
      "cls loss 224.41806030273438  loc loss 9.377049446105957\n",
      "cls loss 375.25665283203125  loc loss 18.767135620117188\n",
      "cls loss 494.73828125  loc loss 31.508541107177734\n",
      "cls loss 199.90625  loc loss 15.645913124084473\n",
      "cls loss 546.617919921875  loc loss 41.498382568359375\n",
      "cls loss 397.26434326171875  loc loss 25.91279411315918\n",
      "cls loss 422.9208679199219  loc loss 27.172969818115234\n",
      "cls loss 541.5838623046875  loc loss 35.88539505004883\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 566.623291015625  loc loss 25.917930603027344\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 769.5009765625  loc loss 64.45613098144531\n",
      "cls loss 999.5046997070312  loc loss 89.30072021484375\n",
      "cls loss 520.1881713867188  loc loss 29.48641014099121\n",
      "cls loss 457.07342529296875  loc loss 27.851730346679688\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3.,  3.,  3.,  3.,  3., 10.])\n",
      "cls loss 227.95977783203125  loc loss 14.156267166137695\n",
      "cls loss 485.3787536621094  loc loss 22.664710998535156\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 1., 1., 1., 3., 3., 3., 3.])\n",
      "cls loss 371.50689697265625  loc loss 20.18802833557129\n",
      "cls loss 722.9861450195312  loc loss 44.876373291015625\n",
      "cls loss 569.8577270507812  loc loss 35.06967544555664\n",
      "cls loss 366.3365478515625  loc loss 21.158077239990234\n",
      "cls loss 571.6145629882812  loc loss 38.54608154296875\n",
      "cls loss 346.0793151855469  loc loss 25.036827087402344\n",
      "cls loss 547.2445068359375  loc loss 37.90618133544922\n",
      "cls loss 415.8905029296875  loc loss 38.65311050415039\n",
      "cls loss 420.4337158203125  loc loss 26.483657836914062\n",
      "cls loss 868.5911254882812  loc loss 69.97367858886719\n",
      "cls loss 577.4615478515625  loc loss 42.09795379638672\n",
      "cls loss 391.6047668457031  loc loss 18.910846710205078\n",
      "cls loss 252.55563354492188  loc loss 11.058503150939941\n",
      "cls loss 304.91534423828125  loc loss 14.550874710083008\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3., 10., 10., 10., 10., 10., 10., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10., 10., 10., 10., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 11., 10., 10., 10., 10., 10.,  3.,  3.,  3.,  3.,  3.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 11., 10., 10., 10., 10., 10.,  3.,  3.,  3.,  3.,  3.])\n",
      "cls loss 251.1876220703125  loc loss 11.891136169433594\n",
      "cls loss 337.27301025390625  loc loss 14.917221069335938\n",
      "cls loss 280.9468994140625  loc loss 16.416227340698242\n",
      "cls loss 297.41595458984375  loc loss 12.949996948242188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 349.6686096191406  loc loss 26.917219161987305\n",
      "cls loss 270.0220947265625  loc loss 10.867398262023926\n",
      "cls loss 530.2138061523438  loc loss 35.249244689941406\n",
      "cls loss 469.35919189453125  loc loss 29.598419189453125\n",
      "cls loss 709.827880859375  loc loss 43.671485900878906\n",
      "cls loss 357.2416076660156  loc loss 24.813966751098633\n",
      "cls loss 625.7952880859375  loc loss 39.950042724609375\n",
      "cls loss 487.6163024902344  loc loss 33.28455352783203\n",
      "cls loss 478.40435791015625  loc loss 30.45728302001953\n",
      "cls loss 468.95770263671875  loc loss 32.79331588745117\n",
      "cls loss 620.8541259765625  loc loss 41.38709259033203\n",
      "cls loss 618.034423828125  loc loss 38.3619270324707\n",
      "cls loss 297.66162109375  loc loss 15.893198013305664\n",
      "cls loss 566.951171875  loc loss 39.12272262573242\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 10.,  1., 18.])\n",
      "cls loss 269.32354736328125  loc loss 17.841360092163086\n",
      "cls loss 343.27069091796875  loc loss 14.110336303710938\n",
      "cls loss 598.2711181640625  loc loss 30.183786392211914\n",
      "cls loss 791.6597900390625  loc loss 44.62860107421875\n",
      "cls loss 467.01214599609375  loc loss 31.48731231689453\n",
      "cls loss 678.7197265625  loc loss 33.64848709106445\n",
      "cls loss 490.11187744140625  loc loss 32.24983596801758\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.,  1.,  1.])\n",
      "cls loss 587.9586181640625  loc loss 37.03589630126953\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1., 38.,  1.])\n",
      "cls loss 503.27459716796875  loc loss 29.87367057800293\n",
      "cls loss 715.30615234375  loc loss 53.453556060791016\n",
      "cls loss 394.60650634765625  loc loss 26.293928146362305\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 536.1280517578125  loc loss 33.19459915161133\n",
      "cls loss 444.29559326171875  loc loss 27.08465576171875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3., 10.,  8.,  3., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.])\n",
      "cls loss 506.8224792480469  loc loss 29.04500961303711\n",
      "cls loss 339.6307067871094  loc loss 22.85752296447754\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3.,  3., 11.,  3., 10., 10.,  3.,  3., 10.])\n",
      "cls loss 411.0058288574219  loc loss 20.64497947692871\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3., 10., 10., 10.])\n",
      "cls loss 434.397705078125  loc loss 25.283706665039062\n",
      "cls loss 360.7222900390625  loc loss 21.59935760498047\n",
      "cls loss 465.12188720703125  loc loss 30.363698959350586\n",
      "cls loss 671.9915161132812  loc loss 37.55536651611328\n",
      "cls loss 444.64862060546875  loc loss 26.553558349609375\n",
      "cls loss 338.7024841308594  loc loss 26.49509048461914\n",
      "cls loss 432.31024169921875  loc loss 27.107973098754883\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 9.,  9., 85., 85.])\n",
      "cls loss 340.7779846191406  loc loss 18.695472717285156\n",
      "cls loss 428.904541015625  loc loss 30.86414909362793\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 675.32666015625  loc loss 46.48244857788086\n",
      "cls loss 580.58056640625  loc loss 28.051847457885742\n",
      "cls loss 648.0999755859375  loc loss 47.063995361328125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10., 10., 10., 10.])\n",
      "cls loss 404.02789306640625  loc loss 25.530662536621094\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([13.])\n",
      "cls loss 634.3345947265625  loc loss 49.82258605957031\n",
      "cls loss 199.12744140625  loc loss 10.865556716918945\n",
      "cls loss 286.4793701171875  loc loss 14.208810806274414\n",
      "cls loss 380.73956298828125  loc loss 21.53434944152832\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19.,  1.,  1.,  1., 19., 19.])\n",
      "cls loss 401.48870849609375  loc loss 25.830520629882812\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 328.17840576171875  loc loss 24.0941162109375\n",
      "cls loss 458.2355041503906  loc loss 33.47732925415039\n",
      "cls loss 360.59173583984375  loc loss 20.316951751708984\n",
      "cls loss 513.0667724609375  loc loss 27.170318603515625\n",
      "cls loss 544.1233520507812  loc loss 40.73243713378906\n",
      "cls loss 414.69525146484375  loc loss 23.077468872070312\n",
      "cls loss 648.4549560546875  loc loss 44.568565368652344\n",
      "cls loss 236.49221801757812  loc loss 10.742110252380371\n",
      "cls loss 452.1890869140625  loc loss 28.11650848388672\n",
      "cls loss 354.3348693847656  loc loss 18.684871673583984\n",
      "cls loss 392.3081970214844  loc loss 22.81099510192871\n",
      "cls loss 520.8924560546875  loc loss 30.59886932373047\n",
      "cls loss 446.42730712890625  loc loss 22.097774505615234\n",
      "cls loss 630.3717041015625  loc loss 41.60758590698242\n",
      "cls loss 409.4790954589844  loc loss 25.796001434326172\n",
      "cls loss 527.1025390625  loc loss 37.5524787902832\n",
      "cls loss 765.5029296875  loc loss 46.15278244018555\n",
      "cls loss 399.282958984375  loc loss 29.848892211914062\n",
      "cls loss 481.73455810546875  loc loss 28.713899612426758\n",
      "cls loss 550.5117797851562  loc loss 43.67519760131836\n",
      "cls loss 637.6069946289062  loc loss 45.091854095458984\n",
      "cls loss 748.6174926757812  loc loss 40.9622802734375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 5.])\n",
      "cls loss 200.2627410888672  loc loss 9.260893821716309\n",
      "cls loss 275.31597900390625  loc loss 11.968448638916016\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 13.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 6., 8., 8.])\n",
      "cls loss 218.8632354736328  loc loss 12.299566268920898\n",
      "cls loss 293.57354736328125  loc loss 15.227483749389648\n",
      "cls loss 577.6890869140625  loc loss 37.891845703125\n",
      "cls loss 245.8679962158203  loc loss 13.89946174621582\n",
      "cls loss 477.09765625  loc loss 35.256614685058594\n",
      "cls loss 711.7255249023438  loc loss 51.301815032958984\n",
      "cls loss 446.660400390625  loc loss 31.13890838623047\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([42., 42.,  1.,  1.,  1.,  1.,  1.,  1.,  1., 42., 42.])\n",
      "cls loss 494.9771728515625  loc loss 25.97872543334961\n",
      "cls loss 632.3467407226562  loc loss 46.24518585205078\n",
      "cls loss 577.0308227539062  loc loss 38.311500549316406\n",
      "cls loss 368.65985107421875  loc loss 22.924175262451172\n",
      "cls loss 483.0914306640625  loc loss 26.016517639160156\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 689.4310302734375  loc loss 43.69666290283203\n",
      "cls loss 551.3732299804688  loc loss 37.86180877685547\n",
      "cls loss 333.5155944824219  loc loss 18.88800811767578\n",
      "cls loss 278.5224609375  loc loss 16.77928352355957\n",
      "cls loss 374.03643798828125  loc loss 23.303390502929688\n",
      "cls loss 533.5701904296875  loc loss 32.29444122314453\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15.])\n",
      "cls loss 266.8802185058594  loc loss 9.69858455657959\n",
      "cls loss 455.216552734375  loc loss 27.468982696533203\n",
      "cls loss 385.9501647949219  loc loss 25.949981689453125\n",
      "cls loss 700.4300537109375  loc loss 46.18661880493164\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19.,  7.])\n",
      "cls loss 348.9584045410156  loc loss 20.29610824584961\n",
      "cls loss 735.003173828125  loc loss 48.93196487426758\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 653.5970458984375  loc loss 32.08356857299805\n",
      "cls loss 547.7523193359375  loc loss 38.257286071777344\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([38., 38.,  1., 18.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1., 18., 18.,  1.])\n",
      "cls loss 388.1758728027344  loc loss 20.469030380249023\n",
      "cls loss 385.74273681640625  loc loss 17.89374542236328\n",
      "cls loss 726.6031494140625  loc loss 49.425052642822266\n",
      "cls loss 539.80712890625  loc loss 30.00461769104004\n",
      "cls loss 454.63470458984375  loc loss 26.346664428710938\n",
      "cls loss 294.0371398925781  loc loss 22.26179313659668\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.])\n",
      "cls loss 197.70388793945312  loc loss 8.057270050048828\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([32.])\n",
      "cls loss 464.48974609375  loc loss 24.867843627929688\n",
      "cls loss 389.42364501953125  loc loss 27.27010726928711\n",
      "cls loss 500.2416076660156  loc loss 38.779945373535156\n",
      "cls loss 442.65728759765625  loc loss 29.128070831298828\n",
      "cls loss 368.5091552734375  loc loss 22.520038604736328\n",
      "cls loss 609.2186889648438  loc loss 35.51924514770508\n",
      "cls loss 692.88671875  loc loss 44.4373664855957\n",
      "cls loss 522.8358764648438  loc loss 34.22340393066406\n",
      "cls loss 418.94757080078125  loc loss 24.218412399291992\n",
      "cls loss 661.7075805664062  loc loss 42.08570098876953\n",
      "cls loss 458.0216064453125  loc loss 22.86019515991211\n",
      "cls loss 772.7802734375  loc loss 49.99647521972656\n",
      "cls loss 512.13037109375  loc loss 28.125267028808594\n",
      "cls loss 411.61962890625  loc loss 31.479795455932617\n",
      "cls loss 317.3248291015625  loc loss 14.669967651367188\n",
      "cls loss 357.99298095703125  loc loss 22.744266510009766\n",
      "cls loss 534.2354736328125  loc loss 34.785484313964844\n",
      "cls loss 568.6807861328125  loc loss 38.37190246582031\n",
      "cls loss 321.38812255859375  loc loss 19.640167236328125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 578.7591552734375  loc loss 38.68873596191406\n",
      "cls loss 705.034912109375  loc loss 43.55885314941406\n",
      "cls loss 259.7930603027344  loc loss 16.14832878112793\n",
      "cls loss 680.0228271484375  loc loss 45.28736877441406\n",
      "cls loss 511.5184020996094  loc loss 34.93782424926758\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 672.682373046875  loc loss 50.8631706237793\n",
      "cls loss 319.16302490234375  loc loss 11.954429626464844\n",
      "cls loss 473.82659912109375  loc loss 25.85978126525879\n",
      "cls loss 477.69830322265625  loc loss 31.205039978027344\n",
      "cls loss 382.8902587890625  loc loss 21.987751007080078\n",
      "cls loss 223.85218811035156  loc loss 12.090932846069336\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 9., 9., 1., 9., 9., 9., 9., 1., 9.])\n",
      "cls loss 857.9843139648438  loc loss 65.26947021484375\n",
      "cls loss 494.455810546875  loc loss 25.576519012451172\n",
      "cls loss 740.18359375  loc loss 57.075035095214844\n",
      "cls loss 310.23089599609375  loc loss 22.143383026123047\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 42., 42.])\n",
      "cls loss 518.6168212890625  loc loss 38.95143127441406\n",
      "cls loss 541.561279296875  loc loss 41.04317855834961\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  2.,  1.,  1.,  1., 38.,\n",
      "         1.,  1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 38., 38., 38.,  1., 38., 38., 38.,  1.,  1., 38.,  1.,\n",
      "         1.])\n",
      "cls loss 329.74542236328125  loc loss 24.945594787597656\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  8.,  8.])\n",
      "cls loss 804.690185546875  loc loss 52.57835006713867\n",
      "cls loss 810.5364990234375  loc loss 61.607540130615234\n",
      "cls loss 307.8888854980469  loc loss 18.47125244140625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([4., 1., 1., 4.])\n",
      "cls loss 476.39691162109375  loc loss 29.501220703125\n",
      "cls loss 566.6094970703125  loc loss 32.45994567871094\n",
      "cls loss 230.76968383789062  loc loss 11.563467025756836\n",
      "cls loss 303.4963684082031  loc loss 19.294830322265625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([51.,  1.])\n",
      "cls loss 221.78488159179688  loc loss 9.251930236816406\n",
      "cls loss 315.01702880859375  loc loss 17.39565086364746\n",
      "cls loss 572.5393676757812  loc loss 31.96792221069336\n",
      "cls loss 572.749267578125  loc loss 40.7877311706543\n",
      "cls loss 840.6036376953125  loc loss 44.140926361083984\n",
      "cls loss 1017.8898315429688  loc loss 67.2227783203125\n",
      "cls loss 416.523681640625  loc loss 26.189281463623047\n",
      "cls loss 607.020263671875  loc loss 46.65272903442383\n",
      "cls loss 666.0526123046875  loc loss 44.91072082519531\n",
      "cls loss 507.2183837890625  loc loss 29.61400604248047\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  3.,  1.,  1.,  1.,  3.,  1.,  1.,\n",
      "         1.,  1.,  1.])\n",
      "cls loss 546.85595703125  loc loss 23.54715919494629\n",
      "cls loss 623.5859375  loc loss 30.51862335205078\n",
      "cls loss 559.1958618164062  loc loss 28.808399200439453\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "cls loss 463.7213134765625  loc loss 27.323692321777344\n",
      "cls loss 250.7967529296875  loc loss 21.263654708862305\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3.])\n",
      "cls loss 197.237548828125  loc loss 11.48095417022705\n",
      "cls loss 368.72784423828125  loc loss 25.056320190429688\n",
      "cls loss 325.89544677734375  loc loss 23.27603530883789\n",
      "cls loss 618.4305419921875  loc loss 38.6943359375\n",
      "cls loss 317.7076721191406  loc loss 21.262149810791016\n",
      "cls loss 326.98614501953125  loc loss 24.087547302246094\n",
      "cls loss 973.0989379882812  loc loss 64.55772399902344\n",
      "cls loss 410.19781494140625  loc loss 32.95830154418945\n",
      "cls loss 325.2318420410156  loc loss 22.539146423339844\n",
      "cls loss 396.9892883300781  loc loss 22.79085922241211\n",
      "cls loss 371.87078857421875  loc loss 26.53160858154297\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 666.3826904296875  loc loss 43.73939514160156\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  9., 64., 64., 64., 64., 64., 64., 64., 64., 64.,  9.,  9.,  9.,\n",
      "         9.])\n",
      "cls loss 332.6525573730469  loc loss 15.700422286987305\n",
      "cls loss 895.37744140625  loc loss 67.65660095214844\n",
      "cls loss 471.3106994628906  loc loss 30.624544143676758\n",
      "cls loss 585.7240600585938  loc loss 38.19465637207031\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.,  3.,  3.])\n",
      "cls loss 357.353759765625  loc loss 19.71174430847168\n",
      "cls loss 391.3350830078125  loc loss 27.210006713867188\n",
      "cls loss 395.4248046875  loc loss 27.955467224121094\n",
      "cls loss 415.7688293457031  loc loss 30.69462013244629\n",
      "cls loss 443.8094482421875  loc loss 35.42681121826172\n",
      "cls loss 472.449951171875  loc loss 33.057334899902344\n",
      "cls loss 424.27166748046875  loc loss 31.348140716552734\n",
      "cls loss 452.39056396484375  loc loss 25.922109603881836\n",
      "cls loss 571.6510009765625  loc loss 37.46144104003906\n",
      "cls loss 421.4939880371094  loc loss 26.827409744262695\n",
      "cls loss 342.3143615722656  loc loss 17.002883911132812\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21.])\n",
      "cls loss 275.31561279296875  loc loss 16.135360717773438\n",
      "cls loss 397.242431640625  loc loss 33.21963119506836\n",
      "cls loss 590.571044921875  loc loss 39.204681396484375\n",
      "cls loss 307.761962890625  loc loss 17.24370002746582\n",
      "cls loss 463.60736083984375  loc loss 28.66785430908203\n",
      "cls loss 865.7657470703125  loc loss 44.99393081665039\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 42., 42.,  1.,  1.])\n",
      "cls loss 460.93115234375  loc loss 27.47820472717285\n",
      "cls loss 298.91510009765625  loc loss 20.143634796142578\n",
      "cls loss 424.29217529296875  loc loss 28.86381721496582\n",
      "cls loss 567.400390625  loc loss 47.044620513916016\n",
      "cls loss 367.52593994140625  loc loss 23.097604751586914\n",
      "cls loss 563.5172119140625  loc loss 41.064971923828125\n",
      "cls loss 522.0394897460938  loc loss 36.68094253540039\n",
      "cls loss 510.22882080078125  loc loss 32.65410614013672\n",
      "cls loss 420.24127197265625  loc loss 25.64092254638672\n",
      "cls loss 343.8679504394531  loc loss 23.1557674407959\n",
      "cls loss 296.6595764160156  loc loss 12.230855941772461\n",
      "cls loss 412.220947265625  loc loss 25.939716339111328\n",
      "cls loss 627.1290283203125  loc loss 41.73331832885742\n",
      "cls loss 491.17950439453125  loc loss 28.095130920410156\n",
      "cls loss 446.3736572265625  loc loss 32.26506423950195\n",
      "cls loss 504.2275085449219  loc loss 29.888404846191406\n",
      "cls loss 726.1529541015625  loc loss 52.54351043701172\n",
      "cls loss 547.9969482421875  loc loss 39.183902740478516\n",
      "cls loss 599.3258056640625  loc loss 33.960201263427734\n",
      "cls loss 351.6926574707031  loc loss 17.29681396484375\n",
      "cls loss 503.0296630859375  loc loss 32.35875701904297\n",
      "cls loss 465.23187255859375  loc loss 27.498966217041016\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 5., 5., 5., 5., 5., 5.])\n",
      "cls loss 311.7153625488281  loc loss 20.90335464477539\n",
      "cls loss 398.2900390625  loc loss 21.54297637939453\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([13.])\n",
      "cls loss 279.46685791015625  loc loss 15.984427452087402\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([44., 10.,  1.,  1.,  1.])\n",
      "cls loss 258.97161865234375  loc loss 17.578508377075195\n",
      "cls loss 472.603271484375  loc loss 26.177669525146484\n",
      "cls loss 424.2610168457031  loc loss 24.25993537902832\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19., 19., 19., 19., 19., 19., 19.])\n",
      "cls loss 478.7812805175781  loc loss 27.287006378173828\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([56.])\n",
      "cls loss 940.05517578125  loc loss 61.90526580810547\n",
      "cls loss 591.127685546875  loc loss 43.767494201660156\n",
      "cls loss 753.7361450195312  loc loss 49.75510787963867\n",
      "cls loss 729.109619140625  loc loss 54.415489196777344\n",
      "cls loss 471.01513671875  loc loss 24.83694076538086\n",
      "cls loss 740.210693359375  loc loss 47.8781852722168\n",
      "cls loss 420.8065185546875  loc loss 27.655536651611328\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 36.])\n",
      "cls loss 524.52685546875  loc loss 26.5172119140625\n",
      "cls loss 443.18212890625  loc loss 29.45709228515625\n",
      "cls loss 420.9757080078125  loc loss 25.44689178466797\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5.])\n",
      "cls loss 479.574462890625  loc loss 30.408245086669922\n",
      "cls loss 260.8492431640625  loc loss 14.314611434936523\n",
      "cls loss 629.3510131835938  loc loss 33.884578704833984\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "cls loss 537.57666015625  loc loss 35.30577087402344\n",
      "cls loss 510.0570068359375  loc loss 35.72679138183594\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 538.49853515625  loc loss 36.34114456176758\n",
      "cls loss 608.2655029296875  loc loss 41.44379806518555\n",
      "cls loss 517.6045532226562  loc loss 44.33057403564453\n",
      "cls loss 369.1152038574219  loc loss 24.53026580810547\n",
      "cls loss 425.3654479980469  loc loss 30.576818466186523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 455.47760009765625  loc loss 28.201499938964844\n",
      "cls loss 718.4285888671875  loc loss 38.2442626953125\n",
      "cls loss 317.59234619140625  loc loss 15.773408889770508\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 11., 15., 10., 10., 10., 10., 10.])\n",
      "cls loss 703.0608520507812  loc loss 45.09518814086914\n",
      "cls loss 406.82550048828125  loc loss 29.65594482421875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3.])\n",
      "cls loss 432.4373779296875  loc loss 30.428781509399414\n",
      "cls loss 395.62823486328125  loc loss 21.59313201904297\n",
      "cls loss 441.475341796875  loc loss 21.89000129699707\n",
      "cls loss 554.8087768554688  loc loss 25.552734375\n",
      "cls loss 275.0345764160156  loc loss 14.177186012268066\n",
      "cls loss 450.2900695800781  loc loss 29.69759750366211\n",
      "cls loss 505.58026123046875  loc loss 35.0920295715332\n",
      "cls loss 430.60736083984375  loc loss 30.588651657104492\n",
      "cls loss 1016.9293212890625  loc loss 68.4384994506836\n",
      "cls loss 688.21923828125  loc loss 44.50294494628906\n",
      "cls loss 454.0914306640625  loc loss 31.577022552490234\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  9.,  9.,  9.,  6.,  6., 85., 85.,  8.,  1.,  1.,  1.,  1.,\n",
      "         6.,  6.])\n",
      "cls loss 299.22088623046875  loc loss 24.788841247558594\n",
      "cls loss 740.0026245117188  loc loss 51.80638122558594\n",
      "cls loss 880.1389770507812  loc loss 53.83116912841797\n",
      "cls loss 580.7100830078125  loc loss 40.410770416259766\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10.,  3.,  3., 10.])\n",
      "cls loss 390.14007568359375  loc loss 20.607131958007812\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([7.])\n",
      "cls loss 477.5802001953125  loc loss 31.01663589477539\n",
      "cls loss 485.2811279296875  loc loss 29.14080047607422\n",
      "cls loss 472.10504150390625  loc loss 38.81736755371094\n",
      "cls loss 691.1805419921875  loc loss 54.21986770629883\n",
      "cls loss 433.6587219238281  loc loss 29.80401611328125\n",
      "cls loss 634.8156127929688  loc loss 41.055564880371094\n",
      "cls loss 808.9539794921875  loc loss 46.364471435546875\n",
      "cls loss 487.30889892578125  loc loss 32.067596435546875\n",
      "cls loss 526.7333984375  loc loss 37.48341369628906\n",
      "cls loss 417.8232421875  loc loss 30.988445281982422\n",
      "cls loss 654.7686767578125  loc loss 49.92675018310547\n",
      "cls loss 490.72052001953125  loc loss 31.422908782958984\n",
      "cls loss 399.7500305175781  loc loss 23.755586624145508\n",
      "cls loss 604.1862182617188  loc loss 45.227195739746094\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([62.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([62.])\n",
      "cls loss 293.7021179199219  loc loss 13.624795913696289\n",
      "cls loss 455.29296875  loc loss 32.70804214477539\n",
      "cls loss 446.3773193359375  loc loss 28.960941314697266\n",
      "cls loss 295.5289306640625  loc loss 14.730039596557617\n",
      "cls loss 588.2408447265625  loc loss 38.783050537109375\n",
      "cls loss 620.4443359375  loc loss 33.93695068359375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([28.])\n",
      "cls loss 730.02734375  loc loss 35.96586990356445\n",
      "cls loss 573.1915283203125  loc loss 35.73052978515625\n",
      "cls loss 574.990966796875  loc loss 38.684112548828125\n",
      "cls loss 589.3182983398438  loc loss 36.314903259277344\n",
      "cls loss 802.3555908203125  loc loss 52.82960891723633\n",
      "cls loss 471.7667236328125  loc loss 28.331201553344727\n",
      "cls loss 601.2879638671875  loc loss 34.6431884765625\n",
      "cls loss 493.0559997558594  loc loss 40.125144958496094\n",
      "cls loss 812.4110717773438  loc loss 64.48832702636719\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([81.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 530.7774658203125  loc loss 22.96929168701172\n",
      "cls loss 399.01861572265625  loc loss 21.95833969116211\n",
      "cls loss 302.8514404296875  loc loss 22.86294174194336\n",
      "cls loss 275.55712890625  loc loss 11.626583099365234\n",
      "cls loss 310.12957763671875  loc loss 23.208816528320312\n",
      "cls loss 369.4869384765625  loc loss 23.01179313659668\n",
      "cls loss 392.275146484375  loc loss 26.284833908081055\n",
      "cls loss 550.6716918945312  loc loss 45.41753387451172\n",
      "cls loss 664.25048828125  loc loss 40.65691375732422\n",
      "cls loss 1164.570556640625  loc loss 77.08979797363281\n",
      "cls loss 468.4178466796875  loc loss 23.984298706054688\n",
      "cls loss 574.1783447265625  loc loss 42.441497802734375\n",
      "cls loss 410.4963684082031  loc loss 26.239337921142578\n",
      "cls loss 552.6127319335938  loc loss 30.52523422241211\n",
      "cls loss 459.39654541015625  loc loss 26.37298583984375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([44., 44.])\n",
      "cls loss 411.9213562011719  loc loss 20.05634117126465\n",
      "cls loss 442.4510498046875  loc loss 28.932126998901367\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15.])\n",
      "cls loss 463.1302795410156  loc loss 23.998722076416016\n",
      "cls loss 224.51339721679688  loc loss 13.959853172302246\n",
      "cls loss 463.773681640625  loc loss 28.821216583251953\n",
      "cls loss 270.8791809082031  loc loss 15.571318626403809\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([1., 3., 3.])\n",
      "cls loss 310.6123962402344  loc loss 21.292739868164062\n",
      "cls loss 232.31353759765625  loc loss 10.863661766052246\n",
      "cls loss 445.0826721191406  loc loss 28.36041259765625\n",
      "cls loss 498.64935302734375  loc loss 28.633346557617188\n",
      "cls loss 450.41119384765625  loc loss 30.572521209716797\n",
      "cls loss 386.71612548828125  loc loss 24.543262481689453\n",
      "cls loss 383.91790771484375  loc loss 28.411130905151367\n",
      "cls loss 528.8554077148438  loc loss 33.50896453857422\n",
      "cls loss 377.88592529296875  loc loss 25.326927185058594\n",
      "cls loss 513.3090209960938  loc loss 34.34074020385742\n",
      "cls loss 343.6357421875  loc loss 18.62810707092285\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 592.4860229492188  loc loss 35.8625373840332\n",
      "cls loss 710.70751953125  loc loss 32.04435348510742\n",
      "cls loss 605.931640625  loc loss 42.03407669067383\n",
      "cls loss 601.7117309570312  loc loss 48.05707550048828\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10., 10., 10.,  1.,  1.,  1.,  1.,  1.,  1.,  8.,  8.,\n",
      "         1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10., 10., 10.,  1.,  1.,  1.,  1.,  1.,  1.,  8.,  8.,\n",
      "         1.])\n",
      "cls loss 513.0316772460938  loc loss 25.44675064086914\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 3., 3., 3.])\n",
      "cls loss 465.85638427734375  loc loss 28.890583038330078\n",
      "cls loss 323.26531982421875  loc loss 19.408897399902344\n",
      "cls loss 248.58424377441406  loc loss 12.222249984741211\n",
      "cls loss 446.55499267578125  loc loss 32.989776611328125\n",
      "cls loss 348.41827392578125  loc loss 15.903907775878906\n",
      "cls loss 406.46209716796875  loc loss 26.2613582611084\n",
      "cls loss 459.3962707519531  loc loss 30.62038230895996\n",
      "cls loss 632.45166015625  loc loss 42.69935989379883\n",
      "cls loss 540.8690185546875  loc loss 26.53158187866211\n",
      "cls loss 505.6064453125  loc loss 28.351158142089844\n",
      "cls loss 526.3482666015625  loc loss 36.816341400146484\n",
      "cls loss 376.77581787109375  loc loss 29.950149536132812\n",
      "cls loss 736.9609985351562  loc loss 55.51216125488281\n",
      "cls loss 346.206787109375  loc loss 18.245588302612305\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 585.3823852539062  loc loss 35.006927490234375\n",
      "cls loss 273.3963623046875  loc loss 11.279072761535645\n",
      "cls loss 685.7586669921875  loc loss 43.41107940673828\n",
      "cls loss 340.2734375  loc loss 20.32535171508789\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 34.])\n",
      "cls loss 558.036376953125  loc loss 30.153980255126953\n",
      "cls loss 273.7722473144531  loc loss 17.947322845458984\n",
      "cls loss 546.8837890625  loc loss 33.8305549621582\n",
      "cls loss 184.2373046875  loc loss 13.45240592956543\n",
      "cls loss 450.39849853515625  loc loss 27.677101135253906\n",
      "cls loss 440.490966796875  loc loss 36.422794342041016\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 38.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16., 16., 16.,  9.,  9.,  9., 16., 16., 16., 85.,  9.])\n",
      "cls loss 458.10791015625  loc loss 29.556529998779297\n",
      "cls loss 504.0946044921875  loc loss 39.5985107421875\n",
      "cls loss 673.9511108398438  loc loss 44.991241455078125\n",
      "cls loss 1035.92626953125  loc loss 64.90331268310547\n",
      "cls loss 291.091552734375  loc loss 15.71904182434082\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3., 10.,  8.,  8., 10., 10., 10.,  3.,  3., 14.])\n",
      "cls loss 308.3569030761719  loc loss 17.050315856933594\n",
      "cls loss 590.4913330078125  loc loss 34.1970100402832\n",
      "cls loss 266.656494140625  loc loss 10.143876075744629\n",
      "cls loss 426.2862548828125  loc loss 18.300657272338867\n",
      "cls loss 560.137939453125  loc loss 33.646583557128906\n",
      "cls loss 479.1752624511719  loc loss 29.423885345458984\n",
      "cls loss 265.3006896972656  loc loss 14.020275115966797\n",
      "cls loss 332.55950927734375  loc loss 18.439729690551758\n",
      "cls loss 530.8967895507812  loc loss 30.0529842376709\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42., 42.,  1.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 502.31353759765625  loc loss 32.41572570800781\n",
      "cls loss 381.4554443359375  loc loss 22.804821014404297\n",
      "cls loss 526.5977172851562  loc loss 40.65481948852539\n",
      "cls loss 615.3309936523438  loc loss 37.412353515625\n",
      "cls loss 422.53094482421875  loc loss 26.804039001464844\n",
      "cls loss 519.1593017578125  loc loss 37.81906509399414\n",
      "cls loss 325.3133544921875  loc loss 22.97700309753418\n",
      "cls loss 343.9972839355469  loc loss 25.020723342895508\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20.])\n",
      "cls loss 250.46835327148438  loc loss 15.672516822814941\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([11.])\n",
      "cls loss 353.9520263671875  loc loss 16.77661895751953\n",
      "cls loss 217.93994140625  loc loss 13.045184135437012\n",
      "cls loss 530.9788818359375  loc loss 40.904476165771484\n",
      "cls loss 239.202880859375  loc loss 11.28638744354248\n",
      "cls loss 528.2130126953125  loc loss 29.00440216064453\n",
      "cls loss 290.7350158691406  loc loss 17.80299949645996\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 35., 27.])\n",
      "cls loss 498.2620849609375  loc loss 28.20806312561035\n",
      "cls loss 545.181396484375  loc loss 40.22343444824219\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 364.629638671875  loc loss 20.33226776123047\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([42.,  1.])\n",
      "cls loss 456.8889465332031  loc loss 31.37276840209961\n",
      "cls loss 450.1470947265625  loc loss 24.8082275390625\n",
      "cls loss 525.3333129882812  loc loss 32.59956359863281\n",
      "cls loss 669.4799194335938  loc loss 40.534690856933594\n",
      "cls loss 582.981201171875  loc loss 34.31364822387695\n",
      "cls loss 391.7025451660156  loc loss 28.105926513671875\n",
      "cls loss 335.9884338378906  loc loss 25.063438415527344\n",
      "cls loss 205.00416564941406  loc loss 9.853614807128906\n",
      "cls loss 394.6842041015625  loc loss 21.746288299560547\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 1., 1.])\n",
      "cls loss 378.3440246582031  loc loss 22.981969833374023\n",
      "cls loss 435.9771728515625  loc loss 28.71302604675293\n",
      "cls loss 426.8885498046875  loc loss 26.649456024169922\n",
      "cls loss 351.95843505859375  loc loss 24.702415466308594\n",
      "cls loss 428.7249450683594  loc loss 26.534658432006836\n",
      "cls loss 467.06048583984375  loc loss 32.18349075317383\n",
      "cls loss 653.1822509765625  loc loss 37.6700325012207\n",
      "cls loss 552.49560546875  loc loss 40.79684829711914\n",
      "cls loss 496.9131164550781  loc loss 30.4553279876709\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 388.3177490234375  loc loss 26.570411682128906\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 485.9117431640625  loc loss 23.158233642578125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([81.])\n",
      "cls loss 574.1729736328125  loc loss 33.026912689208984\n",
      "cls loss 347.3572692871094  loc loss 24.434921264648438\n",
      "cls loss 254.54449462890625  loc loss 14.042928695678711\n",
      "cls loss 389.00048828125  loc loss 21.49875831604004\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3.,  1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 19.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 19.])\n",
      "cls loss 523.15283203125  loc loss 36.466453552246094\n",
      "cls loss 299.51959228515625  loc loss 16.693836212158203\n",
      "cls loss 316.981201171875  loc loss 17.806873321533203\n",
      "cls loss 614.7514038085938  loc loss 44.96318435668945\n",
      "cls loss 307.79241943359375  loc loss 19.19969940185547\n",
      "cls loss 395.0884094238281  loc loss 24.309885025024414\n",
      "cls loss 496.6397705078125  loc loss 31.070470809936523\n",
      "cls loss 380.8367004394531  loc loss 26.222274780273438\n",
      "cls loss 487.71026611328125  loc loss 27.317432403564453\n",
      "cls loss 566.619140625  loc loss 36.747833251953125\n",
      "cls loss 688.8892822265625  loc loss 59.278865814208984\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 81.])\n",
      "cls loss 484.2076721191406  loc loss 24.561752319335938\n",
      "cls loss 425.1918640136719  loc loss 22.86699676513672\n",
      "cls loss 454.9219665527344  loc loss 25.210643768310547\n",
      "cls loss 347.68572998046875  loc loss 18.143430709838867\n",
      "cls loss 305.0862121582031  loc loss 19.98116683959961\n",
      "cls loss 334.088623046875  loc loss 27.34385871887207\n",
      "cls loss 268.6781005859375  loc loss 20.36363983154297\n",
      "cls loss 230.83721923828125  loc loss 15.572884559631348\n",
      "cls loss 318.68389892578125  loc loss 20.778358459472656\n",
      "cls loss 423.5083312988281  loc loss 26.251619338989258\n",
      "cls loss 373.1859130859375  loc loss 28.925661087036133\n",
      "cls loss 391.0205078125  loc loss 28.84620475769043\n",
      "cls loss 234.29757690429688  loc loss 15.901308059692383\n",
      "cls loss 807.8751831054688  loc loss 54.57953643798828\n",
      "cls loss 469.5403137207031  loc loss 31.82892608642578\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 428.8531494140625  loc loss 21.3876953125\n",
      "cls loss 491.23919677734375  loc loss 31.43470001220703\n",
      "cls loss 379.18243408203125  loc loss 23.39794158935547\n",
      "cls loss 579.9805297851562  loc loss 38.62486267089844\n",
      "cls loss 535.0022583007812  loc loss 32.85481643676758\n",
      "cls loss 492.6307067871094  loc loss 29.519283294677734\n",
      "cls loss 367.9771728515625  loc loss 23.4593505859375\n",
      "cls loss 295.4471130371094  loc loss 18.257837295532227\n",
      "cls loss 437.647705078125  loc loss 25.47373390197754\n",
      "cls loss 489.2666931152344  loc loss 32.32879638671875\n",
      "cls loss 480.1693115234375  loc loss 27.311479568481445\n",
      "cls loss 610.1822509765625  loc loss 44.112937927246094\n",
      "cls loss 629.1809692382812  loc loss 50.24713134765625\n",
      "cls loss 447.4071044921875  loc loss 32.25802230834961\n",
      "cls loss 637.8916625976562  loc loss 49.733741760253906\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1., 38., 47.,  1.,  1.,  1.,  1.,  1., 62.])\n",
      "cls loss 435.3092956542969  loc loss 20.987234115600586\n",
      "cls loss 513.5474243164062  loc loss 32.225555419921875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 567.0625  loc loss 32.203182220458984\n",
      "cls loss 587.793212890625  loc loss 43.46770095825195\n",
      "cls loss 403.1104736328125  loc loss 19.39023780822754\n",
      "cls loss 480.07843017578125  loc loss 37.304080963134766\n",
      "cls loss 446.45831298828125  loc loss 25.305326461791992\n",
      "cls loss 252.04893493652344  loc loss 10.116344451904297\n",
      "cls loss 382.41400146484375  loc loss 22.80533218383789\n",
      "cls loss 325.29803466796875  loc loss 15.758685111999512\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1., 35.])\n",
      "cls loss 360.15411376953125  loc loss 21.474750518798828\n",
      "cls loss 567.3720703125  loc loss 29.892425537109375\n",
      "cls loss 551.521728515625  loc loss 36.468563079833984\n",
      "cls loss 486.65106201171875  loc loss 39.85090637207031\n",
      "cls loss 394.4579162597656  loc loss 31.09935188293457\n",
      "cls loss 536.5745849609375  loc loss 40.41959762573242\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 300.985595703125  loc loss 17.410581588745117\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 446.15185546875  loc loss 19.178569793701172\n",
      "cls loss 710.6273193359375  loc loss 36.629371643066406\n",
      "cls loss 833.2286987304688  loc loss 66.01484680175781\n",
      "cls loss 430.47100830078125  loc loss 21.89082145690918\n",
      "cls loss 373.7261657714844  loc loss 23.28696060180664\n",
      "cls loss 379.7176818847656  loc loss 19.409975051879883\n",
      "cls loss 393.09954833984375  loc loss 23.136226654052734\n",
      "cls loss 344.571044921875  loc loss 14.962583541870117\n",
      "cls loss 630.1495361328125  loc loss 42.97552490234375\n",
      "cls loss 532.9229125976562  loc loss 31.912385940551758\n",
      "cls loss 245.82022094726562  loc loss 18.343320846557617\n",
      "cls loss 515.10888671875  loc loss 28.132783889770508\n",
      "cls loss 618.8628540039062  loc loss 49.048091888427734\n",
      "cls loss 493.39654541015625  loc loss 32.76253128051758\n",
      "cls loss 421.2969970703125  loc loss 24.436229705810547\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.])\n",
      "cls loss 412.3790588378906  loc loss 30.20688247680664\n",
      "cls loss 416.3794860839844  loc loss 27.581151962280273\n",
      "cls loss 527.5253295898438  loc loss 33.525577545166016\n",
      "cls loss 838.1625366210938  loc loss 64.32695007324219\n",
      "cls loss 339.57354736328125  loc loss 16.830257415771484\n",
      "cls loss 438.8115234375  loc loss 27.48123550415039\n",
      "cls loss 355.50311279296875  loc loss 19.3114070892334\n",
      "cls loss 372.58428955078125  loc loss 24.779443740844727\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 21., 21., 21.])\n",
      "cls loss 397.2432861328125  loc loss 24.957229614257812\n",
      "cls loss 374.91326904296875  loc loss 18.77793312072754\n",
      "cls loss 400.9444274902344  loc loss 26.63910675048828\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 35.])\n",
      "cls loss 524.4324951171875  loc loss 32.202232360839844\n",
      "cls loss 197.8959197998047  loc loss 10.463696479797363\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 339.7981872558594  loc loss 21.456905364990234\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 322.004150390625  loc loss 13.90864372253418\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 38., 38.,  9., 38.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1.,  1.])\n",
      "cls loss 370.1612548828125  loc loss 23.164213180541992\n",
      "cls loss 611.2286376953125  loc loss 37.442195892333984\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 2.,  1., 77., 31., 10., 10.,  1.,  4., 10.])\n",
      "cls loss 301.91668701171875  loc loss 13.887062072753906\n",
      "cls loss 566.5953369140625  loc loss 32.341922760009766\n",
      "cls loss 1159.2034912109375  loc loss 64.06706237792969\n",
      "cls loss 347.4423828125  loc loss 24.10563087463379\n",
      "cls loss 492.82330322265625  loc loss 36.27849578857422\n",
      "cls loss 364.3026123046875  loc loss 17.696269989013672\n",
      "cls loss 349.4486389160156  loc loss 17.271385192871094\n",
      "cls loss 496.6627502441406  loc loss 26.182512283325195\n",
      "cls loss 509.69964599609375  loc loss 27.68747329711914\n",
      "cls loss 450.2561950683594  loc loss 32.26655960083008\n",
      "cls loss 371.694091796875  loc loss 17.699697494506836\n",
      "cls loss 374.8165283203125  loc loss 20.791757583618164\n",
      "cls loss 706.6806640625  loc loss 43.55066680908203\n",
      "cls loss 640.9755859375  loc loss 37.08518981933594\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1., 42., 42., 42., 42., 42., 42.,  1.,\n",
      "         1.,  1.,  1., 42.,  1.,  1., 42.,  1.])\n",
      "cls loss 353.1210632324219  loc loss 25.01341438293457\n",
      "cls loss 531.161376953125  loc loss 30.930187225341797\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.])\n",
      "cls loss 231.01931762695312  loc loss 12.946367263793945\n",
      "cls loss 535.33447265625  loc loss 33.834327697753906\n",
      "cls loss 397.686279296875  loc loss 29.29439926147461\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([11.])\n",
      "cls loss 249.4031219482422  loc loss 14.706583023071289\n",
      "cls loss 288.7276916503906  loc loss 14.510597229003906\n",
      "cls loss 312.42529296875  loc loss 14.536650657653809\n",
      "cls loss 534.5254516601562  loc loss 32.201908111572266\n",
      "cls loss 427.94873046875  loc loss 24.416351318359375\n",
      "cls loss 457.9498291015625  loc loss 29.720308303833008\n",
      "cls loss 649.0007934570312  loc loss 33.457462310791016\n",
      "cls loss 336.5728759765625  loc loss 19.270471572875977\n",
      "cls loss 705.0631103515625  loc loss 45.697906494140625\n",
      "cls loss 335.4840087890625  loc loss 20.6849365234375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 314.109130859375  loc loss 20.391042709350586\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1., 38., 38., 42.])\n",
      "cls loss 411.2021789550781  loc loss 28.83287239074707\n",
      "cls loss 376.58599853515625  loc loss 22.267412185668945\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 334.8563232421875  loc loss 23.152145385742188\n",
      "cls loss 750.2418212890625  loc loss 50.59879684448242\n",
      "cls loss 461.0758361816406  loc loss 29.018991470336914\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10.,  3.,  3.,  6.,  8.,  8.,  1.,  1.,  1., 10.])\n",
      "cls loss 366.4776611328125  loc loss 18.49824333190918\n",
      "cls loss 232.82693481445312  loc loss 8.85478401184082\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10.,  3.])\n",
      "cls loss 339.79510498046875  loc loss 20.27097511291504\n",
      "cls loss 174.7814178466797  loc loss 10.842546463012695\n",
      "cls loss 439.1448974609375  loc loss 30.40081024169922\n",
      "cls loss 527.7105712890625  loc loss 32.878746032714844\n",
      "cls loss 374.93841552734375  loc loss 22.19740104675293\n",
      "cls loss 253.3124542236328  loc loss 13.68598747253418\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 34.])\n",
      "cls loss 628.11474609375  loc loss 38.686607360839844\n",
      "cls loss 699.708740234375  loc loss 53.656654357910156\n",
      "cls loss 451.5125427246094  loc loss 31.326396942138672\n",
      "cls loss 359.8236389160156  loc loss 23.657615661621094\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.,  1.])\n",
      "cls loss 386.6206359863281  loc loss 17.28330421447754\n",
      "cls loss 607.5712890625  loc loss 44.99677276611328\n",
      "cls loss 882.8861694335938  loc loss 57.30767822265625\n",
      "cls loss 728.9336547851562  loc loss 38.387229919433594\n",
      "cls loss 433.1292724609375  loc loss 22.511371612548828\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 495.62579345703125  loc loss 28.124929428100586\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10.])\n",
      "cls loss 310.1729736328125  loc loss 16.0438289642334\n",
      "cls loss 459.6579284667969  loc loss 22.74658966064453\n",
      "cls loss 426.1251525878906  loc loss 26.348546981811523\n",
      "cls loss 300.5623474121094  loc loss 17.408126831054688\n",
      "cls loss 402.697021484375  loc loss 25.268470764160156\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21.,\n",
      "        21.])\n",
      "cls loss 504.041748046875  loc loss 30.54717254638672\n",
      "cls loss 417.4219970703125  loc loss 24.794071197509766\n",
      "cls loss 278.1636962890625  loc loss 12.776199340820312\n",
      "cls loss 607.299560546875  loc loss 38.531280517578125\n",
      "cls loss 456.69281005859375  loc loss 29.01181411743164\n",
      "cls loss 345.8265380859375  loc loss 16.994497299194336\n",
      "cls loss 677.5880126953125  loc loss 41.67192077636719\n",
      "cls loss 791.2938232421875  loc loss 54.711856842041016\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15., 85.])\n",
      "cls loss 520.2286376953125  loc loss 31.15180015563965\n",
      "cls loss 511.44732666015625  loc loss 37.531063079833984\n",
      "cls loss 528.42822265625  loc loss 38.280330657958984\n",
      "cls loss 446.73028564453125  loc loss 26.724285125732422\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 8., 8.])\n",
      "cls loss 295.3169250488281  loc loss 13.111607551574707\n",
      "cls loss 308.54046630859375  loc loss 23.13848114013672\n",
      "cls loss 391.5235595703125  loc loss 23.95815658569336\n",
      "cls loss 338.0998229980469  loc loss 18.195226669311523\n",
      "cls loss 370.68572998046875  loc loss 21.164730072021484\n",
      "cls loss 533.0601806640625  loc loss 31.224689483642578\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1., 35., 27., 27.,  1., 27.,  1.])\n",
      "cls loss 634.406982421875  loc loss 46.61063003540039\n",
      "cls loss 359.68402099609375  loc loss 20.744718551635742\n",
      "cls loss 399.6832275390625  loc loss 28.66424560546875\n",
      "cls loss 373.0172119140625  loc loss 32.9116325378418\n",
      "cls loss 344.195068359375  loc loss 24.6580867767334\n",
      "cls loss 380.97894287109375  loc loss 28.547489166259766\n",
      "cls loss 388.9130859375  loc loss 29.11450958251953\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  2.,  2.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  2.,  2.])\n",
      "cls loss 198.46156311035156  loc loss 8.377750396728516\n",
      "cls loss 615.29443359375  loc loss 37.27924728393555\n",
      "cls loss 397.1029968261719  loc loss 18.163433074951172\n",
      "cls loss 669.888671875  loc loss 48.153873443603516\n",
      "cls loss 259.99560546875  loc loss 14.93873405456543\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 19., 19., 19., 16.])\n",
      "cls loss 274.8382873535156  loc loss 11.781462669372559\n",
      "cls loss 220.64877319335938  loc loss 9.254194259643555\n",
      "cls loss 369.91064453125  loc loss 18.50171661376953\n",
      "cls loss 488.50946044921875  loc loss 30.909666061401367\n",
      "cls loss 194.19973754882812  loc loss 15.211190223693848\n",
      "cls loss 538.4043579101562  loc loss 40.878822326660156\n",
      "cls loss 393.7818908691406  loc loss 25.441835403442383\n",
      "cls loss 416.41790771484375  loc loss 26.693511962890625\n",
      "cls loss 534.581298828125  loc loss 35.126121520996094\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 556.5338134765625  loc loss 25.538127899169922\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 762.135986328125  loc loss 63.38438034057617\n",
      "cls loss 989.3607177734375  loc loss 87.92792510986328\n",
      "cls loss 513.4925537109375  loc loss 28.684616088867188\n",
      "cls loss 451.986083984375  loc loss 27.293010711669922\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3.,  3.,  3.,  3.,  3., 10.])\n",
      "cls loss 223.83843994140625  loc loss 13.839012145996094\n",
      "cls loss 477.64227294921875  loc loss 22.138395309448242\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 1., 1., 1., 3., 3., 3., 3.])\n",
      "cls loss 367.52130126953125  loc loss 19.586156845092773\n",
      "cls loss 713.3814697265625  loc loss 44.18659210205078\n",
      "cls loss 564.7610473632812  loc loss 34.471046447753906\n",
      "cls loss 361.84100341796875  loc loss 20.899253845214844\n",
      "cls loss 565.1464233398438  loc loss 38.068092346191406\n",
      "cls loss 341.31207275390625  loc loss 24.558555603027344\n",
      "cls loss 540.716552734375  loc loss 37.392250061035156\n",
      "cls loss 412.0501708984375  loc loss 38.05963897705078\n",
      "cls loss 411.497314453125  loc loss 25.993934631347656\n",
      "cls loss 858.8858642578125  loc loss 68.81037902832031\n",
      "cls loss 569.8941040039062  loc loss 41.67943572998047\n",
      "cls loss 385.90576171875  loc loss 18.62887191772461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 247.1317596435547  loc loss 10.941625595092773\n",
      "cls loss 300.43701171875  loc loss 14.363226890563965\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3., 10., 10., 10., 10., 10., 10., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10., 10., 10., 10., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 11., 10., 10., 10., 10., 10.,  3.,  3.,  3.,  3.,  3.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 11., 10., 10., 10., 10., 10.,  3.,  3.,  3.,  3.,  3.])\n",
      "cls loss 244.35276794433594  loc loss 11.596796035766602\n",
      "cls loss 332.74420166015625  loc loss 14.441987991333008\n",
      "cls loss 276.6272277832031  loc loss 16.02175521850586\n",
      "cls loss 290.9818115234375  loc loss 12.6793794631958\n",
      "cls loss 345.1866760253906  loc loss 26.486766815185547\n",
      "cls loss 263.6308288574219  loc loss 10.717495918273926\n",
      "cls loss 523.586181640625  loc loss 34.67167282104492\n",
      "cls loss 467.61175537109375  loc loss 28.912647247314453\n",
      "cls loss 701.7567138671875  loc loss 43.05738830566406\n",
      "cls loss 353.32305908203125  loc loss 24.491344451904297\n",
      "cls loss 617.579345703125  loc loss 39.33441162109375\n",
      "cls loss 478.9043273925781  loc loss 32.91966247558594\n",
      "cls loss 472.9590148925781  loc loss 29.97420310974121\n",
      "cls loss 462.88665771484375  loc loss 32.158050537109375\n",
      "cls loss 610.8231201171875  loc loss 40.482444763183594\n",
      "cls loss 603.5498046875  loc loss 37.8050651550293\n",
      "cls loss 292.35235595703125  loc loss 15.67970085144043\n",
      "cls loss 560.101806640625  loc loss 38.35898971557617\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 10.,  1., 18.])\n",
      "cls loss 264.337646484375  loc loss 17.573110580444336\n",
      "cls loss 336.4048767089844  loc loss 13.920013427734375\n",
      "cls loss 592.0214233398438  loc loss 29.838729858398438\n",
      "cls loss 779.4578857421875  loc loss 43.9113655090332\n",
      "cls loss 461.72235107421875  loc loss 30.92197608947754\n",
      "cls loss 672.4410400390625  loc loss 32.80722427368164\n",
      "cls loss 486.93023681640625  loc loss 31.733169555664062\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.,  1.,  1.])\n",
      "cls loss 580.418701171875  loc loss 36.354427337646484\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1., 38.,  1.])\n",
      "cls loss 490.9341125488281  loc loss 29.35201072692871\n",
      "cls loss 706.3292236328125  loc loss 52.82611083984375\n",
      "cls loss 388.599609375  loc loss 25.914012908935547\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 530.2913818359375  loc loss 32.51265335083008\n",
      "cls loss 436.190185546875  loc loss 26.51970672607422\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3., 10.,  8.,  3., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.])\n",
      "cls loss 497.175048828125  loc loss 28.524173736572266\n",
      "cls loss 332.94384765625  loc loss 22.500635147094727\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3.,  3., 11.,  3., 10., 10.,  3.,  3., 10.])\n",
      "cls loss 401.4667663574219  loc loss 20.279190063476562\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3., 10., 10., 10.])\n",
      "cls loss 428.9537353515625  loc loss 24.539627075195312\n",
      "cls loss 353.27947998046875  loc loss 21.40990447998047\n",
      "cls loss 459.8555908203125  loc loss 29.8886661529541\n",
      "cls loss 663.3489990234375  loc loss 36.93535614013672\n",
      "cls loss 438.0879821777344  loc loss 26.066560745239258\n",
      "cls loss 334.8372802734375  loc loss 25.935110092163086\n",
      "cls loss 424.80303955078125  loc loss 26.321908950805664\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 9.,  9., 85., 85.])\n",
      "cls loss 336.8240661621094  loc loss 18.271909713745117\n",
      "cls loss 426.787353515625  loc loss 30.4339656829834\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 666.753662109375  loc loss 45.42387008666992\n",
      "cls loss 571.3529052734375  loc loss 27.60576629638672\n",
      "cls loss 641.832275390625  loc loss 46.63401412963867\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10., 10., 10., 10.])\n",
      "cls loss 399.156982421875  loc loss 25.399795532226562\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([13.])\n",
      "cls loss 626.2796630859375  loc loss 49.17071533203125\n",
      "cls loss 191.46392822265625  loc loss 10.552078247070312\n",
      "cls loss 279.2597961425781  loc loss 13.87807846069336\n",
      "cls loss 371.72698974609375  loc loss 21.08893394470215\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19.,  1.,  1.,  1., 19., 19.])\n",
      "cls loss 394.14093017578125  loc loss 25.134519577026367\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 323.95721435546875  loc loss 23.569711685180664\n",
      "cls loss 454.1643371582031  loc loss 32.96809387207031\n",
      "cls loss 357.41571044921875  loc loss 20.252389907836914\n",
      "cls loss 507.0757751464844  loc loss 26.787065505981445\n",
      "cls loss 538.0665283203125  loc loss 40.55202865600586\n",
      "cls loss 405.86627197265625  loc loss 23.0396728515625\n",
      "cls loss 640.824951171875  loc loss 43.668277740478516\n",
      "cls loss 230.75643920898438  loc loss 10.5071382522583\n",
      "cls loss 441.7708740234375  loc loss 27.539833068847656\n",
      "cls loss 347.11712646484375  loc loss 18.472232818603516\n",
      "cls loss 384.98284912109375  loc loss 22.64396858215332\n",
      "cls loss 516.7203369140625  loc loss 30.308109283447266\n",
      "cls loss 438.1103820800781  loc loss 21.935165405273438\n",
      "cls loss 618.512451171875  loc loss 41.07756805419922\n",
      "cls loss 403.307373046875  loc loss 25.470081329345703\n",
      "cls loss 520.380615234375  loc loss 37.095733642578125\n",
      "cls loss 752.9952392578125  loc loss 45.665321350097656\n",
      "cls loss 393.9552001953125  loc loss 29.40486717224121\n",
      "cls loss 476.468017578125  loc loss 28.25293731689453\n",
      "cls loss 545.7965087890625  loc loss 43.14844512939453\n",
      "cls loss 633.549560546875  loc loss 44.68760681152344\n",
      "cls loss 735.6015014648438  loc loss 40.783851623535156\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 5.])\n",
      "cls loss 195.83187866210938  loc loss 9.142776489257812\n",
      "cls loss 271.072021484375  loc loss 11.677645683288574\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 13.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 6., 8., 8.])\n",
      "cls loss 213.56442260742188  loc loss 12.060608863830566\n",
      "cls loss 286.1064147949219  loc loss 15.04216480255127\n",
      "cls loss 565.6805419921875  loc loss 36.95823287963867\n",
      "cls loss 238.4774169921875  loc loss 13.61888313293457\n",
      "cls loss 473.4237060546875  loc loss 34.77677536010742\n",
      "cls loss 699.9149169921875  loc loss 50.479896545410156\n",
      "cls loss 442.44183349609375  loc loss 30.582386016845703\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([42., 42.,  1.,  1.,  1.,  1.,  1.,  1.,  1., 42., 42.])\n",
      "cls loss 487.3973388671875  loc loss 25.5133056640625\n",
      "cls loss 626.26220703125  loc loss 45.43538284301758\n",
      "cls loss 574.195068359375  loc loss 37.880126953125\n",
      "cls loss 366.4144287109375  loc loss 22.58909034729004\n",
      "cls loss 478.7059020996094  loc loss 25.4803466796875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 684.3347778320312  loc loss 43.27299880981445\n",
      "cls loss 544.7518310546875  loc loss 37.237525939941406\n",
      "cls loss 329.7515869140625  loc loss 18.554773330688477\n",
      "cls loss 275.6358337402344  loc loss 16.57528305053711\n",
      "cls loss 366.95611572265625  loc loss 22.9908447265625\n",
      "cls loss 525.8383178710938  loc loss 31.915740966796875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15.])\n",
      "cls loss 260.13201904296875  loc loss 9.481107711791992\n",
      "cls loss 446.5273742675781  loc loss 26.899066925048828\n",
      "cls loss 379.7220153808594  loc loss 25.623390197753906\n",
      "cls loss 689.8043212890625  loc loss 45.324066162109375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19.,  7.])\n",
      "cls loss 340.2860107421875  loc loss 19.931869506835938\n",
      "cls loss 720.599853515625  loc loss 48.30207824707031\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 643.19091796875  loc loss 31.72222137451172\n",
      "cls loss 542.7646484375  loc loss 37.6949462890625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([38., 38.,  1., 18.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1., 18., 18.,  1.])\n",
      "cls loss 380.7922058105469  loc loss 20.103975296020508\n",
      "cls loss 377.93316650390625  loc loss 17.52590560913086\n",
      "cls loss 717.9425048828125  loc loss 48.42060089111328\n",
      "cls loss 534.727783203125  loc loss 29.59619140625\n",
      "cls loss 442.82208251953125  loc loss 25.949954986572266\n",
      "cls loss 289.4215087890625  loc loss 21.953981399536133\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.])\n",
      "cls loss 192.75823974609375  loc loss 7.905728340148926\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([32.])\n",
      "cls loss 458.7148742675781  loc loss 24.579689025878906\n",
      "cls loss 383.97216796875  loc loss 26.823057174682617\n",
      "cls loss 492.05377197265625  loc loss 37.90228271484375\n",
      "cls loss 435.5628662109375  loc loss 28.630136489868164\n",
      "cls loss 363.56280517578125  loc loss 21.88129997253418\n",
      "cls loss 598.6553955078125  loc loss 34.61916732788086\n",
      "cls loss 688.2447509765625  loc loss 43.70150375366211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 515.947265625  loc loss 33.628963470458984\n",
      "cls loss 412.12335205078125  loc loss 23.801307678222656\n",
      "cls loss 652.8712158203125  loc loss 41.367271423339844\n",
      "cls loss 452.63421630859375  loc loss 22.438669204711914\n",
      "cls loss 768.722900390625  loc loss 48.70165252685547\n",
      "cls loss 508.21588134765625  loc loss 27.683006286621094\n",
      "cls loss 405.2879638671875  loc loss 30.93616485595703\n",
      "cls loss 312.9456481933594  loc loss 14.389995574951172\n",
      "cls loss 352.9034423828125  loc loss 22.6688232421875\n",
      "cls loss 525.3268432617188  loc loss 34.56033706665039\n",
      "cls loss 561.1842041015625  loc loss 38.05437088012695\n",
      "cls loss 317.3943176269531  loc loss 19.462427139282227\n",
      "cls loss 570.2254638671875  loc loss 38.32984924316406\n",
      "cls loss 694.12158203125  loc loss 43.12630844116211\n",
      "cls loss 256.108642578125  loc loss 15.846620559692383\n",
      "cls loss 670.52587890625  loc loss 44.4290657043457\n",
      "cls loss 506.1083068847656  loc loss 34.31509017944336\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 664.5977783203125  loc loss 50.52141189575195\n",
      "cls loss 314.4476318359375  loc loss 11.881369590759277\n",
      "cls loss 469.6390686035156  loc loss 25.826248168945312\n",
      "cls loss 474.27880859375  loc loss 31.246421813964844\n",
      "cls loss 379.5928955078125  loc loss 22.008636474609375\n",
      "cls loss 218.849609375  loc loss 11.903200149536133\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 9., 9., 1., 9., 9., 9., 9., 1., 9.])\n",
      "cls loss 853.1445922851562  loc loss 63.76764678955078\n",
      "cls loss 487.25091552734375  loc loss 25.09776496887207\n",
      "cls loss 734.376220703125  loc loss 56.21505355834961\n",
      "cls loss 306.483642578125  loc loss 22.061737060546875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 42., 42.])\n",
      "cls loss 511.796875  loc loss 38.76890182495117\n",
      "cls loss 532.4393310546875  loc loss 40.91142654418945\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  2.,  1.,  1.,  1., 38.,\n",
      "         1.,  1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 38., 38., 38.,  1., 38., 38., 38.,  1.,  1., 38.,  1.,\n",
      "         1.])\n",
      "cls loss 321.3288269042969  loc loss 24.271886825561523\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  8.,  8.])\n",
      "cls loss 785.4241943359375  loc loss 51.64224624633789\n",
      "cls loss 796.642578125  loc loss 60.672935485839844\n",
      "cls loss 301.19024658203125  loc loss 18.297252655029297\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([4., 1., 1., 4.])\n",
      "cls loss 474.8009033203125  loc loss 29.05575942993164\n",
      "cls loss 564.1887817382812  loc loss 31.948579788208008\n",
      "cls loss 227.08665466308594  loc loss 11.362205505371094\n",
      "cls loss 297.01397705078125  loc loss 18.942792892456055\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([51.,  1.])\n",
      "cls loss 214.99859619140625  loc loss 8.93461799621582\n",
      "cls loss 306.0933837890625  loc loss 17.046789169311523\n",
      "cls loss 567.461181640625  loc loss 31.165103912353516\n",
      "cls loss 562.477294921875  loc loss 40.188743591308594\n",
      "cls loss 836.3920288085938  loc loss 43.418392181396484\n",
      "cls loss 1006.516845703125  loc loss 66.51265716552734\n",
      "cls loss 407.33782958984375  loc loss 26.050411224365234\n",
      "cls loss 593.3056030273438  loc loss 46.74757766723633\n",
      "cls loss 655.6524658203125  loc loss 45.15888595581055\n",
      "cls loss 492.1729736328125  loc loss 29.16027069091797\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  3.,  1.,  1.,  1.,  3.,  1.,  1.,\n",
      "         1.,  1.,  1.])\n",
      "cls loss 537.04052734375  loc loss 23.517148971557617\n",
      "cls loss 613.4326171875  loc loss 30.06690216064453\n",
      "cls loss 555.530517578125  loc loss 28.200782775878906\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "cls loss 462.0623474121094  loc loss 26.76285743713379\n",
      "cls loss 249.43295288085938  loc loss 20.947635650634766\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3.])\n",
      "cls loss 196.17431640625  loc loss 11.418298721313477\n",
      "cls loss 360.30853271484375  loc loss 25.0971622467041\n",
      "cls loss 322.31292724609375  loc loss 22.864124298095703\n",
      "cls loss 609.5919189453125  loc loss 38.68157958984375\n",
      "cls loss 305.0595703125  loc loss 21.63151741027832\n",
      "cls loss 322.29254150390625  loc loss 24.591196060180664\n",
      "cls loss 957.2374877929688  loc loss 63.680824279785156\n",
      "cls loss 403.0274658203125  loc loss 32.620994567871094\n",
      "cls loss 319.3201904296875  loc loss 22.212085723876953\n",
      "cls loss 387.20721435546875  loc loss 22.460479736328125\n",
      "cls loss 360.98779296875  loc loss 26.607990264892578\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 650.3309326171875  loc loss 43.12681198120117\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  9., 64., 64., 64., 64., 64., 64., 64., 64., 64.,  9.,  9.,  9.,\n",
      "         9.])\n",
      "cls loss 322.1737060546875  loc loss 15.48924446105957\n",
      "cls loss 893.046630859375  loc loss 67.91094970703125\n",
      "cls loss 468.1958923339844  loc loss 30.681564331054688\n",
      "cls loss 579.5052490234375  loc loss 37.750755310058594\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.,  3.,  3.])\n",
      "cls loss 350.0594787597656  loc loss 19.511259078979492\n",
      "cls loss 385.23681640625  loc loss 27.022968292236328\n",
      "cls loss 392.62481689453125  loc loss 27.647958755493164\n",
      "cls loss 411.0566711425781  loc loss 30.703819274902344\n",
      "cls loss 443.8575439453125  loc loss 36.370521545410156\n",
      "cls loss 467.98333740234375  loc loss 33.84236145019531\n",
      "cls loss 419.3250427246094  loc loss 31.40964126586914\n",
      "cls loss 444.54608154296875  loc loss 25.98452377319336\n",
      "cls loss 562.2640991210938  loc loss 36.898193359375\n",
      "cls loss 412.5462646484375  loc loss 26.71516990661621\n",
      "cls loss 333.0306091308594  loc loss 16.780946731567383\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21.])\n",
      "cls loss 268.5824890136719  loc loss 16.072599411010742\n",
      "cls loss 389.98052978515625  loc loss 33.23932647705078\n",
      "cls loss 581.4153442382812  loc loss 39.125247955322266\n",
      "cls loss 303.9910888671875  loc loss 17.24707794189453\n",
      "cls loss 459.86334228515625  loc loss 28.720272064208984\n",
      "cls loss 856.78662109375  loc loss 44.697452545166016\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 42., 42.,  1.,  1.])\n",
      "cls loss 460.7333984375  loc loss 26.920255661010742\n",
      "cls loss 297.10858154296875  loc loss 19.778013229370117\n",
      "cls loss 421.8143310546875  loc loss 28.32503890991211\n",
      "cls loss 559.4547119140625  loc loss 47.21369934082031\n",
      "cls loss 362.17779541015625  loc loss 22.931488037109375\n",
      "cls loss 556.0382080078125  loc loss 40.63814926147461\n",
      "cls loss 513.6827392578125  loc loss 35.995479583740234\n",
      "cls loss 497.8681335449219  loc loss 32.00926208496094\n",
      "cls loss 411.07720947265625  loc loss 25.041263580322266\n",
      "cls loss 335.03173828125  loc loss 22.68622589111328\n",
      "cls loss 289.2690734863281  loc loss 12.075815200805664\n",
      "cls loss 407.58087158203125  loc loss 25.85399627685547\n",
      "cls loss 619.42919921875  loc loss 41.50157165527344\n",
      "cls loss 486.3309020996094  loc loss 27.326168060302734\n",
      "cls loss 441.15765380859375  loc loss 31.780115127563477\n",
      "cls loss 498.4763488769531  loc loss 29.216346740722656\n",
      "cls loss 718.384033203125  loc loss 51.87354278564453\n",
      "cls loss 545.129150390625  loc loss 38.262733459472656\n",
      "cls loss 592.5166015625  loc loss 33.36125183105469\n",
      "cls loss 348.92364501953125  loc loss 17.202579498291016\n",
      "cls loss 496.96466064453125  loc loss 32.08563995361328\n",
      "cls loss 458.0594482421875  loc loss 27.49805450439453\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 5., 5., 5., 5., 5., 5.])\n",
      "cls loss 304.47076416015625  loc loss 20.35905647277832\n",
      "cls loss 390.34552001953125  loc loss 21.24617576599121\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([13.])\n",
      "cls loss 274.29052734375  loc loss 15.30096435546875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([44., 10.,  1.,  1.,  1.])\n",
      "cls loss 254.85760498046875  loc loss 17.218002319335938\n",
      "cls loss 459.3988037109375  loc loss 25.863069534301758\n",
      "cls loss 417.5038146972656  loc loss 23.83802032470703\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19., 19., 19., 19., 19., 19., 19.])\n",
      "cls loss 465.3211669921875  loc loss 27.0316162109375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([56.])\n",
      "cls loss 926.2659912109375  loc loss 61.04383850097656\n",
      "cls loss 585.6942138671875  loc loss 43.484092712402344\n",
      "cls loss 748.7281494140625  loc loss 49.07861328125\n",
      "cls loss 722.8765869140625  loc loss 53.692195892333984\n",
      "cls loss 469.5636901855469  loc loss 24.334909439086914\n",
      "cls loss 735.5812377929688  loc loss 46.99099349975586\n",
      "cls loss 416.2510986328125  loc loss 27.190853118896484\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 36.])\n",
      "cls loss 521.939697265625  loc loss 26.343746185302734\n",
      "cls loss 434.0972900390625  loc loss 29.030933380126953\n",
      "cls loss 413.0936279296875  loc loss 25.267173767089844\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 467.15289306640625  loc loss 30.110485076904297\n",
      "cls loss 255.03652954101562  loc loss 14.280879974365234\n",
      "cls loss 615.0313110351562  loc loss 32.88821029663086\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "cls loss 528.8549194335938  loc loss 34.660186767578125\n",
      "cls loss 501.8762512207031  loc loss 34.90865707397461\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 534.1546630859375  loc loss 35.87509536743164\n",
      "cls loss 601.4896240234375  loc loss 40.89297103881836\n",
      "cls loss 512.3976440429688  loc loss 43.955562591552734\n",
      "cls loss 365.197998046875  loc loss 24.09670066833496\n",
      "cls loss 419.98626708984375  loc loss 29.552648544311523\n",
      "cls loss 451.56146240234375  loc loss 27.807971954345703\n",
      "cls loss 712.715087890625  loc loss 38.05629348754883\n",
      "cls loss 312.5389099121094  loc loss 15.703907012939453\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 11., 15., 10., 10., 10., 10., 10.])\n",
      "cls loss 687.0  loc loss 44.63326644897461\n",
      "cls loss 402.22491455078125  loc loss 29.26395034790039\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3.])\n",
      "cls loss 423.2724609375  loc loss 29.968435287475586\n",
      "cls loss 388.11187744140625  loc loss 21.16565704345703\n",
      "cls loss 434.72906494140625  loc loss 21.8276424407959\n",
      "cls loss 544.3017578125  loc loss 24.991424560546875\n",
      "cls loss 267.01385498046875  loc loss 13.89763069152832\n",
      "cls loss 441.9565734863281  loc loss 29.355499267578125\n",
      "cls loss 499.0473937988281  loc loss 35.26300048828125\n",
      "cls loss 424.75799560546875  loc loss 29.99591827392578\n",
      "cls loss 1006.4779663085938  loc loss 67.18335723876953\n",
      "cls loss 678.14306640625  loc loss 43.9324951171875\n",
      "cls loss 446.72064208984375  loc loss 31.092609405517578\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  9.,  9.,  9.,  6.,  6., 85., 85.,  8.,  1.,  1.,  1.,  1.,\n",
      "         6.,  6.])\n",
      "cls loss 295.153076171875  loc loss 25.213987350463867\n",
      "cls loss 732.8212890625  loc loss 51.1708984375\n",
      "cls loss 869.1624755859375  loc loss 53.53968811035156\n",
      "cls loss 571.3499755859375  loc loss 39.84840774536133\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10.,  3.,  3., 10.])\n",
      "cls loss 381.1612243652344  loc loss 20.251537322998047\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([7.])\n",
      "cls loss 469.6971435546875  loc loss 30.419527053833008\n",
      "cls loss 475.95953369140625  loc loss 28.837486267089844\n",
      "cls loss 467.64923095703125  loc loss 38.68370819091797\n",
      "cls loss 690.0590209960938  loc loss 54.60222625732422\n",
      "cls loss 426.234375  loc loss 29.500944137573242\n",
      "cls loss 623.980712890625  loc loss 41.20752716064453\n",
      "cls loss 799.9403686523438  loc loss 45.566253662109375\n",
      "cls loss 483.02569580078125  loc loss 31.39630126953125\n",
      "cls loss 522.3026733398438  loc loss 36.820213317871094\n",
      "cls loss 410.7397766113281  loc loss 30.50656509399414\n",
      "cls loss 648.2683715820312  loc loss 50.63753128051758\n",
      "cls loss 483.98626708984375  loc loss 32.26618194580078\n",
      "cls loss 393.00823974609375  loc loss 23.932899475097656\n",
      "cls loss 595.2296142578125  loc loss 44.57120132446289\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([62.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([62.])\n",
      "cls loss 289.0450439453125  loc loss 13.297741889953613\n",
      "cls loss 447.38262939453125  loc loss 33.04773712158203\n",
      "cls loss 438.4603271484375  loc loss 28.24906349182129\n",
      "cls loss 288.56439208984375  loc loss 14.450878143310547\n",
      "cls loss 582.34033203125  loc loss 38.79328918457031\n",
      "cls loss 609.0236206054688  loc loss 33.72251510620117\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([28.])\n",
      "cls loss 726.6939697265625  loc loss 36.9195671081543\n",
      "cls loss 561.9829711914062  loc loss 35.9002685546875\n",
      "cls loss 563.8372802734375  loc loss 38.84928894042969\n",
      "cls loss 582.4778442382812  loc loss 36.436195373535156\n",
      "cls loss 790.4750366210938  loc loss 52.585914611816406\n",
      "cls loss 466.844970703125  loc loss 27.968719482421875\n",
      "cls loss 598.2152099609375  loc loss 34.17626953125\n",
      "cls loss 488.8531494140625  loc loss 39.98002624511719\n",
      "cls loss 806.0161743164062  loc loss 65.13371276855469\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([81.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 519.0518798828125  loc loss 23.773601531982422\n",
      "cls loss 392.757568359375  loc loss 22.504535675048828\n",
      "cls loss 295.99365234375  loc loss 23.06526756286621\n",
      "cls loss 269.751953125  loc loss 11.87341594696045\n",
      "cls loss 302.791259765625  loc loss 23.217912673950195\n",
      "cls loss 366.5038146972656  loc loss 22.98036003112793\n",
      "cls loss 383.3193664550781  loc loss 26.0180721282959\n",
      "cls loss 541.9534912109375  loc loss 44.61575698852539\n",
      "cls loss 659.6551513671875  loc loss 39.96291732788086\n",
      "cls loss 1146.9722900390625  loc loss 76.54966735839844\n",
      "cls loss 461.4587707519531  loc loss 23.71401596069336\n",
      "cls loss 565.940185546875  loc loss 43.797584533691406\n",
      "cls loss 403.35369873046875  loc loss 26.686153411865234\n",
      "cls loss 542.6598510742188  loc loss 30.457040786743164\n",
      "cls loss 451.7247314453125  loc loss 25.976787567138672\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([44., 44.])\n",
      "cls loss 401.6678161621094  loc loss 19.837556838989258\n",
      "cls loss 435.4953308105469  loc loss 28.43589973449707\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15.])\n",
      "cls loss 452.00445556640625  loc loss 23.970436096191406\n",
      "cls loss 221.10067749023438  loc loss 13.7828369140625\n",
      "cls loss 455.2558898925781  loc loss 28.788734436035156\n",
      "cls loss 268.11346435546875  loc loss 15.426095962524414\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([1., 3., 3.])\n",
      "cls loss 305.7783508300781  loc loss 21.120285034179688\n",
      "cls loss 227.3670654296875  loc loss 10.69528579711914\n",
      "cls loss 435.45452880859375  loc loss 28.91793441772461\n",
      "cls loss 492.0500183105469  loc loss 28.861858367919922\n",
      "cls loss 442.45977783203125  loc loss 31.154327392578125\n",
      "cls loss 377.9920654296875  loc loss 24.870464324951172\n",
      "cls loss 379.74169921875  loc loss 28.43047332763672\n",
      "cls loss 519.6824340820312  loc loss 33.513946533203125\n",
      "cls loss 371.55078125  loc loss 25.248952865600586\n",
      "cls loss 503.9799499511719  loc loss 33.929901123046875\n",
      "cls loss 340.2315979003906  loc loss 18.6248779296875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 584.5204467773438  loc loss 36.06819152832031\n",
      "cls loss 702.330810546875  loc loss 32.10404968261719\n",
      "cls loss 598.19189453125  loc loss 42.101383209228516\n",
      "cls loss 592.5126953125  loc loss 48.248661041259766\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10., 10., 10.,  1.,  1.,  1.,  1.,  1.,  1.,  8.,  8.,\n",
      "         1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10., 10., 10.,  1.,  1.,  1.,  1.,  1.,  1.,  8.,  8.,\n",
      "         1.])\n",
      "cls loss 500.3818054199219  loc loss 25.27789878845215\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 3., 3., 3.])\n",
      "cls loss 460.8669128417969  loc loss 28.522666931152344\n",
      "cls loss 316.6513671875  loc loss 19.299152374267578\n",
      "cls loss 242.58026123046875  loc loss 12.244145393371582\n",
      "cls loss 442.12615966796875  loc loss 32.250022888183594\n",
      "cls loss 342.86895751953125  loc loss 15.516339302062988\n",
      "cls loss 403.5532531738281  loc loss 25.999732971191406\n",
      "cls loss 456.21051025390625  loc loss 30.604551315307617\n",
      "cls loss 623.8743896484375  loc loss 42.02483367919922\n",
      "cls loss 535.2449951171875  loc loss 26.491172790527344\n",
      "cls loss 497.8662109375  loc loss 28.02450942993164\n",
      "cls loss 516.93359375  loc loss 36.51138687133789\n",
      "cls loss 370.25616455078125  loc loss 29.660892486572266\n",
      "cls loss 728.9279174804688  loc loss 54.62865447998047\n",
      "cls loss 338.60211181640625  loc loss 17.990446090698242\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 581.473876953125  loc loss 34.3587646484375\n",
      "cls loss 269.070556640625  loc loss 11.088364601135254\n",
      "cls loss 673.1680908203125  loc loss 42.83256530761719\n",
      "cls loss 334.601318359375  loc loss 20.05461883544922\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 34.])\n",
      "cls loss 547.4743041992188  loc loss 29.538293838500977\n",
      "cls loss 268.98590087890625  loc loss 17.61949348449707\n",
      "cls loss 541.8701171875  loc loss 33.08937454223633\n",
      "cls loss 182.38143920898438  loc loss 13.185336112976074\n",
      "cls loss 443.56170654296875  loc loss 27.179887771606445\n",
      "cls loss 435.87701416015625  loc loss 35.70753479003906\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 38.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16., 16., 16.,  9.,  9.,  9., 16., 16., 16., 85.,  9.])\n",
      "cls loss 452.82757568359375  loc loss 28.999177932739258\n",
      "cls loss 496.207763671875  loc loss 39.16344451904297\n",
      "cls loss 663.9966430664062  loc loss 44.519779205322266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 1026.518798828125  loc loss 64.18675231933594\n",
      "cls loss 284.6009521484375  loc loss 15.437183380126953\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3., 10.,  8.,  8., 10., 10., 10.,  3.,  3., 14.])\n",
      "cls loss 300.97418212890625  loc loss 16.586000442504883\n",
      "cls loss 574.626708984375  loc loss 33.7395133972168\n",
      "cls loss 259.5343933105469  loc loss 10.003530502319336\n",
      "cls loss 420.846923828125  loc loss 18.08163833618164\n",
      "cls loss 554.0302124023438  loc loss 33.4251594543457\n",
      "cls loss 473.2855224609375  loc loss 29.00787925720215\n",
      "cls loss 261.1019287109375  loc loss 13.80349063873291\n",
      "cls loss 331.36419677734375  loc loss 18.012643814086914\n",
      "cls loss 530.0158081054688  loc loss 29.49650764465332\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42., 42.,  1.])\n",
      "cls loss 497.5513000488281  loc loss 31.835060119628906\n",
      "cls loss 376.4324645996094  loc loss 22.47757339477539\n",
      "cls loss 520.0906372070312  loc loss 39.94646453857422\n",
      "cls loss 604.999755859375  loc loss 36.870906829833984\n",
      "cls loss 417.82366943359375  loc loss 26.294706344604492\n",
      "cls loss 513.1121826171875  loc loss 37.55906677246094\n",
      "cls loss 318.5145568847656  loc loss 22.864953994750977\n",
      "cls loss 338.16485595703125  loc loss 25.280179977416992\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20.])\n",
      "cls loss 246.08480834960938  loc loss 15.617313385009766\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([11.])\n",
      "cls loss 349.49298095703125  loc loss 16.296579360961914\n",
      "cls loss 212.77328491210938  loc loss 13.001104354858398\n",
      "cls loss 523.8719482421875  loc loss 39.93112564086914\n",
      "cls loss 234.626220703125  loc loss 11.108173370361328\n",
      "cls loss 518.1427612304688  loc loss 28.74118423461914\n",
      "cls loss 285.1897888183594  loc loss 17.431316375732422\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 35., 27.])\n",
      "cls loss 494.70806884765625  loc loss 27.627925872802734\n",
      "cls loss 541.0005493164062  loc loss 39.82308578491211\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 360.7149658203125  loc loss 20.12590217590332\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([42.,  1.])\n",
      "cls loss 450.4801940917969  loc loss 31.251140594482422\n",
      "cls loss 446.34661865234375  loc loss 24.725133895874023\n",
      "cls loss 518.4285888671875  loc loss 32.365753173828125\n",
      "cls loss 662.1854858398438  loc loss 39.55005645751953\n",
      "cls loss 573.5888671875  loc loss 33.676395416259766\n",
      "cls loss 385.7965087890625  loc loss 27.52968978881836\n",
      "cls loss 330.0711669921875  loc loss 24.495662689208984\n",
      "cls loss 201.16131591796875  loc loss 9.5918550491333\n",
      "cls loss 389.6221923828125  loc loss 21.640167236328125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 1., 1.])\n",
      "cls loss 371.8057861328125  loc loss 22.8262996673584\n",
      "cls loss 429.56365966796875  loc loss 28.785303115844727\n",
      "cls loss 419.8585205078125  loc loss 26.66744041442871\n",
      "cls loss 345.3162841796875  loc loss 24.829723358154297\n",
      "cls loss 421.54339599609375  loc loss 27.11903190612793\n",
      "cls loss 460.270263671875  loc loss 31.75157356262207\n",
      "cls loss 647.229248046875  loc loss 37.01932907104492\n",
      "cls loss 548.5220336914062  loc loss 40.249244689941406\n",
      "cls loss 490.46405029296875  loc loss 30.324501037597656\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 381.6352233886719  loc loss 26.165708541870117\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 483.1217041015625  loc loss 22.959253311157227\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([81.])\n",
      "cls loss 567.2060546875  loc loss 32.38364028930664\n",
      "cls loss 341.01983642578125  loc loss 24.6153564453125\n",
      "cls loss 249.91470336914062  loc loss 13.718390464782715\n",
      "cls loss 381.38720703125  loc loss 21.69774627685547\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3.,  1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 19.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 19.])\n",
      "cls loss 519.1278686523438  loc loss 36.45209503173828\n",
      "cls loss 293.90716552734375  loc loss 16.601425170898438\n",
      "cls loss 312.9560546875  loc loss 17.629222869873047\n",
      "cls loss 607.5062255859375  loc loss 44.70301818847656\n",
      "cls loss 302.6551208496094  loc loss 18.968955993652344\n",
      "cls loss 390.8729248046875  loc loss 23.698619842529297\n",
      "cls loss 491.42120361328125  loc loss 30.572345733642578\n",
      "cls loss 374.9442138671875  loc loss 25.84661102294922\n",
      "cls loss 481.83367919921875  loc loss 26.933645248413086\n",
      "cls loss 560.907958984375  loc loss 36.16227722167969\n",
      "cls loss 684.9132690429688  loc loss 58.480194091796875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 81.])\n",
      "cls loss 477.612060546875  loc loss 24.149831771850586\n",
      "cls loss 421.9786682128906  loc loss 22.609384536743164\n",
      "cls loss 445.13629150390625  loc loss 24.928089141845703\n",
      "cls loss 341.51080322265625  loc loss 17.964122772216797\n",
      "cls loss 299.65020751953125  loc loss 19.712791442871094\n",
      "cls loss 330.08831787109375  loc loss 26.85821533203125\n",
      "cls loss 262.4560546875  loc loss 20.10947036743164\n",
      "cls loss 227.4105682373047  loc loss 15.429459571838379\n",
      "cls loss 312.3168640136719  loc loss 20.605403900146484\n",
      "cls loss 416.4159851074219  loc loss 26.000532150268555\n",
      "cls loss 368.7229309082031  loc loss 28.378360748291016\n",
      "cls loss 386.68975830078125  loc loss 28.103626251220703\n",
      "cls loss 230.26177978515625  loc loss 15.621158599853516\n",
      "cls loss 797.968994140625  loc loss 53.346500396728516\n",
      "cls loss 459.0175476074219  loc loss 31.1944522857666\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 420.6784362792969  loc loss 20.970739364624023\n",
      "cls loss 485.29840087890625  loc loss 30.968170166015625\n",
      "cls loss 375.7813720703125  loc loss 22.980443954467773\n",
      "cls loss 575.4903564453125  loc loss 38.53614807128906\n",
      "cls loss 528.5478515625  loc loss 32.536590576171875\n",
      "cls loss 486.4289855957031  loc loss 29.298398971557617\n",
      "cls loss 360.3885803222656  loc loss 23.3714656829834\n",
      "cls loss 292.5067443847656  loc loss 17.979951858520508\n",
      "cls loss 430.2810363769531  loc loss 25.185077667236328\n",
      "cls loss 485.12115478515625  loc loss 31.924541473388672\n",
      "cls loss 470.7746887207031  loc loss 26.62112808227539\n",
      "cls loss 599.0763549804688  loc loss 43.08152389526367\n",
      "cls loss 622.8197021484375  loc loss 49.158138275146484\n",
      "cls loss 441.4288024902344  loc loss 31.943933486938477\n",
      "cls loss 632.703369140625  loc loss 50.11502456665039\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1., 38., 47.,  1.,  1.,  1.,  1.,  1., 62.])\n",
      "cls loss 426.5109558105469  loc loss 21.112171173095703\n",
      "cls loss 504.815673828125  loc loss 32.64493179321289\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 559.9522705078125  loc loss 32.212440490722656\n",
      "cls loss 583.26806640625  loc loss 42.83039474487305\n",
      "cls loss 400.7779846191406  loc loss 18.769384384155273\n",
      "cls loss 475.9552001953125  loc loss 36.548500061035156\n",
      "cls loss 444.58685302734375  loc loss 24.886280059814453\n",
      "cls loss 250.39675903320312  loc loss 10.097230911254883\n",
      "cls loss 377.40814208984375  loc loss 22.704505920410156\n",
      "cls loss 318.8443298339844  loc loss 16.04201889038086\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1., 35.])\n",
      "cls loss 353.2451171875  loc loss 21.68204116821289\n",
      "cls loss 559.24267578125  loc loss 30.029130935668945\n",
      "cls loss 543.9359741210938  loc loss 36.76215362548828\n",
      "cls loss 481.67803955078125  loc loss 39.590335845947266\n",
      "cls loss 389.06103515625  loc loss 30.615188598632812\n",
      "cls loss 529.533935546875  loc loss 40.02406692504883\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 295.8405456542969  loc loss 17.204975128173828\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 439.67169189453125  loc loss 18.993057250976562\n",
      "cls loss 700.67041015625  loc loss 36.55162811279297\n",
      "cls loss 824.59765625  loc loss 66.60002136230469\n",
      "cls loss 425.7673645019531  loc loss 21.835254669189453\n",
      "cls loss 367.9921569824219  loc loss 22.834260940551758\n",
      "cls loss 377.1703796386719  loc loss 19.372995376586914\n",
      "cls loss 391.2351379394531  loc loss 22.743328094482422\n",
      "cls loss 340.58038330078125  loc loss 14.661505699157715\n",
      "cls loss 623.5299072265625  loc loss 42.285343170166016\n",
      "cls loss 528.6610107421875  loc loss 31.244876861572266\n",
      "cls loss 239.80084228515625  loc loss 17.91284942626953\n",
      "cls loss 506.987548828125  loc loss 27.91197395324707\n",
      "cls loss 613.4757080078125  loc loss 48.756988525390625\n",
      "cls loss 486.0494384765625  loc loss 32.88844680786133\n",
      "cls loss 413.2866516113281  loc loss 24.279254913330078\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.])\n",
      "cls loss 406.861328125  loc loss 29.952884674072266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 412.5057373046875  loc loss 27.253799438476562\n",
      "cls loss 521.6740112304688  loc loss 32.57240295410156\n",
      "cls loss 833.031005859375  loc loss 63.3890495300293\n",
      "cls loss 333.3077697753906  loc loss 16.58113670349121\n",
      "cls loss 430.9900817871094  loc loss 27.06493377685547\n",
      "cls loss 349.4184265136719  loc loss 18.931610107421875\n",
      "cls loss 367.3172607421875  loc loss 24.755189895629883\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 21., 21., 21.])\n",
      "cls loss 389.62371826171875  loc loss 24.962554931640625\n",
      "cls loss 370.02593994140625  loc loss 18.621912002563477\n",
      "cls loss 394.7596435546875  loc loss 25.825746536254883\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 35.])\n",
      "cls loss 517.428466796875  loc loss 31.945777893066406\n",
      "cls loss 195.61550903320312  loc loss 10.31213665008545\n",
      "cls loss 337.333251953125  loc loss 21.014659881591797\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 317.66741943359375  loc loss 13.683172225952148\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 38., 38.,  9., 38.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1.,  1.])\n",
      "cls loss 366.576904296875  loc loss 22.803171157836914\n",
      "cls loss 602.8763427734375  loc loss 36.989768981933594\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 2.,  1., 77., 31., 10., 10.,  1.,  4., 10.])\n",
      "cls loss 294.7052307128906  loc loss 13.706345558166504\n",
      "cls loss 555.789306640625  loc loss 32.38010787963867\n",
      "cls loss 1145.19970703125  loc loss 63.48692321777344\n",
      "cls loss 342.94287109375  loc loss 24.105091094970703\n",
      "cls loss 485.30657958984375  loc loss 35.9233512878418\n",
      "cls loss 355.98614501953125  loc loss 17.264001846313477\n",
      "cls loss 341.2572937011719  loc loss 17.13665199279785\n",
      "cls loss 486.7627868652344  loc loss 26.091293334960938\n",
      "cls loss 498.5226135253906  loc loss 27.31669044494629\n",
      "cls loss 442.9500732421875  loc loss 31.541187286376953\n",
      "cls loss 367.1031188964844  loc loss 17.556415557861328\n",
      "cls loss 368.6739501953125  loc loss 20.49776268005371\n",
      "cls loss 691.909423828125  loc loss 42.854652404785156\n",
      "cls loss 634.3851318359375  loc loss 36.35860061645508\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1., 42., 42., 42., 42., 42., 42.,  1.,\n",
      "         1.,  1.,  1., 42.,  1.,  1., 42.,  1.])\n",
      "cls loss 349.89776611328125  loc loss 24.84427261352539\n",
      "cls loss 524.5147705078125  loc loss 30.48670196533203\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.])\n",
      "cls loss 228.7935791015625  loc loss 12.771590232849121\n",
      "cls loss 529.0164184570312  loc loss 33.485477447509766\n",
      "cls loss 391.16448974609375  loc loss 29.132221221923828\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([11.])\n",
      "cls loss 244.43795776367188  loc loss 14.339496612548828\n",
      "cls loss 280.98779296875  loc loss 14.343222618103027\n",
      "cls loss 304.8457946777344  loc loss 14.470518112182617\n",
      "cls loss 526.7713012695312  loc loss 31.48829460144043\n",
      "cls loss 419.80950927734375  loc loss 24.065292358398438\n",
      "cls loss 453.45648193359375  loc loss 29.31328582763672\n",
      "cls loss 639.7122802734375  loc loss 33.09235763549805\n",
      "cls loss 334.07354736328125  loc loss 19.13191795349121\n",
      "cls loss 701.0130615234375  loc loss 44.85649108886719\n",
      "cls loss 332.9976501464844  loc loss 20.27557373046875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 310.320068359375  loc loss 19.828994750976562\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1., 38., 38., 42.])\n",
      "cls loss 407.7464904785156  loc loss 28.338459014892578\n",
      "cls loss 372.54864501953125  loc loss 22.00192642211914\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 330.4791259765625  loc loss 22.769689559936523\n",
      "cls loss 740.5308837890625  loc loss 49.757789611816406\n",
      "cls loss 454.70819091796875  loc loss 28.531776428222656\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10.,  3.,  3.,  6.,  8.,  8.,  1.,  1.,  1., 10.])\n",
      "cls loss 358.018310546875  loc loss 18.12026023864746\n",
      "cls loss 229.3381805419922  loc loss 8.814576148986816\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10.,  3.])\n",
      "cls loss 333.51318359375  loc loss 20.016572952270508\n",
      "cls loss 169.60569763183594  loc loss 10.705629348754883\n",
      "cls loss 429.8167724609375  loc loss 29.8410701751709\n",
      "cls loss 519.6053466796875  loc loss 32.36924743652344\n",
      "cls loss 369.00640869140625  loc loss 21.764883041381836\n",
      "cls loss 246.25331115722656  loc loss 13.664030075073242\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 34.])\n",
      "cls loss 616.9227294921875  loc loss 37.807716369628906\n",
      "cls loss 695.7693481445312  loc loss 52.57096862792969\n",
      "cls loss 449.748291015625  loc loss 30.88677978515625\n",
      "cls loss 358.60986328125  loc loss 23.37343978881836\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.,  1.])\n",
      "cls loss 384.6502685546875  loc loss 17.016904830932617\n",
      "cls loss 605.730712890625  loc loss 44.279388427734375\n",
      "cls loss 873.74072265625  loc loss 56.03473663330078\n",
      "cls loss 719.5000610351562  loc loss 37.57658386230469\n",
      "cls loss 424.6087646484375  loc loss 22.149059295654297\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 484.60772705078125  loc loss 27.58584213256836\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10.])\n",
      "cls loss 303.4739990234375  loc loss 15.754663467407227\n",
      "cls loss 450.2825622558594  loc loss 21.90846824645996\n",
      "cls loss 420.12060546875  loc loss 25.60370635986328\n",
      "cls loss 293.07818603515625  loc loss 16.876880645751953\n",
      "cls loss 396.31219482421875  loc loss 24.779800415039062\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21.,\n",
      "        21.])\n",
      "cls loss 492.6039123535156  loc loss 29.988353729248047\n",
      "cls loss 411.89202880859375  loc loss 24.192760467529297\n",
      "cls loss 274.11090087890625  loc loss 12.505629539489746\n",
      "cls loss 600.9632568359375  loc loss 37.92096710205078\n",
      "cls loss 450.0925598144531  loc loss 28.547863006591797\n",
      "cls loss 343.81939697265625  loc loss 16.804824829101562\n",
      "cls loss 672.2195434570312  loc loss 41.325077056884766\n",
      "cls loss 782.6470947265625  loc loss 53.98453140258789\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15., 85.])\n",
      "cls loss 516.328125  loc loss 30.548524856567383\n",
      "cls loss 504.4970397949219  loc loss 36.81690216064453\n",
      "cls loss 520.441162109375  loc loss 37.839111328125\n",
      "cls loss 436.72625732421875  loc loss 26.660348892211914\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 8., 8.])\n",
      "cls loss 291.24853515625  loc loss 12.779693603515625\n",
      "cls loss 302.2987060546875  loc loss 23.008575439453125\n",
      "cls loss 385.3155517578125  loc loss 23.523117065429688\n",
      "cls loss 333.9530944824219  loc loss 18.240880966186523\n",
      "cls loss 366.48358154296875  loc loss 20.678434371948242\n",
      "cls loss 527.2174072265625  loc loss 30.54730796813965\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1., 35., 27., 27.,  1., 27.,  1.])\n",
      "cls loss 619.899169921875  loc loss 45.906272888183594\n",
      "cls loss 356.6991271972656  loc loss 20.389633178710938\n",
      "cls loss 394.3289794921875  loc loss 28.24226188659668\n",
      "cls loss 370.1747131347656  loc loss 32.44284439086914\n",
      "cls loss 341.7088928222656  loc loss 24.326250076293945\n",
      "cls loss 378.1203918457031  loc loss 28.463857650756836\n",
      "cls loss 386.5307312011719  loc loss 28.62766456604004\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  2.,  2.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  2.,  2.])\n",
      "cls loss 195.83255004882812  loc loss 8.387797355651855\n",
      "cls loss 608.541259765625  loc loss 36.950889587402344\n",
      "cls loss 387.1241455078125  loc loss 18.083179473876953\n",
      "cls loss 660.2205810546875  loc loss 47.36838912963867\n",
      "cls loss 255.38754272460938  loc loss 14.495427131652832\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 19., 19., 19., 16.])\n",
      "cls loss 268.3782043457031  loc loss 11.524913787841797\n",
      "cls loss 217.3610382080078  loc loss 9.192097663879395\n",
      "cls loss 364.78997802734375  loc loss 18.29658317565918\n",
      "cls loss 482.32379150390625  loc loss 30.287696838378906\n",
      "cls loss 189.5393524169922  loc loss 14.735137939453125\n",
      "cls loss 530.9459228515625  loc loss 40.598541259765625\n",
      "cls loss 390.51483154296875  loc loss 25.18964195251465\n",
      "cls loss 410.0422668457031  loc loss 26.29115867614746\n",
      "cls loss 527.905029296875  loc loss 34.366493225097656\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 547.354248046875  loc loss 25.251968383789062\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 755.7881469726562  loc loss 62.485008239746094\n",
      "cls loss 979.9217529296875  loc loss 86.89353942871094\n",
      "cls loss 506.46856689453125  loc loss 27.780799865722656\n",
      "cls loss 447.6944885253906  loc loss 26.65835952758789\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3.,  3.,  3.,  3.,  3., 10.])\n",
      "cls loss 220.7625732421875  loc loss 13.489709854125977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 471.2920837402344  loc loss 21.473020553588867\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 1., 1., 1., 3., 3., 3., 3.])\n",
      "cls loss 363.832763671875  loc loss 19.168291091918945\n",
      "cls loss 704.2992553710938  loc loss 43.40598678588867\n",
      "cls loss 559.4517822265625  loc loss 34.06129837036133\n",
      "cls loss 357.4139404296875  loc loss 20.9372501373291\n",
      "cls loss 559.8377685546875  loc loss 37.69462585449219\n",
      "cls loss 336.702392578125  loc loss 24.12828826904297\n",
      "cls loss 535.0338134765625  loc loss 37.005577087402344\n",
      "cls loss 408.2466125488281  loc loss 37.376983642578125\n",
      "cls loss 403.313720703125  loc loss 25.576587677001953\n",
      "cls loss 849.7275390625  loc loss 67.62097930908203\n",
      "cls loss 562.5379638671875  loc loss 41.363407135009766\n",
      "cls loss 380.88818359375  loc loss 18.45977783203125\n",
      "cls loss 242.33984375  loc loss 10.84704303741455\n",
      "cls loss 296.0979919433594  loc loss 14.18157958984375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3., 10., 10., 10., 10., 10., 10., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10., 10., 10., 10., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 11., 10., 10., 10., 10., 10.,  3.,  3.,  3.,  3.,  3.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 11., 10., 10., 10., 10., 10.,  3.,  3.,  3.,  3.,  3.])\n",
      "cls loss 238.82644653320312  loc loss 11.503535270690918\n",
      "cls loss 328.7344970703125  loc loss 13.869163513183594\n",
      "cls loss 273.6864318847656  loc loss 15.544853210449219\n",
      "cls loss 285.05816650390625  loc loss 12.419805526733398\n",
      "cls loss 341.58306884765625  loc loss 26.001657485961914\n",
      "cls loss 257.8092041015625  loc loss 10.541374206542969\n",
      "cls loss 517.36767578125  loc loss 34.0782470703125\n",
      "cls loss 466.0371398925781  loc loss 28.396175384521484\n",
      "cls loss 693.9854736328125  loc loss 42.48115158081055\n",
      "cls loss 349.4902038574219  loc loss 24.302690505981445\n",
      "cls loss 610.4560546875  loc loss 38.87896728515625\n",
      "cls loss 471.5013122558594  loc loss 32.609710693359375\n",
      "cls loss 467.9963073730469  loc loss 29.640241622924805\n",
      "cls loss 457.13372802734375  loc loss 31.541828155517578\n",
      "cls loss 602.757568359375  loc loss 39.66864776611328\n",
      "cls loss 590.9688720703125  loc loss 37.64609146118164\n",
      "cls loss 287.2554626464844  loc loss 15.498172760009766\n",
      "cls loss 554.5489501953125  loc loss 37.65127944946289\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 10.,  1., 18.])\n",
      "cls loss 259.813720703125  loc loss 17.399085998535156\n",
      "cls loss 330.03277587890625  loc loss 13.854764938354492\n",
      "cls loss 585.833740234375  loc loss 29.71646499633789\n",
      "cls loss 768.2266845703125  loc loss 43.552127838134766\n",
      "cls loss 456.83148193359375  loc loss 30.870189666748047\n",
      "cls loss 666.611572265625  loc loss 32.06768035888672\n",
      "cls loss 484.03857421875  loc loss 31.292720794677734\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.,  1.,  1.])\n",
      "cls loss 573.6217041015625  loc loss 35.76941680908203\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1., 38.,  1.])\n",
      "cls loss 480.5091552734375  loc loss 28.855693817138672\n",
      "cls loss 698.5419921875  loc loss 52.13307571411133\n",
      "cls loss 382.9744567871094  loc loss 25.6994571685791\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 524.647705078125  loc loss 31.851560592651367\n",
      "cls loss 428.5215148925781  loc loss 26.113704681396484\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3., 10.,  8.,  3., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.])\n",
      "cls loss 488.8008117675781  loc loss 28.39322280883789\n",
      "cls loss 327.37762451171875  loc loss 22.340314865112305\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3.,  3., 11.,  3., 10., 10.,  3.,  3., 10.])\n",
      "cls loss 391.10137939453125  loc loss 19.9776668548584\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3., 10., 10., 10.])\n",
      "cls loss 424.0069580078125  loc loss 23.89462661743164\n",
      "cls loss 346.641357421875  loc loss 21.475656509399414\n",
      "cls loss 454.6195373535156  loc loss 29.73427391052246\n",
      "cls loss 656.0821533203125  loc loss 36.55824279785156\n",
      "cls loss 431.65826416015625  loc loss 25.666038513183594\n",
      "cls loss 331.4318542480469  loc loss 25.283536911010742\n",
      "cls loss 418.10198974609375  loc loss 25.65688133239746\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 9.,  9., 85., 85.])\n",
      "cls loss 333.7027282714844  loc loss 17.841962814331055\n",
      "cls loss 424.57568359375  loc loss 29.980945587158203\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 658.937744140625  loc loss 44.45103454589844\n",
      "cls loss 562.929931640625  loc loss 27.19635772705078\n",
      "cls loss 635.333740234375  loc loss 46.50082015991211\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10., 10., 10., 10.])\n",
      "cls loss 394.71282958984375  loc loss 25.538660049438477\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([13.])\n",
      "cls loss 619.0633544921875  loc loss 48.94407653808594\n",
      "cls loss 184.63426208496094  loc loss 10.31294059753418\n",
      "cls loss 272.8902587890625  loc loss 13.505576133728027\n",
      "cls loss 363.10772705078125  loc loss 20.655834197998047\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19.,  1.,  1.,  1., 19., 19.])\n",
      "cls loss 387.1310119628906  loc loss 24.557613372802734\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 319.4051513671875  loc loss 23.070220947265625\n",
      "cls loss 450.2583312988281  loc loss 32.52265548706055\n",
      "cls loss 353.6166687011719  loc loss 20.234193801879883\n",
      "cls loss 502.13653564453125  loc loss 26.56585693359375\n",
      "cls loss 532.4097900390625  loc loss 40.857276916503906\n",
      "cls loss 398.74969482421875  loc loss 23.355409622192383\n",
      "cls loss 634.1587524414062  loc loss 43.06210708618164\n",
      "cls loss 225.89306640625  loc loss 10.448805809020996\n",
      "cls loss 432.6139221191406  loc loss 27.094745635986328\n",
      "cls loss 340.76739501953125  loc loss 18.2152042388916\n",
      "cls loss 378.0932312011719  loc loss 22.401004791259766\n",
      "cls loss 512.4574584960938  loc loss 30.032665252685547\n",
      "cls loss 430.31170654296875  loc loss 21.854869842529297\n",
      "cls loss 607.6815795898438  loc loss 40.944026947021484\n",
      "cls loss 397.53863525390625  loc loss 25.50577163696289\n",
      "cls loss 513.312744140625  loc loss 36.95180892944336\n",
      "cls loss 742.0253295898438  loc loss 46.05704879760742\n",
      "cls loss 389.7567138671875  loc loss 29.301347732543945\n",
      "cls loss 471.81005859375  loc loss 27.74152374267578\n",
      "cls loss 542.3541259765625  loc loss 42.65217208862305\n",
      "cls loss 629.7933349609375  loc loss 44.25066375732422\n",
      "cls loss 723.779052734375  loc loss 40.80382537841797\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 5.])\n",
      "cls loss 192.00558471679688  loc loss 9.09562873840332\n",
      "cls loss 267.3244323730469  loc loss 11.57094955444336\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 13.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 6., 8., 8.])\n",
      "cls loss 208.958984375  loc loss 12.109269142150879\n",
      "cls loss 279.630126953125  loc loss 15.318487167358398\n",
      "cls loss 555.120849609375  loc loss 36.853424072265625\n",
      "cls loss 232.3468017578125  loc loss 13.340808868408203\n",
      "cls loss 469.7612609863281  loc loss 34.69078063964844\n",
      "cls loss 688.9227294921875  loc loss 50.052947998046875\n",
      "cls loss 438.8697204589844  loc loss 29.932544708251953\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([42., 42.,  1.,  1.,  1.,  1.,  1.,  1.,  1., 42., 42.])\n",
      "cls loss 480.24420166015625  loc loss 25.03035545349121\n",
      "cls loss 619.42333984375  loc loss 44.93229675292969\n",
      "cls loss 570.53369140625  loc loss 38.18252182006836\n",
      "cls loss 363.58074951171875  loc loss 22.31113624572754\n",
      "cls loss 474.4719543457031  loc loss 25.509241104125977\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 680.1857299804688  loc loss 42.965736389160156\n",
      "cls loss 539.447265625  loc loss 36.72467803955078\n",
      "cls loss 326.49798583984375  loc loss 18.126760482788086\n",
      "cls loss 273.34576416015625  loc loss 16.605003356933594\n",
      "cls loss 361.35223388671875  loc loss 23.016124725341797\n",
      "cls loss 518.56103515625  loc loss 31.82369613647461\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15.])\n",
      "cls loss 254.3377685546875  loc loss 9.353302001953125\n",
      "cls loss 439.12567138671875  loc loss 26.532093048095703\n",
      "cls loss 374.20562744140625  loc loss 25.683507919311523\n",
      "cls loss 680.7493896484375  loc loss 45.3826789855957\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19.,  7.])\n",
      "cls loss 333.2767333984375  loc loss 19.529626846313477\n",
      "cls loss 706.306640625  loc loss 47.96232604980469\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 632.2892456054688  loc loss 31.658361434936523\n",
      "cls loss 538.1233520507812  loc loss 37.43618392944336\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([38., 38.,  1., 18.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1., 18., 18.,  1.])\n",
      "cls loss 375.0216064453125  loc loss 20.05622100830078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 370.8184814453125  loc loss 17.230539321899414\n",
      "cls loss 710.4053955078125  loc loss 47.631736755371094\n",
      "cls loss 530.34814453125  loc loss 29.280445098876953\n",
      "cls loss 432.8070983886719  loc loss 25.436267852783203\n",
      "cls loss 285.4814758300781  loc loss 22.327972412109375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.])\n",
      "cls loss 188.5376739501953  loc loss 8.0562744140625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([32.])\n",
      "cls loss 452.8632507324219  loc loss 24.248424530029297\n",
      "cls loss 379.2799072265625  loc loss 26.592205047607422\n",
      "cls loss 484.7542419433594  loc loss 37.274757385253906\n",
      "cls loss 429.3623046875  loc loss 27.89038848876953\n",
      "cls loss 359.34130859375  loc loss 21.339353561401367\n",
      "cls loss 588.9736938476562  loc loss 33.45455551147461\n",
      "cls loss 683.913330078125  loc loss 43.338321685791016\n",
      "cls loss 509.27398681640625  loc loss 32.89547348022461\n",
      "cls loss 405.79754638671875  loc loss 23.51966667175293\n",
      "cls loss 644.8509521484375  loc loss 40.6307373046875\n",
      "cls loss 447.18701171875  loc loss 21.9423828125\n",
      "cls loss 764.2883911132812  loc loss 47.371429443359375\n",
      "cls loss 505.31939697265625  loc loss 27.251060485839844\n",
      "cls loss 399.9080505371094  loc loss 30.24925422668457\n",
      "cls loss 309.1425476074219  loc loss 14.170753479003906\n",
      "cls loss 348.00140380859375  loc loss 22.42513656616211\n",
      "cls loss 516.2605590820312  loc loss 34.39043426513672\n",
      "cls loss 554.2950439453125  loc loss 37.97406768798828\n",
      "cls loss 313.90399169921875  loc loss 19.42420768737793\n",
      "cls loss 562.008544921875  loc loss 38.112815856933594\n",
      "cls loss 683.3548583984375  loc loss 42.9711799621582\n",
      "cls loss 252.52955627441406  loc loss 15.732866287231445\n",
      "cls loss 661.8407592773438  loc loss 43.16484069824219\n",
      "cls loss 500.2226867675781  loc loss 33.49576950073242\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 656.5447998046875  loc loss 49.75335693359375\n",
      "cls loss 309.33294677734375  loc loss 11.77575969696045\n",
      "cls loss 465.24310302734375  loc loss 26.030073165893555\n",
      "cls loss 471.04364013671875  loc loss 31.88650131225586\n",
      "cls loss 377.319580078125  loc loss 22.67339515686035\n",
      "cls loss 214.49896240234375  loc loss 11.834861755371094\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 9., 9., 1., 9., 9., 9., 9., 1., 9.])\n",
      "cls loss 849.9979248046875  loc loss 62.59180450439453\n",
      "cls loss 480.91363525390625  loc loss 24.819747924804688\n",
      "cls loss 729.0302734375  loc loss 55.452754974365234\n",
      "cls loss 302.75811767578125  loc loss 22.114526748657227\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 42., 42.])\n",
      "cls loss 505.7257995605469  loc loss 39.70585632324219\n",
      "cls loss 524.5010986328125  loc loss 42.46787643432617\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  2.,  1.,  1.,  1., 38.,\n",
      "         1.,  1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 38., 38., 38.,  1., 38., 38., 38.,  1.,  1., 38.,  1.,\n",
      "         1.])\n",
      "cls loss 313.383544921875  loc loss 23.625131607055664\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  8.,  8.])\n",
      "cls loss 766.4414672851562  loc loss 51.418983459472656\n",
      "cls loss 781.2752685546875  loc loss 59.858558654785156\n",
      "cls loss 294.41094970703125  loc loss 18.288311004638672\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([4., 1., 1., 4.])\n",
      "cls loss 473.2145080566406  loc loss 28.713525772094727\n",
      "cls loss 562.6598510742188  loc loss 31.729263305664062\n",
      "cls loss 224.22988891601562  loc loss 11.283717155456543\n",
      "cls loss 292.115234375  loc loss 19.00648307800293\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([51.,  1.])\n",
      "cls loss 209.20455932617188  loc loss 8.61524486541748\n",
      "cls loss 298.3304443359375  loc loss 17.311222076416016\n",
      "cls loss 564.392578125  loc loss 31.244874954223633\n",
      "cls loss 553.4053955078125  loc loss 40.938987731933594\n",
      "cls loss 833.3829345703125  loc loss 43.71910095214844\n",
      "cls loss 994.9418334960938  loc loss 66.81210327148438\n",
      "cls loss 399.4068603515625  loc loss 26.293392181396484\n",
      "cls loss 580.72216796875  loc loss 47.03066635131836\n",
      "cls loss 646.7498779296875  loc loss 47.16753387451172\n",
      "cls loss 477.8590393066406  loc loss 29.964693069458008\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  3.,  1.,  1.,  1.,  3.,  1.,  1.,\n",
      "         1.,  1.,  1.])\n",
      "cls loss 525.8760986328125  loc loss 25.809932708740234\n",
      "cls loss 600.78173828125  loc loss 31.412334442138672\n",
      "cls loss 550.6883544921875  loc loss 29.066072463989258\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "cls loss 461.3355712890625  loc loss 25.6737003326416\n",
      "cls loss 249.45814514160156  loc loss 20.73113441467285\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3.])\n",
      "cls loss 196.6641082763672  loc loss 11.010805130004883\n",
      "cls loss 353.4134826660156  loc loss 25.473011016845703\n",
      "cls loss 320.3616027832031  loc loss 22.932220458984375\n",
      "cls loss 601.2291870117188  loc loss 40.43921661376953\n",
      "cls loss 294.7099609375  loc loss 23.704355239868164\n",
      "cls loss 317.85791015625  loc loss 27.585229873657227\n",
      "cls loss 941.4859619140625  loc loss 66.00994110107422\n",
      "cls loss 396.85699462890625  loc loss 33.12028884887695\n",
      "cls loss 312.97796630859375  loc loss 22.681015014648438\n",
      "cls loss 377.4140625  loc loss 22.145719528198242\n",
      "cls loss 349.80828857421875  loc loss 26.3917179107666\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 635.4937744140625  loc loss 42.90553283691406\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  9., 64., 64., 64., 64., 64., 64., 64., 64., 64.,  9.,  9.,  9.,\n",
      "         9.])\n",
      "cls loss 312.03045654296875  loc loss 15.772865295410156\n",
      "cls loss 889.46923828125  loc loss 71.30553436279297\n",
      "cls loss 464.58868408203125  loc loss 32.12256622314453\n",
      "cls loss 574.1605224609375  loc loss 40.15034866333008\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.,  3.,  3.])\n",
      "cls loss 343.3483581542969  loc loss 20.787372589111328\n",
      "cls loss 380.54876708984375  loc loss 28.006710052490234\n",
      "cls loss 391.29193115234375  loc loss 28.084896087646484\n",
      "cls loss 408.29248046875  loc loss 29.811058044433594\n",
      "cls loss 445.5204162597656  loc loss 36.70210266113281\n",
      "cls loss 463.8250427246094  loc loss 35.76504135131836\n",
      "cls loss 414.7840576171875  loc loss 32.79326248168945\n",
      "cls loss 437.10491943359375  loc loss 28.460350036621094\n",
      "cls loss 553.5880126953125  loc loss 39.438377380371094\n",
      "cls loss 405.2137145996094  loc loss 28.090312957763672\n",
      "cls loss 324.42779541015625  loc loss 16.607391357421875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21.])\n",
      "cls loss 262.16925048828125  loc loss 16.066082000732422\n",
      "cls loss 381.912109375  loc loss 33.17559051513672\n",
      "cls loss 572.37060546875  loc loss 38.740325927734375\n",
      "cls loss 301.24664306640625  loc loss 17.90093231201172\n",
      "cls loss 457.2239990234375  loc loss 30.40776824951172\n",
      "cls loss 848.1717529296875  loc loss 46.95305633544922\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 42., 42.,  1.,  1.])\n",
      "cls loss 461.9981689453125  loc loss 26.88871955871582\n",
      "cls loss 296.455078125  loc loss 19.647153854370117\n",
      "cls loss 420.6400451660156  loc loss 28.254440307617188\n",
      "cls loss 553.4087524414062  loc loss 45.59278106689453\n",
      "cls loss 357.1806640625  loc loss 22.505146026611328\n",
      "cls loss 549.2698364257812  loc loss 40.549381256103516\n",
      "cls loss 505.4079284667969  loc loss 36.02495193481445\n",
      "cls loss 487.50799560546875  loc loss 32.02251434326172\n",
      "cls loss 402.648193359375  loc loss 24.79939079284668\n",
      "cls loss 327.6025390625  loc loss 22.364221572875977\n",
      "cls loss 282.20355224609375  loc loss 12.368438720703125\n",
      "cls loss 402.89373779296875  loc loss 25.261550903320312\n",
      "cls loss 611.693603515625  loc loss 43.000030517578125\n",
      "cls loss 481.6793518066406  loc loss 27.32204246520996\n",
      "cls loss 436.629150390625  loc loss 31.753915786743164\n",
      "cls loss 492.666015625  loc loss 28.78177833557129\n",
      "cls loss 711.1063232421875  loc loss 52.24267578125\n",
      "cls loss 543.0745239257812  loc loss 36.83990478515625\n",
      "cls loss 587.6727294921875  loc loss 32.61347198486328\n",
      "cls loss 347.710693359375  loc loss 17.075193405151367\n",
      "cls loss 492.3505859375  loc loss 30.72449493408203\n",
      "cls loss 452.0828857421875  loc loss 26.84058952331543\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 5., 5., 5., 5., 5., 5.])\n",
      "cls loss 298.18597412109375  loc loss 19.74830436706543\n",
      "cls loss 383.1251525878906  loc loss 20.888809204101562\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([13.])\n",
      "cls loss 269.35797119140625  loc loss 14.667080879211426\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([44., 10.,  1.,  1.,  1.])\n",
      "cls loss 251.15267944335938  loc loss 16.904794692993164\n",
      "cls loss 449.0148620605469  loc loss 25.468151092529297\n",
      "cls loss 411.4372863769531  loc loss 23.34366798400879\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19., 19., 19., 19., 19., 19., 19.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 453.13189697265625  loc loss 27.276166915893555\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([56.])\n",
      "cls loss 912.2806396484375  loc loss 59.12101745605469\n",
      "cls loss 580.2025146484375  loc loss 43.12178039550781\n",
      "cls loss 743.0139770507812  loc loss 47.7302360534668\n",
      "cls loss 717.298828125  loc loss 52.94213104248047\n",
      "cls loss 469.78338623046875  loc loss 24.859519958496094\n",
      "cls loss 732.6973876953125  loc loss 47.15938949584961\n",
      "cls loss 413.50531005859375  loc loss 27.054113388061523\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 36.])\n",
      "cls loss 520.002685546875  loc loss 26.07839584350586\n",
      "cls loss 426.3167419433594  loc loss 28.396198272705078\n",
      "cls loss 405.58734130859375  loc loss 25.20648765563965\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5.])\n",
      "cls loss 456.85479736328125  loc loss 29.292404174804688\n",
      "cls loss 249.37808227539062  loc loss 13.925374984741211\n",
      "cls loss 601.8231201171875  loc loss 32.727378845214844\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "cls loss 521.4967651367188  loc loss 35.765892028808594\n",
      "cls loss 494.6015930175781  loc loss 34.113922119140625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 529.1341552734375  loc loss 35.07939147949219\n",
      "cls loss 595.0332641601562  loc loss 39.66981506347656\n",
      "cls loss 507.1303405761719  loc loss 43.264400482177734\n",
      "cls loss 361.769775390625  loc loss 23.929006576538086\n",
      "cls loss 415.05560302734375  loc loss 28.775243759155273\n",
      "cls loss 448.24554443359375  loc loss 27.403656005859375\n",
      "cls loss 707.1492919921875  loc loss 39.68130111694336\n",
      "cls loss 307.91705322265625  loc loss 15.925634384155273\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 11., 15., 10., 10., 10., 10., 10.])\n",
      "cls loss 674.3195190429688  loc loss 45.39194869995117\n",
      "cls loss 397.4660949707031  loc loss 29.755813598632812\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3.])\n",
      "cls loss 415.39495849609375  loc loss 29.62743377685547\n",
      "cls loss 381.6119384765625  loc loss 20.50519561767578\n",
      "cls loss 428.55889892578125  loc loss 22.123868942260742\n",
      "cls loss 535.3292236328125  loc loss 24.932905197143555\n",
      "cls loss 260.33843994140625  loc loss 14.081851959228516\n",
      "cls loss 433.35498046875  loc loss 29.832763671875\n",
      "cls loss 493.6256103515625  loc loss 37.578792572021484\n",
      "cls loss 419.0049743652344  loc loss 30.669391632080078\n",
      "cls loss 995.8836669921875  loc loss 67.29842376708984\n",
      "cls loss 668.8184204101562  loc loss 45.12638473510742\n",
      "cls loss 439.45306396484375  loc loss 29.87533187866211\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  9.,  9.,  9.,  6.,  6., 85., 85.,  8.,  1.,  1.,  1.,  1.,\n",
      "         6.,  6.])\n",
      "cls loss 291.3961486816406  loc loss 25.371742248535156\n",
      "cls loss 726.7543334960938  loc loss 50.89338684082031\n",
      "cls loss 860.1355590820312  loc loss 56.692440032958984\n",
      "cls loss 563.552734375  loc loss 40.259300231933594\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10.,  3.,  3., 10.])\n",
      "cls loss 372.93865966796875  loc loss 20.286184310913086\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([7.])\n",
      "cls loss 462.7528381347656  loc loss 30.460365295410156\n",
      "cls loss 466.8330078125  loc loss 29.00040054321289\n",
      "cls loss 461.962890625  loc loss 37.754791259765625\n",
      "cls loss 687.6806640625  loc loss 53.390106201171875\n",
      "cls loss 419.260009765625  loc loss 29.425874710083008\n",
      "cls loss 614.6300048828125  loc loss 43.359657287597656\n",
      "cls loss 791.7691040039062  loc loss 45.25669479370117\n",
      "cls loss 478.9480895996094  loc loss 31.39702796936035\n",
      "cls loss 518.7610473632812  loc loss 35.185508728027344\n",
      "cls loss 404.8046569824219  loc loss 30.361814498901367\n",
      "cls loss 641.6051635742188  loc loss 49.29325485229492\n",
      "cls loss 478.18707275390625  loc loss 32.260440826416016\n",
      "cls loss 386.36651611328125  loc loss 24.36471939086914\n",
      "cls loss 586.6410522460938  loc loss 45.4904670715332\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([62.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([62.])\n",
      "cls loss 284.34539794921875  loc loss 13.201924324035645\n",
      "cls loss 439.14422607421875  loc loss 35.71683883666992\n",
      "cls loss 431.1960144042969  loc loss 28.400466918945312\n",
      "cls loss 282.5874328613281  loc loss 14.177170753479004\n",
      "cls loss 577.4697265625  loc loss 37.466068267822266\n",
      "cls loss 599.107666015625  loc loss 33.27509689331055\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([28.])\n",
      "cls loss 723.133056640625  loc loss 37.259361267089844\n",
      "cls loss 551.766357421875  loc loss 37.35551452636719\n",
      "cls loss 553.4970703125  loc loss 40.68950653076172\n",
      "cls loss 576.0045166015625  loc loss 39.40436553955078\n",
      "cls loss 780.17578125  loc loss 58.877052307128906\n",
      "cls loss 462.2767333984375  loc loss 28.19341278076172\n",
      "cls loss 596.0823974609375  loc loss 33.84654998779297\n",
      "cls loss 485.1556396484375  loc loss 39.904354095458984\n",
      "cls loss 800.8992919921875  loc loss 63.994110107421875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([81.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 508.822509765625  loc loss 23.835981369018555\n",
      "cls loss 387.7628173828125  loc loss 24.241785049438477\n",
      "cls loss 290.42889404296875  loc loss 25.58722496032715\n",
      "cls loss 264.8291015625  loc loss 13.989956855773926\n",
      "cls loss 296.43646240234375  loc loss 27.817626953125\n",
      "cls loss 363.52154541015625  loc loss 25.057743072509766\n",
      "cls loss 375.3774108886719  loc loss 30.30438995361328\n",
      "cls loss 534.45703125  loc loss 46.547489166259766\n",
      "cls loss 655.1808471679688  loc loss 39.66465759277344\n",
      "cls loss 1130.206298828125  loc loss 77.99911499023438\n",
      "cls loss 454.6443176269531  loc loss 23.173921585083008\n",
      "cls loss 558.2216796875  loc loss 46.53843688964844\n",
      "cls loss 396.5297546386719  loc loss 28.86642074584961\n",
      "cls loss 532.5528564453125  loc loss 37.12986755371094\n",
      "cls loss 444.56488037109375  loc loss 29.646007537841797\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([44., 44.])\n",
      "cls loss 392.72064208984375  loc loss 24.588388442993164\n",
      "cls loss 429.5937194824219  loc loss 35.828636169433594\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15.])\n",
      "cls loss 442.31866455078125  loc loss 33.97278594970703\n",
      "cls loss 218.66232299804688  loc loss 16.307220458984375\n",
      "cls loss 447.8734130859375  loc loss 30.488492965698242\n",
      "cls loss 265.76690673828125  loc loss 14.550209999084473\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([1., 3., 3.])\n",
      "cls loss 301.4613037109375  loc loss 20.95153045654297\n",
      "cls loss 223.1472930908203  loc loss 10.744434356689453\n",
      "cls loss 426.5825500488281  loc loss 31.06067657470703\n",
      "cls loss 485.9988708496094  loc loss 32.585227966308594\n",
      "cls loss 434.969970703125  loc loss 35.421836853027344\n",
      "cls loss 370.80133056640625  loc loss 31.711790084838867\n",
      "cls loss 375.89031982421875  loc loss 35.00681686401367\n",
      "cls loss 511.8224182128906  loc loss 42.04386520385742\n",
      "cls loss 365.1729431152344  loc loss 29.145992279052734\n",
      "cls loss 494.9678955078125  loc loss 37.0129508972168\n",
      "cls loss 337.54931640625  loc loss 20.422109603881836\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 577.5867309570312  loc loss 35.50991439819336\n",
      "cls loss 694.619873046875  loc loss 31.694671630859375\n",
      "cls loss 591.3775634765625  loc loss 43.57640075683594\n",
      "cls loss 584.5482177734375  loc loss 47.33443069458008\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10., 10., 10.,  1.,  1.,  1.,  1.,  1.,  1.,  8.,  8.,\n",
      "         1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10., 10., 10.,  1.,  1.,  1.,  1.,  1.,  1.,  8.,  8.,\n",
      "         1.])\n",
      "cls loss 488.98333740234375  loc loss 27.655502319335938\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 3., 3., 3.])\n",
      "cls loss 456.52532958984375  loc loss 31.401357650756836\n",
      "cls loss 310.63385009765625  loc loss 21.773786544799805\n",
      "cls loss 237.11312866210938  loc loss 17.51597023010254\n",
      "cls loss 437.3590393066406  loc loss 39.3719482421875\n",
      "cls loss 337.19805908203125  loc loss 17.922040939331055\n",
      "cls loss 400.6174621582031  loc loss 32.57855224609375\n",
      "cls loss 452.89727783203125  loc loss 32.50548553466797\n",
      "cls loss 615.7973022460938  loc loss 43.36286163330078\n",
      "cls loss 529.711669921875  loc loss 27.25723648071289\n",
      "cls loss 491.1278381347656  loc loss 27.400222778320312\n",
      "cls loss 509.6168212890625  loc loss 36.30439758300781\n",
      "cls loss 364.6426696777344  loc loss 32.0067138671875\n",
      "cls loss 722.2951049804688  loc loss 57.829612731933594\n",
      "cls loss 332.1281433105469  loc loss 22.488304138183594\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 577.8694458007812  loc loss 38.263916015625\n",
      "cls loss 265.1650695800781  loc loss 14.032299041748047\n",
      "cls loss 661.767333984375  loc loss 52.52066421508789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 329.3161926269531  loc loss 20.810077667236328\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 34.])\n",
      "cls loss 538.197509765625  loc loss 31.848840713500977\n",
      "cls loss 264.70166015625  loc loss 17.806392669677734\n",
      "cls loss 537.0150756835938  loc loss 34.339115142822266\n",
      "cls loss 180.8565673828125  loc loss 14.059284210205078\n",
      "cls loss 437.0341796875  loc loss 28.48736572265625\n",
      "cls loss 431.3843994140625  loc loss 36.87852096557617\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 38.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16., 16., 16.,  9.,  9.,  9., 16., 16., 16., 85.,  9.])\n",
      "cls loss 447.6280517578125  loc loss 31.39016342163086\n",
      "cls loss 489.11041259765625  loc loss 44.71807098388672\n",
      "cls loss 654.8472900390625  loc loss 48.62249755859375\n",
      "cls loss 1017.2030639648438  loc loss 68.04121398925781\n",
      "cls loss 278.80322265625  loc loss 15.579891204833984\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3., 10.,  8.,  8., 10., 10., 10.,  3.,  3., 14.])\n",
      "cls loss 294.9989929199219  loc loss 21.001522064208984\n",
      "cls loss 561.3978271484375  loc loss 35.74606704711914\n",
      "cls loss 253.0243377685547  loc loss 10.616755485534668\n",
      "cls loss 415.1794128417969  loc loss 19.27525520324707\n",
      "cls loss 548.2528686523438  loc loss 34.822303771972656\n",
      "cls loss 468.0164794921875  loc loss 29.863948822021484\n",
      "cls loss 257.4019775390625  loc loss 15.353474617004395\n",
      "cls loss 330.61224365234375  loc loss 20.479751586914062\n",
      "cls loss 529.4503784179688  loc loss 32.95547103881836\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42., 42.,  1.])\n",
      "cls loss 492.9041748046875  loc loss 32.90137481689453\n",
      "cls loss 372.38226318359375  loc loss 24.33481216430664\n",
      "cls loss 514.277099609375  loc loss 40.64695358276367\n",
      "cls loss 595.9466552734375  loc loss 39.642086029052734\n",
      "cls loss 413.3711242675781  loc loss 26.942420959472656\n",
      "cls loss 507.5442810058594  loc loss 37.43817901611328\n",
      "cls loss 312.5586242675781  loc loss 23.43729591369629\n",
      "cls loss 333.1258544921875  loc loss 25.286304473876953\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20.])\n",
      "cls loss 241.90084838867188  loc loss 15.334352493286133\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([11.])\n",
      "cls loss 344.8865051269531  loc loss 17.697664260864258\n",
      "cls loss 208.2720184326172  loc loss 13.516361236572266\n",
      "cls loss 518.013671875  loc loss 41.019615173339844\n",
      "cls loss 230.75209045410156  loc loss 11.972344398498535\n",
      "cls loss 508.7552490234375  loc loss 29.537385940551758\n",
      "cls loss 280.19415283203125  loc loss 17.669170379638672\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 35., 27.])\n",
      "cls loss 491.4151306152344  loc loss 28.976764678955078\n",
      "cls loss 537.5787353515625  loc loss 39.668521881103516\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 357.1748046875  loc loss 20.728740692138672\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([42.,  1.])\n",
      "cls loss 444.8424072265625  loc loss 31.831806182861328\n",
      "cls loss 442.5035705566406  loc loss 25.392898559570312\n",
      "cls loss 512.3161010742188  loc loss 33.06046676635742\n",
      "cls loss 655.3357543945312  loc loss 40.45762634277344\n",
      "cls loss 565.1207885742188  loc loss 36.57141876220703\n",
      "cls loss 380.570068359375  loc loss 31.00860595703125\n",
      "cls loss 324.68817138671875  loc loss 26.205013275146484\n",
      "cls loss 197.80908203125  loc loss 9.749469757080078\n",
      "cls loss 384.50238037109375  loc loss 21.171092987060547\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 1., 1.])\n",
      "cls loss 365.6326904296875  loc loss 22.884504318237305\n",
      "cls loss 423.6904296875  loc loss 27.711811065673828\n",
      "cls loss 413.2183837890625  loc loss 26.88927459716797\n",
      "cls loss 339.29718017578125  loc loss 26.369701385498047\n",
      "cls loss 415.2408447265625  loc loss 28.59823989868164\n",
      "cls loss 453.2535400390625  loc loss 32.43503189086914\n",
      "cls loss 641.55517578125  loc loss 38.61784744262695\n",
      "cls loss 545.1500244140625  loc loss 43.168819427490234\n",
      "cls loss 485.5157775878906  loc loss 33.32600402832031\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 376.1549072265625  loc loss 28.67658233642578\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 480.9486999511719  loc loss 23.803070068359375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([81.])\n",
      "cls loss 560.5032958984375  loc loss 33.67815399169922\n",
      "cls loss 335.3952941894531  loc loss 24.329998016357422\n",
      "cls loss 245.5347900390625  loc loss 13.863937377929688\n",
      "cls loss 374.4488830566406  loc loss 21.47987937927246\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3.,  1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 19.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 19.])\n",
      "cls loss 515.532470703125  loc loss 37.455684661865234\n",
      "cls loss 288.44024658203125  loc loss 17.03887367248535\n",
      "cls loss 309.1947021484375  loc loss 19.090660095214844\n",
      "cls loss 600.9675903320312  loc loss 48.84733200073242\n",
      "cls loss 297.63568115234375  loc loss 22.093597412109375\n",
      "cls loss 386.138427734375  loc loss 24.670448303222656\n",
      "cls loss 486.34234619140625  loc loss 35.34511184692383\n",
      "cls loss 369.1445617675781  loc loss 25.732345581054688\n",
      "cls loss 477.24920654296875  loc loss 27.58023452758789\n",
      "cls loss 555.8779296875  loc loss 35.880802154541016\n",
      "cls loss 681.7510375976562  loc loss 57.59931564331055\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 81.])\n",
      "cls loss 472.4344482421875  loc loss 24.223648071289062\n",
      "cls loss 418.8385314941406  loc loss 23.475263595581055\n",
      "cls loss 436.3703308105469  loc loss 26.108959197998047\n",
      "cls loss 336.28472900390625  loc loss 19.05314826965332\n",
      "cls loss 294.547119140625  loc loss 21.253339767456055\n",
      "cls loss 326.31500244140625  loc loss 28.1121826171875\n",
      "cls loss 257.083984375  loc loss 21.35690689086914\n",
      "cls loss 224.44078063964844  loc loss 17.31052017211914\n",
      "cls loss 305.9501953125  loc loss 22.68537139892578\n",
      "cls loss 409.92657470703125  loc loss 28.40693473815918\n",
      "cls loss 364.381591796875  loc loss 28.423078536987305\n",
      "cls loss 382.4660339355469  loc loss 27.646352767944336\n",
      "cls loss 226.8041229248047  loc loss 15.342291831970215\n",
      "cls loss 789.2930297851562  loc loss 53.019832611083984\n",
      "cls loss 450.2315979003906  loc loss 31.294479370117188\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 413.3333740234375  loc loss 21.055017471313477\n",
      "cls loss 479.91864013671875  loc loss 32.221092224121094\n",
      "cls loss 373.2668151855469  loc loss 22.831804275512695\n",
      "cls loss 572.3037719726562  loc loss 40.90296173095703\n",
      "cls loss 522.9365234375  loc loss 34.664451599121094\n",
      "cls loss 480.9644775390625  loc loss 31.09065818786621\n",
      "cls loss 353.5115966796875  loc loss 24.677352905273438\n",
      "cls loss 289.94677734375  loc loss 18.821744918823242\n",
      "cls loss 423.3280334472656  loc loss 27.70119857788086\n",
      "cls loss 480.94854736328125  loc loss 33.152854919433594\n",
      "cls loss 462.67913818359375  loc loss 26.191009521484375\n",
      "cls loss 588.3892211914062  loc loss 41.35135269165039\n",
      "cls loss 616.40625  loc loss 47.51498794555664\n",
      "cls loss 435.47296142578125  loc loss 30.962766647338867\n",
      "cls loss 627.2518310546875  loc loss 52.427406311035156\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1., 38., 47.,  1.,  1.,  1.,  1.,  1., 62.])\n",
      "cls loss 418.3179931640625  loc loss 22.898513793945312\n",
      "cls loss 496.82440185546875  loc loss 37.037559509277344\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 553.35107421875  loc loss 34.70879364013672\n",
      "cls loss 579.6237182617188  loc loss 44.04912567138672\n",
      "cls loss 398.6476745605469  loc loss 19.62172508239746\n",
      "cls loss 471.8517761230469  loc loss 37.78813552856445\n",
      "cls loss 443.21124267578125  loc loss 26.57318878173828\n",
      "cls loss 249.79168701171875  loc loss 10.5958251953125\n",
      "cls loss 373.60870361328125  loc loss 22.071086883544922\n",
      "cls loss 313.7444152832031  loc loss 15.364522933959961\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1., 35.])\n",
      "cls loss 347.5397033691406  loc loss 21.885629653930664\n",
      "cls loss 551.770263671875  loc loss 31.953310012817383\n",
      "cls loss 536.9783325195312  loc loss 39.56638717651367\n",
      "cls loss 477.12835693359375  loc loss 44.53685760498047\n",
      "cls loss 384.31787109375  loc loss 33.26044845581055\n",
      "cls loss 522.9717407226562  loc loss 41.950225830078125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 290.7144470214844  loc loss 18.084924697875977\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 432.42022705078125  loc loss 18.623058319091797\n",
      "cls loss 690.0716552734375  loc loss 39.04298782348633\n",
      "cls loss 817.2100830078125  loc loss 64.56135559082031\n",
      "cls loss 421.25372314453125  loc loss 23.49195098876953\n",
      "cls loss 363.34051513671875  loc loss 23.46932601928711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 375.51129150390625  loc loss 21.444000244140625\n",
      "cls loss 390.3426513671875  loc loss 25.025897979736328\n",
      "cls loss 338.0626220703125  loc loss 16.318424224853516\n",
      "cls loss 618.20947265625  loc loss 44.31831741333008\n",
      "cls loss 525.5266723632812  loc loss 31.425737380981445\n",
      "cls loss 234.70266723632812  loc loss 18.76494789123535\n",
      "cls loss 498.96234130859375  loc loss 30.652956008911133\n",
      "cls loss 608.736328125  loc loss 49.22251892089844\n",
      "cls loss 479.091064453125  loc loss 32.7935676574707\n",
      "cls loss 405.50250244140625  loc loss 24.5705509185791\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.])\n",
      "cls loss 401.8273620605469  loc loss 29.802759170532227\n",
      "cls loss 408.20965576171875  loc loss 29.265914916992188\n",
      "cls loss 516.5116577148438  loc loss 32.65500259399414\n",
      "cls loss 828.5093994140625  loc loss 67.9326171875\n",
      "cls loss 327.79583740234375  loc loss 16.460052490234375\n",
      "cls loss 424.30645751953125  loc loss 24.455289840698242\n",
      "cls loss 344.0122985839844  loc loss 21.403404235839844\n",
      "cls loss 363.4348449707031  loc loss 25.162147521972656\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 21., 21., 21.])\n",
      "cls loss 383.4930419921875  loc loss 24.387802124023438\n",
      "cls loss 366.01947021484375  loc loss 19.538433074951172\n",
      "cls loss 388.84869384765625  loc loss 25.860271453857422\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 35.])\n",
      "cls loss 511.0145263671875  loc loss 34.52741622924805\n",
      "cls loss 193.199951171875  loc loss 10.355123519897461\n",
      "cls loss 334.93646240234375  loc loss 21.886751174926758\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 313.2069396972656  loc loss 15.10151481628418\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 38., 38.,  9., 38.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1.,  1.])\n",
      "cls loss 362.79229736328125  loc loss 23.174562454223633\n",
      "cls loss 594.6023559570312  loc loss 40.640018463134766\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 2.,  1., 77., 31., 10., 10.,  1.,  4., 10.])\n",
      "cls loss 287.72930908203125  loc loss 12.77426528930664\n",
      "cls loss 546.162841796875  loc loss 34.32729721069336\n",
      "cls loss 1131.2392578125  loc loss 65.72560119628906\n",
      "cls loss 338.9039001464844  loc loss 23.772274017333984\n",
      "cls loss 479.0382080078125  loc loss 36.73672103881836\n",
      "cls loss 348.11383056640625  loc loss 18.467510223388672\n",
      "cls loss 333.91107177734375  loc loss 17.008853912353516\n",
      "cls loss 478.745849609375  loc loss 27.31752586364746\n",
      "cls loss 489.20416259765625  loc loss 27.9327449798584\n",
      "cls loss 436.4368591308594  loc loss 32.98102569580078\n",
      "cls loss 362.773681640625  loc loss 17.345243453979492\n",
      "cls loss 363.3189392089844  loc loss 20.878047943115234\n",
      "cls loss 678.7488403320312  loc loss 43.81067657470703\n",
      "cls loss 627.6325073242188  loc loss 37.661251068115234\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1., 42., 42., 42., 42., 42., 42.,  1.,\n",
      "         1.,  1.,  1., 42.,  1.,  1., 42.,  1.])\n",
      "cls loss 346.95428466796875  loc loss 25.219310760498047\n",
      "cls loss 518.9002685546875  loc loss 30.535917282104492\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.])\n",
      "cls loss 226.71829223632812  loc loss 12.470518112182617\n",
      "cls loss 523.5115356445312  loc loss 35.037559509277344\n",
      "cls loss 385.9862060546875  loc loss 29.203643798828125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([11.])\n",
      "cls loss 240.1845245361328  loc loss 15.314815521240234\n",
      "cls loss 274.2879333496094  loc loss 14.004027366638184\n",
      "cls loss 298.48114013671875  loc loss 14.88134765625\n",
      "cls loss 519.640869140625  loc loss 31.39995574951172\n",
      "cls loss 412.177490234375  loc loss 24.877567291259766\n",
      "cls loss 448.2543029785156  loc loss 28.759963989257812\n",
      "cls loss 631.0371704101562  loc loss 32.94940948486328\n",
      "cls loss 331.45562744140625  loc loss 19.186939239501953\n",
      "cls loss 696.9273071289062  loc loss 46.19796371459961\n",
      "cls loss 331.64093017578125  loc loss 20.60955810546875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 307.3548583984375  loc loss 19.92311668395996\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1., 38., 38., 42.])\n",
      "cls loss 404.74212646484375  loc loss 28.324369430541992\n",
      "cls loss 369.33154296875  loc loss 21.542133331298828\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 326.64056396484375  loc loss 22.23122787475586\n",
      "cls loss 731.8137817382812  loc loss 49.6717529296875\n",
      "cls loss 448.71795654296875  loc loss 28.077713012695312\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10.,  3.,  3.,  6.,  8.,  8.,  1.,  1.,  1., 10.])\n",
      "cls loss 350.68310546875  loc loss 18.404951095581055\n",
      "cls loss 226.07119750976562  loc loss 9.032011985778809\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10.,  3.])\n",
      "cls loss 327.8966064453125  loc loss 19.863000869750977\n",
      "cls loss 165.04571533203125  loc loss 10.376953125\n",
      "cls loss 420.95074462890625  loc loss 30.50453758239746\n",
      "cls loss 511.66046142578125  loc loss 33.07316589355469\n",
      "cls loss 363.8681640625  loc loss 22.42275619506836\n",
      "cls loss 240.18600463867188  loc loss 14.223604202270508\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 34.])\n",
      "cls loss 606.568359375  loc loss 38.14717102050781\n",
      "cls loss 692.7347412109375  loc loss 51.92605209350586\n",
      "cls loss 447.59417724609375  loc loss 31.180147171020508\n",
      "cls loss 357.4461975097656  loc loss 23.486373901367188\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.,  1.])\n",
      "cls loss 383.261474609375  loc loss 17.03033447265625\n",
      "cls loss 604.1346435546875  loc loss 43.95549011230469\n",
      "cls loss 865.110595703125  loc loss 56.33495330810547\n",
      "cls loss 711.0239868164062  loc loss 38.67362976074219\n",
      "cls loss 416.9159851074219  loc loss 22.580209732055664\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 474.5297546386719  loc loss 27.373809814453125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10.])\n",
      "cls loss 297.3042907714844  loc loss 15.645995140075684\n",
      "cls loss 441.75164794921875  loc loss 21.40518569946289\n",
      "cls loss 414.3131103515625  loc loss 24.597333908081055\n",
      "cls loss 286.2035827636719  loc loss 16.661611557006836\n",
      "cls loss 390.2078857421875  loc loss 24.342731475830078\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21.,\n",
      "        21.])\n",
      "cls loss 482.38433837890625  loc loss 29.665796279907227\n",
      "cls loss 406.78839111328125  loc loss 23.80299949645996\n",
      "cls loss 270.3382873535156  loc loss 12.313713073730469\n",
      "cls loss 595.2606201171875  loc loss 37.695213317871094\n",
      "cls loss 444.201904296875  loc loss 29.18778419494629\n",
      "cls loss 342.1911926269531  loc loss 17.174657821655273\n",
      "cls loss 667.5067138671875  loc loss 41.792816162109375\n",
      "cls loss 775.1361083984375  loc loss 55.601436614990234\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15., 85.])\n",
      "cls loss 512.3572998046875  loc loss 30.463579177856445\n",
      "cls loss 498.1213684082031  loc loss 36.81082534790039\n",
      "cls loss 512.9132080078125  loc loss 37.34636688232422\n",
      "cls loss 427.3511962890625  loc loss 26.355703353881836\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 8., 8.])\n",
      "cls loss 287.49249267578125  loc loss 12.763943672180176\n",
      "cls loss 296.4564208984375  loc loss 23.373506546020508\n",
      "cls loss 379.7247314453125  loc loss 24.60198974609375\n",
      "cls loss 329.79058837890625  loc loss 20.33024787902832\n",
      "cls loss 362.2411193847656  loc loss 22.01229476928711\n",
      "cls loss 521.310302734375  loc loss 30.980838775634766\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1., 35., 27., 27.,  1., 27.,  1.])\n",
      "cls loss 605.995849609375  loc loss 47.67106246948242\n",
      "cls loss 353.9286804199219  loc loss 21.320911407470703\n",
      "cls loss 388.899658203125  loc loss 28.357973098754883\n",
      "cls loss 367.9817199707031  loc loss 32.16328048706055\n",
      "cls loss 339.50762939453125  loc loss 24.424074172973633\n",
      "cls loss 375.99725341796875  loc loss 28.832115173339844\n",
      "cls loss 385.0498046875  loc loss 29.47939682006836\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  2.,  2.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  2.,  2.])\n",
      "cls loss 194.0079345703125  loc loss 9.327336311340332\n",
      "cls loss 602.58203125  loc loss 39.06134796142578\n",
      "cls loss 378.3199462890625  loc loss 20.835948944091797\n",
      "cls loss 650.9100341796875  loc loss 48.70028305053711\n",
      "cls loss 251.2940673828125  loc loss 13.930540084838867\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 19., 19., 19., 16.])\n",
      "cls loss 262.0224609375  loc loss 11.95748519897461\n",
      "cls loss 214.37252807617188  loc loss 9.206609725952148\n",
      "cls loss 359.96600341796875  loc loss 17.316394805908203\n",
      "cls loss 476.4216003417969  loc loss 30.27606201171875\n",
      "cls loss 185.7982177734375  loc loss 14.494619369506836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 524.0399169921875  loc loss 40.69535446166992\n",
      "cls loss 387.01336669921875  loc loss 26.584714889526367\n",
      "cls loss 404.1668701171875  loc loss 26.280323028564453\n",
      "cls loss 521.5671997070312  loc loss 34.94716262817383\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 538.9849853515625  loc loss 26.456375122070312\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 750.315673828125  loc loss 62.915470123291016\n",
      "cls loss 972.0576171875  loc loss 87.95830535888672\n",
      "cls loss 499.92559814453125  loc loss 27.914997100830078\n",
      "cls loss 444.37957763671875  loc loss 26.584609985351562\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3.,  3.,  3.,  3.,  3., 10.])\n",
      "cls loss 218.28196716308594  loc loss 13.553772926330566\n",
      "cls loss 465.35101318359375  loc loss 21.655231475830078\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 1., 1., 1., 3., 3., 3., 3.])\n",
      "cls loss 360.28216552734375  loc loss 20.82851791381836\n",
      "cls loss 695.5684204101562  loc loss 44.50326919555664\n",
      "cls loss 554.0505981445312  loc loss 36.51470184326172\n",
      "cls loss 352.8665771484375  loc loss 21.245967864990234\n",
      "cls loss 555.525146484375  loc loss 37.7907829284668\n",
      "cls loss 332.4214782714844  loc loss 24.238754272460938\n",
      "cls loss 530.0675048828125  loc loss 37.019874572753906\n",
      "cls loss 404.9378662109375  loc loss 37.04311752319336\n",
      "cls loss 395.9228210449219  loc loss 26.63390350341797\n",
      "cls loss 841.1396484375  loc loss 71.12724304199219\n",
      "cls loss 555.5188598632812  loc loss 40.111846923828125\n",
      "cls loss 376.07928466796875  loc loss 17.814577102661133\n",
      "cls loss 237.85791015625  loc loss 10.782976150512695\n",
      "cls loss 292.064208984375  loc loss 14.019378662109375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3., 10., 10., 10., 10., 10., 10., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10., 10., 10., 10., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 11., 10., 10., 10., 10., 10.,  3.,  3.,  3.,  3.,  3.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 11., 10., 10., 10., 10., 10.,  3.,  3.,  3.,  3.,  3.])\n",
      "cls loss 234.12213134765625  loc loss 11.157896041870117\n",
      "cls loss 324.82781982421875  loc loss 14.012676239013672\n",
      "cls loss 271.2098693847656  loc loss 15.389557838439941\n",
      "cls loss 279.43646240234375  loc loss 12.475488662719727\n",
      "cls loss 338.60986328125  loc loss 26.316120147705078\n",
      "cls loss 252.69691467285156  loc loss 10.639908790588379\n",
      "cls loss 511.7901306152344  loc loss 34.67911911010742\n",
      "cls loss 464.4184875488281  loc loss 30.749847412109375\n",
      "cls loss 686.876708984375  loc loss 44.55252456665039\n",
      "cls loss 345.621826171875  loc loss 23.9616641998291\n",
      "cls loss 603.7081298828125  loc loss 39.168792724609375\n",
      "cls loss 464.95672607421875  loc loss 33.506900787353516\n",
      "cls loss 463.55145263671875  loc loss 32.108001708984375\n",
      "cls loss 451.70855712890625  loc loss 34.11933517456055\n",
      "cls loss 595.050048828125  loc loss 44.698883056640625\n",
      "cls loss 579.9610595703125  loc loss 42.199405670166016\n",
      "cls loss 282.5985412597656  loc loss 15.566004753112793\n",
      "cls loss 549.919677734375  loc loss 39.033626556396484\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 10.,  1., 18.])\n",
      "cls loss 255.75863647460938  loc loss 17.815093994140625\n",
      "cls loss 324.2537536621094  loc loss 13.515880584716797\n",
      "cls loss 579.5191040039062  loc loss 29.262256622314453\n",
      "cls loss 758.410400390625  loc loss 44.53086853027344\n",
      "cls loss 452.0887451171875  loc loss 33.395729064941406\n",
      "cls loss 661.050537109375  loc loss 34.37003707885742\n",
      "cls loss 481.62310791015625  loc loss 34.26339340209961\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.,  1.,  1.])\n",
      "cls loss 567.6264038085938  loc loss 41.10634231567383\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1., 38.,  1.])\n",
      "cls loss 471.8880310058594  loc loss 31.919288635253906\n",
      "cls loss 691.8134765625  loc loss 56.27458572387695\n",
      "cls loss 377.95294189453125  loc loss 26.51951789855957\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 519.4649658203125  loc loss 30.81804084777832\n",
      "cls loss 421.39752197265625  loc loss 27.025264739990234\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3., 10.,  8.,  3., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.])\n",
      "cls loss 481.6030578613281  loc loss 28.371368408203125\n",
      "cls loss 322.4489440917969  loc loss 22.797561645507812\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3.,  3., 11.,  3., 10., 10.,  3.,  3., 10.])\n",
      "cls loss 380.34588623046875  loc loss 21.67730712890625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3., 10., 10., 10.])\n",
      "cls loss 418.626953125  loc loss 27.1082763671875\n",
      "cls loss 340.03515625  loc loss 25.986129760742188\n",
      "cls loss 449.68927001953125  loc loss 36.209716796875\n",
      "cls loss 649.0726928710938  loc loss 42.506221771240234\n",
      "cls loss 425.65850830078125  loc loss 29.92200469970703\n",
      "cls loss 328.2193908691406  loc loss 27.171619415283203\n",
      "cls loss 412.2424621582031  loc loss 24.636402130126953\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 9.,  9., 85., 85.])\n",
      "cls loss 330.55029296875  loc loss 16.79741096496582\n",
      "cls loss 422.13836669921875  loc loss 28.722957611083984\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 651.4884643554688  loc loss 43.97170639038086\n",
      "cls loss 555.2850952148438  loc loss 28.78095054626465\n",
      "cls loss 629.32275390625  loc loss 49.521732330322266\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10., 10., 10., 10.])\n",
      "cls loss 390.70477294921875  loc loss 29.524272918701172\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([13.])\n",
      "cls loss 612.7348022460938  loc loss 57.17662048339844\n",
      "cls loss 178.88475036621094  loc loss 11.550220489501953\n",
      "cls loss 267.3711242675781  loc loss 14.195728302001953\n",
      "cls loss 355.36859130859375  loc loss 23.680696487426758\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19.,  1.,  1.,  1., 19., 19.])\n",
      "cls loss 380.3705139160156  loc loss 26.099206924438477\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 314.2830810546875  loc loss 21.798694610595703\n",
      "cls loss 446.5240783691406  loc loss 30.79384994506836\n",
      "cls loss 349.9713134765625  loc loss 18.81875228881836\n",
      "cls loss 498.00543212890625  loc loss 25.55942726135254\n",
      "cls loss 527.7841186523438  loc loss 40.69886779785156\n",
      "cls loss 393.30999755859375  loc loss 25.652908325195312\n",
      "cls loss 628.3265991210938  loc loss 47.95259094238281\n",
      "cls loss 221.8369903564453  loc loss 14.80545425415039\n",
      "cls loss 424.73345947265625  loc loss 31.952836990356445\n",
      "cls loss 335.4244689941406  loc loss 20.00269889831543\n",
      "cls loss 371.75457763671875  loc loss 21.410308837890625\n",
      "cls loss 508.2229309082031  loc loss 31.599641799926758\n",
      "cls loss 422.76361083984375  loc loss 21.716716766357422\n",
      "cls loss 597.8414306640625  loc loss 41.55527877807617\n",
      "cls loss 391.51202392578125  loc loss 25.363767623901367\n",
      "cls loss 506.5346374511719  loc loss 36.5844841003418\n",
      "cls loss 732.15380859375  loc loss 51.40812683105469\n",
      "cls loss 386.13079833984375  loc loss 33.9619255065918\n",
      "cls loss 467.18316650390625  loc loss 29.12751007080078\n",
      "cls loss 539.962158203125  loc loss 43.869686126708984\n",
      "cls loss 626.6904907226562  loc loss 49.621551513671875\n",
      "cls loss 713.4613037109375  loc loss 45.02916717529297\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 5.])\n",
      "cls loss 188.6262969970703  loc loss 9.39957046508789\n",
      "cls loss 263.858154296875  loc loss 11.419977188110352\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 13.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 6., 8., 8.])\n",
      "cls loss 204.88223266601562  loc loss 12.068958282470703\n",
      "cls loss 273.82769775390625  loc loss 16.815608978271484\n",
      "cls loss 545.93994140625  loc loss 42.94055938720703\n",
      "cls loss 227.27264404296875  loc loss 13.229422569274902\n",
      "cls loss 466.1215515136719  loc loss 39.49399185180664\n",
      "cls loss 678.8795166015625  loc loss 60.72651672363281\n",
      "cls loss 435.3505859375  loc loss 33.112396240234375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([42., 42.,  1.,  1.,  1.,  1.,  1.,  1.,  1., 42., 42.])\n",
      "cls loss 473.25286865234375  loc loss 28.507583618164062\n",
      "cls loss 611.8145751953125  loc loss 49.6964225769043\n",
      "cls loss 566.51611328125  loc loss 37.82231140136719\n",
      "cls loss 360.76495361328125  loc loss 21.566604614257812\n",
      "cls loss 470.7015686035156  loc loss 26.386472702026367\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 676.6666259765625  loc loss 45.08671951293945\n",
      "cls loss 535.3451538085938  loc loss 39.9062385559082\n",
      "cls loss 323.413818359375  loc loss 19.069799423217773\n",
      "cls loss 271.3712158203125  loc loss 20.151731491088867\n",
      "cls loss 356.6922302246094  loc loss 29.180273056030273\n",
      "cls loss 511.564208984375  loc loss 45.01100158691406\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 249.10360717773438  loc loss 10.30715560913086\n",
      "cls loss 431.99908447265625  loc loss 28.185773849487305\n",
      "cls loss 369.4330749511719  loc loss 27.365068435668945\n",
      "cls loss 672.8076171875  loc loss 47.74587631225586\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19.,  7.])\n",
      "cls loss 327.1256103515625  loc loss 20.111597061157227\n",
      "cls loss 692.781005859375  loc loss 50.867881774902344\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 621.4204711914062  loc loss 32.32389831542969\n",
      "cls loss 533.5942993164062  loc loss 41.97328186035156\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([38., 38.,  1., 18.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1., 18., 18.,  1.])\n",
      "cls loss 369.79083251953125  loc loss 24.319412231445312\n",
      "cls loss 364.0546569824219  loc loss 23.10791778564453\n",
      "cls loss 702.5958251953125  loc loss 54.92858123779297\n",
      "cls loss 525.9603271484375  loc loss 34.90386199951172\n",
      "cls loss 424.1672058105469  loc loss 29.300241470336914\n",
      "cls loss 282.2292175292969  loc loss 22.317873001098633\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.])\n",
      "cls loss 184.86370849609375  loc loss 8.04467487335205\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([32.])\n",
      "cls loss 447.1764221191406  loc loss 28.2813720703125\n",
      "cls loss 375.76507568359375  loc loss 26.72787094116211\n",
      "cls loss 478.3603515625  loc loss 40.014625549316406\n",
      "cls loss 423.91778564453125  loc loss 28.146881103515625\n",
      "cls loss 355.2469177246094  loc loss 24.75355339050293\n",
      "cls loss 579.888916015625  loc loss 36.228050231933594\n",
      "cls loss 679.577880859375  loc loss 49.78529739379883\n",
      "cls loss 502.4620361328125  loc loss 40.122676849365234\n",
      "cls loss 399.03997802734375  loc loss 27.461610794067383\n",
      "cls loss 636.9552001953125  loc loss 47.0459098815918\n",
      "cls loss 440.6544189453125  loc loss 24.308515548706055\n",
      "cls loss 758.7559204101562  loc loss 52.944244384765625\n",
      "cls loss 503.24432373046875  loc loss 27.642440795898438\n",
      "cls loss 395.4796142578125  loc loss 29.854652404785156\n",
      "cls loss 306.181640625  loc loss 15.690896987915039\n",
      "cls loss 343.7401123046875  loc loss 23.016799926757812\n",
      "cls loss 507.779296875  loc loss 37.64756774902344\n",
      "cls loss 548.1463012695312  loc loss 41.82781982421875\n",
      "cls loss 311.16094970703125  loc loss 20.529632568359375\n",
      "cls loss 554.5385131835938  loc loss 44.196044921875\n",
      "cls loss 673.2037353515625  loc loss 57.115909576416016\n",
      "cls loss 248.76296997070312  loc loss 17.944780349731445\n",
      "cls loss 653.515869140625  loc loss 49.2953987121582\n",
      "cls loss 493.9018859863281  loc loss 36.073814392089844\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 648.3424072265625  loc loss 50.99497985839844\n",
      "cls loss 303.8983154296875  loc loss 12.171163558959961\n",
      "cls loss 460.32562255859375  loc loss 25.777803421020508\n",
      "cls loss 467.7367248535156  loc loss 34.08741760253906\n",
      "cls loss 375.6119384765625  loc loss 26.50633430480957\n",
      "cls loss 210.90066528320312  loc loss 12.822504043579102\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 9., 9., 1., 9., 9., 9., 9., 1., 9.])\n",
      "cls loss 848.2684326171875  loc loss 76.89228820800781\n",
      "cls loss 475.27587890625  loc loss 34.811073303222656\n",
      "cls loss 724.5861206054688  loc loss 64.8936996459961\n",
      "cls loss 299.20526123046875  loc loss 23.18854331970215\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 42., 42.])\n",
      "cls loss 499.8924255371094  loc loss 38.87265396118164\n",
      "cls loss 517.9134521484375  loc loss 40.9041748046875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  2.,  1.,  1.,  1., 38.,\n",
      "         1.,  1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 38., 38., 38.,  1., 38., 38., 38.,  1.,  1., 38.,  1.,\n",
      "         1.])\n",
      "cls loss 306.0281982421875  loc loss 23.91328239440918\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  8.,  8.])\n",
      "cls loss 748.0542602539062  loc loss 53.168819427490234\n",
      "cls loss 765.3170166015625  loc loss 59.378929138183594\n",
      "cls loss 287.49560546875  loc loss 19.772626876831055\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([4., 1., 1., 4.])\n",
      "cls loss 471.11627197265625  loc loss 30.988712310791016\n",
      "cls loss 561.6785888671875  loc loss 37.939388275146484\n",
      "cls loss 222.27430725097656  loc loss 12.0389404296875\n",
      "cls loss 288.3207092285156  loc loss 19.990367889404297\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([51.,  1.])\n",
      "cls loss 204.22372436523438  loc loss 9.508846282958984\n",
      "cls loss 291.5804748535156  loc loss 17.827617645263672\n",
      "cls loss 563.2117919921875  loc loss 33.58840560913086\n",
      "cls loss 545.566162109375  loc loss 47.458553314208984\n",
      "cls loss 831.3538818359375  loc loss 46.817596435546875\n",
      "cls loss 983.8568115234375  loc loss 69.19294738769531\n",
      "cls loss 392.50567626953125  loc loss 26.775535583496094\n",
      "cls loss 569.5357666015625  loc loss 44.94883346557617\n",
      "cls loss 639.609619140625  loc loss 42.079872131347656\n",
      "cls loss 464.1744079589844  loc loss 29.296607971191406\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  3.,  1.,  1.,  1.,  3.,  1.,  1.,\n",
      "         1.,  1.,  1.])\n",
      "cls loss 513.6122436523438  loc loss 22.696331024169922\n",
      "cls loss 586.240478515625  loc loss 30.72597312927246\n",
      "cls loss 545.3382568359375  loc loss 29.12808609008789\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "cls loss 459.95989990234375  loc loss 27.01080322265625\n",
      "cls loss 250.17642211914062  loc loss 21.330820083618164\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3.])\n",
      "cls loss 198.37442016601562  loc loss 11.25088119506836\n",
      "cls loss 348.5972900390625  loc loss 26.129159927368164\n",
      "cls loss 320.6577453613281  loc loss 23.829368591308594\n",
      "cls loss 594.3963623046875  loc loss 40.9056282043457\n",
      "cls loss 286.2855224609375  loc loss 21.52349281311035\n",
      "cls loss 313.8504638671875  loc loss 24.780139923095703\n",
      "cls loss 925.9773559570312  loc loss 70.54319763183594\n",
      "cls loss 391.66314697265625  loc loss 31.75316619873047\n",
      "cls loss 306.81536865234375  loc loss 23.42766571044922\n",
      "cls loss 368.144775390625  loc loss 21.53726577758789\n",
      "cls loss 339.09820556640625  loc loss 26.05974578857422\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 622.00830078125  loc loss 44.74103546142578\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  9., 64., 64., 64., 64., 64., 64., 64., 64., 64.,  9.,  9.,  9.,\n",
      "         9.])\n",
      "cls loss 302.54168701171875  loc loss 17.302326202392578\n",
      "cls loss 884.02685546875  loc loss 67.21965026855469\n",
      "cls loss 460.5440673828125  loc loss 30.747238159179688\n",
      "cls loss 569.196533203125  loc loss 38.291805267333984\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.,  3.,  3.])\n",
      "cls loss 337.7920227050781  loc loss 20.534446716308594\n",
      "cls loss 377.12506103515625  loc loss 30.315601348876953\n",
      "cls loss 391.17926025390625  loc loss 31.46106719970703\n",
      "cls loss 407.2272033691406  loc loss 31.770477294921875\n",
      "cls loss 449.00750732421875  loc loss 35.217063903808594\n",
      "cls loss 460.2374267578125  loc loss 32.6773567199707\n",
      "cls loss 410.96923828125  loc loss 30.988109588623047\n",
      "cls loss 430.4202575683594  loc loss 24.637149810791016\n",
      "cls loss 545.770751953125  loc loss 37.79384994506836\n",
      "cls loss 399.86187744140625  loc loss 30.809600830078125\n",
      "cls loss 316.92242431640625  loc loss 18.20440673828125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21.])\n",
      "cls loss 256.31744384765625  loc loss 16.902639389038086\n",
      "cls loss 373.37237548828125  loc loss 34.09747314453125\n",
      "cls loss 562.6704711914062  loc loss 42.00938034057617\n",
      "cls loss 298.05731201171875  loc loss 17.856584548950195\n",
      "cls loss 454.9306945800781  loc loss 31.09501838684082\n",
      "cls loss 839.2803344726562  loc loss 44.42926025390625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 42., 42.,  1.,  1.])\n",
      "cls loss 464.42987060546875  loc loss 27.88319206237793\n",
      "cls loss 296.83154296875  loc loss 19.510986328125\n",
      "cls loss 420.66766357421875  loc loss 29.825559616088867\n",
      "cls loss 548.9494018554688  loc loss 46.755680084228516\n",
      "cls loss 352.53143310546875  loc loss 23.42801856994629\n",
      "cls loss 542.9905395507812  loc loss 41.34681701660156\n",
      "cls loss 497.52996826171875  loc loss 38.235816955566406\n",
      "cls loss 478.8734130859375  loc loss 33.09930419921875\n",
      "cls loss 395.3134460449219  loc loss 28.340009689331055\n",
      "cls loss 321.17041015625  loc loss 23.72544288635254\n",
      "cls loss 275.1714172363281  loc loss 13.278036117553711\n",
      "cls loss 398.0369567871094  loc loss 25.522472381591797\n",
      "cls loss 604.047119140625  loc loss 40.70871353149414\n",
      "cls loss 477.0315246582031  loc loss 27.660541534423828\n",
      "cls loss 432.70208740234375  loc loss 31.150724411010742\n",
      "cls loss 487.1522216796875  loc loss 28.6875057220459\n",
      "cls loss 704.445556640625  loc loss 53.565330505371094\n",
      "cls loss 542.217041015625  loc loss 39.487876892089844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 583.9923095703125  loc loss 32.327232360839844\n",
      "cls loss 347.8972473144531  loc loss 17.622819900512695\n",
      "cls loss 488.8055114746094  loc loss 31.631206512451172\n",
      "cls loss 446.84271240234375  loc loss 28.990612030029297\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 5., 5., 5., 5., 5., 5.])\n",
      "cls loss 292.4656982421875  loc loss 20.943191528320312\n",
      "cls loss 376.4763488769531  loc loss 21.620779037475586\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([13.])\n",
      "cls loss 264.93267822265625  loc loss 15.006606101989746\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([44., 10.,  1.,  1.,  1.])\n",
      "cls loss 248.04800415039062  loc loss 16.802892684936523\n",
      "cls loss 440.6044921875  loc loss 25.150497436523438\n",
      "cls loss 406.1939697265625  loc loss 23.07992172241211\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19., 19., 19., 19., 19., 19., 19.])\n",
      "cls loss 441.7217102050781  loc loss 26.855382919311523\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([56.])\n",
      "cls loss 898.0343017578125  loc loss 62.181583404541016\n",
      "cls loss 574.50732421875  loc loss 42.05009460449219\n",
      "cls loss 736.8345336914062  loc loss 47.44602966308594\n",
      "cls loss 712.4163818359375  loc loss 54.571861267089844\n",
      "cls loss 471.81866455078125  loc loss 25.21726417541504\n",
      "cls loss 731.0195922851562  loc loss 47.79753112792969\n",
      "cls loss 412.5856018066406  loc loss 27.91122055053711\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 36.])\n",
      "cls loss 518.5553588867188  loc loss 25.76984405517578\n",
      "cls loss 419.25933837890625  loc loss 28.847089767456055\n",
      "cls loss 398.58013916015625  loc loss 24.26093864440918\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5.])\n",
      "cls loss 447.61773681640625  loc loss 29.236162185668945\n",
      "cls loss 244.21591186523438  loc loss 13.718786239624023\n",
      "cls loss 589.7151489257812  loc loss 33.9121208190918\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "cls loss 515.2041015625  loc loss 35.87974166870117\n",
      "cls loss 487.99969482421875  loc loss 33.03607177734375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 524.030029296875  loc loss 34.67487716674805\n",
      "cls loss 588.652099609375  loc loss 40.896949768066406\n",
      "cls loss 502.120849609375  loc loss 43.35845947265625\n",
      "cls loss 359.0130920410156  loc loss 23.009632110595703\n",
      "cls loss 411.1042175292969  loc loss 29.987611770629883\n",
      "cls loss 445.99993896484375  loc loss 27.152389526367188\n",
      "cls loss 701.3201904296875  loc loss 36.62446594238281\n",
      "cls loss 303.86822509765625  loc loss 14.672650337219238\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 11., 15., 10., 10., 10., 10., 10.])\n",
      "cls loss 663.4893798828125  loc loss 44.101829528808594\n",
      "cls loss 393.11126708984375  loc loss 30.589305877685547\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3.])\n",
      "cls loss 407.919921875  loc loss 30.246540069580078\n",
      "cls loss 375.9267578125  loc loss 20.378782272338867\n",
      "cls loss 422.41455078125  loc loss 20.174861907958984\n",
      "cls loss 527.6275634765625  loc loss 23.72125816345215\n",
      "cls loss 254.76173400878906  loc loss 12.607499122619629\n",
      "cls loss 424.9935302734375  loc loss 28.698482513427734\n",
      "cls loss 489.3003845214844  loc loss 33.37491989135742\n",
      "cls loss 413.3189697265625  loc loss 29.551170349121094\n",
      "cls loss 985.6206665039062  loc loss 67.36309051513672\n",
      "cls loss 660.0670776367188  loc loss 45.83214569091797\n",
      "cls loss 432.64715576171875  loc loss 30.022594451904297\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  9.,  9.,  9.,  6.,  6., 85., 85.,  8.,  1.,  1.,  1.,  1.,\n",
      "         6.,  6.])\n",
      "cls loss 288.2307434082031  loc loss 25.25838851928711\n",
      "cls loss 721.4970703125  loc loss 51.161766052246094\n",
      "cls loss 852.774658203125  loc loss 54.149776458740234\n",
      "cls loss 556.7510986328125  loc loss 39.85234451293945\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10.,  3.,  3., 10.])\n",
      "cls loss 365.7925109863281  loc loss 20.31264305114746\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([7.])\n",
      "cls loss 457.35498046875  loc loss 32.27490234375\n",
      "cls loss 458.2952880859375  loc loss 31.773731231689453\n",
      "cls loss 455.7330322265625  loc loss 38.76122283935547\n",
      "cls loss 684.2697143554688  loc loss 52.7468147277832\n",
      "cls loss 412.4906311035156  loc loss 29.234060287475586\n",
      "cls loss 606.2952880859375  loc loss 42.159156799316406\n",
      "cls loss 784.0885009765625  loc loss 47.79198455810547\n",
      "cls loss 474.91064453125  loc loss 31.15081214904785\n",
      "cls loss 515.7769775390625  loc loss 36.83510208129883\n",
      "cls loss 399.53240966796875  loc loss 30.372024536132812\n",
      "cls loss 635.0210571289062  loc loss 48.26927185058594\n",
      "cls loss 473.172119140625  loc loss 32.49838638305664\n",
      "cls loss 380.4993591308594  loc loss 23.128131866455078\n",
      "cls loss 578.6451416015625  loc loss 43.718162536621094\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([62.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([62.])\n",
      "cls loss 279.8522033691406  loc loss 12.914624214172363\n",
      "cls loss 431.1490478515625  loc loss 33.213523864746094\n",
      "cls loss 424.87860107421875  loc loss 28.115509033203125\n",
      "cls loss 277.203857421875  loc loss 13.938993453979492\n",
      "cls loss 573.8168334960938  loc loss 39.131500244140625\n",
      "cls loss 590.720458984375  loc loss 33.844024658203125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([28.])\n",
      "cls loss 719.2066650390625  loc loss 35.287872314453125\n",
      "cls loss 542.4569091796875  loc loss 35.06336212158203\n",
      "cls loss 544.0861206054688  loc loss 37.27494812011719\n",
      "cls loss 570.6318969726562  loc loss 37.00989532470703\n",
      "cls loss 771.4111328125  loc loss 51.47160720825195\n",
      "cls loss 457.9109802246094  loc loss 29.117408752441406\n",
      "cls loss 593.93701171875  loc loss 33.287132263183594\n",
      "cls loss 481.56341552734375  loc loss 39.05971145629883\n",
      "cls loss 796.6749267578125  loc loss 60.27700424194336\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([81.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 499.5640869140625  loc loss 22.634607315063477\n",
      "cls loss 383.44403076171875  loc loss 20.790647506713867\n",
      "cls loss 285.7911376953125  loc loss 22.297428131103516\n",
      "cls loss 260.6092529296875  loc loss 12.07150650024414\n",
      "cls loss 291.1272888183594  loc loss 25.072994232177734\n",
      "cls loss 360.67327880859375  loc loss 23.059717178344727\n",
      "cls loss 368.43115234375  loc loss 30.756591796875\n",
      "cls loss 527.5853881835938  loc loss 47.15574645996094\n",
      "cls loss 650.7282104492188  loc loss 41.659358978271484\n",
      "cls loss 1114.6669921875  loc loss 79.92626953125\n",
      "cls loss 448.1668701171875  loc loss 22.724899291992188\n",
      "cls loss 551.2279052734375  loc loss 40.199378967285156\n",
      "cls loss 390.4179992675781  loc loss 24.073518753051758\n",
      "cls loss 523.0869750976562  loc loss 31.98564910888672\n",
      "cls loss 438.2457275390625  loc loss 27.420074462890625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([44., 44.])\n",
      "cls loss 384.86029052734375  loc loss 22.640411376953125\n",
      "cls loss 424.3883361816406  loc loss 37.495201110839844\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15.])\n",
      "cls loss 433.53143310546875  loc loss 35.22234344482422\n",
      "cls loss 216.7386474609375  loc loss 17.17038917541504\n",
      "cls loss 441.1033020019531  loc loss 34.1961669921875\n",
      "cls loss 263.6912841796875  loc loss 15.25704288482666\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([1., 3., 3.])\n",
      "cls loss 297.8437805175781  loc loss 19.909530639648438\n",
      "cls loss 219.55686950683594  loc loss 11.670077323913574\n",
      "cls loss 418.2335510253906  loc loss 35.48691177368164\n",
      "cls loss 480.4322509765625  loc loss 33.88275909423828\n",
      "cls loss 428.13690185546875  loc loss 31.498138427734375\n",
      "cls loss 364.7774658203125  loc loss 27.816425323486328\n",
      "cls loss 372.31561279296875  loc loss 31.26181983947754\n",
      "cls loss 504.83880615234375  loc loss 38.587703704833984\n",
      "cls loss 359.1856689453125  loc loss 27.82879066467285\n",
      "cls loss 486.57427978515625  loc loss 40.15237045288086\n",
      "cls loss 334.5320129394531  loc loss 24.314292907714844\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 571.6815185546875  loc loss 41.77476119995117\n",
      "cls loss 688.0382080078125  loc loss 36.89836502075195\n",
      "cls loss 585.3773193359375  loc loss 43.5679817199707\n",
      "cls loss 577.35498046875  loc loss 45.72335433959961\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10., 10., 10.,  1.,  1.,  1.,  1.,  1.,  1.,  8.,  8.,\n",
      "         1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10., 10., 10.,  1.,  1.,  1.,  1.,  1.,  1.,  8.,  8.,\n",
      "         1.])\n",
      "cls loss 479.1330261230469  loc loss 26.310821533203125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 3., 3., 3.])\n",
      "cls loss 452.7735290527344  loc loss 27.75214958190918\n",
      "cls loss 305.1265563964844  loc loss 19.273019790649414\n",
      "cls loss 231.82345581054688  loc loss 15.598297119140625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 432.7022399902344  loc loss 42.16887283325195\n",
      "cls loss 331.73150634765625  loc loss 21.94330596923828\n",
      "cls loss 397.58184814453125  loc loss 35.518558502197266\n",
      "cls loss 449.5319519042969  loc loss 39.98596954345703\n",
      "cls loss 608.0176391601562  loc loss 54.48509979248047\n",
      "cls loss 524.3788452148438  loc loss 34.281578063964844\n",
      "cls loss 485.1068115234375  loc loss 32.685882568359375\n",
      "cls loss 503.56396484375  loc loss 35.38922882080078\n",
      "cls loss 359.6011962890625  loc loss 28.499221801757812\n",
      "cls loss 716.2037353515625  loc loss 53.61631774902344\n",
      "cls loss 326.33807373046875  loc loss 22.807174682617188\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 574.2047119140625  loc loss 38.72910690307617\n",
      "cls loss 261.3050537109375  loc loss 16.896751403808594\n",
      "cls loss 650.727294921875  loc loss 59.69766616821289\n",
      "cls loss 324.35662841796875  loc loss 25.94440269470215\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 34.])\n",
      "cls loss 530.048828125  loc loss 38.79667663574219\n",
      "cls loss 261.1469421386719  loc loss 20.031906127929688\n",
      "cls loss 533.260009765625  loc loss 36.77873992919922\n",
      "cls loss 179.7340850830078  loc loss 16.865678787231445\n",
      "cls loss 431.28118896484375  loc loss 36.822052001953125\n",
      "cls loss 427.53167724609375  loc loss 38.65300750732422\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 38.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16., 16., 16.,  9.,  9.,  9., 16., 16., 16., 85.,  9.])\n",
      "cls loss 442.42626953125  loc loss 31.794574737548828\n",
      "cls loss 482.86767578125  loc loss 41.95766067504883\n",
      "cls loss 646.6029052734375  loc loss 47.79956817626953\n",
      "cls loss 1008.3123779296875  loc loss 65.30809020996094\n",
      "cls loss 273.6427001953125  loc loss 15.498772621154785\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3., 10.,  8.,  8., 10., 10., 10.,  3.,  3., 14.])\n",
      "cls loss 289.9347839355469  loc loss 19.935306549072266\n",
      "cls loss 550.2916259765625  loc loss 39.96826934814453\n",
      "cls loss 247.3206787109375  loc loss 12.299015998840332\n",
      "cls loss 410.25408935546875  loc loss 25.332822799682617\n",
      "cls loss 542.6543579101562  loc loss 42.5119743347168\n",
      "cls loss 462.654296875  loc loss 34.76739501953125\n",
      "cls loss 253.854736328125  loc loss 17.043453216552734\n",
      "cls loss 329.7486267089844  loc loss 19.1103515625\n",
      "cls loss 528.909423828125  loc loss 35.145809173583984\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42., 42.,  1.])\n",
      "cls loss 488.0840759277344  loc loss 33.67326736450195\n",
      "cls loss 368.90155029296875  loc loss 24.51580047607422\n",
      "cls loss 509.09814453125  loc loss 42.18678665161133\n",
      "cls loss 587.9246826171875  loc loss 38.57613754272461\n",
      "cls loss 409.35980224609375  loc loss 27.210494995117188\n",
      "cls loss 502.3475341796875  loc loss 37.37144088745117\n",
      "cls loss 307.27581787109375  loc loss 22.977447509765625\n",
      "cls loss 328.65362548828125  loc loss 24.842451095581055\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20.])\n",
      "cls loss 238.05325317382812  loc loss 15.684566497802734\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([11.])\n",
      "cls loss 340.1974182128906  loc loss 17.378843307495117\n",
      "cls loss 204.32083129882812  loc loss 13.995438575744629\n",
      "cls loss 512.7105712890625  loc loss 41.600643157958984\n",
      "cls loss 227.38546752929688  loc loss 12.13916015625\n",
      "cls loss 500.1215515136719  loc loss 31.185800552368164\n",
      "cls loss 275.8689880371094  loc loss 17.80248260498047\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 35., 27.])\n",
      "cls loss 489.1764221191406  loc loss 29.577428817749023\n",
      "cls loss 534.430419921875  loc loss 41.06190872192383\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 354.2735900878906  loc loss 21.615659713745117\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([42.,  1.])\n",
      "cls loss 439.8778076171875  loc loss 32.955902099609375\n",
      "cls loss 438.6705017089844  loc loss 24.480117797851562\n",
      "cls loss 507.217041015625  loc loss 33.56827926635742\n",
      "cls loss 649.27880859375  loc loss 39.702064514160156\n",
      "cls loss 557.1009521484375  loc loss 35.96269607543945\n",
      "cls loss 375.97735595703125  loc loss 29.834754943847656\n",
      "cls loss 319.55389404296875  loc loss 24.459442138671875\n",
      "cls loss 194.56442260742188  loc loss 9.424192428588867\n",
      "cls loss 379.1854248046875  loc loss 22.41848373413086\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 1., 1.])\n",
      "cls loss 359.5574951171875  loc loss 23.73373031616211\n",
      "cls loss 418.2667541503906  loc loss 28.89547348022461\n",
      "cls loss 406.9205017089844  loc loss 27.316761016845703\n",
      "cls loss 333.4560241699219  loc loss 25.2005672454834\n",
      "cls loss 409.2275695800781  loc loss 28.41698455810547\n",
      "cls loss 446.05609130859375  loc loss 32.397945404052734\n",
      "cls loss 636.1994018554688  loc loss 39.31026840209961\n",
      "cls loss 542.1947021484375  loc loss 42.909584045410156\n",
      "cls loss 481.97735595703125  loc loss 33.034000396728516\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 371.89794921875  loc loss 30.34428596496582\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 479.4022216796875  loc loss 21.61823081970215\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([81.])\n",
      "cls loss 554.4979248046875  loc loss 35.326416015625\n",
      "cls loss 330.25775146484375  loc loss 24.58639907836914\n",
      "cls loss 241.2720947265625  loc loss 14.007255554199219\n",
      "cls loss 368.3546142578125  loc loss 20.687761306762695\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3.,  1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 19.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 19.])\n",
      "cls loss 511.8860778808594  loc loss 36.68085861206055\n",
      "cls loss 283.5791015625  loc loss 16.73842430114746\n",
      "cls loss 305.8541564941406  loc loss 19.535348892211914\n",
      "cls loss 595.0546875  loc loss 46.84442138671875\n",
      "cls loss 292.9748840332031  loc loss 20.45093536376953\n",
      "cls loss 381.3397216796875  loc loss 24.876352310180664\n",
      "cls loss 481.52606201171875  loc loss 34.53232955932617\n",
      "cls loss 363.5189208984375  loc loss 26.545015335083008\n",
      "cls loss 473.14129638671875  loc loss 27.07206916809082\n",
      "cls loss 550.7628784179688  loc loss 35.94293975830078\n",
      "cls loss 679.420166015625  loc loss 58.720001220703125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 81.])\n",
      "cls loss 468.15093994140625  loc loss 24.36320686340332\n",
      "cls loss 415.8619384765625  loc loss 23.772714614868164\n",
      "cls loss 428.46173095703125  loc loss 24.263324737548828\n",
      "cls loss 331.73974609375  loc loss 17.96625518798828\n",
      "cls loss 289.6766357421875  loc loss 19.779884338378906\n",
      "cls loss 322.80078125  loc loss 27.790302276611328\n",
      "cls loss 252.4267120361328  loc loss 21.15276336669922\n",
      "cls loss 221.92112731933594  loc loss 17.700098037719727\n",
      "cls loss 299.95867919921875  loc loss 22.33180046081543\n",
      "cls loss 404.18927001953125  loc loss 29.851266860961914\n",
      "cls loss 360.30010986328125  loc loss 29.832468032836914\n",
      "cls loss 378.31610107421875  loc loss 27.556407928466797\n",
      "cls loss 223.31982421875  loc loss 15.831430435180664\n",
      "cls loss 781.3406982421875  loc loss 53.298927307128906\n",
      "cls loss 442.49853515625  loc loss 31.95220947265625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 406.6006164550781  loc loss 21.30340003967285\n",
      "cls loss 474.3671875  loc loss 31.31283187866211\n",
      "cls loss 370.574951171875  loc loss 22.87848472595215\n",
      "cls loss 569.8037719726562  loc loss 39.47157669067383\n",
      "cls loss 517.817626953125  loc loss 33.97317886352539\n",
      "cls loss 476.1186218261719  loc loss 31.513755798339844\n",
      "cls loss 347.670654296875  loc loss 25.041271209716797\n",
      "cls loss 287.9382019042969  loc loss 19.168190002441406\n",
      "cls loss 417.01025390625  loc loss 28.814258575439453\n",
      "cls loss 476.9979248046875  loc loss 34.304595947265625\n",
      "cls loss 455.373779296875  loc loss 27.226917266845703\n",
      "cls loss 578.6456909179688  loc loss 41.343379974365234\n",
      "cls loss 610.4580688476562  loc loss 48.068294525146484\n",
      "cls loss 429.8511047363281  loc loss 31.288097381591797\n",
      "cls loss 621.5234375  loc loss 50.85109329223633\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1., 38., 47.,  1.,  1.,  1.,  1.,  1., 62.])\n",
      "cls loss 410.4522705078125  loc loss 21.570581436157227\n",
      "cls loss 489.0918884277344  loc loss 35.64643478393555\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 546.794921875  loc loss 33.035160064697266\n",
      "cls loss 576.7762451171875  loc loss 43.21385192871094\n",
      "cls loss 396.3096923828125  loc loss 20.823400497436523\n",
      "cls loss 467.7275390625  loc loss 40.30879592895508\n",
      "cls loss 442.158447265625  loc loss 28.868331909179688\n",
      "cls loss 249.94161987304688  loc loss 11.771259307861328\n",
      "cls loss 370.96142578125  loc loss 23.574634552001953\n",
      "cls loss 309.74395751953125  loc loss 14.81750202178955\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1., 35.])\n",
      "cls loss 342.7189025878906  loc loss 20.504121780395508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 544.8864135742188  loc loss 28.5069637298584\n",
      "cls loss 530.5615234375  loc loss 34.74816131591797\n",
      "cls loss 473.2306213378906  loc loss 42.536834716796875\n",
      "cls loss 380.18017578125  loc loss 31.102582931518555\n",
      "cls loss 517.0849609375  loc loss 42.26898193359375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 285.87518310546875  loc loss 19.010364532470703\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 425.0609130859375  loc loss 19.576929092407227\n",
      "cls loss 679.220458984375  loc loss 42.78186798095703\n",
      "cls loss 809.9564208984375  loc loss 63.45895004272461\n",
      "cls loss 416.931884765625  loc loss 22.841611862182617\n",
      "cls loss 359.293212890625  loc loss 22.410560607910156\n",
      "cls loss 374.7362976074219  loc loss 20.892202377319336\n",
      "cls loss 390.19671630859375  loc loss 26.81938362121582\n",
      "cls loss 336.37835693359375  loc loss 16.839923858642578\n",
      "cls loss 614.0604248046875  loc loss 47.74717330932617\n",
      "cls loss 523.2677001953125  loc loss 33.587303161621094\n",
      "cls loss 230.4058380126953  loc loss 18.242753982543945\n",
      "cls loss 491.58868408203125  loc loss 29.772172927856445\n",
      "cls loss 604.3252563476562  loc loss 48.994380950927734\n",
      "cls loss 472.3916320800781  loc loss 32.77560806274414\n",
      "cls loss 397.992919921875  loc loss 27.205089569091797\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.])\n",
      "cls loss 397.4984436035156  loc loss 29.639270782470703\n",
      "cls loss 403.7539367675781  loc loss 27.732891082763672\n",
      "cls loss 511.58880615234375  loc loss 34.38743591308594\n",
      "cls loss 824.0760498046875  loc loss 65.73899841308594\n",
      "cls loss 322.50933837890625  loc loss 17.143476486206055\n",
      "cls loss 418.30126953125  loc loss 24.620582580566406\n",
      "cls loss 339.1178894042969  loc loss 21.044179916381836\n",
      "cls loss 360.3872375488281  loc loss 25.723350524902344\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 21., 21., 21.])\n",
      "cls loss 378.58258056640625  loc loss 24.492868423461914\n",
      "cls loss 362.8039245605469  loc loss 21.227123260498047\n",
      "cls loss 383.34619140625  loc loss 28.388696670532227\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 35.])\n",
      "cls loss 505.4835205078125  loc loss 34.909358978271484\n",
      "cls loss 190.88314819335938  loc loss 11.014826774597168\n",
      "cls loss 332.4243469238281  loc loss 23.447887420654297\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 308.9597473144531  loc loss 15.79019832611084\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 38., 38.,  9., 38.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1.,  1.])\n",
      "cls loss 358.7174072265625  loc loss 23.02939224243164\n",
      "cls loss 586.735595703125  loc loss 37.90416717529297\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 2.,  1., 77., 31., 10., 10.,  1.,  4., 10.])\n",
      "cls loss 280.92987060546875  loc loss 13.067428588867188\n",
      "cls loss 537.522216796875  loc loss 33.790435791015625\n",
      "cls loss 1117.909912109375  loc loss 64.02449798583984\n",
      "cls loss 334.97344970703125  loc loss 23.990827560424805\n",
      "cls loss 473.2418212890625  loc loss 35.756378173828125\n",
      "cls loss 340.4718017578125  loc loss 18.097360610961914\n",
      "cls loss 327.20587158203125  loc loss 16.64517593383789\n",
      "cls loss 471.8155212402344  loc loss 25.67622947692871\n",
      "cls loss 480.9154968261719  loc loss 27.15851593017578\n",
      "cls loss 430.74090576171875  loc loss 31.183000564575195\n",
      "cls loss 359.20355224609375  loc loss 16.77422332763672\n",
      "cls loss 358.96014404296875  loc loss 21.1101131439209\n",
      "cls loss 667.32666015625  loc loss 43.694801330566406\n",
      "cls loss 620.9144287109375  loc loss 38.8273811340332\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1., 42., 42., 42., 42., 42., 42.,  1.,\n",
      "         1.,  1.,  1., 42.,  1.,  1., 42.,  1.])\n",
      "cls loss 344.0504150390625  loc loss 24.59007453918457\n",
      "cls loss 514.189697265625  loc loss 30.49323081970215\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.])\n",
      "cls loss 224.5922088623047  loc loss 12.77108383178711\n",
      "cls loss 519.0062255859375  loc loss 32.7198486328125\n",
      "cls loss 381.8047790527344  loc loss 28.27237319946289\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([11.])\n",
      "cls loss 236.25579833984375  loc loss 16.101675033569336\n",
      "cls loss 268.3822326660156  loc loss 15.215173721313477\n",
      "cls loss 292.8935852050781  loc loss 14.699023246765137\n",
      "cls loss 513.26611328125  loc loss 31.751827239990234\n",
      "cls loss 405.28082275390625  loc loss 25.185028076171875\n",
      "cls loss 442.9788818359375  loc loss 28.714500427246094\n",
      "cls loss 623.2882690429688  loc loss 33.105857849121094\n",
      "cls loss 329.3727111816406  loc loss 18.859333038330078\n",
      "cls loss 693.2243041992188  loc loss 45.029319763183594\n",
      "cls loss 330.94512939453125  loc loss 20.679996490478516\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 305.36688232421875  loc loss 19.036544799804688\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1., 38., 38., 42.])\n",
      "cls loss 402.2234802246094  loc loss 27.833053588867188\n",
      "cls loss 366.5375061035156  loc loss 21.276044845581055\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 323.0572509765625  loc loss 21.920265197753906\n",
      "cls loss 723.8159790039062  loc loss 49.64241409301758\n",
      "cls loss 443.30291748046875  loc loss 28.367053985595703\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10.,  3.,  3.,  6.,  8.,  8.,  1.,  1.,  1., 10.])\n",
      "cls loss 344.3002014160156  loc loss 18.370677947998047\n",
      "cls loss 223.04058837890625  loc loss 8.869684219360352\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10.,  3.])\n",
      "cls loss 322.7578125  loc loss 19.181766510009766\n",
      "cls loss 161.2763671875  loc loss 10.30659294128418\n",
      "cls loss 412.78656005859375  loc loss 31.712318420410156\n",
      "cls loss 503.7232971191406  loc loss 32.30913162231445\n",
      "cls loss 359.1064453125  loc loss 21.641544342041016\n",
      "cls loss 234.5491943359375  loc loss 14.223429679870605\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 34.])\n",
      "cls loss 596.0952758789062  loc loss 38.385520935058594\n",
      "cls loss 689.8316040039062  loc loss 52.98553466796875\n",
      "cls loss 445.37872314453125  loc loss 30.767244338989258\n",
      "cls loss 356.1990966796875  loc loss 24.84786033630371\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.,  1.])\n",
      "cls loss 382.5095520019531  loc loss 16.840206146240234\n",
      "cls loss 602.60888671875  loc loss 44.606197357177734\n",
      "cls loss 857.3372802734375  loc loss 55.50551223754883\n",
      "cls loss 703.0575561523438  loc loss 37.14265823364258\n",
      "cls loss 410.0130615234375  loc loss 22.56965446472168\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 464.88751220703125  loc loss 28.160959243774414\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10.])\n",
      "cls loss 291.228271484375  loc loss 16.091259002685547\n",
      "cls loss 434.1128845214844  loc loss 21.692419052124023\n",
      "cls loss 408.5511474609375  loc loss 25.129253387451172\n",
      "cls loss 280.1356201171875  loc loss 17.169246673583984\n",
      "cls loss 384.21539306640625  loc loss 24.789995193481445\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21.,\n",
      "        21.])\n",
      "cls loss 473.4626159667969  loc loss 29.350414276123047\n",
      "cls loss 401.85064697265625  loc loss 24.774417877197266\n",
      "cls loss 266.8524169921875  loc loss 12.469894409179688\n",
      "cls loss 589.7484741210938  loc loss 36.620567321777344\n",
      "cls loss 438.97174072265625  loc loss 29.310073852539062\n",
      "cls loss 340.8572998046875  loc loss 17.26100730895996\n",
      "cls loss 663.4653930664062  loc loss 41.68501663208008\n",
      "cls loss 768.7523193359375  loc loss 55.89879608154297\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15., 85.])\n",
      "cls loss 508.63092041015625  loc loss 31.25115203857422\n",
      "cls loss 492.45159912109375  loc loss 37.798187255859375\n",
      "cls loss 506.0589294433594  loc loss 36.35875701904297\n",
      "cls loss 418.76971435546875  loc loss 27.524002075195312\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 8., 8.])\n",
      "cls loss 284.0498046875  loc loss 12.899426460266113\n",
      "cls loss 291.4032287597656  loc loss 23.57485008239746\n",
      "cls loss 374.4190673828125  loc loss 24.271997451782227\n",
      "cls loss 325.5677185058594  loc loss 19.932262420654297\n",
      "cls loss 358.05645751953125  loc loss 22.85179901123047\n",
      "cls loss 515.5804443359375  loc loss 32.77155303955078\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1., 35., 27., 27.,  1., 27.,  1.])\n",
      "cls loss 592.5084228515625  loc loss 52.706512451171875\n",
      "cls loss 351.15191650390625  loc loss 23.88401222229004\n",
      "cls loss 383.37994384765625  loc loss 29.35403823852539\n",
      "cls loss 365.55010986328125  loc loss 32.57494354248047\n",
      "cls loss 337.3676452636719  loc loss 22.345632553100586\n",
      "cls loss 374.317138671875  loc loss 27.722400665283203\n",
      "cls loss 384.54620361328125  loc loss 28.24226951599121\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  2.,  2.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  2.,  2.])\n",
      "cls loss 192.57882690429688  loc loss 8.968320846557617\n",
      "cls loss 597.82177734375  loc loss 39.16576385498047\n",
      "cls loss 371.087158203125  loc loss 22.466773986816406\n",
      "cls loss 643.0657958984375  loc loss 53.01243591308594\n",
      "cls loss 247.7262420654297  loc loss 15.596565246582031\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 19., 19., 19., 16.])\n",
      "cls loss 256.29022216796875  loc loss 13.118432998657227\n",
      "cls loss 211.4210662841797  loc loss 9.209298133850098\n",
      "cls loss 355.6524658203125  loc loss 17.36355972290039\n",
      "cls loss 470.8663635253906  loc loss 30.86578369140625\n",
      "cls loss 182.38446044921875  loc loss 15.4453763961792\n",
      "cls loss 517.6327514648438  loc loss 39.41065979003906\n",
      "cls loss 383.4577331542969  loc loss 26.881662368774414\n",
      "cls loss 398.30938720703125  loc loss 25.324228286743164\n",
      "cls loss 515.4076538085938  loc loss 34.00153350830078\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 531.0685424804688  loc loss 26.296432495117188\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 744.791015625  loc loss 64.88951110839844\n",
      "cls loss 964.33154296875  loc loss 92.06058502197266\n",
      "cls loss 494.02789306640625  loc loss 31.187105178833008\n",
      "cls loss 442.32513427734375  loc loss 27.483325958251953\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3.,  3.,  3.,  3.,  3., 10.])\n",
      "cls loss 216.771484375  loc loss 13.629250526428223\n",
      "cls loss 461.57550048828125  loc loss 21.230735778808594\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 1., 1., 1., 3., 3., 3., 3.])\n",
      "cls loss 357.460693359375  loc loss 19.17547607421875\n",
      "cls loss 688.5418701171875  loc loss 41.44245910644531\n",
      "cls loss 548.874267578125  loc loss 35.64195251464844\n",
      "cls loss 347.88897705078125  loc loss 20.05424690246582\n",
      "cls loss 551.750244140625  loc loss 38.65937423706055\n",
      "cls loss 327.9493103027344  loc loss 24.47132682800293\n",
      "cls loss 525.31884765625  loc loss 36.599422454833984\n",
      "cls loss 401.006591796875  loc loss 37.885372161865234\n",
      "cls loss 388.611083984375  loc loss 25.66568374633789\n",
      "cls loss 832.8570556640625  loc loss 66.49070739746094\n",
      "cls loss 548.7862548828125  loc loss 40.07355499267578\n",
      "cls loss 371.8101806640625  loc loss 17.90593719482422\n",
      "cls loss 234.28414916992188  loc loss 10.709433555603027\n",
      "cls loss 288.5628356933594  loc loss 14.820754051208496\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3., 10., 10., 10., 10., 10., 10., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10., 10., 10., 10., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 11., 10., 10., 10., 10., 10.,  3.,  3.,  3.,  3.,  3.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 11., 10., 10., 10., 10., 10.,  3.,  3.,  3.,  3.,  3.])\n",
      "cls loss 230.42828369140625  loc loss 10.997647285461426\n",
      "cls loss 321.6814880371094  loc loss 14.552177429199219\n",
      "cls loss 269.91937255859375  loc loss 16.242145538330078\n",
      "cls loss 275.0316162109375  loc loss 12.47584056854248\n",
      "cls loss 336.76751708984375  loc loss 26.035728454589844\n",
      "cls loss 248.42526245117188  loc loss 10.476842880249023\n",
      "cls loss 507.0375671386719  loc loss 34.57931900024414\n",
      "cls loss 463.0205078125  loc loss 28.205224990844727\n",
      "cls loss 680.0153198242188  loc loss 42.0040168762207\n",
      "cls loss 341.75970458984375  loc loss 24.219453811645508\n",
      "cls loss 596.9249267578125  loc loss 38.15548324584961\n",
      "cls loss 458.93865966796875  loc loss 33.41271209716797\n",
      "cls loss 459.45050048828125  loc loss 30.538360595703125\n",
      "cls loss 446.6854248046875  loc loss 31.860383987426758\n",
      "cls loss 587.7710571289062  loc loss 40.01212692260742\n",
      "cls loss 570.2392578125  loc loss 37.37351989746094\n",
      "cls loss 278.1878662109375  loc loss 15.088623046875\n",
      "cls loss 545.9556884765625  loc loss 37.96366882324219\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 10.,  1., 18.])\n",
      "cls loss 252.26077270507812  loc loss 18.32312774658203\n",
      "cls loss 319.9925842285156  loc loss 14.047082901000977\n",
      "cls loss 575.1048583984375  loc loss 29.022014617919922\n",
      "cls loss 749.7850341796875  loc loss 46.832611083984375\n",
      "cls loss 448.11895751953125  loc loss 30.635435104370117\n",
      "cls loss 655.7847900390625  loc loss 32.99025344848633\n",
      "cls loss 478.8341064453125  loc loss 31.27911376953125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.,  1.,  1.])\n",
      "cls loss 561.658447265625  loc loss 35.56079864501953\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1., 38.,  1.])\n",
      "cls loss 463.59637451171875  loc loss 29.17125701904297\n",
      "cls loss 685.3516235351562  loc loss 55.31119155883789\n",
      "cls loss 373.3114013671875  loc loss 25.989198684692383\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 514.4990234375  loc loss 30.70295524597168\n",
      "cls loss 414.83148193359375  loc loss 27.169830322265625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3., 10.,  8.,  3., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.])\n",
      "cls loss 475.2213134765625  loc loss 29.307506561279297\n",
      "cls loss 318.11761474609375  loc loss 22.05950164794922\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3.,  3., 11.,  3., 10., 10.,  3.,  3., 10.])\n",
      "cls loss 369.9267578125  loc loss 24.00269317626953\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3., 10., 10., 10.])\n",
      "cls loss 414.1538391113281  loc loss 23.10797882080078\n",
      "cls loss 334.5201416015625  loc loss 22.916322708129883\n",
      "cls loss 445.3828125  loc loss 33.68570327758789\n",
      "cls loss 642.6346435546875  loc loss 40.78993606567383\n",
      "cls loss 419.8863220214844  loc loss 30.467697143554688\n",
      "cls loss 325.04058837890625  loc loss 26.952377319335938\n",
      "cls loss 406.7826843261719  loc loss 25.14261245727539\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 9.,  9., 85., 85.])\n",
      "cls loss 327.2755126953125  loc loss 16.973827362060547\n",
      "cls loss 419.37579345703125  loc loss 29.56366729736328\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 644.0914306640625  loc loss 42.1291389465332\n",
      "cls loss 548.2100830078125  loc loss 24.53608512878418\n",
      "cls loss 623.1300659179688  loc loss 46.13568115234375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10., 10., 10., 10.])\n",
      "cls loss 386.81414794921875  loc loss 26.32480239868164\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([13.])\n",
      "cls loss 607.2135620117188  loc loss 52.85536193847656\n",
      "cls loss 174.0493927001953  loc loss 12.025287628173828\n",
      "cls loss 262.67218017578125  loc loss 15.285201072692871\n",
      "cls loss 348.8770751953125  loc loss 24.729042053222656\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19.,  1.,  1.,  1., 19., 19.])\n",
      "cls loss 374.90960693359375  loc loss 28.534135818481445\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 310.0762939453125  loc loss 23.314180374145508\n",
      "cls loss 443.0797119140625  loc loss 35.21800231933594\n",
      "cls loss 346.5179138183594  loc loss 19.090818405151367\n",
      "cls loss 493.6580810546875  loc loss 25.53403091430664\n",
      "cls loss 522.89208984375  loc loss 38.71430969238281\n",
      "cls loss 388.4605712890625  loc loss 24.476736068725586\n",
      "cls loss 622.4879150390625  loc loss 44.06843948364258\n",
      "cls loss 218.21347045898438  loc loss 13.032537460327148\n",
      "cls loss 417.7701721191406  loc loss 36.16150665283203\n",
      "cls loss 330.86083984375  loc loss 21.969993591308594\n",
      "cls loss 365.9415588378906  loc loss 23.24724578857422\n",
      "cls loss 503.5541076660156  loc loss 36.43307876586914\n",
      "cls loss 415.6300048828125  loc loss 22.537336349487305\n",
      "cls loss 589.13818359375  loc loss 44.13190460205078\n",
      "cls loss 385.83746337890625  loc loss 25.394126892089844\n",
      "cls loss 501.2896423339844  loc loss 36.0487060546875\n",
      "cls loss 724.2367553710938  loc loss 47.04824447631836\n",
      "cls loss 382.8180236816406  loc loss 30.361228942871094\n",
      "cls loss 462.9407958984375  loc loss 27.75480079650879\n",
      "cls loss 537.3668823242188  loc loss 44.43516159057617\n",
      "cls loss 623.1928100585938  loc loss 49.73651123046875\n",
      "cls loss 704.315185546875  loc loss 48.086181640625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 5.])\n",
      "cls loss 185.1415557861328  loc loss 10.75704288482666\n",
      "cls loss 260.43646240234375  loc loss 12.418930053710938\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 13.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 6., 8., 8.])\n",
      "cls loss 201.3990478515625  loc loss 11.781011581420898\n",
      "cls loss 268.74639892578125  loc loss 14.942514419555664\n",
      "cls loss 537.7376708984375  loc loss 38.6781005859375\n",
      "cls loss 223.0003662109375  loc loss 13.797134399414062\n",
      "cls loss 462.3879089355469  loc loss 36.796058654785156\n",
      "cls loss 669.0946044921875  loc loss 53.63153839111328\n",
      "cls loss 431.7234802246094  loc loss 32.43450164794922\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([42., 42.,  1.,  1.,  1.,  1.,  1.,  1.,  1., 42., 42.])\n",
      "cls loss 465.9013671875  loc loss 27.000431060791016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 603.9081420898438  loc loss 50.02400207519531\n",
      "cls loss 561.5868530273438  loc loss 38.20907211303711\n",
      "cls loss 358.2784423828125  loc loss 22.237627029418945\n",
      "cls loss 467.3662414550781  loc loss 24.95448875427246\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 674.1328125  loc loss 45.27147674560547\n",
      "cls loss 532.45703125  loc loss 39.609798431396484\n",
      "cls loss 321.0195617675781  loc loss 19.00689697265625\n",
      "cls loss 269.803466796875  loc loss 18.5029354095459\n",
      "cls loss 352.84674072265625  loc loss 26.30729866027832\n",
      "cls loss 504.86529541015625  loc loss 41.05986785888672\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15.])\n",
      "cls loss 244.57305908203125  loc loss 9.445696830749512\n",
      "cls loss 425.62811279296875  loc loss 26.916776657104492\n",
      "cls loss 365.05511474609375  loc loss 25.972909927368164\n",
      "cls loss 665.378662109375  loc loss 45.698280334472656\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19.,  7.])\n",
      "cls loss 321.39599609375  loc loss 19.787363052368164\n",
      "cls loss 679.275634765625  loc loss 50.31180953979492\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 610.08349609375  loc loss 33.11253356933594\n",
      "cls loss 528.9049072265625  loc loss 42.18455505371094\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([38., 38.,  1., 18.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1., 18., 18.,  1.])\n",
      "cls loss 364.3846435546875  loc loss 23.22146224975586\n",
      "cls loss 357.6091613769531  loc loss 22.666934967041016\n",
      "cls loss 695.7214965820312  loc loss 50.72142028808594\n",
      "cls loss 522.5491943359375  loc loss 35.75266647338867\n",
      "cls loss 417.0115051269531  loc loss 28.551122665405273\n",
      "cls loss 279.49786376953125  loc loss 21.39385414123535\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.])\n",
      "cls loss 181.74447631835938  loc loss 8.119813919067383\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([32.])\n",
      "cls loss 441.5028076171875  loc loss 28.00208854675293\n",
      "cls loss 372.783447265625  loc loss 30.248210906982422\n",
      "cls loss 472.61395263671875  loc loss 42.35797882080078\n",
      "cls loss 418.87908935546875  loc loss 33.81781768798828\n",
      "cls loss 351.45147705078125  loc loss 27.48345947265625\n",
      "cls loss 571.4306640625  loc loss 36.00959777832031\n",
      "cls loss 675.102783203125  loc loss 45.073265075683594\n",
      "cls loss 495.446044921875  loc loss 36.097957611083984\n",
      "cls loss 391.843017578125  loc loss 25.807470321655273\n",
      "cls loss 628.9091796875  loc loss 45.03544998168945\n",
      "cls loss 434.33294677734375  loc loss 25.52897071838379\n",
      "cls loss 753.0671997070312  loc loss 56.5047492980957\n",
      "cls loss 501.4564208984375  loc loss 31.322853088378906\n",
      "cls loss 391.6331787109375  loc loss 34.19784164428711\n",
      "cls loss 303.92144775390625  loc loss 17.838245391845703\n",
      "cls loss 340.01666259765625  loc loss 22.08137321472168\n",
      "cls loss 499.6213073730469  loc loss 34.56118392944336\n",
      "cls loss 542.7182006835938  loc loss 38.76481628417969\n",
      "cls loss 309.1241455078125  loc loss 19.862607955932617\n",
      "cls loss 547.5869140625  loc loss 41.3448486328125\n",
      "cls loss 663.613525390625  loc loss 53.818206787109375\n",
      "cls loss 245.2940673828125  loc loss 17.857234954833984\n",
      "cls loss 645.8465576171875  loc loss 55.23584747314453\n",
      "cls loss 487.54412841796875  loc loss 34.97595977783203\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 640.1515502929688  loc loss 53.09610366821289\n",
      "cls loss 298.3731384277344  loc loss 12.382699966430664\n",
      "cls loss 454.83856201171875  loc loss 24.096187591552734\n",
      "cls loss 463.748291015625  loc loss 30.530643463134766\n",
      "cls loss 373.9399719238281  loc loss 24.608318328857422\n",
      "cls loss 207.82278442382812  loc loss 13.050293922424316\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 9., 9., 1., 9., 9., 9., 9., 1., 9.])\n",
      "cls loss 847.6043090820312  loc loss 79.97566223144531\n",
      "cls loss 470.11529541015625  loc loss 37.013668060302734\n",
      "cls loss 720.9234619140625  loc loss 64.33131408691406\n",
      "cls loss 295.8668212890625  loc loss 24.197738647460938\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 42., 42.])\n",
      "cls loss 494.47186279296875  loc loss 40.13755798339844\n",
      "cls loss 512.2398071289062  loc loss 40.24415969848633\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  2.,  1.,  1.,  1., 38.,\n",
      "         1.,  1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 38., 38., 38.,  1., 38., 38., 38.,  1.,  1., 38.,  1.,\n",
      "         1.])\n",
      "cls loss 299.47918701171875  loc loss 24.075868606567383\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  8.,  8.])\n",
      "cls loss 730.7293701171875  loc loss 55.52378463745117\n",
      "cls loss 749.0264892578125  loc loss 61.364410400390625\n",
      "cls loss 280.9025573730469  loc loss 20.347145080566406\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([4., 1., 1., 4.])\n",
      "cls loss 468.01776123046875  loc loss 29.554872512817383\n",
      "cls loss 560.3397216796875  loc loss 38.48398208618164\n",
      "cls loss 220.7895050048828  loc loss 12.202180862426758\n",
      "cls loss 285.303955078125  loc loss 19.659503936767578\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([51.,  1.])\n",
      "cls loss 200.1772918701172  loc loss 10.066734313964844\n",
      "cls loss 285.98504638671875  loc loss 19.036487579345703\n",
      "cls loss 563.6236572265625  loc loss 33.71171188354492\n",
      "cls loss 538.550048828125  loc loss 46.937320709228516\n",
      "cls loss 829.819580078125  loc loss 46.594261169433594\n",
      "cls loss 973.29736328125  loc loss 72.95413208007812\n",
      "cls loss 386.768798828125  loc loss 29.02225112915039\n",
      "cls loss 560.5267333984375  loc loss 46.76080322265625\n",
      "cls loss 634.394287109375  loc loss 47.212127685546875\n",
      "cls loss 452.2190856933594  loc loss 29.55797576904297\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  3.,  1.,  1.,  1.,  3.,  1.,  1.,\n",
      "         1.,  1.,  1.])\n",
      "cls loss 501.0218811035156  loc loss 22.877239227294922\n",
      "cls loss 569.2763671875  loc loss 31.04692840576172\n",
      "cls loss 537.30712890625  loc loss 28.09418487548828\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "cls loss 456.8414306640625  loc loss 25.988828659057617\n",
      "cls loss 251.09031677246094  loc loss 20.713088989257812\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3.])\n",
      "cls loss 201.30711364746094  loc loss 12.263019561767578\n",
      "cls loss 346.1461181640625  loc loss 28.592161178588867\n",
      "cls loss 323.75946044921875  loc loss 27.151477813720703\n",
      "cls loss 589.8814086914062  loc loss 47.3624267578125\n",
      "cls loss 279.4836120605469  loc loss 23.834108352661133\n",
      "cls loss 310.359619140625  loc loss 27.035917282104492\n",
      "cls loss 911.924560546875  loc loss 71.28472900390625\n",
      "cls loss 387.27679443359375  loc loss 31.24421501159668\n",
      "cls loss 300.27252197265625  loc loss 21.98016357421875\n",
      "cls loss 358.87164306640625  loc loss 20.774593353271484\n",
      "cls loss 329.1016540527344  loc loss 25.93143081665039\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 609.6997680664062  loc loss 45.63273239135742\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  9., 64., 64., 64., 64., 64., 64., 64., 64., 64.,  9.,  9.,  9.,\n",
      "         9.])\n",
      "cls loss 294.1859130859375  loc loss 15.996423721313477\n",
      "cls loss 877.302001953125  loc loss 75.75678253173828\n",
      "cls loss 456.36968994140625  loc loss 32.61974334716797\n",
      "cls loss 564.1365966796875  loc loss 43.987030029296875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.,  3.,  3.])\n",
      "cls loss 333.06158447265625  loc loss 22.020465850830078\n",
      "cls loss 375.2400817871094  loc loss 29.768705368041992\n",
      "cls loss 392.004638671875  loc loss 30.773292541503906\n",
      "cls loss 408.36553955078125  loc loss 29.284942626953125\n",
      "cls loss 453.9600830078125  loc loss 33.63169479370117\n",
      "cls loss 457.3662414550781  loc loss 33.94173049926758\n",
      "cls loss 407.3453674316406  loc loss 33.46681213378906\n",
      "cls loss 424.31988525390625  loc loss 26.520994186401367\n",
      "cls loss 538.68603515625  loc loss 39.78907775878906\n",
      "cls loss 396.19366455078125  loc loss 26.00198745727539\n",
      "cls loss 310.65087890625  loc loss 19.896240234375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21.])\n",
      "cls loss 251.002685546875  loc loss 17.123703002929688\n",
      "cls loss 364.6838684082031  loc loss 33.35572814941406\n",
      "cls loss 552.1478271484375  loc loss 40.83663558959961\n",
      "cls loss 293.9693603515625  loc loss 19.759397506713867\n",
      "cls loss 453.75  loc loss 32.25048828125\n",
      "cls loss 831.5618896484375  loc loss 46.486202239990234\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 42., 42.,  1.,  1.])\n",
      "cls loss 468.87060546875  loc loss 26.702350616455078\n",
      "cls loss 298.6851501464844  loc loss 19.754676818847656\n",
      "cls loss 421.62591552734375  loc loss 28.315492630004883\n",
      "cls loss 546.139404296875  loc loss 44.2860107421875\n",
      "cls loss 348.21807861328125  loc loss 22.319005966186523\n",
      "cls loss 537.1609497070312  loc loss 41.07099914550781\n",
      "cls loss 490.0112609863281  loc loss 37.452964782714844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 471.29541015625  loc loss 30.846332550048828\n",
      "cls loss 389.0854797363281  loc loss 27.07845115661621\n",
      "cls loss 315.28448486328125  loc loss 23.343721389770508\n",
      "cls loss 268.1016540527344  loc loss 13.628657341003418\n",
      "cls loss 393.04132080078125  loc loss 25.898801803588867\n",
      "cls loss 596.47119140625  loc loss 42.52888870239258\n",
      "cls loss 472.17156982421875  loc loss 26.462661743164062\n",
      "cls loss 429.197021484375  loc loss 32.24032211303711\n",
      "cls loss 482.0400390625  loc loss 29.163482666015625\n",
      "cls loss 699.2569580078125  loc loss 51.707603454589844\n",
      "cls loss 542.7972412109375  loc loss 36.51005935668945\n",
      "cls loss 582.0965576171875  loc loss 33.318885803222656\n",
      "cls loss 349.9939270019531  loc loss 17.015403747558594\n",
      "cls loss 486.79254150390625  loc loss 31.74848175048828\n",
      "cls loss 442.6189270019531  loc loss 29.62150764465332\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 5., 5., 5., 5., 5., 5.])\n",
      "cls loss 287.554443359375  loc loss 20.125062942504883\n",
      "cls loss 370.2003173828125  loc loss 22.104782104492188\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([13.])\n",
      "cls loss 260.65338134765625  loc loss 15.216360092163086\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([44., 10.,  1.,  1.,  1.])\n",
      "cls loss 245.28326416015625  loc loss 17.966184616088867\n",
      "cls loss 433.6654357910156  loc loss 26.917123794555664\n",
      "cls loss 401.47906494140625  loc loss 22.803741455078125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19., 19., 19., 19., 19., 19., 19.])\n",
      "cls loss 430.6295471191406  loc loss 27.416507720947266\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([56.])\n",
      "cls loss 884.344482421875  loc loss 61.668819427490234\n",
      "cls loss 568.2072143554688  loc loss 44.17751693725586\n",
      "cls loss 729.4068603515625  loc loss 46.95329666137695\n",
      "cls loss 707.4656982421875  loc loss 54.09344482421875\n",
      "cls loss 474.77935791015625  loc loss 24.893810272216797\n",
      "cls loss 731.055908203125  loc loss 47.48944854736328\n",
      "cls loss 414.26434326171875  loc loss 28.387042999267578\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 36.])\n",
      "cls loss 518.4747314453125  loc loss 26.801788330078125\n",
      "cls loss 413.6895751953125  loc loss 29.62990379333496\n",
      "cls loss 392.183349609375  loc loss 27.805437088012695\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5.])\n",
      "cls loss 440.36773681640625  loc loss 29.700790405273438\n",
      "cls loss 239.64053344726562  loc loss 13.382560729980469\n",
      "cls loss 579.1110229492188  loc loss 36.06781005859375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "cls loss 509.4272766113281  loc loss 33.73563003540039\n",
      "cls loss 481.810546875  loc loss 33.10281753540039\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 518.619873046875  loc loss 34.5928955078125\n",
      "cls loss 581.68408203125  loc loss 40.777034759521484\n",
      "cls loss 496.71380615234375  loc loss 44.45923614501953\n",
      "cls loss 356.5919494628906  loc loss 23.398555755615234\n",
      "cls loss 407.8570556640625  loc loss 31.05958366394043\n",
      "cls loss 444.82830810546875  loc loss 25.556838989257812\n",
      "cls loss 695.843505859375  loc loss 36.61359405517578\n",
      "cls loss 300.7301025390625  loc loss 14.798083305358887\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 11., 15., 10., 10., 10., 10., 10.])\n",
      "cls loss 655.6431884765625  loc loss 43.63252258300781\n",
      "cls loss 389.47332763671875  loc loss 29.500761032104492\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3.])\n",
      "cls loss 401.6332092285156  loc loss 29.542837142944336\n",
      "cls loss 370.9340515136719  loc loss 21.25884437561035\n",
      "cls loss 416.1094970703125  loc loss 21.02687644958496\n",
      "cls loss 520.4943237304688  loc loss 24.464622497558594\n",
      "cls loss 249.68173217773438  loc loss 12.326498031616211\n",
      "cls loss 416.9737243652344  loc loss 29.27356719970703\n",
      "cls loss 486.5449523925781  loc loss 33.088531494140625\n",
      "cls loss 408.0787353515625  loc loss 28.985355377197266\n",
      "cls loss 976.2407836914062  loc loss 68.79411315917969\n",
      "cls loss 652.0469970703125  loc loss 45.35403060913086\n",
      "cls loss 426.36724853515625  loc loss 29.96314239501953\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  9.,  9.,  9.,  6.,  6., 85., 85.,  8.,  1.,  1.,  1.,  1.,\n",
      "         6.,  6.])\n",
      "cls loss 285.376708984375  loc loss 24.069969177246094\n",
      "cls loss 716.795166015625  loc loss 51.85486602783203\n",
      "cls loss 845.88134765625  loc loss 54.021507263183594\n",
      "cls loss 550.714111328125  loc loss 39.263816833496094\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10.,  3.,  3., 10.])\n",
      "cls loss 359.48980712890625  loc loss 19.56371307373047\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([7.])\n",
      "cls loss 453.4503173828125  loc loss 31.43704605102539\n",
      "cls loss 450.79083251953125  loc loss 29.896194458007812\n",
      "cls loss 450.0409240722656  loc loss 39.269107818603516\n",
      "cls loss 680.8531494140625  loc loss 52.10459518432617\n",
      "cls loss 406.41387939453125  loc loss 29.423913955688477\n",
      "cls loss 598.7249145507812  loc loss 43.66259765625\n",
      "cls loss 776.5113525390625  loc loss 49.04423522949219\n",
      "cls loss 470.67706298828125  loc loss 31.099334716796875\n",
      "cls loss 512.9576416015625  loc loss 36.01774215698242\n",
      "cls loss 394.8492736816406  loc loss 30.581478118896484\n",
      "cls loss 628.5355224609375  loc loss 46.780784606933594\n",
      "cls loss 468.38037109375  loc loss 32.68818283081055\n",
      "cls loss 374.5218505859375  loc loss 23.665245056152344\n",
      "cls loss 571.288330078125  loc loss 45.36579132080078\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([62.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([62.])\n",
      "cls loss 275.7838439941406  loc loss 12.91656494140625\n",
      "cls loss 423.9313659667969  loc loss 34.0119514465332\n",
      "cls loss 419.3784484863281  loc loss 28.512794494628906\n",
      "cls loss 272.4620361328125  loc loss 15.408467292785645\n",
      "cls loss 571.4097290039062  loc loss 38.458953857421875\n",
      "cls loss 583.3525390625  loc loss 32.43497848510742\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([28.])\n",
      "cls loss 714.713623046875  loc loss 33.949920654296875\n",
      "cls loss 533.69970703125  loc loss 34.94683074951172\n",
      "cls loss 535.2958374023438  loc loss 38.686607360839844\n",
      "cls loss 565.4224243164062  loc loss 38.225250244140625\n",
      "cls loss 762.7857666015625  loc loss 54.82442855834961\n",
      "cls loss 453.4378662109375  loc loss 28.683500289916992\n",
      "cls loss 591.704833984375  loc loss 33.28378677368164\n",
      "cls loss 478.10614013671875  loc loss 38.928977966308594\n",
      "cls loss 792.819580078125  loc loss 59.768760681152344\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([81.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 491.5351257324219  loc loss 21.485671997070312\n",
      "cls loss 380.10418701171875  loc loss 20.847553253173828\n",
      "cls loss 282.02294921875  loc loss 21.436214447021484\n",
      "cls loss 256.8392639160156  loc loss 11.68626880645752\n",
      "cls loss 286.40997314453125  loc loss 23.90407943725586\n",
      "cls loss 357.79949951171875  loc loss 24.945938110351562\n",
      "cls loss 361.95452880859375  loc loss 30.513036727905273\n",
      "cls loss 521.276123046875  loc loss 47.7476806640625\n",
      "cls loss 646.3887939453125  loc loss 41.48431396484375\n",
      "cls loss 1099.991455078125  loc loss 76.90809631347656\n",
      "cls loss 441.8893737792969  loc loss 21.977323532104492\n",
      "cls loss 544.902099609375  loc loss 40.37804412841797\n",
      "cls loss 384.6160583496094  loc loss 24.981220245361328\n",
      "cls loss 513.6915893554688  loc loss 31.684661865234375\n",
      "cls loss 432.303466796875  loc loss 26.690261840820312\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([44., 44.])\n",
      "cls loss 378.2020263671875  loc loss 21.720396041870117\n",
      "cls loss 419.5846252441406  loc loss 32.206729888916016\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15.])\n",
      "cls loss 425.7596435546875  loc loss 31.399198532104492\n",
      "cls loss 215.35655212402344  loc loss 16.20340919494629\n",
      "cls loss 435.165771484375  loc loss 32.798492431640625\n",
      "cls loss 262.1118469238281  loc loss 16.377561569213867\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([1., 3., 3.])\n",
      "cls loss 294.69580078125  loc loss 20.982633590698242\n",
      "cls loss 216.28567504882812  loc loss 12.011346817016602\n",
      "cls loss 410.248046875  loc loss 30.63506317138672\n",
      "cls loss 475.07757568359375  loc loss 31.256471633911133\n",
      "cls loss 421.6947021484375  loc loss 29.303926467895508\n",
      "cls loss 359.5028076171875  loc loss 24.61667251586914\n",
      "cls loss 369.0545349121094  loc loss 29.766828536987305\n",
      "cls loss 498.7889099121094  loc loss 35.45123291015625\n",
      "cls loss 353.62451171875  loc loss 25.09969139099121\n",
      "cls loss 478.5789794921875  loc loss 37.06906509399414\n",
      "cls loss 331.53424072265625  loc loss 23.321422576904297\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 566.3431396484375  loc loss 37.36450958251953\n",
      "cls loss 681.9280395507812  loc loss 36.51978302001953\n",
      "cls loss 579.7869262695312  loc loss 44.160091400146484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 570.7147216796875  loc loss 47.0432014465332\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10., 10., 10.,  1.,  1.,  1.,  1.,  1.,  1.,  8.,  8.,\n",
      "         1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10., 10., 10.,  1.,  1.,  1.,  1.,  1.,  1.,  8.,  8.,\n",
      "         1.])\n",
      "cls loss 470.4408264160156  loc loss 25.387882232666016\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 3., 3., 3.])\n",
      "cls loss 449.5094909667969  loc loss 27.927852630615234\n",
      "cls loss 300.14892578125  loc loss 18.638320922851562\n",
      "cls loss 227.2685089111328  loc loss 12.700904846191406\n",
      "cls loss 428.2205505371094  loc loss 37.06515121459961\n",
      "cls loss 326.60015869140625  loc loss 19.05990982055664\n",
      "cls loss 394.4469909667969  loc loss 32.49827575683594\n",
      "cls loss 445.74371337890625  loc loss 35.0601692199707\n",
      "cls loss 600.4901123046875  loc loss 53.043304443359375\n",
      "cls loss 519.4395751953125  loc loss 31.72745132446289\n",
      "cls loss 479.4103698730469  loc loss 31.510738372802734\n",
      "cls loss 498.1248779296875  loc loss 34.6002311706543\n",
      "cls loss 354.76910400390625  loc loss 28.841970443725586\n",
      "cls loss 710.2840576171875  loc loss 53.5211067199707\n",
      "cls loss 321.3461608886719  loc loss 19.25570297241211\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 570.4317626953125  loc loss 34.656436920166016\n",
      "cls loss 257.7232360839844  loc loss 13.945178031921387\n",
      "cls loss 640.793701171875  loc loss 53.619239807128906\n",
      "cls loss 319.88043212890625  loc loss 24.51996612548828\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 34.])\n",
      "cls loss 522.4785766601562  loc loss 39.296905517578125\n",
      "cls loss 257.91107177734375  loc loss 19.751893997192383\n",
      "cls loss 529.7760009765625  loc loss 35.83872985839844\n",
      "cls loss 179.0072021484375  loc loss 15.326749801635742\n",
      "cls loss 426.33709716796875  loc loss 32.64693832397461\n",
      "cls loss 423.69427490234375  loc loss 35.52952575683594\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 38.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16., 16., 16.,  9.,  9.,  9., 16., 16., 16., 85.,  9.])\n",
      "cls loss 437.6679382324219  loc loss 28.95889663696289\n",
      "cls loss 477.10052490234375  loc loss 37.37206268310547\n",
      "cls loss 639.20166015625  loc loss 43.75869369506836\n",
      "cls loss 999.3812255859375  loc loss 63.8674201965332\n",
      "cls loss 268.9625244140625  loc loss 14.39997386932373\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3., 10.,  8.,  8., 10., 10., 10.,  3.,  3., 14.])\n",
      "cls loss 285.4056396484375  loc loss 17.534595489501953\n",
      "cls loss 540.155517578125  loc loss 35.50402069091797\n",
      "cls loss 241.5886993408203  loc loss 10.231573104858398\n",
      "cls loss 404.97686767578125  loc loss 18.74675941467285\n",
      "cls loss 537.240234375  loc loss 38.01622772216797\n",
      "cls loss 457.83856201171875  loc loss 32.39442825317383\n",
      "cls loss 251.2474822998047  loc loss 16.512327194213867\n",
      "cls loss 329.40740966796875  loc loss 18.7097225189209\n",
      "cls loss 529.0614624023438  loc loss 33.045108795166016\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42., 42.,  1.])\n",
      "cls loss 483.552490234375  loc loss 33.71000289916992\n",
      "cls loss 366.44427490234375  loc loss 23.582111358642578\n",
      "cls loss 504.3810729980469  loc loss 41.213035583496094\n",
      "cls loss 580.89013671875  loc loss 35.73701477050781\n",
      "cls loss 405.7522277832031  loc loss 26.012279510498047\n",
      "cls loss 497.6448974609375  loc loss 35.7350959777832\n",
      "cls loss 302.75018310546875  loc loss 21.475229263305664\n",
      "cls loss 324.5903015136719  loc loss 24.018230438232422\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20.])\n",
      "cls loss 234.42523193359375  loc loss 14.736832618713379\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([11.])\n",
      "cls loss 335.50250244140625  loc loss 16.539844512939453\n",
      "cls loss 200.72109985351562  loc loss 13.6326904296875\n",
      "cls loss 507.5924377441406  loc loss 40.22871017456055\n",
      "cls loss 224.1080322265625  loc loss 11.36912727355957\n",
      "cls loss 491.46893310546875  loc loss 31.06201934814453\n",
      "cls loss 271.74407958984375  loc loss 17.376873016357422\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 35., 27.])\n",
      "cls loss 487.1090087890625  loc loss 27.57952308654785\n",
      "cls loss 531.4424438476562  loc loss 39.461002349853516\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 351.79754638671875  loc loss 20.5176944732666\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([42.,  1.])\n",
      "cls loss 436.0387878417969  loc loss 31.616010665893555\n",
      "cls loss 435.7318115234375  loc loss 24.396739959716797\n",
      "cls loss 503.5027770996094  loc loss 31.529338836669922\n",
      "cls loss 644.2442626953125  loc loss 38.69841766357422\n",
      "cls loss 549.6383056640625  loc loss 33.62216567993164\n",
      "cls loss 371.889892578125  loc loss 26.962919235229492\n",
      "cls loss 314.81903076171875  loc loss 25.25006103515625\n",
      "cls loss 191.2688751220703  loc loss 8.967105865478516\n",
      "cls loss 373.5625  loc loss 21.284029006958008\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 1., 1.])\n",
      "cls loss 353.25579833984375  loc loss 21.685792922973633\n",
      "cls loss 413.1079406738281  loc loss 27.71403694152832\n",
      "cls loss 401.1158447265625  loc loss 25.792997360229492\n",
      "cls loss 327.7510986328125  loc loss 24.88203239440918\n",
      "cls loss 403.106201171875  loc loss 27.79755401611328\n",
      "cls loss 438.6205749511719  loc loss 31.66402244567871\n",
      "cls loss 630.7935791015625  loc loss 38.046566009521484\n",
      "cls loss 540.0071411132812  loc loss 42.285606384277344\n",
      "cls loss 480.281005859375  loc loss 31.760250091552734\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 369.168212890625  loc loss 28.586015701293945\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 477.939697265625  loc loss 21.52756690979004\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([81.])\n",
      "cls loss 548.6544189453125  loc loss 33.08734130859375\n",
      "cls loss 325.43597412109375  loc loss 23.39261817932129\n",
      "cls loss 237.156494140625  loc loss 13.578351974487305\n",
      "cls loss 362.44476318359375  loc loss 20.70151138305664\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3.,  1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 19.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 19.])\n",
      "cls loss 507.96490478515625  loc loss 36.78240203857422\n",
      "cls loss 279.04443359375  loc loss 16.290611267089844\n",
      "cls loss 302.5579833984375  loc loss 18.527149200439453\n",
      "cls loss 589.6973876953125  loc loss 44.025081634521484\n",
      "cls loss 288.88836669921875  loc loss 19.330976486206055\n",
      "cls loss 376.61138916015625  loc loss 23.329788208007812\n",
      "cls loss 476.54736328125  loc loss 33.23944091796875\n",
      "cls loss 357.8770751953125  loc loss 25.898792266845703\n",
      "cls loss 469.49163818359375  loc loss 26.866493225097656\n",
      "cls loss 546.7860107421875  loc loss 34.99674606323242\n",
      "cls loss 678.459228515625  loc loss 58.63089370727539\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 81.])\n",
      "cls loss 465.0619201660156  loc loss 23.109235763549805\n",
      "cls loss 413.5170593261719  loc loss 23.087955474853516\n",
      "cls loss 421.48681640625  loc loss 23.726835250854492\n",
      "cls loss 327.7512512207031  loc loss 17.232248306274414\n",
      "cls loss 285.0991516113281  loc loss 18.69674301147461\n",
      "cls loss 319.2536926269531  loc loss 27.426084518432617\n",
      "cls loss 248.27090454101562  loc loss 20.27383804321289\n",
      "cls loss 219.84060668945312  loc loss 16.740938186645508\n",
      "cls loss 294.0600891113281  loc loss 21.90418815612793\n",
      "cls loss 398.7681884765625  loc loss 28.292572021484375\n",
      "cls loss 356.1935729980469  loc loss 30.249570846557617\n",
      "cls loss 374.5824279785156  loc loss 26.524539947509766\n",
      "cls loss 220.23764038085938  loc loss 15.867805480957031\n",
      "cls loss 773.870849609375  loc loss 51.86334228515625\n",
      "cls loss 435.66912841796875  loc loss 30.675289154052734\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 400.27105712890625  loc loss 20.614320755004883\n",
      "cls loss 468.90948486328125  loc loss 29.470882415771484\n",
      "cls loss 368.8819580078125  loc loss 22.793203353881836\n",
      "cls loss 567.7048950195312  loc loss 38.138267517089844\n",
      "cls loss 512.8848876953125  loc loss 32.904903411865234\n",
      "cls loss 472.1771240234375  loc loss 30.813987731933594\n",
      "cls loss 342.4296875  loc loss 24.55116844177246\n",
      "cls loss 286.09259033203125  loc loss 18.69131088256836\n",
      "cls loss 411.0906982421875  loc loss 27.858150482177734\n",
      "cls loss 473.2065734863281  loc loss 34.08479690551758\n",
      "cls loss 448.8993225097656  loc loss 26.450803756713867\n",
      "cls loss 569.6229248046875  loc loss 40.71117401123047\n",
      "cls loss 604.504150390625  loc loss 46.97982406616211\n",
      "cls loss 424.37054443359375  loc loss 30.758136749267578\n",
      "cls loss 615.0514526367188  loc loss 48.84585189819336\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1., 38., 47.,  1.,  1.,  1.,  1.,  1., 62.])\n",
      "cls loss 402.2821960449219  loc loss 20.464012145996094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 481.249755859375  loc loss 34.70851135253906\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 540.2504272460938  loc loss 31.675222396850586\n",
      "cls loss 574.49560546875  loc loss 42.215919494628906\n",
      "cls loss 394.2154235839844  loc loss 19.98821258544922\n",
      "cls loss 464.1063232421875  loc loss 38.34922790527344\n",
      "cls loss 442.01904296875  loc loss 27.850597381591797\n",
      "cls loss 250.8873748779297  loc loss 11.413505554199219\n",
      "cls loss 369.66278076171875  loc loss 23.41908836364746\n",
      "cls loss 306.55804443359375  loc loss 15.002610206604004\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1., 35.])\n",
      "cls loss 338.50872802734375  loc loss 20.461000442504883\n",
      "cls loss 538.5730590820312  loc loss 28.13176727294922\n",
      "cls loss 524.55078125  loc loss 33.73139953613281\n",
      "cls loss 469.61865234375  loc loss 39.76678466796875\n",
      "cls loss 376.5284729003906  loc loss 29.940372467041016\n",
      "cls loss 511.5423583984375  loc loss 41.164493560791016\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 281.2443542480469  loc loss 18.2532901763916\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 416.74652099609375  loc loss 18.91830825805664\n",
      "cls loss 667.5472412109375  loc loss 42.56861877441406\n",
      "cls loss 802.3885498046875  loc loss 63.34632873535156\n",
      "cls loss 412.89739990234375  loc loss 22.3354549407959\n",
      "cls loss 356.04852294921875  loc loss 21.49972915649414\n",
      "cls loss 375.1364440917969  loc loss 19.557632446289062\n",
      "cls loss 390.6649169921875  loc loss 25.08068084716797\n",
      "cls loss 335.6679382324219  loc loss 16.053260803222656\n",
      "cls loss 610.9522094726562  loc loss 45.9725227355957\n",
      "cls loss 521.8306884765625  loc loss 33.7249755859375\n",
      "cls loss 226.7490234375  loc loss 17.679136276245117\n",
      "cls loss 484.70977783203125  loc loss 29.181848526000977\n",
      "cls loss 600.4780883789062  loc loss 48.4869384765625\n",
      "cls loss 466.3223876953125  loc loss 32.43291091918945\n",
      "cls loss 390.86798095703125  loc loss 25.23175811767578\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.])\n",
      "cls loss 393.564453125  loc loss 29.33989143371582\n",
      "cls loss 399.050537109375  loc loss 27.141860961914062\n",
      "cls loss 506.5220642089844  loc loss 34.989906311035156\n",
      "cls loss 818.8602905273438  loc loss 66.1875228881836\n",
      "cls loss 317.20550537109375  loc loss 17.312835693359375\n",
      "cls loss 413.0549011230469  loc loss 25.66779899597168\n",
      "cls loss 334.75  loc loss 20.615840911865234\n",
      "cls loss 358.2731018066406  loc loss 25.632173538208008\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 21., 21., 21.])\n",
      "cls loss 375.44451904296875  loc loss 23.486770629882812\n",
      "cls loss 361.2403869628906  loc loss 19.895103454589844\n",
      "cls loss 378.8038330078125  loc loss 27.147205352783203\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 35.])\n",
      "cls loss 501.22894287109375  loc loss 31.506101608276367\n",
      "cls loss 188.4122772216797  loc loss 10.505144119262695\n",
      "cls loss 330.0104064941406  loc loss 21.138181686401367\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 304.7020263671875  loc loss 15.243061065673828\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 38., 38.,  9., 38.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1.,  1.])\n",
      "cls loss 354.6219787597656  loc loss 23.437206268310547\n",
      "cls loss 578.9985961914062  loc loss 37.59516525268555\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 2.,  1., 77., 31., 10., 10.,  1.,  4., 10.])\n",
      "cls loss 274.05224609375  loc loss 13.557175636291504\n",
      "cls loss 529.237548828125  loc loss 34.04737091064453\n",
      "cls loss 1104.164306640625  loc loss 63.79801559448242\n",
      "cls loss 331.3732604980469  loc loss 22.190629959106445\n",
      "cls loss 468.03802490234375  loc loss 35.12223434448242\n",
      "cls loss 333.7295837402344  loc loss 17.251541137695312\n",
      "cls loss 321.1719665527344  loc loss 16.788286209106445\n",
      "cls loss 466.696044921875  loc loss 26.333574295043945\n",
      "cls loss 474.35308837890625  loc loss 27.587461471557617\n",
      "cls loss 425.7549743652344  loc loss 31.839069366455078\n",
      "cls loss 356.4617919921875  loc loss 16.661712646484375\n",
      "cls loss 355.53076171875  loc loss 21.236328125\n",
      "cls loss 657.5809936523438  loc loss 41.22570037841797\n",
      "cls loss 614.514404296875  loc loss 35.36057662963867\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1., 42., 42., 42., 42., 42., 42.,  1.,\n",
      "         1.,  1.,  1., 42.,  1.,  1., 42.,  1.])\n",
      "cls loss 341.10272216796875  loc loss 24.300397872924805\n",
      "cls loss 510.0557861328125  loc loss 30.078508377075195\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.])\n",
      "cls loss 222.28004455566406  loc loss 12.903375625610352\n",
      "cls loss 514.8272094726562  loc loss 32.64215850830078\n",
      "cls loss 378.2852478027344  loc loss 29.051685333251953\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([11.])\n",
      "cls loss 232.68930053710938  loc loss 14.68260383605957\n",
      "cls loss 262.87042236328125  loc loss 14.398377418518066\n",
      "cls loss 287.49993896484375  loc loss 14.699214935302734\n",
      "cls loss 506.53692626953125  loc loss 31.44297981262207\n",
      "cls loss 398.9918212890625  loc loss 24.562166213989258\n",
      "cls loss 437.6331787109375  loc loss 28.043994903564453\n",
      "cls loss 616.41259765625  loc loss 32.868438720703125\n",
      "cls loss 327.6285400390625  loc loss 18.749431610107422\n",
      "cls loss 690.59423828125  loc loss 44.48035430908203\n",
      "cls loss 331.7177734375  loc loss 20.895620346069336\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 304.5528869628906  loc loss 18.998762130737305\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1., 38., 38., 42.])\n",
      "cls loss 400.19659423828125  loc loss 27.767284393310547\n",
      "cls loss 364.4416809082031  loc loss 21.571548461914062\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 319.93951416015625  loc loss 21.17038917541504\n",
      "cls loss 716.0403442382812  loc loss 46.53254318237305\n",
      "cls loss 438.3944396972656  loc loss 26.93638038635254\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10.,  3.,  3.,  6.,  8.,  8.,  1.,  1.,  1., 10.])\n",
      "cls loss 338.5999755859375  loc loss 17.744274139404297\n",
      "cls loss 220.16513061523438  loc loss 8.540853500366211\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10.,  3.])\n",
      "cls loss 317.89422607421875  loc loss 18.899843215942383\n",
      "cls loss 157.92105102539062  loc loss 10.210618019104004\n",
      "cls loss 404.8494567871094  loc loss 29.427574157714844\n",
      "cls loss 495.75048828125  loc loss 31.37254524230957\n",
      "cls loss 354.5213623046875  loc loss 21.812402725219727\n",
      "cls loss 229.21884155273438  loc loss 13.681612014770508\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 34.])\n",
      "cls loss 584.68408203125  loc loss 37.29564666748047\n",
      "cls loss 687.8065185546875  loc loss 51.298606872558594\n",
      "cls loss 443.6961975097656  loc loss 31.194011688232422\n",
      "cls loss 355.66534423828125  loc loss 23.46739959716797\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.,  1.])\n",
      "cls loss 383.32977294921875  loc loss 16.622451782226562\n",
      "cls loss 602.9225463867188  loc loss 43.53665542602539\n",
      "cls loss 850.8150634765625  loc loss 54.895164489746094\n",
      "cls loss 696.395263671875  loc loss 37.797508239746094\n",
      "cls loss 403.46173095703125  loc loss 22.019901275634766\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 455.73187255859375  loc loss 26.825090408325195\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10.])\n",
      "cls loss 284.88641357421875  loc loss 15.563193321228027\n",
      "cls loss 426.508056640625  loc loss 21.499897003173828\n",
      "cls loss 402.3503112792969  loc loss 24.170055389404297\n",
      "cls loss 274.2966003417969  loc loss 16.10919952392578\n",
      "cls loss 378.28314208984375  loc loss 25.00235939025879\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21.,\n",
      "        21.])\n",
      "cls loss 465.2196960449219  loc loss 28.492504119873047\n",
      "cls loss 397.26861572265625  loc loss 24.56368637084961\n",
      "cls loss 263.95684814453125  loc loss 12.495955467224121\n",
      "cls loss 584.757568359375  loc loss 36.468055725097656\n",
      "cls loss 434.2044677734375  loc loss 28.509166717529297\n",
      "cls loss 339.92193603515625  loc loss 16.555072784423828\n",
      "cls loss 660.512451171875  loc loss 39.75171661376953\n",
      "cls loss 763.0533447265625  loc loss 53.54956817626953\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15., 85.])\n",
      "cls loss 505.1051940917969  loc loss 30.598426818847656\n",
      "cls loss 487.2633056640625  loc loss 37.58702087402344\n",
      "cls loss 499.1935729980469  loc loss 35.32378387451172\n",
      "cls loss 410.5591125488281  loc loss 25.182537078857422\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 8., 8.])\n",
      "cls loss 280.94927978515625  loc loss 12.419231414794922\n",
      "cls loss 286.89300537109375  loc loss 22.85616111755371\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 369.4141845703125  loc loss 22.98287010192871\n",
      "cls loss 321.166015625  loc loss 18.3585205078125\n",
      "cls loss 353.92291259765625  loc loss 21.30051040649414\n",
      "cls loss 510.04351806640625  loc loss 30.665992736816406\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1., 35., 27., 27.,  1., 27.,  1.])\n",
      "cls loss 579.947998046875  loc loss 46.89846420288086\n",
      "cls loss 348.47247314453125  loc loss 22.56395721435547\n",
      "cls loss 377.6019287109375  loc loss 28.402090072631836\n",
      "cls loss 363.7127685546875  loc loss 31.95246696472168\n",
      "cls loss 335.13800048828125  loc loss 22.445960998535156\n",
      "cls loss 373.21173095703125  loc loss 27.14697265625\n",
      "cls loss 385.02783203125  loc loss 26.800365447998047\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  2.,  2.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  2.,  2.])\n",
      "cls loss 191.7666778564453  loc loss 8.087993621826172\n",
      "cls loss 594.3017578125  loc loss 36.851829528808594\n",
      "cls loss 365.29412841796875  loc loss 19.762191772460938\n",
      "cls loss 636.6791381835938  loc loss 49.454593658447266\n",
      "cls loss 244.51905822753906  loc loss 14.613207817077637\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 19., 19., 19., 16.])\n",
      "cls loss 250.97412109375  loc loss 12.1588716506958\n",
      "cls loss 208.641357421875  loc loss 9.091447830200195\n",
      "cls loss 351.71533203125  loc loss 17.082988739013672\n",
      "cls loss 465.83062744140625  loc loss 30.21275520324707\n",
      "cls loss 179.0857696533203  loc loss 15.943520545959473\n",
      "cls loss 511.4743347167969  loc loss 38.382659912109375\n",
      "cls loss 379.97412109375  loc loss 25.05895233154297\n",
      "cls loss 392.37115478515625  loc loss 25.058435440063477\n",
      "cls loss 509.40350341796875  loc loss 33.023834228515625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 523.311279296875  loc loss 24.99674415588379\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 739.2168579101562  loc loss 61.05028533935547\n",
      "cls loss 956.5038452148438  loc loss 87.04993438720703\n",
      "cls loss 488.912841796875  loc loss 29.23061752319336\n",
      "cls loss 441.2104797363281  loc loss 26.301450729370117\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3.,  3.,  3.,  3.,  3., 10.])\n",
      "cls loss 216.28839111328125  loc loss 13.247949600219727\n",
      "cls loss 459.5094299316406  loc loss 20.93604278564453\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 1., 1., 1., 3., 3., 3., 3.])\n",
      "cls loss 355.31707763671875  loc loss 18.188861846923828\n",
      "cls loss 682.9548950195312  loc loss 41.27635955810547\n",
      "cls loss 544.0661010742188  loc loss 32.2993278503418\n",
      "cls loss 343.13641357421875  loc loss 19.40896224975586\n",
      "cls loss 548.5374755859375  loc loss 37.05216979980469\n",
      "cls loss 323.64373779296875  loc loss 23.655954360961914\n",
      "cls loss 520.66748046875  loc loss 35.33124923706055\n",
      "cls loss 396.93560791015625  loc loss 36.440608978271484\n",
      "cls loss 381.8785400390625  loc loss 24.665287017822266\n",
      "cls loss 824.7774047851562  loc loss 65.3095703125\n",
      "cls loss 542.112060546875  loc loss 40.27277755737305\n",
      "cls loss 367.63397216796875  loc loss 17.9578857421875\n",
      "cls loss 231.17898559570312  loc loss 10.160113334655762\n",
      "cls loss 285.2882080078125  loc loss 13.648590087890625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3., 10., 10., 10., 10., 10., 10., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10., 10., 10., 10., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 11., 10., 10., 10., 10., 10.,  3.,  3.,  3.,  3.,  3.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 11., 10., 10., 10., 10., 10.,  3.,  3.,  3.,  3.,  3.])\n",
      "cls loss 227.5106201171875  loc loss 10.676233291625977\n",
      "cls loss 318.8633117675781  loc loss 13.620614051818848\n",
      "cls loss 269.573486328125  loc loss 15.782988548278809\n",
      "cls loss 272.0079650878906  loc loss 11.710479736328125\n",
      "cls loss 336.20574951171875  loc loss 25.697473526000977\n",
      "cls loss 244.91275024414062  loc loss 10.083806991577148\n",
      "cls loss 502.92596435546875  loc loss 32.23110580444336\n",
      "cls loss 461.60943603515625  loc loss 26.914968490600586\n",
      "cls loss 673.7872924804688  loc loss 40.6756706237793\n",
      "cls loss 337.9706726074219  loc loss 24.04258155822754\n",
      "cls loss 589.9163208007812  loc loss 36.92495346069336\n",
      "cls loss 453.0494689941406  loc loss 32.664127349853516\n",
      "cls loss 455.6452941894531  loc loss 29.56940460205078\n",
      "cls loss 441.9176025390625  loc loss 31.020463943481445\n",
      "cls loss 580.580810546875  loc loss 38.77227020263672\n",
      "cls loss 561.4615478515625  loc loss 36.140403747558594\n",
      "cls loss 273.9170227050781  loc loss 14.489570617675781\n",
      "cls loss 542.0430297851562  loc loss 36.796913146972656\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 10.,  1., 18.])\n",
      "cls loss 248.8736572265625  loc loss 17.830066680908203\n",
      "cls loss 316.975341796875  loc loss 13.238909721374512\n",
      "cls loss 572.322998046875  loc loss 27.76154327392578\n",
      "cls loss 742.897216796875  loc loss 42.7337532043457\n",
      "cls loss 445.1053466796875  loc loss 29.8179931640625\n",
      "cls loss 650.8721923828125  loc loss 32.881858825683594\n",
      "cls loss 475.89276123046875  loc loss 31.463993072509766\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.,  1.,  1.])\n",
      "cls loss 555.92236328125  loc loss 34.53718948364258\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1., 38.,  1.])\n",
      "cls loss 456.03961181640625  loc loss 29.038681030273438\n",
      "cls loss 679.2984619140625  loc loss 52.657161712646484\n",
      "cls loss 369.2713623046875  loc loss 25.26144790649414\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 509.31591796875  loc loss 29.774093627929688\n",
      "cls loss 408.55096435546875  loc loss 25.325481414794922\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3., 10.,  8.,  3., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.])\n",
      "cls loss 469.20538330078125  loc loss 27.836750030517578\n",
      "cls loss 313.90411376953125  loc loss 22.257951736450195\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3.,  3., 11.,  3., 10., 10.,  3.,  3., 10.])\n",
      "cls loss 359.3417663574219  loc loss 19.939876556396484\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3., 10., 10., 10.])\n",
      "cls loss 410.032958984375  loc loss 22.17571449279785\n",
      "cls loss 329.7569580078125  loc loss 21.668781280517578\n",
      "cls loss 442.2509765625  loc loss 29.894168853759766\n",
      "cls loss 637.889404296875  loc loss 37.136512756347656\n",
      "cls loss 414.78228759765625  loc loss 26.805208206176758\n",
      "cls loss 321.8328857421875  loc loss 24.59615707397461\n",
      "cls loss 402.0201110839844  loc loss 23.677392959594727\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 9.,  9., 85., 85.])\n",
      "cls loss 323.7931213378906  loc loss 16.02764320373535\n",
      "cls loss 416.375  loc loss 29.131092071533203\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 637.0294189453125  loc loss 41.1099853515625\n",
      "cls loss 541.8678588867188  loc loss 23.498435974121094\n",
      "cls loss 616.8372192382812  loc loss 43.96894073486328\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10., 10., 10., 10.])\n",
      "cls loss 382.2774353027344  loc loss 25.20405387878418\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([13.])\n",
      "cls loss 602.4376220703125  loc loss 49.15239715576172\n",
      "cls loss 170.18081665039062  loc loss 11.044767379760742\n",
      "cls loss 258.9050598144531  loc loss 14.138053894042969\n",
      "cls loss 343.752197265625  loc loss 22.276105880737305\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19.,  1.,  1.,  1., 19., 19.])\n",
      "cls loss 370.5775146484375  loc loss 27.355457305908203\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 306.9205322265625  loc loss 23.293420791625977\n",
      "cls loss 440.2630310058594  loc loss 30.656539916992188\n",
      "cls loss 343.7414855957031  loc loss 18.765613555908203\n",
      "cls loss 489.8201904296875  loc loss 23.79686164855957\n",
      "cls loss 518.102783203125  loc loss 36.395294189453125\n",
      "cls loss 384.42095947265625  loc loss 22.5672607421875\n",
      "cls loss 616.6640625  loc loss 42.91173553466797\n",
      "cls loss 214.7777099609375  loc loss 10.7740478515625\n",
      "cls loss 411.7106018066406  loc loss 31.127788543701172\n",
      "cls loss 326.4892578125  loc loss 20.590293884277344\n",
      "cls loss 360.0748291015625  loc loss 21.214937210083008\n",
      "cls loss 498.5316162109375  loc loss 32.67430114746094\n",
      "cls loss 408.62652587890625  loc loss 20.924663543701172\n",
      "cls loss 580.97119140625  loc loss 41.32857131958008\n",
      "cls loss 380.5791015625  loc loss 24.36764144897461\n",
      "cls loss 496.8243713378906  loc loss 34.362060546875\n",
      "cls loss 718.103271484375  loc loss 44.82041931152344\n",
      "cls loss 380.12939453125  loc loss 30.394559860229492\n",
      "cls loss 459.996826171875  loc loss 26.610498428344727\n",
      "cls loss 535.9385986328125  loc loss 41.8819580078125\n",
      "cls loss 620.16064453125  loc loss 46.38810729980469\n",
      "cls loss 695.9693603515625  loc loss 43.16994094848633\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 5.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 181.6800994873047  loc loss 9.900666236877441\n",
      "cls loss 257.1750793457031  loc loss 11.824893951416016\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 13.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 6., 8., 8.])\n",
      "cls loss 198.30032348632812  loc loss 10.888638496398926\n",
      "cls loss 263.78070068359375  loc loss 14.145021438598633\n",
      "cls loss 530.3367309570312  loc loss 36.227935791015625\n",
      "cls loss 219.3385467529297  loc loss 12.817821502685547\n",
      "cls loss 458.95941162109375  loc loss 33.80240249633789\n",
      "cls loss 659.7222900390625  loc loss 50.2703971862793\n",
      "cls loss 428.27496337890625  loc loss 30.130577087402344\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([42., 42.,  1.,  1.,  1.,  1.,  1.,  1.,  1., 42., 42.])\n",
      "cls loss 458.8515625  loc loss 25.82649803161621\n",
      "cls loss 595.9805908203125  loc loss 48.86045837402344\n",
      "cls loss 557.1767578125  loc loss 37.74393081665039\n",
      "cls loss 355.765380859375  loc loss 21.508407592773438\n",
      "cls loss 464.89208984375  loc loss 24.617958068847656\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 671.9666137695312  loc loss 42.15626525878906\n",
      "cls loss 530.5157470703125  loc loss 35.59137725830078\n",
      "cls loss 318.9443359375  loc loss 17.868209838867188\n",
      "cls loss 268.4562072753906  loc loss 17.396251678466797\n",
      "cls loss 349.8319091796875  loc loss 25.38405990600586\n",
      "cls loss 498.4557189941406  loc loss 38.12712097167969\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15.])\n",
      "cls loss 240.37744140625  loc loss 9.654516220092773\n",
      "cls loss 419.4306945800781  loc loss 27.886377334594727\n",
      "cls loss 360.8620300292969  loc loss 25.583030700683594\n",
      "cls loss 658.310302734375  loc loss 43.84315490722656\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19.,  7.])\n",
      "cls loss 315.8262939453125  loc loss 18.640695571899414\n",
      "cls loss 665.6084594726562  loc loss 46.95301818847656\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 598.2646484375  loc loss 30.510082244873047\n",
      "cls loss 524.1296997070312  loc loss 38.341758728027344\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([38., 38.,  1., 18.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1., 18., 18.,  1.])\n",
      "cls loss 359.0875244140625  loc loss 21.716556549072266\n",
      "cls loss 352.21624755859375  loc loss 22.200347900390625\n",
      "cls loss 689.6069946289062  loc loss 50.30552291870117\n",
      "cls loss 520.6524047851562  loc loss 37.38840103149414\n",
      "cls loss 411.28643798828125  loc loss 28.24505043029785\n",
      "cls loss 277.28594970703125  loc loss 21.38772964477539\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.])\n",
      "cls loss 179.36181640625  loc loss 7.3006510734558105\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([32.])\n",
      "cls loss 435.9825134277344  loc loss 24.224525451660156\n",
      "cls loss 369.96636962890625  loc loss 26.363025665283203\n",
      "cls loss 467.4097595214844  loc loss 38.4642448425293\n",
      "cls loss 414.08575439453125  loc loss 29.57265853881836\n",
      "cls loss 347.7465515136719  loc loss 26.77401351928711\n",
      "cls loss 562.9129638671875  loc loss 37.41264343261719\n",
      "cls loss 670.3823852539062  loc loss 48.732765197753906\n",
      "cls loss 488.16033935546875  loc loss 36.93971252441406\n",
      "cls loss 384.7148742675781  loc loss 24.221084594726562\n",
      "cls loss 621.0179443359375  loc loss 40.52385711669922\n",
      "cls loss 427.6923828125  loc loss 23.637435913085938\n",
      "cls loss 748.0852661132812  loc loss 53.34413146972656\n",
      "cls loss 500.8711853027344  loc loss 30.69705581665039\n",
      "cls loss 389.011474609375  loc loss 34.25033950805664\n",
      "cls loss 302.58721923828125  loc loss 18.98340606689453\n",
      "cls loss 336.87628173828125  loc loss 23.487871170043945\n",
      "cls loss 491.6609802246094  loc loss 35.03407669067383\n",
      "cls loss 537.6492919921875  loc loss 40.51626205444336\n",
      "cls loss 307.400146484375  loc loss 20.41963005065918\n",
      "cls loss 541.052001953125  loc loss 40.66569519042969\n",
      "cls loss 654.12109375  loc loss 47.562217712402344\n",
      "cls loss 241.88031005859375  loc loss 17.40355110168457\n",
      "cls loss 638.762451171875  loc loss 51.43484115600586\n",
      "cls loss 480.96063232421875  loc loss 34.63835906982422\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 631.749267578125  loc loss 54.56269454956055\n",
      "cls loss 292.5086975097656  loc loss 13.238191604614258\n",
      "cls loss 448.8695068359375  loc loss 25.522459030151367\n",
      "cls loss 459.83905029296875  loc loss 29.908193588256836\n",
      "cls loss 374.4005126953125  loc loss 23.515743255615234\n",
      "cls loss 205.49447631835938  loc loss 11.468934059143066\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 9., 9., 1., 9., 9., 9., 9., 1., 9.])\n",
      "cls loss 849.9126586914062  loc loss 71.7629165649414\n",
      "cls loss 465.8277893066406  loc loss 33.97747039794922\n",
      "cls loss 718.522705078125  loc loss 63.154380798339844\n",
      "cls loss 292.6625671386719  loc loss 24.939922332763672\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 42., 42.])\n",
      "cls loss 489.3124694824219  loc loss 40.90230178833008\n",
      "cls loss 507.392822265625  loc loss 41.374610900878906\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  2.,  1.,  1.,  1., 38.,\n",
      "         1.,  1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 38., 38., 38.,  1., 38., 38., 38.,  1.,  1., 38.,  1.,\n",
      "         1.])\n",
      "cls loss 292.8743591308594  loc loss 23.07883071899414\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  8.,  8.])\n",
      "cls loss 712.5689086914062  loc loss 52.3651237487793\n",
      "cls loss 730.840087890625  loc loss 56.70709228515625\n",
      "cls loss 274.24249267578125  loc loss 18.598711013793945\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([4., 1., 1., 4.])\n",
      "cls loss 463.7607116699219  loc loss 28.420574188232422\n",
      "cls loss 559.9620361328125  loc loss 36.65883255004883\n",
      "cls loss 220.31613159179688  loc loss 12.529362678527832\n",
      "cls loss 283.9692687988281  loc loss 20.484844207763672\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([51.,  1.])\n",
      "cls loss 197.02809143066406  loc loss 10.371074676513672\n",
      "cls loss 281.8752746582031  loc loss 20.99384307861328\n",
      "cls loss 567.833251953125  loc loss 33.803802490234375\n",
      "cls loss 532.8256225585938  loc loss 47.52720642089844\n",
      "cls loss 830.2105712890625  loc loss 45.08060073852539\n",
      "cls loss 962.5965576171875  loc loss 67.70067596435547\n",
      "cls loss 381.7071533203125  loc loss 27.288766860961914\n",
      "cls loss 552.22021484375  loc loss 47.55035400390625\n",
      "cls loss 631.19921875  loc loss 50.31881332397461\n",
      "cls loss 440.80120849609375  loc loss 31.876834869384766\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  3.,  1.,  1.,  1.,  3.,  1.,  1.,\n",
      "         1.,  1.,  1.])\n",
      "cls loss 487.35040283203125  loc loss 24.691905975341797\n",
      "cls loss 550.47509765625  loc loss 35.82070541381836\n",
      "cls loss 527.42626953125  loc loss 33.6962776184082\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "cls loss 452.2974548339844  loc loss 26.853116989135742\n",
      "cls loss 252.291748046875  loc loss 20.298479080200195\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3.])\n",
      "cls loss 206.3222198486328  loc loss 11.61880874633789\n",
      "cls loss 346.9598388671875  loc loss 24.657062530517578\n",
      "cls loss 331.59796142578125  loc loss 26.227081298828125\n",
      "cls loss 589.3561401367188  loc loss 43.758392333984375\n",
      "cls loss 274.39666748046875  loc loss 23.87762451171875\n",
      "cls loss 307.41156005859375  loc loss 28.776582717895508\n",
      "cls loss 899.0060424804688  loc loss 74.69355010986328\n",
      "cls loss 383.2754821777344  loc loss 33.548828125\n",
      "cls loss 292.7746887207031  loc loss 24.489686965942383\n",
      "cls loss 349.37646484375  loc loss 21.140609741210938\n",
      "cls loss 319.52227783203125  loc loss 25.402973175048828\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 597.7508544921875  loc loss 43.627174377441406\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  9., 64., 64., 64., 64., 64., 64., 64., 64., 64.,  9.,  9.,  9.,\n",
      "         9.])\n",
      "cls loss 286.5162353515625  loc loss 16.358718872070312\n",
      "cls loss 868.8606567382812  loc loss 70.4113998413086\n",
      "cls loss 451.96923828125  loc loss 31.48908233642578\n",
      "cls loss 559.59521484375  loc loss 43.06475067138672\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.,  3.,  3.])\n",
      "cls loss 328.9077453613281  loc loss 22.926002502441406\n",
      "cls loss 376.053466796875  loc loss 31.270776748657227\n",
      "cls loss 395.8480224609375  loc loss 32.73948669433594\n",
      "cls loss 414.2384338378906  loc loss 27.819347381591797\n",
      "cls loss 462.447509765625  loc loss 33.312347412109375\n",
      "cls loss 455.38922119140625  loc loss 31.543975830078125\n",
      "cls loss 404.04107666015625  loc loss 30.739856719970703\n",
      "cls loss 418.57330322265625  loc loss 24.93289566040039\n",
      "cls loss 532.2881469726562  loc loss 37.75067901611328\n",
      "cls loss 394.99359130859375  loc loss 25.757217407226562\n",
      "cls loss 306.66815185546875  loc loss 17.34089469909668\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21.])\n",
      "cls loss 246.07696533203125  loc loss 17.553007125854492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 355.84869384765625  loc loss 32.9979133605957\n",
      "cls loss 539.94189453125  loc loss 39.0402717590332\n",
      "cls loss 289.42779541015625  loc loss 17.186843872070312\n",
      "cls loss 453.41815185546875  loc loss 31.039823532104492\n",
      "cls loss 825.0088500976562  loc loss 44.8032341003418\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 42., 42.,  1.,  1.])\n",
      "cls loss 477.70489501953125  loc loss 27.131534576416016\n",
      "cls loss 304.10198974609375  loc loss 18.916845321655273\n",
      "cls loss 425.185546875  loc loss 27.828636169433594\n",
      "cls loss 546.56787109375  loc loss 44.019222259521484\n",
      "cls loss 344.3858642578125  loc loss 21.85854148864746\n",
      "cls loss 531.6699829101562  loc loss 39.71144104003906\n",
      "cls loss 483.0578308105469  loc loss 36.913421630859375\n",
      "cls loss 464.7176513671875  loc loss 30.954845428466797\n",
      "cls loss 384.1842346191406  loc loss 26.434972763061523\n",
      "cls loss 309.7318115234375  loc loss 23.151897430419922\n",
      "cls loss 260.3167724609375  loc loss 12.35011100769043\n",
      "cls loss 387.750244140625  loc loss 25.254735946655273\n",
      "cls loss 587.8983154296875  loc loss 39.83488464355469\n",
      "cls loss 466.31689453125  loc loss 26.193288803100586\n",
      "cls loss 425.92779541015625  loc loss 31.048341751098633\n",
      "cls loss 477.2711181640625  loc loss 28.381208419799805\n",
      "cls loss 696.2437133789062  loc loss 52.504146575927734\n",
      "cls loss 546.4962158203125  loc loss 36.53154754638672\n",
      "cls loss 583.9019775390625  loc loss 31.268653869628906\n",
      "cls loss 355.64520263671875  loc loss 16.586746215820312\n",
      "cls loss 487.8255310058594  loc loss 30.98987579345703\n",
      "cls loss 440.26910400390625  loc loss 27.732093811035156\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 5., 5., 5., 5., 5., 5.])\n",
      "cls loss 283.26763916015625  loc loss 20.23598289489746\n",
      "cls loss 364.24493408203125  loc loss 21.29576873779297\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([13.])\n",
      "cls loss 256.50311279296875  loc loss 14.204514503479004\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([44., 10.,  1.,  1.,  1.])\n",
      "cls loss 242.95953369140625  loc loss 16.783052444458008\n",
      "cls loss 428.5771484375  loc loss 25.066469192504883\n",
      "cls loss 397.24249267578125  loc loss 22.09231185913086\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19., 19., 19., 19., 19., 19., 19.])\n",
      "cls loss 420.1310119628906  loc loss 27.17827606201172\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([56.])\n",
      "cls loss 872.0440673828125  loc loss 59.985816955566406\n",
      "cls loss 560.5814208984375  loc loss 42.769283294677734\n",
      "cls loss 719.3837890625  loc loss 46.36241912841797\n",
      "cls loss 702.596923828125  loc loss 54.464881896972656\n",
      "cls loss 479.006103515625  loc loss 25.28257179260254\n",
      "cls loss 734.8377685546875  loc loss 47.229408264160156\n",
      "cls loss 421.79119873046875  loc loss 26.520381927490234\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 36.])\n",
      "cls loss 522.6296997070312  loc loss 24.510435104370117\n",
      "cls loss 410.34326171875  loc loss 27.761920928955078\n",
      "cls loss 386.6144104003906  loc loss 24.32706069946289\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5.])\n",
      "cls loss 435.2086181640625  loc loss 28.677553176879883\n",
      "cls loss 236.15707397460938  loc loss 13.230188369750977\n",
      "cls loss 569.9124145507812  loc loss 35.490760803222656\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "cls loss 504.59735107421875  loc loss 34.01924133300781\n",
      "cls loss 476.48712158203125  loc loss 32.00825119018555\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 513.4827880859375  loc loss 33.76256561279297\n",
      "cls loss 573.1871337890625  loc loss 39.54825210571289\n",
      "cls loss 490.4132995605469  loc loss 41.99570846557617\n",
      "cls loss 354.29644775390625  loc loss 22.380023956298828\n",
      "cls loss 405.31048583984375  loc loss 29.82341766357422\n",
      "cls loss 445.2156982421875  loc loss 25.292343139648438\n",
      "cls loss 691.3788452148438  loc loss 35.26549530029297\n",
      "cls loss 298.7576904296875  loc loss 14.169795989990234\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 11., 15., 10., 10., 10., 10., 10.])\n",
      "cls loss 652.2871704101562  loc loss 41.81189727783203\n",
      "cls loss 387.6577453613281  loc loss 28.663713455200195\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3.])\n",
      "cls loss 396.94854736328125  loc loss 28.922161102294922\n",
      "cls loss 366.6239013671875  loc loss 19.91771125793457\n",
      "cls loss 409.07928466796875  loc loss 19.646221160888672\n",
      "cls loss 513.306640625  loc loss 23.516551971435547\n",
      "cls loss 244.89968872070312  loc loss 11.987469673156738\n",
      "cls loss 409.52093505859375  loc loss 28.344202041625977\n",
      "cls loss 484.59393310546875  loc loss 32.37502670288086\n",
      "cls loss 403.3258056640625  loc loss 29.07332992553711\n",
      "cls loss 967.5283203125  loc loss 66.29420471191406\n",
      "cls loss 644.8909912109375  loc loss 43.28083038330078\n",
      "cls loss 420.37054443359375  loc loss 29.08626365661621\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  9.,  9.,  9.,  6.,  6., 85., 85.,  8.,  1.,  1.,  1.,  1.,\n",
      "         6.,  6.])\n",
      "cls loss 282.922119140625  loc loss 23.27363395690918\n",
      "cls loss 712.6884765625  loc loss 50.64051055908203\n",
      "cls loss 839.8959350585938  loc loss 52.55311584472656\n",
      "cls loss 545.6328735351562  loc loss 37.834434509277344\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10.,  3.,  3., 10.])\n",
      "cls loss 354.3622131347656  loc loss 19.03152084350586\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([7.])\n",
      "cls loss 451.9726257324219  loc loss 30.3051815032959\n",
      "cls loss 445.783447265625  loc loss 28.09574317932129\n",
      "cls loss 446.0218811035156  loc loss 37.93934631347656\n",
      "cls loss 679.159912109375  loc loss 50.12431335449219\n",
      "cls loss 401.7596740722656  loc loss 28.054853439331055\n",
      "cls loss 591.6387939453125  loc loss 41.04149627685547\n",
      "cls loss 768.6912841796875  loc loss 47.36065673828125\n",
      "cls loss 465.38836669921875  loc loss 30.647939682006836\n",
      "cls loss 509.3186340332031  loc loss 35.748287200927734\n",
      "cls loss 390.27447509765625  loc loss 30.86726188659668\n",
      "cls loss 622.6297607421875  loc loss 46.011253356933594\n",
      "cls loss 464.02545166015625  loc loss 30.71856689453125\n",
      "cls loss 368.76446533203125  loc loss 22.812641143798828\n",
      "cls loss 564.8001708984375  loc loss 44.35475158691406\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([62.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([62.])\n",
      "cls loss 272.3790588378906  loc loss 12.633343696594238\n",
      "cls loss 418.311767578125  loc loss 32.2068977355957\n",
      "cls loss 414.761962890625  loc loss 28.36671257019043\n",
      "cls loss 268.21966552734375  loc loss 15.314276695251465\n",
      "cls loss 571.2030029296875  loc loss 37.581871032714844\n",
      "cls loss 577.3435668945312  loc loss 32.21958541870117\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([28.])\n",
      "cls loss 710.9901123046875  loc loss 33.12083435058594\n",
      "cls loss 526.3939208984375  loc loss 34.10161209106445\n",
      "cls loss 528.3386840820312  loc loss 37.833492279052734\n",
      "cls loss 560.4432373046875  loc loss 37.685218811035156\n",
      "cls loss 753.6708374023438  loc loss 53.62767791748047\n",
      "cls loss 448.54931640625  loc loss 28.225296020507812\n",
      "cls loss 589.28662109375  loc loss 33.2708740234375\n",
      "cls loss 474.3070068359375  loc loss 38.66218185424805\n",
      "cls loss 789.5628051757812  loc loss 60.08863067626953\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([81.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 484.8131103515625  loc loss 20.918582916259766\n",
      "cls loss 377.45489501953125  loc loss 20.43451690673828\n",
      "cls loss 278.8006286621094  loc loss 21.010868072509766\n",
      "cls loss 253.54974365234375  loc loss 11.472587585449219\n",
      "cls loss 282.3543701171875  loc loss 23.537221908569336\n",
      "cls loss 354.9434814453125  loc loss 24.107139587402344\n",
      "cls loss 355.99566650390625  loc loss 29.38583755493164\n",
      "cls loss 515.1826171875  loc loss 47.69819641113281\n",
      "cls loss 641.4614868164062  loc loss 40.4546012878418\n",
      "cls loss 1086.07861328125  loc loss 76.25882720947266\n",
      "cls loss 436.00372314453125  loc loss 21.768030166625977\n",
      "cls loss 539.3429565429688  loc loss 39.899070739746094\n",
      "cls loss 379.31829833984375  loc loss 23.881420135498047\n",
      "cls loss 504.53857421875  loc loss 30.218626022338867\n",
      "cls loss 426.4547119140625  loc loss 26.810470581054688\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([44., 44.])\n",
      "cls loss 372.0486145019531  loc loss 21.317913055419922\n",
      "cls loss 415.04376220703125  loc loss 32.13665008544922\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15.])\n",
      "cls loss 418.6183776855469  loc loss 28.566112518310547\n",
      "cls loss 214.89088439941406  loc loss 16.353866577148438\n",
      "cls loss 430.1578369140625  loc loss 32.72901153564453\n",
      "cls loss 261.3512878417969  loc loss 14.622681617736816\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([1., 3., 3.])\n",
      "cls loss 292.15533447265625  loc loss 19.52873420715332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 213.4518585205078  loc loss 11.516886711120605\n",
      "cls loss 402.9366455078125  loc loss 29.04450225830078\n",
      "cls loss 470.13299560546875  loc loss 28.106557846069336\n",
      "cls loss 415.47344970703125  loc loss 28.60686683654785\n",
      "cls loss 354.6300354003906  loc loss 24.117544174194336\n",
      "cls loss 366.1691589355469  loc loss 28.35116958618164\n",
      "cls loss 493.05645751953125  loc loss 33.68814468383789\n",
      "cls loss 347.6211242675781  loc loss 24.311138153076172\n",
      "cls loss 469.3187255859375  loc loss 35.954750061035156\n",
      "cls loss 328.97393798828125  loc loss 21.946744918823242\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 562.315185546875  loc loss 35.374534606933594\n",
      "cls loss 677.42529296875  loc loss 34.67118835449219\n",
      "cls loss 575.2489013671875  loc loss 42.20825958251953\n",
      "cls loss 564.7661743164062  loc loss 46.6879997253418\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10., 10., 10.,  1.,  1.,  1.,  1.,  1.,  1.,  8.,  8.,\n",
      "         1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10., 10., 10.,  1.,  1.,  1.,  1.,  1.,  1.,  8.,  8.,\n",
      "         1.])\n",
      "cls loss 462.78143310546875  loc loss 24.731170654296875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 3., 3., 3.])\n",
      "cls loss 446.8060302734375  loc loss 26.763471603393555\n",
      "cls loss 295.3947448730469  loc loss 18.383817672729492\n",
      "cls loss 222.96739196777344  loc loss 12.05330753326416\n",
      "cls loss 423.8781433105469  loc loss 35.53852844238281\n",
      "cls loss 321.5018615722656  loc loss 17.964277267456055\n",
      "cls loss 391.10223388671875  loc loss 31.27175521850586\n",
      "cls loss 441.37969970703125  loc loss 35.41685485839844\n",
      "cls loss 592.9625854492188  loc loss 51.18781661987305\n",
      "cls loss 514.7041015625  loc loss 30.92989730834961\n",
      "cls loss 474.1594543457031  loc loss 29.201448440551758\n",
      "cls loss 492.9532165527344  loc loss 33.52659225463867\n",
      "cls loss 350.488037109375  loc loss 28.07721710205078\n",
      "cls loss 704.85302734375  loc loss 51.82825469970703\n",
      "cls loss 316.94866943359375  loc loss 18.333389282226562\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 566.4843139648438  loc loss 34.24665069580078\n",
      "cls loss 254.0035858154297  loc loss 13.185403823852539\n",
      "cls loss 631.8975219726562  loc loss 50.27583312988281\n",
      "cls loss 315.8388366699219  loc loss 23.29155731201172\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 34.])\n",
      "cls loss 515.7157592773438  loc loss 35.708213806152344\n",
      "cls loss 255.538330078125  loc loss 18.931594848632812\n",
      "cls loss 527.0093994140625  loc loss 35.24388122558594\n",
      "cls loss 178.53396606445312  loc loss 15.187051773071289\n",
      "cls loss 422.19793701171875  loc loss 30.386123657226562\n",
      "cls loss 420.271484375  loc loss 34.477821350097656\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 38.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16., 16., 16.,  9.,  9.,  9., 16., 16., 16., 85.,  9.])\n",
      "cls loss 433.09423828125  loc loss 28.042530059814453\n",
      "cls loss 471.68701171875  loc loss 36.3446044921875\n",
      "cls loss 632.5936279296875  loc loss 42.37316131591797\n",
      "cls loss 990.5005493164062  loc loss 62.48691177368164\n",
      "cls loss 264.6288146972656  loc loss 14.21047592163086\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3., 10.,  8.,  8., 10., 10., 10.,  3.,  3., 14.])\n",
      "cls loss 281.0828552246094  loc loss 16.919601440429688\n",
      "cls loss 531.0361938476562  loc loss 34.91353225708008\n",
      "cls loss 236.19223022460938  loc loss 10.082470893859863\n",
      "cls loss 399.15289306640625  loc loss 18.55632972717285\n",
      "cls loss 531.5765380859375  loc loss 37.03245162963867\n",
      "cls loss 454.228759765625  loc loss 31.0596923828125\n",
      "cls loss 249.33718872070312  loc loss 15.560811996459961\n",
      "cls loss 329.52471923828125  loc loss 17.717071533203125\n",
      "cls loss 530.1547241210938  loc loss 31.48784637451172\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42., 42.,  1.])\n",
      "cls loss 480.0206298828125  loc loss 32.21274948120117\n",
      "cls loss 365.26727294921875  loc loss 22.57280158996582\n",
      "cls loss 500.3700866699219  loc loss 40.16536331176758\n",
      "cls loss 574.5595703125  loc loss 35.50971221923828\n",
      "cls loss 402.3969421386719  loc loss 25.42820167541504\n",
      "cls loss 493.5054931640625  loc loss 35.60269546508789\n",
      "cls loss 298.9129333496094  loc loss 20.72511100769043\n",
      "cls loss 320.9349060058594  loc loss 23.664522171020508\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20.])\n",
      "cls loss 230.64515686035156  loc loss 14.041847229003906\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([11.])\n",
      "cls loss 330.92486572265625  loc loss 15.712818145751953\n",
      "cls loss 196.87677001953125  loc loss 13.010169982910156\n",
      "cls loss 501.65740966796875  loc loss 38.80522155761719\n",
      "cls loss 220.48760986328125  loc loss 11.112558364868164\n",
      "cls loss 482.54815673828125  loc loss 29.408451080322266\n",
      "cls loss 268.0201416015625  loc loss 17.008699417114258\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 35., 27.])\n",
      "cls loss 485.0662841796875  loc loss 26.86016082763672\n",
      "cls loss 528.99755859375  loc loss 38.352813720703125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 350.98919677734375  loc loss 19.49806022644043\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([42.,  1.])\n",
      "cls loss 433.76947021484375  loc loss 30.581693649291992\n",
      "cls loss 434.9940490722656  loc loss 23.71817398071289\n",
      "cls loss 502.2862854003906  loc loss 30.76482391357422\n",
      "cls loss 640.1563110351562  loc loss 37.65834045410156\n",
      "cls loss 542.2437744140625  loc loss 32.383365631103516\n",
      "cls loss 368.2418212890625  loc loss 25.921842575073242\n",
      "cls loss 310.37298583984375  loc loss 24.12160873413086\n",
      "cls loss 187.74044799804688  loc loss 8.784004211425781\n",
      "cls loss 367.4088134765625  loc loss 20.713916778564453\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 1., 1.])\n",
      "cls loss 346.39898681640625  loc loss 21.822242736816406\n",
      "cls loss 408.1783142089844  loc loss 27.53687858581543\n",
      "cls loss 395.232421875  loc loss 25.195837020874023\n",
      "cls loss 321.7315368652344  loc loss 24.057374954223633\n",
      "cls loss 395.9383850097656  loc loss 27.16767692565918\n",
      "cls loss 430.4391174316406  loc loss 30.872440338134766\n",
      "cls loss 625.3101806640625  loc loss 37.20090103149414\n",
      "cls loss 539.594970703125  loc loss 41.395790100097656\n",
      "cls loss 481.4774169921875  loc loss 31.15966796875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 370.20526123046875  loc loss 28.06847381591797\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 478.62841796875  loc loss 20.988746643066406\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([81.])\n",
      "cls loss 544.9671630859375  loc loss 32.94389343261719\n",
      "cls loss 321.4625244140625  loc loss 23.242595672607422\n",
      "cls loss 233.34629821777344  loc loss 13.179330825805664\n",
      "cls loss 356.58831787109375  loc loss 20.418649673461914\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3.,  1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 19.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 19.])\n",
      "cls loss 503.32293701171875  loc loss 35.429691314697266\n",
      "cls loss 274.46527099609375  loc loss 16.208444595336914\n",
      "cls loss 298.80841064453125  loc loss 17.96263313293457\n",
      "cls loss 585.1027221679688  loc loss 43.04344177246094\n",
      "cls loss 285.02459716796875  loc loss 18.663516998291016\n",
      "cls loss 371.4656982421875  loc loss 22.97039794921875\n",
      "cls loss 471.13787841796875  loc loss 32.526554107666016\n",
      "cls loss 351.934326171875  loc loss 25.66542625427246\n",
      "cls loss 465.834228515625  loc loss 26.564252853393555\n",
      "cls loss 543.0173950195312  loc loss 34.307281494140625\n",
      "cls loss 680.3162841796875  loc loss 58.176429748535156\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 81.])\n",
      "cls loss 464.0973815917969  loc loss 22.761384963989258\n",
      "cls loss 413.2270202636719  loc loss 22.542348861694336\n",
      "cls loss 416.3797607421875  loc loss 23.415306091308594\n",
      "cls loss 325.2642822265625  loc loss 17.06207275390625\n",
      "cls loss 281.6954345703125  loc loss 18.373165130615234\n",
      "cls loss 316.558837890625  loc loss 26.897876739501953\n",
      "cls loss 244.64242553710938  loc loss 19.825153350830078\n",
      "cls loss 218.06582641601562  loc loss 16.165897369384766\n",
      "cls loss 288.2729187011719  loc loss 21.155546188354492\n",
      "cls loss 393.51641845703125  loc loss 27.650897979736328\n",
      "cls loss 352.2396240234375  loc loss 29.898880004882812\n",
      "cls loss 371.2720947265625  loc loss 25.953227996826172\n",
      "cls loss 217.15255737304688  loc loss 15.224628448486328\n",
      "cls loss 767.3182373046875  loc loss 50.84009552001953\n",
      "cls loss 429.8072509765625  loc loss 29.841724395751953\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 393.8787536621094  loc loss 20.17009735107422\n",
      "cls loss 463.28558349609375  loc loss 28.571752548217773\n",
      "cls loss 368.9114990234375  loc loss 22.430707931518555\n",
      "cls loss 567.8232421875  loc loss 37.408599853515625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 509.4715270996094  loc loss 32.159454345703125\n",
      "cls loss 471.25042724609375  loc loss 30.01949691772461\n",
      "cls loss 338.717529296875  loc loss 23.983646392822266\n",
      "cls loss 284.6715087890625  loc loss 18.004676818847656\n",
      "cls loss 405.3546142578125  loc loss 27.09630584716797\n",
      "cls loss 469.29302978515625  loc loss 33.31853485107422\n",
      "cls loss 443.22882080078125  loc loss 25.879817962646484\n",
      "cls loss 560.7116088867188  loc loss 39.434139251708984\n",
      "cls loss 598.153564453125  loc loss 45.13985061645508\n",
      "cls loss 418.695068359375  loc loss 29.794404983520508\n",
      "cls loss 607.4381103515625  loc loss 48.041141510009766\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1., 38., 47.,  1.,  1.,  1.,  1.,  1., 62.])\n",
      "cls loss 393.5291748046875  loc loss 19.896028518676758\n",
      "cls loss 472.522216796875  loc loss 34.09524154663086\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 532.9696044921875  loc loss 30.671926498413086\n",
      "cls loss 573.2703247070312  loc loss 41.402854919433594\n",
      "cls loss 393.3044738769531  loc loss 19.129318237304688\n",
      "cls loss 461.88934326171875  loc loss 36.923728942871094\n",
      "cls loss 443.87652587890625  loc loss 26.907697677612305\n",
      "cls loss 253.6626739501953  loc loss 10.670296669006348\n",
      "cls loss 370.78485107421875  loc loss 22.692317962646484\n",
      "cls loss 304.8216552734375  loc loss 14.749348640441895\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1., 35.])\n",
      "cls loss 335.1261291503906  loc loss 20.370742797851562\n",
      "cls loss 532.8087768554688  loc loss 27.612667083740234\n",
      "cls loss 519.0692749023438  loc loss 32.78649139404297\n",
      "cls loss 466.5055847167969  loc loss 38.37999725341797\n",
      "cls loss 372.7567443847656  loc loss 29.217870712280273\n",
      "cls loss 505.97686767578125  loc loss 40.29610061645508\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 276.2530517578125  loc loss 17.596511840820312\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 405.95062255859375  loc loss 18.275142669677734\n",
      "cls loss 654.1900024414062  loc loss 41.09879684448242\n",
      "cls loss 793.4747314453125  loc loss 63.57585906982422\n",
      "cls loss 409.0028076171875  loc loss 22.009090423583984\n",
      "cls loss 353.669677734375  loc loss 21.235271453857422\n",
      "cls loss 379.2630310058594  loc loss 18.757246017456055\n",
      "cls loss 394.1305847167969  loc loss 23.62434959411621\n",
      "cls loss 338.60711669921875  loc loss 15.05224323272705\n",
      "cls loss 610.772216796875  loc loss 44.06895446777344\n",
      "cls loss 523.3017578125  loc loss 33.15587615966797\n",
      "cls loss 223.6563720703125  loc loss 17.44951820373535\n",
      "cls loss 478.4490051269531  loc loss 28.55131721496582\n",
      "cls loss 597.29248046875  loc loss 48.232791900634766\n",
      "cls loss 459.6324462890625  loc loss 32.69273376464844\n",
      "cls loss 382.92413330078125  loc loss 24.3519344329834\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.])\n",
      "cls loss 390.5622253417969  loc loss 28.87482261657715\n",
      "cls loss 393.48046875  loc loss 26.2349853515625\n",
      "cls loss 501.43280029296875  loc loss 33.43081283569336\n",
      "cls loss 812.084716796875  loc loss 64.28050231933594\n",
      "cls loss 311.2926025390625  loc loss 17.205705642700195\n",
      "cls loss 407.9377136230469  loc loss 26.512863159179688\n",
      "cls loss 331.08026123046875  loc loss 20.42300796508789\n",
      "cls loss 357.3919677734375  loc loss 26.2193603515625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 21., 21., 21.])\n",
      "cls loss 376.8412780761719  loc loss 23.253551483154297\n",
      "cls loss 364.4036560058594  loc loss 19.392545700073242\n",
      "cls loss 376.0328063964844  loc loss 26.37615966796875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 35.])\n",
      "cls loss 499.818603515625  loc loss 30.718523025512695\n",
      "cls loss 186.0490264892578  loc loss 10.049163818359375\n",
      "cls loss 327.5747375488281  loc loss 20.51837158203125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 300.355712890625  loc loss 14.427913665771484\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 38., 38.,  9., 38.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1.,  1.])\n",
      "cls loss 350.5683288574219  loc loss 22.806781768798828\n",
      "cls loss 569.9439697265625  loc loss 36.97726058959961\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 2.,  1., 77., 31., 10., 10.,  1.,  4., 10.])\n",
      "cls loss 266.2299499511719  loc loss 13.458084106445312\n",
      "cls loss 520.371337890625  loc loss 34.80021667480469\n",
      "cls loss 1089.0477294921875  loc loss 63.759212493896484\n",
      "cls loss 327.5780944824219  loc loss 22.003135681152344\n",
      "cls loss 463.2133483886719  loc loss 34.309505462646484\n",
      "cls loss 327.5221252441406  loc loss 16.813005447387695\n",
      "cls loss 316.02947998046875  loc loss 16.770092010498047\n",
      "cls loss 467.93212890625  loc loss 26.090600967407227\n",
      "cls loss 473.1060791015625  loc loss 27.56271743774414\n",
      "cls loss 421.78472900390625  loc loss 31.763011932373047\n",
      "cls loss 355.003173828125  loc loss 16.935945510864258\n",
      "cls loss 353.12353515625  loc loss 21.115442276000977\n",
      "cls loss 650.16943359375  loc loss 41.46327590942383\n",
      "cls loss 609.020263671875  loc loss 35.19033432006836\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1., 42., 42., 42., 42., 42., 42.,  1.,\n",
      "         1.,  1.,  1., 42.,  1.,  1., 42.,  1.])\n",
      "cls loss 338.4068603515625  loc loss 24.166336059570312\n",
      "cls loss 507.03680419921875  loc loss 29.291868209838867\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.])\n",
      "cls loss 219.83004760742188  loc loss 12.442400932312012\n",
      "cls loss 511.14727783203125  loc loss 32.713985443115234\n",
      "cls loss 375.42572021484375  loc loss 29.195987701416016\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([11.])\n",
      "cls loss 229.4257354736328  loc loss 14.669520378112793\n",
      "cls loss 256.75140380859375  loc loss 14.434564590454102\n",
      "cls loss 281.27105712890625  loc loss 15.350205421447754\n",
      "cls loss 498.7265625  loc loss 32.04344177246094\n",
      "cls loss 392.7004699707031  loc loss 24.792123794555664\n",
      "cls loss 432.3758544921875  loc loss 27.820831298828125\n",
      "cls loss 612.0645751953125  loc loss 32.229644775390625\n",
      "cls loss 328.41162109375  loc loss 18.60620880126953\n",
      "cls loss 691.970947265625  loc loss 44.196712493896484\n",
      "cls loss 335.8968505859375  loc loss 21.087358474731445\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 306.29998779296875  loc loss 19.349838256835938\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1., 38., 38., 42.])\n",
      "cls loss 399.416748046875  loc loss 28.238523483276367\n",
      "cls loss 363.0211181640625  loc loss 22.284761428833008\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 317.1734924316406  loc loss 21.22869110107422\n",
      "cls loss 708.7612915039062  loc loss 46.11780548095703\n",
      "cls loss 433.9730224609375  loc loss 26.663742065429688\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10.,  3.,  3.,  6.,  8.,  8.,  1.,  1.,  1., 10.])\n",
      "cls loss 333.616943359375  loc loss 17.188980102539062\n",
      "cls loss 217.10202026367188  loc loss 8.43095874786377\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10.,  3.])\n",
      "cls loss 313.39617919921875  loc loss 18.638656616210938\n",
      "cls loss 154.79263305664062  loc loss 10.033551216125488\n",
      "cls loss 396.26519775390625  loc loss 29.10692596435547\n",
      "cls loss 487.55224609375  loc loss 31.222137451171875\n",
      "cls loss 349.28900146484375  loc loss 22.32464599609375\n",
      "cls loss 223.2489013671875  loc loss 13.559577941894531\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 34.])\n",
      "cls loss 571.64208984375  loc loss 38.48775100708008\n",
      "cls loss 686.640869140625  loc loss 51.11956787109375\n",
      "cls loss 443.5606689453125  loc loss 30.874563217163086\n",
      "cls loss 357.01617431640625  loc loss 23.63330841064453\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.,  1.])\n",
      "cls loss 388.1566162109375  loc loss 16.607818603515625\n",
      "cls loss 608.1553955078125  loc loss 43.48055648803711\n",
      "cls loss 847.3310546875  loc loss 54.39803695678711\n",
      "cls loss 691.4652099609375  loc loss 38.60028839111328\n",
      "cls loss 397.07354736328125  loc loss 22.159942626953125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 446.8402099609375  loc loss 27.38548469543457\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10.])\n",
      "cls loss 277.3941650390625  loc loss 16.28146743774414\n",
      "cls loss 418.5077209472656  loc loss 21.066844940185547\n",
      "cls loss 395.2206115722656  loc loss 23.74475860595703\n",
      "cls loss 267.9034729003906  loc loss 15.783184051513672\n",
      "cls loss 371.3706970214844  loc loss 24.208778381347656\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21.,\n",
      "        21.])\n",
      "cls loss 457.5887451171875  loc loss 27.985708236694336\n",
      "cls loss 393.0628662109375  loc loss 23.909387588500977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 261.5907287597656  loc loss 12.158235549926758\n",
      "cls loss 579.9765625  loc loss 36.88197708129883\n",
      "cls loss 430.53009033203125  loc loss 28.261554718017578\n",
      "cls loss 340.5502624511719  loc loss 16.63372802734375\n",
      "cls loss 659.10693359375  loc loss 39.01811218261719\n",
      "cls loss 758.4594116210938  loc loss 52.81614303588867\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15., 85.])\n",
      "cls loss 501.4534912109375  loc loss 29.448226928710938\n",
      "cls loss 482.67303466796875  loc loss 36.87636947631836\n",
      "cls loss 492.82476806640625  loc loss 34.95132827758789\n",
      "cls loss 403.6107482910156  loc loss 25.0643310546875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 8., 8.])\n",
      "cls loss 278.70489501953125  loc loss 12.57316780090332\n",
      "cls loss 283.2303161621094  loc loss 22.78665542602539\n",
      "cls loss 364.6798095703125  loc loss 22.47669219970703\n",
      "cls loss 316.56884765625  loc loss 18.050762176513672\n",
      "cls loss 350.00604248046875  loc loss 21.395139694213867\n",
      "cls loss 504.1663513183594  loc loss 29.517274856567383\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1., 35., 27., 27.,  1., 27.,  1.])\n",
      "cls loss 567.9969482421875  loc loss 44.92171859741211\n",
      "cls loss 345.81072998046875  loc loss 21.23754119873047\n",
      "cls loss 371.35919189453125  loc loss 28.305999755859375\n",
      "cls loss 361.57623291015625  loc loss 31.844867706298828\n",
      "cls loss 332.83355712890625  loc loss 21.739334106445312\n",
      "cls loss 373.1041564941406  loc loss 27.242305755615234\n",
      "cls loss 388.09576416015625  loc loss 26.9320068359375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  2.,  2.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  2.,  2.])\n",
      "cls loss 193.32765197753906  loc loss 8.284892082214355\n",
      "cls loss 594.8805541992188  loc loss 36.31325912475586\n",
      "cls loss 361.78619384765625  loc loss 18.56434440612793\n",
      "cls loss 632.9569702148438  loc loss 47.574798583984375\n",
      "cls loss 241.72970581054688  loc loss 14.336466789245605\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 19., 19., 19., 16.])\n",
      "cls loss 245.7813720703125  loc loss 11.366361618041992\n",
      "cls loss 205.6744842529297  loc loss 8.858861923217773\n",
      "cls loss 347.97991943359375  loc loss 17.268938064575195\n",
      "cls loss 461.6563720703125  loc loss 29.84628677368164\n",
      "cls loss 175.5006561279297  loc loss 15.300371170043945\n",
      "cls loss 505.6685485839844  loc loss 38.21221923828125\n",
      "cls loss 376.7595520019531  loc loss 25.050350189208984\n",
      "cls loss 385.84979248046875  loc loss 24.710063934326172\n",
      "cls loss 503.3846740722656  loc loss 32.533199310302734\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 515.3796997070312  loc loss 24.28068733215332\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 733.2977294921875  loc loss 61.833251953125\n",
      "cls loss 948.89013671875  loc loss 85.37254333496094\n",
      "cls loss 485.8460693359375  loc loss 28.909189224243164\n",
      "cls loss 443.0594787597656  loc loss 25.82292366027832\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3.,  3.,  3.,  3.,  3., 10.])\n",
      "cls loss 218.44573974609375  loc loss 13.546344757080078\n",
      "cls loss 462.9116516113281  loc loss 20.73982048034668\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 1., 1., 1., 3., 3., 3., 3.])\n",
      "cls loss 355.118408203125  loc loss 18.00037384033203\n",
      "cls loss 679.715576171875  loc loss 40.9420051574707\n",
      "cls loss 539.9983520507812  loc loss 31.377193450927734\n",
      "cls loss 338.54150390625  loc loss 19.083694458007812\n",
      "cls loss 546.0401611328125  loc loss 35.96101760864258\n",
      "cls loss 319.21002197265625  loc loss 23.149307250976562\n",
      "cls loss 515.8958129882812  loc loss 35.026405334472656\n",
      "cls loss 392.00872802734375  loc loss 36.23149490356445\n",
      "cls loss 375.11553955078125  loc loss 24.30738067626953\n",
      "cls loss 816.5736083984375  loc loss 64.50604248046875\n",
      "cls loss 535.5022583007812  loc loss 39.96051788330078\n",
      "cls loss 363.5976257324219  loc loss 17.96448516845703\n",
      "cls loss 228.5666046142578  loc loss 9.97770881652832\n",
      "cls loss 282.5621337890625  loc loss 12.823507308959961\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3., 10., 10., 10., 10., 10., 10., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10., 10., 10., 10., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 11., 10., 10., 10., 10., 10.,  3.,  3.,  3.,  3.,  3.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 11., 10., 10., 10., 10., 10.,  3.,  3.,  3.,  3.,  3.])\n",
      "cls loss 225.3061981201172  loc loss 10.446062088012695\n",
      "cls loss 318.0550842285156  loc loss 13.41085433959961\n",
      "cls loss 271.59014892578125  loc loss 15.3462495803833\n",
      "cls loss 272.1680908203125  loc loss 11.542440414428711\n",
      "cls loss 338.762451171875  loc loss 25.49593162536621\n",
      "cls loss 243.14962768554688  loc loss 10.007547378540039\n",
      "cls loss 501.0994873046875  loc loss 31.474985122680664\n",
      "cls loss 462.12432861328125  loc loss 26.058547973632812\n",
      "cls loss 668.0420532226562  loc loss 39.85913848876953\n",
      "cls loss 334.07208251953125  loc loss 23.56039047241211\n",
      "cls loss 582.4813232421875  loc loss 36.79560852050781\n",
      "cls loss 446.8660888671875  loc loss 32.56269454956055\n",
      "cls loss 452.07281494140625  loc loss 29.609376907348633\n",
      "cls loss 437.3448791503906  loc loss 30.456268310546875\n",
      "cls loss 572.1325073242188  loc loss 38.61638641357422\n",
      "cls loss 552.9598999023438  loc loss 35.89453125\n",
      "cls loss 269.201416015625  loc loss 14.16765308380127\n",
      "cls loss 537.3401489257812  loc loss 36.21753692626953\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 10.,  1., 18.])\n",
      "cls loss 245.95364379882812  loc loss 17.69035530090332\n",
      "cls loss 317.71527099609375  loc loss 12.895780563354492\n",
      "cls loss 577.8109130859375  loc loss 27.346338272094727\n",
      "cls loss 739.7994384765625  loc loss 41.83769226074219\n",
      "cls loss 444.703369140625  loc loss 29.250850677490234\n",
      "cls loss 647.5111083984375  loc loss 32.252525329589844\n",
      "cls loss 472.8376770019531  loc loss 31.703195571899414\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.,  1.,  1.])\n",
      "cls loss 550.281494140625  loc loss 34.125038146972656\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1., 38.,  1.])\n",
      "cls loss 447.9152526855469  loc loss 29.09463119506836\n",
      "cls loss 673.06298828125  loc loss 52.29668426513672\n",
      "cls loss 365.4640808105469  loc loss 25.233835220336914\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 503.9117431640625  loc loss 29.329925537109375\n",
      "cls loss 402.198974609375  loc loss 24.695037841796875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3., 10.,  8.,  3., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.])\n",
      "cls loss 463.1215515136719  loc loss 27.288524627685547\n",
      "cls loss 309.6275634765625  loc loss 22.107975006103516\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3.,  3., 11.,  3., 10., 10.,  3.,  3., 10.])\n",
      "cls loss 349.0965576171875  loc loss 19.767412185668945\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3., 10., 10., 10.])\n",
      "cls loss 406.7303466796875  loc loss 21.695083618164062\n",
      "cls loss 326.1246337890625  loc loss 21.8851318359375\n",
      "cls loss 441.23834228515625  loc loss 30.382217407226562\n",
      "cls loss 636.48291015625  loc loss 36.9379997253418\n",
      "cls loss 411.0592041015625  loc loss 26.817514419555664\n",
      "cls loss 319.4422607421875  loc loss 24.67243003845215\n",
      "cls loss 398.24371337890625  loc loss 23.07654571533203\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 9.,  9., 85., 85.])\n",
      "cls loss 320.48529052734375  loc loss 15.740180015563965\n",
      "cls loss 412.95721435546875  loc loss 28.814922332763672\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 630.2940673828125  loc loss 40.188697814941406\n",
      "cls loss 536.1588745117188  loc loss 23.375167846679688\n",
      "cls loss 610.5880126953125  loc loss 43.700439453125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10., 10., 10., 10.])\n",
      "cls loss 376.3699645996094  loc loss 25.027498245239258\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([13.])\n",
      "cls loss 597.6578979492188  loc loss 48.622894287109375\n",
      "cls loss 166.42428588867188  loc loss 10.74151611328125\n",
      "cls loss 254.96913146972656  loc loss 14.06184196472168\n",
      "cls loss 339.3652038574219  loc loss 22.30240821838379\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19.,  1.,  1.,  1., 19., 19.])\n",
      "cls loss 367.99542236328125  loc loss 26.760387420654297\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 305.19061279296875  loc loss 22.10512351989746\n",
      "cls loss 438.3780517578125  loc loss 30.68329429626465\n",
      "cls loss 342.4446105957031  loc loss 18.543479919433594\n",
      "cls loss 487.67962646484375  loc loss 23.888822555541992\n",
      "cls loss 514.8963623046875  loc loss 35.98130798339844\n",
      "cls loss 381.2567443847656  loc loss 22.41728973388672\n",
      "cls loss 610.9825439453125  loc loss 42.51348876953125\n",
      "cls loss 211.83189392089844  loc loss 10.481483459472656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 406.37127685546875  loc loss 30.988845825195312\n",
      "cls loss 321.9027099609375  loc loss 20.135482788085938\n",
      "cls loss 353.49908447265625  loc loss 20.610267639160156\n",
      "cls loss 492.51483154296875  loc loss 30.467790603637695\n",
      "cls loss 400.92462158203125  loc loss 20.997188568115234\n",
      "cls loss 572.3651123046875  loc loss 40.16352081298828\n",
      "cls loss 375.1187744140625  loc loss 23.606834411621094\n",
      "cls loss 492.553955078125  loc loss 34.12826156616211\n",
      "cls loss 713.54638671875  loc loss 43.699649810791016\n",
      "cls loss 378.70269775390625  loc loss 29.498390197753906\n",
      "cls loss 459.0986328125  loc loss 25.993206024169922\n",
      "cls loss 537.9293823242188  loc loss 41.17525863647461\n",
      "cls loss 618.9593505859375  loc loss 44.09169006347656\n",
      "cls loss 689.9945068359375  loc loss 42.00325393676758\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 5.])\n",
      "cls loss 178.39761352539062  loc loss 9.553840637207031\n",
      "cls loss 253.66278076171875  loc loss 10.946529388427734\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 13.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 6., 8., 8.])\n",
      "cls loss 195.4580078125  loc loss 10.766382217407227\n",
      "cls loss 258.5569152832031  loc loss 13.451292037963867\n",
      "cls loss 524.3135986328125  loc loss 34.97853469848633\n",
      "cls loss 216.15077209472656  loc loss 12.382109642028809\n",
      "cls loss 456.857666015625  loc loss 32.709373474121094\n",
      "cls loss 650.556640625  loc loss 48.4055290222168\n",
      "cls loss 424.593017578125  loc loss 28.910804748535156\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([42., 42.,  1.,  1.,  1.,  1.,  1.,  1.,  1., 42., 42.])\n",
      "cls loss 451.4091491699219  loc loss 24.064096450805664\n",
      "cls loss 587.8963623046875  loc loss 46.39192581176758\n",
      "cls loss 553.425537109375  loc loss 36.594886779785156\n",
      "cls loss 354.21002197265625  loc loss 21.16323471069336\n",
      "cls loss 465.6693115234375  loc loss 24.317886352539062\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 673.2151489257812  loc loss 40.78856658935547\n",
      "cls loss 530.9959716796875  loc loss 34.77787780761719\n",
      "cls loss 318.074462890625  loc loss 16.821685791015625\n",
      "cls loss 268.0157165527344  loc loss 15.849603652954102\n",
      "cls loss 347.6545715332031  loc loss 23.763511657714844\n",
      "cls loss 492.63055419921875  loc loss 34.09726333618164\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15.])\n",
      "cls loss 236.0882568359375  loc loss 9.308940887451172\n",
      "cls loss 413.14013671875  loc loss 26.738483428955078\n",
      "cls loss 356.7043151855469  loc loss 25.377796173095703\n",
      "cls loss 651.3226318359375  loc loss 42.95941925048828\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19.,  7.])\n",
      "cls loss 309.9187927246094  loc loss 18.347137451171875\n",
      "cls loss 650.7969970703125  loc loss 45.0862922668457\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 585.5257568359375  loc loss 29.860397338867188\n",
      "cls loss 518.71826171875  loc loss 36.69172286987305\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([38., 38.,  1., 18.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1., 18., 18.,  1.])\n",
      "cls loss 353.7218017578125  loc loss 20.80221176147461\n",
      "cls loss 348.03350830078125  loc loss 20.322242736816406\n",
      "cls loss 685.34130859375  loc loss 49.47845458984375\n",
      "cls loss 523.773681640625  loc loss 37.03934097290039\n",
      "cls loss 408.0936279296875  loc loss 28.66058349609375\n",
      "cls loss 276.39434814453125  loc loss 21.588714599609375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.])\n",
      "cls loss 179.330078125  loc loss 7.3381829261779785\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([32.])\n",
      "cls loss 431.4619140625  loc loss 23.72594451904297\n",
      "cls loss 366.98101806640625  loc loss 25.530662536621094\n",
      "cls loss 462.7313232421875  loc loss 36.957759857177734\n",
      "cls loss 409.26397705078125  loc loss 27.005645751953125\n",
      "cls loss 343.9791564941406  loc loss 23.577608108520508\n",
      "cls loss 553.3741455078125  loc loss 36.164188385009766\n",
      "cls loss 665.9359130859375  loc loss 48.56651306152344\n",
      "cls loss 479.5325927734375  loc loss 38.05384826660156\n",
      "cls loss 376.4804992675781  loc loss 23.841594696044922\n",
      "cls loss 612.413330078125  loc loss 42.032039642333984\n",
      "cls loss 421.7879638671875  loc loss 22.478723526000977\n",
      "cls loss 746.0279541015625  loc loss 49.435264587402344\n",
      "cls loss 503.58905029296875  loc loss 29.202434539794922\n",
      "cls loss 388.4464416503906  loc loss 33.83808898925781\n",
      "cls loss 303.6929626464844  loc loss 18.348962783813477\n",
      "cls loss 334.5758972167969  loc loss 23.922945022583008\n",
      "cls loss 484.5782775878906  loc loss 35.534000396728516\n",
      "cls loss 533.3635864257812  loc loss 42.591453552246094\n",
      "cls loss 306.0440673828125  loc loss 21.115427017211914\n",
      "cls loss 534.9061279296875  loc loss 40.85457229614258\n",
      "cls loss 644.54296875  loc loss 45.448726654052734\n",
      "cls loss 238.72116088867188  loc loss 16.309274673461914\n",
      "cls loss 632.40771484375  loc loss 47.72846984863281\n",
      "cls loss 473.499267578125  loc loss 33.76266860961914\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 622.194091796875  loc loss 53.49140167236328\n",
      "cls loss 285.014404296875  loc loss 13.600351333618164\n",
      "cls loss 441.185546875  loc loss 26.893056869506836\n",
      "cls loss 456.8221435546875  loc loss 30.441329956054688\n",
      "cls loss 377.16522216796875  loc loss 23.39406394958496\n",
      "cls loss 204.59384155273438  loc loss 11.206358909606934\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 9., 9., 1., 9., 9., 9., 9., 1., 9.])\n",
      "cls loss 860.0014038085938  loc loss 65.49132537841797\n",
      "cls loss 463.1739501953125  loc loss 30.656776428222656\n",
      "cls loss 718.8946533203125  loc loss 60.98194122314453\n",
      "cls loss 289.9251708984375  loc loss 24.831945419311523\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 42., 42.])\n",
      "cls loss 485.0303039550781  loc loss 41.24919509887695\n",
      "cls loss 504.07537841796875  loc loss 43.904178619384766\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  2.,  1.,  1.,  1., 38.,\n",
      "         1.,  1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 38., 38., 38.,  1., 38., 38., 38.,  1.,  1., 38.,  1.,\n",
      "         1.])\n",
      "cls loss 286.5384521484375  loc loss 23.575979232788086\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  8.,  8.])\n",
      "cls loss 693.14501953125  loc loss 53.358192443847656\n",
      "cls loss 708.3170166015625  loc loss 54.8341064453125\n",
      "cls loss 267.0416259765625  loc loss 17.338960647583008\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([4., 1., 1., 4.])\n",
      "cls loss 456.4908752441406  loc loss 27.166982650756836\n",
      "cls loss 559.7750244140625  loc loss 33.91307830810547\n",
      "cls loss 221.00564575195312  loc loss 12.163902282714844\n",
      "cls loss 285.43701171875  loc loss 19.84390640258789\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([51.,  1.])\n",
      "cls loss 195.34410095214844  loc loss 10.824170112609863\n",
      "cls loss 280.59521484375  loc loss 22.57208824157715\n",
      "cls loss 582.7745361328125  loc loss 34.51084899902344\n",
      "cls loss 529.8790893554688  loc loss 48.47371292114258\n",
      "cls loss 834.3710327148438  loc loss 45.85923385620117\n",
      "cls loss 952.265380859375  loc loss 65.7325668334961\n",
      "cls loss 376.86724853515625  loc loss 26.106170654296875\n",
      "cls loss 544.9171142578125  loc loss 45.82054138183594\n",
      "cls loss 632.2093505859375  loc loss 48.64594268798828\n",
      "cls loss 430.55181884765625  loc loss 32.535484313964844\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  3.,  1.,  1.,  1.,  3.,  1.,  1.,\n",
      "         1.,  1.,  1.])\n",
      "cls loss 471.51336669921875  loc loss 25.48155403137207\n",
      "cls loss 527.4346313476562  loc loss 37.984405517578125\n",
      "cls loss 511.6191711425781  loc loss 36.702823638916016\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "cls loss 444.0780029296875  loc loss 28.415531158447266\n",
      "cls loss 252.7010498046875  loc loss 20.34695053100586\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3.])\n",
      "cls loss 215.31317138671875  loc loss 11.791338920593262\n",
      "cls loss 354.39276123046875  loc loss 22.76205062866211\n",
      "cls loss 351.71917724609375  loc loss 24.009126663208008\n",
      "cls loss 599.936279296875  loc loss 40.405494689941406\n",
      "cls loss 271.849365234375  loc loss 22.66600799560547\n",
      "cls loss 305.6309814453125  loc loss 27.576759338378906\n",
      "cls loss 888.28662109375  loc loss 73.474609375\n",
      "cls loss 380.0304870605469  loc loss 33.38671875\n",
      "cls loss 284.3651123046875  loc loss 25.995975494384766\n",
      "cls loss 339.013671875  loc loss 21.74503517150879\n",
      "cls loss 310.91009521484375  loc loss 26.27098274230957\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 585.4879150390625  loc loss 44.09607696533203\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  9., 64., 64., 64., 64., 64., 64., 64., 64., 64.,  9.,  9.,  9.,\n",
      "         9.])\n",
      "cls loss 278.6419677734375  loc loss 18.470046997070312\n",
      "cls loss 855.2392578125  loc loss 66.54593658447266\n",
      "cls loss 445.9536437988281  loc loss 30.011211395263672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 554.9924926757812  loc loss 39.585289001464844\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.,  3.,  3.])\n",
      "cls loss 325.0304870605469  loc loss 21.438541412353516\n",
      "cls loss 383.17901611328125  loc loss 31.0443115234375\n",
      "cls loss 407.2881164550781  loc loss 32.47645568847656\n",
      "cls loss 433.866455078125  loc loss 28.339982986450195\n",
      "cls loss 483.08026123046875  loc loss 34.23344802856445\n",
      "cls loss 456.29412841796875  loc loss 31.650026321411133\n",
      "cls loss 401.46600341796875  loc loss 30.02853775024414\n",
      "cls loss 412.8370056152344  loc loss 24.47077178955078\n",
      "cls loss 527.2559814453125  loc loss 36.97610092163086\n",
      "cls loss 399.1676940917969  loc loss 25.20427131652832\n",
      "cls loss 307.3538513183594  loc loss 16.650575637817383\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21.])\n",
      "cls loss 242.0469970703125  loc loss 17.207386016845703\n",
      "cls loss 346.5653381347656  loc loss 31.812789916992188\n",
      "cls loss 521.7545776367188  loc loss 38.12498474121094\n",
      "cls loss 279.58123779296875  loc loss 16.86585807800293\n",
      "cls loss 449.3514709472656  loc loss 30.38106346130371\n",
      "cls loss 817.2841186523438  loc loss 44.58301544189453\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 42., 42.,  1.,  1.])\n",
      "cls loss 497.814697265625  loc loss 27.15184211730957\n",
      "cls loss 320.40386962890625  loc loss 18.61964988708496\n",
      "cls loss 439.4023132324219  loc loss 27.792142868041992\n",
      "cls loss 559.3110961914062  loc loss 43.679691314697266\n",
      "cls loss 343.23846435546875  loc loss 21.170732498168945\n",
      "cls loss 527.021728515625  loc loss 39.053062438964844\n",
      "cls loss 477.23211669921875  loc loss 36.41514205932617\n",
      "cls loss 459.54754638671875  loc loss 30.33391571044922\n",
      "cls loss 382.46929931640625  loc loss 25.6400089263916\n",
      "cls loss 303.9647521972656  loc loss 22.8018798828125\n",
      "cls loss 249.44818115234375  loc loss 11.58358383178711\n",
      "cls loss 383.46600341796875  loc loss 25.206090927124023\n",
      "cls loss 576.7286376953125  loc loss 38.54914474487305\n",
      "cls loss 455.4216613769531  loc loss 26.081945419311523\n",
      "cls loss 421.70330810546875  loc loss 31.199268341064453\n",
      "cls loss 472.1180725097656  loc loss 27.658817291259766\n",
      "cls loss 697.30224609375  loc loss 50.73554611206055\n",
      "cls loss 557.4698486328125  loc loss 35.79501724243164\n",
      "cls loss 595.5482788085938  loc loss 31.151193618774414\n",
      "cls loss 372.2671813964844  loc loss 16.55777359008789\n",
      "cls loss 498.5977783203125  loc loss 30.65889549255371\n",
      "cls loss 444.96466064453125  loc loss 26.692251205444336\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 5., 5., 5., 5., 5., 5.])\n",
      "cls loss 280.3059997558594  loc loss 18.402294158935547\n",
      "cls loss 359.79052734375  loc loss 20.769872665405273\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([13.])\n",
      "cls loss 253.126708984375  loc loss 13.32686996459961\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([44., 10.,  1.,  1.,  1.])\n",
      "cls loss 241.94024658203125  loc loss 16.30379867553711\n",
      "cls loss 427.0662841796875  loc loss 24.640766143798828\n",
      "cls loss 395.8023681640625  loc loss 21.72081184387207\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19., 19., 19., 19., 19., 19., 19.])\n",
      "cls loss 411.1553955078125  loc loss 26.779407501220703\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([56.])\n",
      "cls loss 863.5093994140625  loc loss 57.86345672607422\n",
      "cls loss 549.9855346679688  loc loss 40.892173767089844\n",
      "cls loss 702.4220581054688  loc loss 45.573204040527344\n",
      "cls loss 694.5078125  loc loss 52.996795654296875\n",
      "cls loss 481.15277099609375  loc loss 24.15223503112793\n",
      "cls loss 746.2274169921875  loc loss 45.43110275268555\n",
      "cls loss 448.07244873046875  loc loss 26.27422523498535\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 36.])\n",
      "cls loss 544.1142578125  loc loss 23.922788619995117\n",
      "cls loss 414.40234375  loc loss 27.433950424194336\n",
      "cls loss 383.4487609863281  loc loss 24.060815811157227\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5.])\n",
      "cls loss 434.94091796875  loc loss 28.125469207763672\n",
      "cls loss 234.3931427001953  loc loss 12.813355445861816\n",
      "cls loss 563.7369995117188  loc loss 33.557289123535156\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "cls loss 501.7010192871094  loc loss 32.390472412109375\n",
      "cls loss 472.4980773925781  loc loss 31.79192352294922\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 509.75213623046875  loc loss 33.12656021118164\n",
      "cls loss 560.9891357421875  loc loss 38.777061462402344\n",
      "cls loss 481.727294921875  loc loss 41.37474822998047\n",
      "cls loss 350.05792236328125  loc loss 22.138553619384766\n",
      "cls loss 399.9790344238281  loc loss 28.823007583618164\n",
      "cls loss 444.5166320800781  loc loss 24.430923461914062\n",
      "cls loss 689.1766357421875  loc loss 34.40510559082031\n",
      "cls loss 299.3609619140625  loc loss 14.095878601074219\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 11., 15., 10., 10., 10., 10., 10.])\n",
      "cls loss 661.6100463867188  loc loss 40.7849006652832\n",
      "cls loss 393.64312744140625  loc loss 27.817745208740234\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3.])\n",
      "cls loss 400.8140869140625  loc loss 28.515525817871094\n",
      "cls loss 365.51165771484375  loc loss 19.62803840637207\n",
      "cls loss 402.74029541015625  loc loss 19.19870376586914\n",
      "cls loss 504.9211120605469  loc loss 23.356245040893555\n",
      "cls loss 238.7206573486328  loc loss 11.928963661193848\n",
      "cls loss 402.47393798828125  loc loss 28.235044479370117\n",
      "cls loss 484.01123046875  loc loss 31.51627540588379\n",
      "cls loss 399.3413391113281  loc loss 29.002159118652344\n",
      "cls loss 960.1458129882812  loc loss 64.90792083740234\n",
      "cls loss 638.0945434570312  loc loss 42.582523345947266\n",
      "cls loss 413.1990966796875  loc loss 28.416404724121094\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  9.,  9.,  9.,  6.,  6., 85., 85.,  8.,  1.,  1.,  1.,  1.,\n",
      "         6.,  6.])\n",
      "cls loss 280.44158935546875  loc loss 22.42982292175293\n",
      "cls loss 709.4009399414062  loc loss 49.259552001953125\n",
      "cls loss 836.312255859375  loc loss 49.95458221435547\n",
      "cls loss 541.18896484375  loc loss 36.683074951171875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10.,  3.,  3., 10.])\n",
      "cls loss 350.926025390625  loc loss 18.74262237548828\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([7.])\n",
      "cls loss 455.328369140625  loc loss 28.98699188232422\n",
      "cls loss 447.0998840332031  loc loss 27.278160095214844\n",
      "cls loss 448.6656494140625  loc loss 37.077049255371094\n",
      "cls loss 684.6927490234375  loc loss 49.284698486328125\n",
      "cls loss 400.7344970703125  loc loss 27.14949607849121\n",
      "cls loss 586.4092407226562  loc loss 39.31023406982422\n",
      "cls loss 761.4161376953125  loc loss 45.13092041015625\n",
      "cls loss 458.9831848144531  loc loss 29.57809066772461\n",
      "cls loss 503.6287841796875  loc loss 34.45059585571289\n",
      "cls loss 384.4307861328125  loc loss 29.601316452026367\n",
      "cls loss 618.5111083984375  loc loss 45.204803466796875\n",
      "cls loss 460.06219482421875  loc loss 29.889039993286133\n",
      "cls loss 359.7668762207031  loc loss 22.28628158569336\n",
      "cls loss 556.787109375  loc loss 42.297080993652344\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([62.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([62.])\n",
      "cls loss 268.05133056640625  loc loss 12.31430435180664\n",
      "cls loss 413.74468994140625  loc loss 30.235261917114258\n",
      "cls loss 411.70574951171875  loc loss 27.446786880493164\n",
      "cls loss 266.15057373046875  loc loss 13.96950912475586\n",
      "cls loss 581.08349609375  loc loss 36.871063232421875\n",
      "cls loss 577.27587890625  loc loss 31.705575942993164\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([28.])\n",
      "cls loss 712.28271484375  loc loss 32.53718566894531\n",
      "cls loss 522.1021118164062  loc loss 33.307106018066406\n",
      "cls loss 523.488525390625  loc loss 36.940433502197266\n",
      "cls loss 555.6658325195312  loc loss 35.796695709228516\n",
      "cls loss 742.6173095703125  loc loss 50.532352447509766\n",
      "cls loss 442.34613037109375  loc loss 27.194194793701172\n",
      "cls loss 585.6991577148438  loc loss 32.129295349121094\n",
      "cls loss 468.85333251953125  loc loss 37.53590393066406\n",
      "cls loss 788.20654296875  loc loss 58.93911361694336\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([81.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 478.94366455078125  loc loss 20.387775421142578\n",
      "cls loss 375.9378356933594  loc loss 19.78529167175293\n",
      "cls loss 276.37420654296875  loc loss 20.914554595947266\n",
      "cls loss 251.25221252441406  loc loss 11.035799026489258\n",
      "cls loss 279.565185546875  loc loss 22.495059967041016\n",
      "cls loss 352.6502380371094  loc loss 22.702930450439453\n",
      "cls loss 350.6875305175781  loc loss 27.537580490112305\n",
      "cls loss 509.8302917480469  loc loss 45.1011848449707\n",
      "cls loss 638.3289794921875  loc loss 38.60578536987305\n",
      "cls loss 1073.712158203125  loc loss 75.02995300292969\n",
      "cls loss 430.7212219238281  loc loss 21.900999069213867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 533.7216186523438  loc loss 39.31743240356445\n",
      "cls loss 373.09564208984375  loc loss 23.107128143310547\n",
      "cls loss 493.4024658203125  loc loss 28.628435134887695\n",
      "cls loss 418.5086669921875  loc loss 25.82275390625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([44., 44.])\n",
      "cls loss 363.88507080078125  loc loss 20.12262725830078\n",
      "cls loss 409.80419921875  loc loss 31.141088485717773\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15.])\n",
      "cls loss 412.10150146484375  loc loss 25.480695724487305\n",
      "cls loss 216.7025146484375  loc loss 15.939520835876465\n",
      "cls loss 427.2923889160156  loc loss 32.61515808105469\n",
      "cls loss 263.2598571777344  loc loss 13.669137954711914\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([1., 3., 3.])\n",
      "cls loss 291.91778564453125  loc loss 18.92184066772461\n",
      "cls loss 211.25160217285156  loc loss 10.901683807373047\n",
      "cls loss 396.4895324707031  loc loss 28.452537536621094\n",
      "cls loss 465.364013671875  loc loss 27.459190368652344\n",
      "cls loss 409.3562316894531  loc loss 27.8989200592041\n",
      "cls loss 350.07867431640625  loc loss 23.548776626586914\n",
      "cls loss 363.54510498046875  loc loss 27.754547119140625\n",
      "cls loss 487.8319091796875  loc loss 32.60329818725586\n",
      "cls loss 339.46563720703125  loc loss 23.772520065307617\n",
      "cls loss 454.5627746582031  loc loss 35.47081756591797\n",
      "cls loss 324.5389404296875  loc loss 21.168928146362305\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 557.377197265625  loc loss 34.61164093017578\n",
      "cls loss 674.7296142578125  loc loss 33.144683837890625\n",
      "cls loss 573.666259765625  loc loss 40.498146057128906\n",
      "cls loss 560.8934326171875  loc loss 45.83619689941406\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10., 10., 10.,  1.,  1.,  1.,  1.,  1.,  1.,  8.,  8.,\n",
      "         1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10., 10., 10.,  1.,  1.,  1.,  1.,  1.,  1.,  8.,  8.,\n",
      "         1.])\n",
      "cls loss 457.72967529296875  loc loss 24.379837036132812\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 3., 3., 3.])\n",
      "cls loss 446.0576477050781  loc loss 26.322711944580078\n",
      "cls loss 290.31207275390625  loc loss 18.16730308532715\n",
      "cls loss 218.50567626953125  loc loss 11.679779052734375\n",
      "cls loss 420.546875  loc loss 34.915992736816406\n",
      "cls loss 316.76593017578125  loc loss 17.46089744567871\n",
      "cls loss 387.9310302734375  loc loss 30.282485961914062\n",
      "cls loss 436.8927001953125  loc loss 36.0698127746582\n",
      "cls loss 586.0138549804688  loc loss 49.85584259033203\n",
      "cls loss 510.10357666015625  loc loss 30.275882720947266\n",
      "cls loss 468.51055908203125  loc loss 27.624338150024414\n",
      "cls loss 487.06121826171875  loc loss 32.735992431640625\n",
      "cls loss 346.9212951660156  loc loss 26.862503051757812\n",
      "cls loss 699.0824584960938  loc loss 50.82594299316406\n",
      "cls loss 311.7198791503906  loc loss 18.24362564086914\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 563.1785278320312  loc loss 33.86507034301758\n",
      "cls loss 249.98980712890625  loc loss 12.659598350524902\n",
      "cls loss 624.4818115234375  loc loss 48.6618537902832\n",
      "cls loss 313.1059265136719  loc loss 22.29282569885254\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 34.])\n",
      "cls loss 511.6567687988281  loc loss 33.6433219909668\n",
      "cls loss 256.46295166015625  loc loss 18.395126342773438\n",
      "cls loss 527.7811889648438  loc loss 34.48023986816406\n",
      "cls loss 179.03628540039062  loc loss 14.666560173034668\n",
      "cls loss 419.3339538574219  loc loss 29.009178161621094\n",
      "cls loss 416.6875915527344  loc loss 34.253517150878906\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 38.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16., 16., 16.,  9.,  9.,  9., 16., 16., 16., 85.,  9.])\n",
      "cls loss 428.50146484375  loc loss 27.67061996459961\n",
      "cls loss 466.3952331542969  loc loss 36.160377502441406\n",
      "cls loss 626.0963134765625  loc loss 41.92382049560547\n",
      "cls loss 981.0557861328125  loc loss 61.52993392944336\n",
      "cls loss 259.9064025878906  loc loss 14.26447868347168\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3., 10.,  8.,  8., 10., 10., 10.,  3.,  3., 14.])\n",
      "cls loss 276.7018737792969  loc loss 16.316312789916992\n",
      "cls loss 521.0931396484375  loc loss 34.06991195678711\n",
      "cls loss 230.12725830078125  loc loss 9.964029312133789\n",
      "cls loss 392.64569091796875  loc loss 18.303974151611328\n",
      "cls loss 526.0616455078125  loc loss 36.254302978515625\n",
      "cls loss 453.81982421875  loc loss 29.74166488647461\n",
      "cls loss 249.52098083496094  loc loss 14.975736618041992\n",
      "cls loss 332.45452880859375  loc loss 16.82107925415039\n",
      "cls loss 536.651123046875  loc loss 30.68369483947754\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42., 42.,  1.])\n",
      "cls loss 479.618896484375  loc loss 30.8935604095459\n",
      "cls loss 367.5025329589844  loc loss 21.762163162231445\n",
      "cls loss 497.5902099609375  loc loss 39.26396179199219\n",
      "cls loss 568.8365478515625  loc loss 35.66706085205078\n",
      "cls loss 399.43017578125  loc loss 24.898984909057617\n",
      "cls loss 490.3841552734375  loc loss 35.4605712890625\n",
      "cls loss 296.3370361328125  loc loss 20.334266662597656\n",
      "cls loss 318.0305480957031  loc loss 23.48946189880371\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20.])\n",
      "cls loss 226.29177856445312  loc loss 13.623966217041016\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([11.])\n",
      "cls loss 326.8092041015625  loc loss 15.286296844482422\n",
      "cls loss 191.71327209472656  loc loss 12.715277671813965\n",
      "cls loss 493.80267333984375  loc loss 37.84385681152344\n",
      "cls loss 215.5296630859375  loc loss 10.949705123901367\n",
      "cls loss 471.51409912109375  loc loss 28.342947006225586\n",
      "cls loss 264.41778564453125  loc loss 16.638593673706055\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 35., 27.])\n",
      "cls loss 483.7646484375  loc loss 26.15052032470703\n",
      "cls loss 528.2470703125  loc loss 37.37926483154297\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 353.9669189453125  loc loss 18.651817321777344\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([42.,  1.])\n",
      "cls loss 435.4349365234375  loc loss 29.536361694335938\n",
      "cls loss 439.8941345214844  loc loss 23.189453125\n",
      "cls loss 509.6883544921875  loc loss 30.05684471130371\n",
      "cls loss 638.763427734375  loc loss 36.605812072753906\n",
      "cls loss 534.9033203125  loc loss 31.401500701904297\n",
      "cls loss 365.38043212890625  loc loss 25.105913162231445\n",
      "cls loss 306.15753173828125  loc loss 23.23521614074707\n",
      "cls loss 183.34092712402344  loc loss 8.570817947387695\n",
      "cls loss 360.67181396484375  loc loss 20.247770309448242\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 1., 1.])\n",
      "cls loss 338.85565185546875  loc loss 21.454307556152344\n",
      "cls loss 404.00616455078125  loc loss 27.351932525634766\n",
      "cls loss 389.4742736816406  loc loss 24.745418548583984\n",
      "cls loss 314.9117126464844  loc loss 23.457019805908203\n",
      "cls loss 386.3983459472656  loc loss 26.705108642578125\n",
      "cls loss 419.275390625  loc loss 30.400606155395508\n",
      "cls loss 617.2713623046875  loc loss 36.35772705078125\n",
      "cls loss 541.18310546875  loc loss 40.51919174194336\n",
      "cls loss 488.32940673828125  loc loss 30.5201416015625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 380.4130859375  loc loss 27.462291717529297\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 486.27850341796875  loc loss 20.651344299316406\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([81.])\n",
      "cls loss 549.01806640625  loc loss 32.83885955810547\n",
      "cls loss 319.7625732421875  loc loss 23.11793327331543\n",
      "cls loss 232.14376831054688  loc loss 13.0078763961792\n",
      "cls loss 350.8330078125  loc loss 19.979562759399414\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3.,  1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 19.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 19.])\n",
      "cls loss 498.47540283203125  loc loss 34.50345993041992\n",
      "cls loss 269.5971374511719  loc loss 15.982394218444824\n",
      "cls loss 294.73455810546875  loc loss 17.535781860351562\n",
      "cls loss 583.4613037109375  loc loss 42.25876235961914\n",
      "cls loss 281.47662353515625  loc loss 18.42824935913086\n",
      "cls loss 365.2448425292969  loc loss 22.636028289794922\n",
      "cls loss 464.64630126953125  loc loss 31.982765197753906\n",
      "cls loss 343.21795654296875  loc loss 25.504484176635742\n",
      "cls loss 459.9957275390625  loc loss 26.31452178955078\n",
      "cls loss 536.8453369140625  loc loss 33.55086135864258\n",
      "cls loss 688.859619140625  loc loss 57.45096969604492\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 81.])\n",
      "cls loss 468.9557800292969  loc loss 22.27399253845215\n",
      "cls loss 420.8233642578125  loc loss 22.064199447631836\n",
      "cls loss 416.9425048828125  loc loss 23.02012825012207\n",
      "cls loss 327.56671142578125  loc loss 16.9183292388916\n",
      "cls loss 282.9373474121094  loc loss 18.094228744506836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 316.91375732421875  loc loss 26.430456161499023\n",
      "cls loss 241.51023864746094  loc loss 19.414541244506836\n",
      "cls loss 216.42276000976562  loc loss 15.634033203125\n",
      "cls loss 282.1651916503906  loc loss 20.640857696533203\n",
      "cls loss 388.81109619140625  loc loss 26.82526397705078\n",
      "cls loss 348.29400634765625  loc loss 29.086868286132812\n",
      "cls loss 369.4574890136719  loc loss 25.742650985717773\n",
      "cls loss 213.96778869628906  loc loss 14.649765014648438\n",
      "cls loss 763.0965576171875  loc loss 49.90169143676758\n",
      "cls loss 425.614501953125  loc loss 29.445703506469727\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 385.8033447265625  loc loss 19.768938064575195\n",
      "cls loss 455.1787414550781  loc loss 27.734817504882812\n",
      "cls loss 368.1300964355469  loc loss 21.778947830200195\n",
      "cls loss 568.6946411132812  loc loss 36.615501403808594\n",
      "cls loss 510.9291687011719  loc loss 31.248451232910156\n",
      "cls loss 480.1580810546875  loc loss 29.45027732849121\n",
      "cls loss 340.08978271484375  loc loss 23.576589584350586\n",
      "cls loss 287.0301208496094  loc loss 17.490697860717773\n",
      "cls loss 400.67401123046875  loc loss 26.320571899414062\n",
      "cls loss 466.59515380859375  loc loss 32.64813995361328\n",
      "cls loss 437.8028564453125  loc loss 25.26412010192871\n",
      "cls loss 552.0211181640625  loc loss 38.43674850463867\n",
      "cls loss 591.2633056640625  loc loss 43.693153381347656\n",
      "cls loss 412.50146484375  loc loss 28.778717041015625\n",
      "cls loss 597.349853515625  loc loss 46.721656799316406\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1., 38., 47.,  1.,  1.,  1.,  1.,  1., 62.])\n",
      "cls loss 382.1409912109375  loc loss 19.262191772460938\n",
      "cls loss 458.64349365234375  loc loss 33.32933044433594\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 519.733642578125  loc loss 29.94301986694336\n",
      "cls loss 572.4105224609375  loc loss 40.84373474121094\n",
      "cls loss 390.99755859375  loc loss 18.42213249206543\n",
      "cls loss 462.49615478515625  loc loss 35.77288818359375\n",
      "cls loss 450.65411376953125  loc loss 25.86187744140625\n",
      "cls loss 262.20599365234375  loc loss 9.70581340789795\n",
      "cls loss 381.2854309082031  loc loss 22.067781448364258\n",
      "cls loss 308.503662109375  loc loss 14.271858215332031\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1., 35.])\n",
      "cls loss 333.84796142578125  loc loss 19.941125869750977\n",
      "cls loss 529.291015625  loc loss 27.397884368896484\n",
      "cls loss 514.9755859375  loc loss 32.16969299316406\n",
      "cls loss 463.68292236328125  loc loss 37.51945495605469\n",
      "cls loss 368.9065856933594  loc loss 28.655698776245117\n",
      "cls loss 500.4944152832031  loc loss 39.5558967590332\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 270.3375244140625  loc loss 16.98504638671875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 388.5684814453125  loc loss 17.601932525634766\n",
      "cls loss 633.341064453125  loc loss 39.47864532470703\n",
      "cls loss 777.0665283203125  loc loss 62.98994445800781\n",
      "cls loss 400.4468078613281  loc loss 21.61343002319336\n",
      "cls loss 350.12237548828125  loc loss 20.819393157958984\n",
      "cls loss 392.67620849609375  loc loss 18.225820541381836\n",
      "cls loss 409.31341552734375  loc loss 22.442413330078125\n",
      "cls loss 354.2646484375  loc loss 14.431818008422852\n",
      "cls loss 621.204833984375  loc loss 41.838722229003906\n",
      "cls loss 534.4072265625  loc loss 32.256290435791016\n",
      "cls loss 222.0308837890625  loc loss 17.007888793945312\n",
      "cls loss 474.39215087890625  loc loss 28.08846664428711\n",
      "cls loss 595.9089965820312  loc loss 47.44783401489258\n",
      "cls loss 452.49432373046875  loc loss 32.487159729003906\n",
      "cls loss 373.2677001953125  loc loss 24.28404998779297\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.])\n",
      "cls loss 390.8769226074219  loc loss 28.446556091308594\n",
      "cls loss 386.96197509765625  loc loss 25.64826202392578\n",
      "cls loss 495.80450439453125  loc loss 32.064453125\n",
      "cls loss 799.5556640625  loc loss 62.373069763183594\n",
      "cls loss 301.4544677734375  loc loss 16.816804885864258\n",
      "cls loss 399.1121826171875  loc loss 26.21068572998047\n",
      "cls loss 326.70123291015625  loc loss 19.853452682495117\n",
      "cls loss 358.166748046875  loc loss 26.29424476623535\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 21., 21., 21.])\n",
      "cls loss 390.7777404785156  loc loss 22.901269912719727\n",
      "cls loss 383.2300109863281  loc loss 18.878738403320312\n",
      "cls loss 380.1523132324219  loc loss 25.678573608398438\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 35.])\n",
      "cls loss 511.63641357421875  loc loss 30.25242805480957\n",
      "cls loss 185.03775024414062  loc loss 9.886479377746582\n",
      "cls loss 326.23175048828125  loc loss 20.06377601623535\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 296.1988525390625  loc loss 13.832243919372559\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 38., 38.,  9., 38.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1.,  1.])\n",
      "cls loss 346.68255615234375  loc loss 22.06939125061035\n",
      "cls loss 557.8580322265625  loc loss 35.74302291870117\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 2.,  1., 77., 31., 10., 10.,  1.,  4., 10.])\n",
      "cls loss 255.69891357421875  loc loss 13.07125473022461\n",
      "cls loss 509.23333740234375  loc loss 34.89185333251953\n",
      "cls loss 1070.286865234375  loc loss 62.936012268066406\n",
      "cls loss 323.6080322265625  loc loss 22.268024444580078\n",
      "cls loss 458.27410888671875  loc loss 33.98334884643555\n",
      "cls loss 321.504638671875  loc loss 16.688278198242188\n",
      "cls loss 311.82110595703125  loc loss 16.50102996826172\n",
      "cls loss 486.2507019042969  loc loss 25.42715072631836\n",
      "cls loss 487.1424560546875  loc loss 26.960567474365234\n",
      "cls loss 424.0213623046875  loc loss 30.98809242248535\n",
      "cls loss 361.35101318359375  loc loss 16.879472732543945\n",
      "cls loss 357.984619140625  loc loss 20.737621307373047\n",
      "cls loss 650.2314453125  loc loss 41.11986541748047\n",
      "cls loss 607.9903564453125  loc loss 35.187259674072266\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1., 42., 42., 42., 42., 42., 42.,  1.,\n",
      "         1.,  1.,  1., 42.,  1.,  1., 42.,  1.])\n",
      "cls loss 336.9041748046875  loc loss 24.117753982543945\n",
      "cls loss 505.78857421875  loc loss 28.677104949951172\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.])\n",
      "cls loss 216.50411987304688  loc loss 11.847957611083984\n",
      "cls loss 511.1557312011719  loc loss 31.746274948120117\n",
      "cls loss 374.51611328125  loc loss 28.424116134643555\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([11.])\n",
      "cls loss 227.95989990234375  loc loss 14.313920974731445\n",
      "cls loss 248.18914794921875  loc loss 14.2176513671875\n",
      "cls loss 272.93206787109375  loc loss 15.03559398651123\n",
      "cls loss 485.0350646972656  loc loss 32.504756927490234\n",
      "cls loss 384.87615966796875  loc loss 24.875337600708008\n",
      "cls loss 422.6553649902344  loc loss 28.035444259643555\n",
      "cls loss 610.124267578125  loc loss 31.711740493774414\n",
      "cls loss 336.04034423828125  loc loss 18.348989486694336\n",
      "cls loss 711.2904052734375  loc loss 43.11827087402344\n",
      "cls loss 357.9536437988281  loc loss 20.463651657104492\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 322.51849365234375  loc loss 19.045738220214844\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1., 38., 38., 42.])\n",
      "cls loss 406.6789245605469  loc loss 28.21982192993164\n",
      "cls loss 366.91650390625  loc loss 22.840965270996094\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 314.9862060546875  loc loss 21.41688346862793\n",
      "cls loss 702.3446044921875  loc loss 46.17618179321289\n",
      "cls loss 431.5030517578125  loc loss 26.564130783081055\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10.,  3.,  3.,  6.,  8.,  8.,  1.,  1.,  1., 10.])\n",
      "cls loss 330.4830017089844  loc loss 16.88536834716797\n",
      "cls loss 213.16122436523438  loc loss 8.349370956420898\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10.,  3.])\n",
      "cls loss 310.09991455078125  loc loss 18.406007766723633\n",
      "cls loss 151.10235595703125  loc loss 9.689535140991211\n",
      "cls loss 384.116943359375  loc loss 28.425636291503906\n",
      "cls loss 478.89013671875  loc loss 30.8254451751709\n",
      "cls loss 342.1292724609375  loc loss 21.95996856689453\n",
      "cls loss 213.2529296875  loc loss 13.557718276977539\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 34.])\n",
      "cls loss 552.10302734375  loc loss 38.87422561645508\n",
      "cls loss 687.4151611328125  loc loss 50.89015579223633\n",
      "cls loss 446.6627197265625  loc loss 30.851482391357422\n",
      "cls loss 364.4312744140625  loc loss 24.23707389831543\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.,  1.])\n",
      "cls loss 409.2384338378906  loc loss 16.583423614501953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 636.803466796875  loc loss 42.90208435058594\n",
      "cls loss 856.4566650390625  loc loss 53.38605880737305\n",
      "cls loss 693.4806518554688  loc loss 38.0057373046875\n",
      "cls loss 392.0501708984375  loc loss 21.916641235351562\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 439.6956787109375  loc loss 27.790267944335938\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10.])\n",
      "cls loss 267.79693603515625  loc loss 16.848403930664062\n",
      "cls loss 411.78204345703125  loc loss 20.97039794921875\n",
      "cls loss 386.69677734375  loc loss 23.847923278808594\n",
      "cls loss 258.19140625  loc loss 15.984210968017578\n",
      "cls loss 360.37933349609375  loc loss 23.5018367767334\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21.,\n",
      "        21.])\n",
      "cls loss 443.820068359375  loc loss 27.50646209716797\n",
      "cls loss 387.4932556152344  loc loss 22.793045043945312\n",
      "cls loss 258.6536560058594  loc loss 11.913688659667969\n",
      "cls loss 574.1015625  loc loss 36.515907287597656\n",
      "cls loss 429.50421142578125  loc loss 28.181577682495117\n",
      "cls loss 347.96099853515625  loc loss 16.57860565185547\n",
      "cls loss 667.0656127929688  loc loss 39.49311828613281\n",
      "cls loss 764.651611328125  loc loss 52.89950942993164\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15., 85.])\n",
      "cls loss 501.9718322753906  loc loss 28.60565757751465\n",
      "cls loss 486.1478271484375  loc loss 35.88372039794922\n",
      "cls loss 488.5375671386719  loc loss 34.181427001953125\n",
      "cls loss 401.5125732421875  loc loss 24.483171463012695\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 8., 8.])\n",
      "cls loss 278.1586608886719  loc loss 12.242191314697266\n",
      "cls loss 280.1735534667969  loc loss 22.671499252319336\n",
      "cls loss 359.5177001953125  loc loss 22.49001693725586\n",
      "cls loss 308.59619140625  loc loss 17.905725479125977\n",
      "cls loss 350.01287841796875  loc loss 21.978717803955078\n",
      "cls loss 496.8695373535156  loc loss 29.50299835205078\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1., 35., 27., 27.,  1., 27.,  1.])\n",
      "cls loss 556.30322265625  loc loss 45.95913314819336\n",
      "cls loss 342.7755432128906  loc loss 19.70892906188965\n",
      "cls loss 363.14715576171875  loc loss 27.22333526611328\n",
      "cls loss 357.6136474609375  loc loss 31.22582244873047\n",
      "cls loss 330.46063232421875  loc loss 21.70926284790039\n",
      "cls loss 376.9096984863281  loc loss 27.62493896484375\n",
      "cls loss 402.4502258300781  loc loss 27.511445999145508\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  2.,  2.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  2.,  2.])\n",
      "cls loss 205.79666137695312  loc loss 8.562203407287598\n",
      "cls loss 617.1766357421875  loc loss 37.14071273803711\n",
      "cls loss 370.25994873046875  loc loss 18.587257385253906\n",
      "cls loss 648.5946044921875  loc loss 46.098533630371094\n",
      "cls loss 241.03765869140625  loc loss 13.794333457946777\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 19., 19., 19., 16.])\n",
      "cls loss 241.76364135742188  loc loss 10.867887496948242\n",
      "cls loss 201.63259887695312  loc loss 8.789312362670898\n",
      "cls loss 344.49822998046875  loc loss 17.011964797973633\n",
      "cls loss 460.9010009765625  loc loss 29.353742599487305\n",
      "cls loss 170.47898864746094  loc loss 14.915934562683105\n",
      "cls loss 502.3614501953125  loc loss 39.344940185546875\n",
      "cls loss 377.32073974609375  loc loss 25.39130401611328\n",
      "cls loss 378.47369384765625  loc loss 25.11833381652832\n",
      "cls loss 498.2392272949219  loc loss 32.89069747924805\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 504.7520751953125  loc loss 24.44269371032715\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 724.5367431640625  loc loss 61.990596771240234\n",
      "cls loss 938.0064697265625  loc loss 84.1895751953125\n",
      "cls loss 486.188720703125  loc loss 28.347087860107422\n",
      "cls loss 455.1876220703125  loc loss 25.379993438720703\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3.,  3.,  3.,  3.,  3., 10.])\n",
      "cls loss 235.19552612304688  loc loss 13.704543113708496\n",
      "cls loss 500.4007568359375  loc loss 21.165069580078125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 1., 1., 1., 3., 3., 3., 3.])\n",
      "cls loss 370.9490661621094  loc loss 18.59283447265625\n",
      "cls loss 698.6715698242188  loc loss 42.20771789550781\n",
      "cls loss 540.414794921875  loc loss 30.94896697998047\n",
      "cls loss 336.8134765625  loc loss 19.633209228515625\n",
      "cls loss 545.6463623046875  loc loss 35.476280212402344\n",
      "cls loss 314.11572265625  loc loss 23.112281799316406\n",
      "cls loss 512.019775390625  loc loss 34.68250274658203\n",
      "cls loss 384.9765625  loc loss 36.40471267700195\n",
      "cls loss 369.6596374511719  loc loss 24.844135284423828\n",
      "cls loss 808.5587158203125  loc loss 65.17079162597656\n",
      "cls loss 527.3356323242188  loc loss 40.50775909423828\n",
      "cls loss 356.66497802734375  loc loss 17.79673957824707\n",
      "cls loss 224.69801330566406  loc loss 9.916942596435547\n",
      "cls loss 280.3634338378906  loc loss 12.795390129089355\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3., 10., 10., 10., 10., 10., 10., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10., 10., 10., 10., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 11., 10., 10., 10., 10., 10.,  3.,  3.,  3.,  3.,  3.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 11., 10., 10., 10., 10., 10.,  3.,  3.,  3.,  3.,  3.])\n",
      "cls loss 224.80422973632812  loc loss 10.301423072814941\n",
      "cls loss 328.43902587890625  loc loss 13.296220779418945\n",
      "cls loss 286.46234130859375  loc loss 15.278779983520508\n",
      "cls loss 290.9239196777344  loc loss 11.401775360107422\n",
      "cls loss 362.555908203125  loc loss 25.112895965576172\n",
      "cls loss 250.81304931640625  loc loss 9.91507339477539\n",
      "cls loss 512.783447265625  loc loss 31.408309936523438\n",
      "cls loss 477.3460693359375  loc loss 25.846824645996094\n",
      "cls loss 668.2039794921875  loc loss 40.42041015625\n",
      "cls loss 330.3084716796875  loc loss 23.165449142456055\n",
      "cls loss 572.12744140625  loc loss 36.74433517456055\n",
      "cls loss 440.3453369140625  loc loss 32.46808624267578\n",
      "cls loss 452.29083251953125  loc loss 28.76765251159668\n",
      "cls loss 437.1539001464844  loc loss 29.571210861206055\n",
      "cls loss 557.284912109375  loc loss 37.530426025390625\n",
      "cls loss 544.3530883789062  loc loss 35.041072845458984\n",
      "cls loss 260.63616943359375  loc loss 13.898366928100586\n",
      "cls loss 528.8255615234375  loc loss 35.93826675415039\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 10.,  1., 18.])\n",
      "cls loss 241.9259033203125  loc loss 17.410144805908203\n",
      "cls loss 328.7039489746094  loc loss 12.689090728759766\n",
      "cls loss 623.3466796875  loc loss 26.85174560546875\n",
      "cls loss 755.7421875  loc loss 40.70260238647461\n",
      "cls loss 460.8072509765625  loc loss 28.1444149017334\n",
      "cls loss 655.0511474609375  loc loss 31.681665420532227\n",
      "cls loss 471.75860595703125  loc loss 31.44972801208496\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.,  1.,  1.])\n",
      "cls loss 547.8245849609375  loc loss 33.488468170166016\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1., 38.,  1.])\n",
      "cls loss 438.9969482421875  loc loss 28.534076690673828\n",
      "cls loss 667.1558837890625  loc loss 51.860816955566406\n",
      "cls loss 362.41986083984375  loc loss 24.980621337890625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 497.594970703125  loc loss 28.950185775756836\n",
      "cls loss 393.07208251953125  loc loss 24.160249710083008\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3., 10.,  8.,  3., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.])\n",
      "cls loss 455.877685546875  loc loss 26.614910125732422\n",
      "cls loss 304.48028564453125  loc loss 21.29718017578125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3.,  3., 11.,  3., 10., 10.,  3.,  3., 10.])\n",
      "cls loss 337.46246337890625  loc loss 19.01654815673828\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3., 10., 10., 10.])\n",
      "cls loss 403.4657287597656  loc loss 21.577180862426758\n",
      "cls loss 323.0069580078125  loc loss 21.48664093017578\n",
      "cls loss 446.0775146484375  loc loss 30.272628784179688\n",
      "cls loss 650.7415161132812  loc loss 36.83478927612305\n",
      "cls loss 415.669189453125  loc loss 26.00226402282715\n",
      "cls loss 323.199462890625  loc loss 24.010635375976562\n",
      "cls loss 405.3399658203125  loc loss 22.697288513183594\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 9.,  9., 85., 85.])\n",
      "cls loss 322.43511962890625  loc loss 15.535514831542969\n",
      "cls loss 410.568115234375  loc loss 28.08052635192871\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 624.646484375  loc loss 39.78934097290039\n",
      "cls loss 530.7647094726562  loc loss 22.8382625579834\n",
      "cls loss 605.5523071289062  loc loss 42.98283386230469\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10., 10., 10., 10.])\n",
      "cls loss 366.2335205078125  loc loss 24.44526481628418\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([13.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 593.1956176757812  loc loss 48.0908203125\n",
      "cls loss 161.4680938720703  loc loss 10.148311614990234\n",
      "cls loss 247.60906982421875  loc loss 13.685463905334473\n",
      "cls loss 330.49847412109375  loc loss 21.00738525390625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19.,  1.,  1.,  1., 19., 19.])\n",
      "cls loss 359.984375  loc loss 25.642715454101562\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 299.5000915527344  loc loss 21.159320831298828\n",
      "cls loss 437.4545593261719  loc loss 30.0191707611084\n",
      "cls loss 345.60125732421875  loc loss 18.331398010253906\n",
      "cls loss 495.3775939941406  loc loss 24.016773223876953\n",
      "cls loss 523.3472900390625  loc loss 35.310264587402344\n",
      "cls loss 387.9912414550781  loc loss 21.564382553100586\n",
      "cls loss 610.986328125  loc loss 41.57501220703125\n",
      "cls loss 211.5849609375  loc loss 9.789340019226074\n",
      "cls loss 401.0421142578125  loc loss 29.100017547607422\n",
      "cls loss 316.4229736328125  loc loss 19.736833572387695\n",
      "cls loss 345.12713623046875  loc loss 19.84389877319336\n",
      "cls loss 485.97479248046875  loc loss 30.213336944580078\n",
      "cls loss 390.20880126953125  loc loss 20.567110061645508\n",
      "cls loss 558.1891479492188  loc loss 40.27949523925781\n",
      "cls loss 366.347412109375  loc loss 23.035282135009766\n",
      "cls loss 478.24713134765625  loc loss 34.10863494873047\n",
      "cls loss 702.2198486328125  loc loss 42.74919509887695\n",
      "cls loss 378.3525390625  loc loss 29.004976272583008\n",
      "cls loss 464.2125244140625  loc loss 25.611379623413086\n",
      "cls loss 562.717041015625  loc loss 40.73197937011719\n",
      "cls loss 635.304443359375  loc loss 43.01055145263672\n",
      "cls loss 698.948486328125  loc loss 41.47620391845703\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 5.])\n",
      "cls loss 180.25904846191406  loc loss 9.373784065246582\n",
      "cls loss 251.7601776123047  loc loss 10.65727424621582\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 13.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 6., 8., 8.])\n",
      "cls loss 193.75711059570312  loc loss 10.57998275756836\n",
      "cls loss 253.34471130371094  loc loss 13.04111099243164\n",
      "cls loss 522.241455078125  loc loss 33.7795524597168\n",
      "cls loss 213.81288146972656  loc loss 12.187978744506836\n",
      "cls loss 461.551513671875  loc loss 31.645610809326172\n",
      "cls loss 644.6155395507812  loc loss 47.337493896484375\n",
      "cls loss 421.5003662109375  loc loss 28.28997039794922\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([42., 42.,  1.,  1.,  1.,  1.,  1.,  1.,  1., 42., 42.])\n",
      "cls loss 440.69384765625  loc loss 23.48556900024414\n",
      "cls loss 577.346435546875  loc loss 44.56378936767578\n",
      "cls loss 537.4036254882812  loc loss 35.17953872680664\n",
      "cls loss 349.88421630859375  loc loss 20.47104263305664\n",
      "cls loss 473.111083984375  loc loss 23.642656326293945\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 692.20068359375  loc loss 39.953468322753906\n",
      "cls loss 548.2445068359375  loc loss 34.40264892578125\n",
      "cls loss 327.7043151855469  loc loss 16.15193748474121\n",
      "cls loss 274.4858703613281  loc loss 15.03110122680664\n",
      "cls loss 354.96282958984375  loc loss 22.879728317260742\n",
      "cls loss 486.8316345214844  loc loss 31.892637252807617\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15.])\n",
      "cls loss 231.9575653076172  loc loss 8.799403190612793\n",
      "cls loss 406.41339111328125  loc loss 25.83759117126465\n",
      "cls loss 352.3564453125  loc loss 24.465665817260742\n",
      "cls loss 643.57958984375  loc loss 41.35036087036133\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19.,  7.])\n",
      "cls loss 300.7943420410156  loc loss 18.191253662109375\n",
      "cls loss 629.5867309570312  loc loss 44.3995475769043\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 565.8632202148438  loc loss 29.44609832763672\n",
      "cls loss 511.0472412109375  loc loss 35.226314544677734\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([38., 38.,  1., 18.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1., 18., 18.,  1.])\n",
      "cls loss 342.38043212890625  loc loss 19.9193115234375\n",
      "cls loss 344.52691650390625  loc loss 18.716758728027344\n",
      "cls loss 682.320556640625  loc loss 48.25501251220703\n",
      "cls loss 539.006103515625  loc loss 35.344932556152344\n",
      "cls loss 417.11328125  loc loss 28.291942596435547\n",
      "cls loss 282.3271789550781  loc loss 20.72753143310547\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.])\n",
      "cls loss 192.3531494140625  loc loss 7.144010543823242\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([32.])\n",
      "cls loss 434.1280822753906  loc loss 23.042133331298828\n",
      "cls loss 369.58160400390625  loc loss 25.12299156188965\n",
      "cls loss 458.796142578125  loc loss 36.210731506347656\n",
      "cls loss 411.16265869140625  loc loss 25.76339340209961\n",
      "cls loss 341.73211669921875  loc loss 21.555973052978516\n",
      "cls loss 545.07666015625  loc loss 34.630130767822266\n",
      "cls loss 666.10400390625  loc loss 46.759376525878906\n",
      "cls loss 465.9588623046875  loc loss 37.154273986816406\n",
      "cls loss 359.4649963378906  loc loss 23.71691131591797\n",
      "cls loss 593.3682861328125  loc loss 42.49467849731445\n",
      "cls loss 404.95849609375  loc loss 22.07971954345703\n",
      "cls loss 739.2047119140625  loc loss 46.8752555847168\n",
      "cls loss 511.49981689453125  loc loss 27.177532196044922\n",
      "cls loss 395.69036865234375  loc loss 32.3206901550293\n",
      "cls loss 325.629150390625  loc loss 17.033580780029297\n",
      "cls loss 338.743896484375  loc loss 23.323904037475586\n",
      "cls loss 486.45062255859375  loc loss 35.07512664794922\n",
      "cls loss 543.3831787109375  loc loss 42.74110794067383\n",
      "cls loss 312.119384765625  loc loss 21.4742488861084\n",
      "cls loss 531.1063232421875  loc loss 40.53800964355469\n",
      "cls loss 634.7410278320312  loc loss 44.389339447021484\n",
      "cls loss 238.3271026611328  loc loss 15.457168579101562\n",
      "cls loss 627.7266235351562  loc loss 45.04962158203125\n",
      "cls loss 465.85723876953125  loc loss 32.741432189941406\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 608.2203369140625  loc loss 50.40335464477539\n",
      "cls loss 265.478271484375  loc loss 13.040973663330078\n",
      "cls loss 411.83929443359375  loc loss 26.807758331298828\n",
      "cls loss 438.57086181640625  loc loss 30.034286499023438\n",
      "cls loss 372.6910400390625  loc loss 23.39523696899414\n",
      "cls loss 209.372802734375  loc loss 11.26353931427002\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 9., 9., 1., 9., 9., 9., 9., 1., 9.])\n",
      "cls loss 939.7410278320312  loc loss 63.307857513427734\n",
      "cls loss 478.58270263671875  loc loss 28.505800247192383\n",
      "cls loss 749.7955322265625  loc loss 58.786746978759766\n",
      "cls loss 289.17962646484375  loc loss 24.05443572998047\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 42., 42.])\n",
      "cls loss 482.70458984375  loc loss 40.111629486083984\n",
      "cls loss 505.10693359375  loc loss 43.72393798828125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  2.,  1.,  1.,  1., 38.,\n",
      "         1.,  1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 38., 38., 38.,  1., 38., 38., 38.,  1.,  1., 38.,  1.,\n",
      "         1.])\n",
      "cls loss 281.51690673828125  loc loss 23.648401260375977\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  8.,  8.])\n",
      "cls loss 675.9553833007812  loc loss 52.46147155761719\n",
      "cls loss 674.15869140625  loc loss 54.298343658447266\n",
      "cls loss 257.123291015625  loc loss 16.887357711791992\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([4., 1., 1., 4.])\n",
      "cls loss 424.8612060546875  loc loss 26.555326461791992\n",
      "cls loss 545.1892700195312  loc loss 32.63882064819336\n",
      "cls loss 219.94947814941406  loc loss 11.750747680664062\n",
      "cls loss 288.1024475097656  loc loss 18.81589126586914\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([51.,  1.])\n",
      "cls loss 199.52212524414062  loc loss 10.621124267578125\n",
      "cls loss 292.3129577636719  loc loss 21.948078155517578\n",
      "cls loss 660.8448486328125  loc loss 32.79469680786133\n",
      "cls loss 541.3753662109375  loc loss 45.46205139160156\n",
      "cls loss 855.4420776367188  loc loss 44.626609802246094\n",
      "cls loss 949.3006591796875  loc loss 63.62699890136719\n",
      "cls loss 374.27130126953125  loc loss 25.385652542114258\n",
      "cls loss 541.0133666992188  loc loss 43.693695068359375\n",
      "cls loss 644.067626953125  loc loss 45.546897888183594\n",
      "cls loss 422.8485107421875  loc loss 31.52352523803711\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  3.,  1.,  1.,  1.,  3.,  1.,  1.,\n",
      "         1.,  1.,  1.])\n",
      "cls loss 453.00628662109375  loc loss 24.405818939208984\n",
      "cls loss 496.39874267578125  loc loss 35.41010284423828\n",
      "cls loss 478.08746337890625  loc loss 34.32624053955078\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "cls loss 420.9971618652344  loc loss 27.60271453857422\n",
      "cls loss 239.87350463867188  loc loss 19.862403869628906\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3.])\n",
      "cls loss 222.31939697265625  loc loss 11.549188613891602\n",
      "cls loss 370.289306640625  loc loss 21.781768798828125\n",
      "cls loss 402.88226318359375  loc loss 22.92263412475586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 647.932861328125  loc loss 38.590782165527344\n",
      "cls loss 282.54327392578125  loc loss 21.668292999267578\n",
      "cls loss 312.69158935546875  loc loss 26.410066604614258\n",
      "cls loss 889.7579345703125  loc loss 67.19699096679688\n",
      "cls loss 381.57366943359375  loc loss 31.376541137695312\n",
      "cls loss 279.70611572265625  loc loss 24.05554962158203\n",
      "cls loss 330.878173828125  loc loss 20.937837600708008\n",
      "cls loss 309.3386535644531  loc loss 25.51833724975586\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 576.5069580078125  loc loss 42.71878433227539\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  9., 64., 64., 64., 64., 64., 64., 64., 64., 64.,  9.,  9.,  9.,\n",
      "         9.])\n",
      "cls loss 268.5131530761719  loc loss 16.899696350097656\n",
      "cls loss 815.7802734375  loc loss 65.1287612915039\n",
      "cls loss 433.8463134765625  loc loss 29.40290641784668\n",
      "cls loss 543.7744140625  loc loss 37.82271957397461\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.,  3.,  3.])\n",
      "cls loss 318.1043701171875  loc loss 20.085588455200195\n",
      "cls loss 396.7183837890625  loc loss 29.55429458618164\n",
      "cls loss 429.1171875  loc loss 30.32390594482422\n",
      "cls loss 501.93499755859375  loc loss 27.428346633911133\n",
      "cls loss 553.410888671875  loc loss 32.66499328613281\n",
      "cls loss 476.18011474609375  loc loss 30.643661499023438\n",
      "cls loss 409.7602844238281  loc loss 29.070466995239258\n",
      "cls loss 406.55230712890625  loc loss 23.6884765625\n",
      "cls loss 520.7681884765625  loc loss 35.74039077758789\n",
      "cls loss 406.5797424316406  loc loss 24.64118003845215\n",
      "cls loss 315.80706787109375  loc loss 16.145986557006836\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21.])\n",
      "cls loss 243.63973999023438  loc loss 16.74846649169922\n",
      "cls loss 345.8280029296875  loc loss 30.707935333251953\n",
      "cls loss 504.8486633300781  loc loss 36.646034240722656\n",
      "cls loss 253.31796264648438  loc loss 16.40604019165039\n",
      "cls loss 426.59368896484375  loc loss 29.13920021057129\n",
      "cls loss 779.4157104492188  loc loss 42.81595993041992\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 42., 42.,  1.,  1.])\n",
      "cls loss 505.154296875  loc loss 26.409868240356445\n",
      "cls loss 349.6337585449219  loc loss 18.200841903686523\n",
      "cls loss 489.65045166015625  loc loss 27.16004753112793\n",
      "cls loss 653.1463623046875  loc loss 42.73267364501953\n",
      "cls loss 369.8277587890625  loc loss 20.690107345581055\n",
      "cls loss 536.0289306640625  loc loss 38.183101654052734\n",
      "cls loss 475.37945556640625  loc loss 35.29863739013672\n",
      "cls loss 457.55169677734375  loc loss 30.01880645751953\n",
      "cls loss 385.1822814941406  loc loss 24.570362091064453\n",
      "cls loss 300.83648681640625  loc loss 21.964366912841797\n",
      "cls loss 237.45819091796875  loc loss 11.414475440979004\n",
      "cls loss 395.8457336425781  loc loss 24.702768325805664\n",
      "cls loss 573.06201171875  loc loss 37.57297897338867\n",
      "cls loss 426.338623046875  loc loss 25.632427215576172\n",
      "cls loss 413.31121826171875  loc loss 30.204225540161133\n",
      "cls loss 453.93084716796875  loc loss 27.113061904907227\n",
      "cls loss 680.7557373046875  loc loss 49.96657180786133\n",
      "cls loss 555.5594482421875  loc loss 35.27454376220703\n",
      "cls loss 616.260986328125  loc loss 30.676790237426758\n",
      "cls loss 406.71337890625  loc loss 16.15316390991211\n",
      "cls loss 544.3848876953125  loc loss 29.6992130279541\n",
      "cls loss 496.0128173828125  loc loss 25.947500228881836\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 5., 5., 5., 5., 5., 5.])\n",
      "cls loss 291.1767578125  loc loss 17.930980682373047\n",
      "cls loss 382.9951477050781  loc loss 20.234615325927734\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([13.])\n",
      "cls loss 255.9922637939453  loc loss 12.752809524536133\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([44., 10.,  1.,  1.,  1.])\n",
      "cls loss 239.81521606445312  loc loss 15.923239707946777\n",
      "cls loss 427.0068664550781  loc loss 24.087427139282227\n",
      "cls loss 396.37530517578125  loc loss 21.307212829589844\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19., 19., 19., 19., 19., 19., 19.])\n",
      "cls loss 410.1612548828125  loc loss 26.318552017211914\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([56.])\n",
      "cls loss 863.8858032226562  loc loss 57.064353942871094\n",
      "cls loss 545.8074951171875  loc loss 40.48311996459961\n",
      "cls loss 684.4844970703125  loc loss 44.766937255859375\n",
      "cls loss 659.561279296875  loc loss 51.68586349487305\n",
      "cls loss 410.00054931640625  loc loss 23.54867172241211\n",
      "cls loss 709.551513671875  loc loss 44.14115524291992\n",
      "cls loss 456.3262634277344  loc loss 25.884672164916992\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 36.])\n",
      "cls loss 605.9796752929688  loc loss 23.2597713470459\n",
      "cls loss 462.0692443847656  loc loss 26.89078140258789\n",
      "cls loss 412.693359375  loc loss 23.756013870239258\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5.])\n",
      "cls loss 481.9073486328125  loc loss 27.591106414794922\n",
      "cls loss 255.9810791015625  loc loss 12.610641479492188\n",
      "cls loss 570.7909545898438  loc loss 32.71089172363281\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "cls loss 505.8468322753906  loc loss 31.778167724609375\n",
      "cls loss 465.8615417480469  loc loss 31.39592742919922\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 508.5693359375  loc loss 32.377891540527344\n",
      "cls loss 553.6129760742188  loc loss 37.810508728027344\n",
      "cls loss 478.3684997558594  loc loss 40.89042663574219\n",
      "cls loss 342.98541259765625  loc loss 21.96044158935547\n",
      "cls loss 380.2088623046875  loc loss 28.370525360107422\n",
      "cls loss 410.78851318359375  loc loss 24.002832412719727\n",
      "cls loss 679.56787109375  loc loss 33.69392013549805\n",
      "cls loss 281.73077392578125  loc loss 13.96577262878418\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 11., 15., 10., 10., 10., 10., 10.])\n",
      "cls loss 638.593505859375  loc loss 40.13640213012695\n",
      "cls loss 395.19580078125  loc loss 27.43648338317871\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3.])\n",
      "cls loss 433.49383544921875  loc loss 28.090091705322266\n",
      "cls loss 400.572021484375  loc loss 19.175437927246094\n",
      "cls loss 441.8987121582031  loc loss 18.772371292114258\n",
      "cls loss 519.7013549804688  loc loss 22.897146224975586\n",
      "cls loss 237.95242309570312  loc loss 11.708175659179688\n",
      "cls loss 420.06494140625  loc loss 27.693756103515625\n",
      "cls loss 483.0748596191406  loc loss 30.789226531982422\n",
      "cls loss 402.2269287109375  loc loss 28.348737716674805\n",
      "cls loss 961.73828125  loc loss 63.726417541503906\n",
      "cls loss 636.5050659179688  loc loss 41.57097625732422\n",
      "cls loss 408.1432189941406  loc loss 27.94577407836914\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  9.,  9.,  9.,  6.,  6., 85., 85.,  8.,  1.,  1.,  1.,  1.,\n",
      "         6.,  6.])\n",
      "cls loss 280.5943603515625  loc loss 22.155370712280273\n",
      "cls loss 689.0737915039062  loc loss 48.57762908935547\n",
      "cls loss 813.0234375  loc loss 48.89573287963867\n",
      "cls loss 531.7507934570312  loc loss 36.067726135253906\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10.,  3.,  3., 10.])\n",
      "cls loss 337.6539306640625  loc loss 18.47321891784668\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([7.])\n",
      "cls loss 441.13116455078125  loc loss 28.305496215820312\n",
      "cls loss 462.23370361328125  loc loss 26.642723083496094\n",
      "cls loss 509.5731506347656  loc loss 36.78118896484375\n",
      "cls loss 772.1390380859375  loc loss 48.73918151855469\n",
      "cls loss 435.8381042480469  loc loss 26.608158111572266\n",
      "cls loss 634.35791015625  loc loss 38.58308792114258\n",
      "cls loss 768.366455078125  loc loss 44.008670806884766\n",
      "cls loss 464.87384033203125  loc loss 28.75508689880371\n",
      "cls loss 506.2523193359375  loc loss 33.77565383911133\n",
      "cls loss 382.1147766113281  loc loss 28.853933334350586\n",
      "cls loss 628.999267578125  loc loss 44.293731689453125\n",
      "cls loss 467.93572998046875  loc loss 29.574411392211914\n",
      "cls loss 333.7230224609375  loc loss 21.95069122314453\n",
      "cls loss 542.1007690429688  loc loss 41.47303009033203\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([62.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([62.])\n",
      "cls loss 242.95083618164062  loc loss 12.066972732543945\n",
      "cls loss 398.6061096191406  loc loss 29.59729766845703\n",
      "cls loss 397.84344482421875  loc loss 26.862913131713867\n",
      "cls loss 263.900146484375  loc loss 13.340275764465332\n",
      "cls loss 592.709716796875  loc loss 35.673282623291016\n",
      "cls loss 582.967529296875  loc loss 31.23217010498047\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([28.])\n",
      "cls loss 747.9061889648438  loc loss 31.914710998535156\n",
      "cls loss 537.2017211914062  loc loss 33.1425666809082\n",
      "cls loss 553.0532836914062  loc loss 36.40174102783203\n",
      "cls loss 599.58056640625  loc loss 34.86322021484375\n",
      "cls loss 806.8668212890625  loc loss 49.21375274658203\n",
      "cls loss 445.877197265625  loc loss 26.781343460083008\n",
      "cls loss 590.3658447265625  loc loss 31.520126342773438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 464.60443115234375  loc loss 36.68083572387695\n",
      "cls loss 761.5496826171875  loc loss 58.397613525390625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([81.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 462.8903503417969  loc loss 19.97577476501465\n",
      "cls loss 360.9680480957031  loc loss 19.42193031311035\n",
      "cls loss 264.5461120605469  loc loss 20.605985641479492\n",
      "cls loss 243.70655822753906  loc loss 10.831600189208984\n",
      "cls loss 277.5190124511719  loc loss 22.022369384765625\n",
      "cls loss 340.68560791015625  loc loss 22.020809173583984\n",
      "cls loss 344.3745422363281  loc loss 26.54069709777832\n",
      "cls loss 501.4009094238281  loc loss 43.496665954589844\n",
      "cls loss 626.4442749023438  loc loss 37.427608489990234\n",
      "cls loss 1063.6690673828125  loc loss 73.29822540283203\n",
      "cls loss 431.75103759765625  loc loss 21.387859344482422\n",
      "cls loss 545.9229125976562  loc loss 38.763492584228516\n",
      "cls loss 383.9791564941406  loc loss 22.64209747314453\n",
      "cls loss 516.4156494140625  loc loss 27.72520637512207\n",
      "cls loss 428.19024658203125  loc loss 25.252586364746094\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([44., 44.])\n",
      "cls loss 380.6205139160156  loc loss 19.546497344970703\n",
      "cls loss 417.6119079589844  loc loss 29.568012237548828\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15.])\n",
      "cls loss 410.1446838378906  loc loss 24.02663803100586\n",
      "cls loss 214.5523681640625  loc loss 15.161783218383789\n",
      "cls loss 420.7059326171875  loc loss 31.801719665527344\n",
      "cls loss 254.88839721679688  loc loss 13.310552597045898\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([1., 3., 3.])\n",
      "cls loss 285.0415954589844  loc loss 18.539766311645508\n",
      "cls loss 206.75103759765625  loc loss 10.479893684387207\n",
      "cls loss 394.522705078125  loc loss 28.23834800720215\n",
      "cls loss 460.9625244140625  loc loss 26.931320190429688\n",
      "cls loss 401.50262451171875  loc loss 27.60216522216797\n",
      "cls loss 342.5162353515625  loc loss 23.164382934570312\n",
      "cls loss 362.7525634765625  loc loss 27.326671600341797\n",
      "cls loss 484.13592529296875  loc loss 31.949649810791016\n",
      "cls loss 332.2929992675781  loc loss 23.1155948638916\n",
      "cls loss 448.73663330078125  loc loss 34.96786117553711\n",
      "cls loss 338.8146667480469  loc loss 20.59723663330078\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 568.0195922851562  loc loss 33.90713882446289\n",
      "cls loss 699.0466918945312  loc loss 31.61337661743164\n",
      "cls loss 575.7611083984375  loc loss 39.44622802734375\n",
      "cls loss 563.3003540039062  loc loss 45.05936813354492\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10., 10., 10.,  1.,  1.,  1.,  1.,  1.,  1.,  8.,  8.,\n",
      "         1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10., 10., 10.,  1.,  1.,  1.,  1.,  1.,  1.,  8.,  8.,\n",
      "         1.])\n",
      "cls loss 455.103271484375  loc loss 24.02386474609375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 3., 3., 3.])\n",
      "cls loss 442.08514404296875  loc loss 26.001373291015625\n",
      "cls loss 282.459716796875  loc loss 18.008153915405273\n",
      "cls loss 210.556396484375  loc loss 11.3046236038208\n",
      "cls loss 415.5121154785156  loc loss 33.996097564697266\n",
      "cls loss 306.0726013183594  loc loss 16.656967163085938\n",
      "cls loss 379.20458984375  loc loss 29.46807861328125\n",
      "cls loss 420.47967529296875  loc loss 35.381404876708984\n",
      "cls loss 577.8074951171875  loc loss 48.50200653076172\n",
      "cls loss 503.921630859375  loc loss 29.029035568237305\n",
      "cls loss 463.3804016113281  loc loss 26.44418716430664\n",
      "cls loss 485.39849853515625  loc loss 31.92215347290039\n",
      "cls loss 344.6566467285156  loc loss 25.661523818969727\n",
      "cls loss 703.1076049804688  loc loss 50.14937973022461\n",
      "cls loss 315.75103759765625  loc loss 18.12472915649414\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 567.000732421875  loc loss 33.607147216796875\n",
      "cls loss 251.40037536621094  loc loss 12.240195274353027\n",
      "cls loss 621.8983764648438  loc loss 47.03927993774414\n",
      "cls loss 305.1913146972656  loc loss 21.419246673583984\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 34.])\n",
      "cls loss 503.28253173828125  loc loss 31.724769592285156\n",
      "cls loss 260.353271484375  loc loss 17.792888641357422\n",
      "cls loss 530.9368286132812  loc loss 32.907379150390625\n",
      "cls loss 179.15402221679688  loc loss 14.125720977783203\n",
      "cls loss 420.4891662597656  loc loss 27.836288452148438\n",
      "cls loss 412.52020263671875  loc loss 33.6387825012207\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 38.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16., 16., 16.,  9.,  9.,  9., 16., 16., 16., 85.,  9.])\n",
      "cls loss 423.86181640625  loc loss 27.1627254486084\n",
      "cls loss 459.5682067871094  loc loss 35.830413818359375\n",
      "cls loss 622.10693359375  loc loss 41.3504753112793\n",
      "cls loss 973.472900390625  loc loss 60.66347885131836\n",
      "cls loss 253.43936157226562  loc loss 14.202531814575195\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3., 10.,  8.,  8., 10., 10., 10.,  3.,  3., 14.])\n",
      "cls loss 274.0035095214844  loc loss 15.964263916015625\n",
      "cls loss 509.1478271484375  loc loss 33.22871780395508\n",
      "cls loss 217.89476013183594  loc loss 9.621017456054688\n",
      "cls loss 380.3695068359375  loc loss 17.84514617919922\n",
      "cls loss 519.8511962890625  loc loss 34.855613708496094\n",
      "cls loss 451.1339111328125  loc loss 27.89691925048828\n",
      "cls loss 256.0290222167969  loc loss 14.442442893981934\n",
      "cls loss 342.27276611328125  loc loss 16.395959854125977\n",
      "cls loss 548.14697265625  loc loss 29.942087173461914\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42., 42.,  1.])\n",
      "cls loss 497.80560302734375  loc loss 30.082382202148438\n",
      "cls loss 383.10528564453125  loc loss 21.34555435180664\n",
      "cls loss 501.99481201171875  loc loss 38.510677337646484\n",
      "cls loss 570.336181640625  loc loss 35.41150665283203\n",
      "cls loss 396.89715576171875  loc loss 24.262168884277344\n",
      "cls loss 484.82666015625  loc loss 35.030399322509766\n",
      "cls loss 295.1849365234375  loc loss 20.025623321533203\n",
      "cls loss 314.65423583984375  loc loss 23.167137145996094\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20.])\n",
      "cls loss 222.2857208251953  loc loss 13.289145469665527\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([11.])\n",
      "cls loss 324.833740234375  loc loss 14.9507474899292\n",
      "cls loss 184.11471557617188  loc loss 12.024396896362305\n",
      "cls loss 485.2021179199219  loc loss 36.99930191040039\n",
      "cls loss 209.8196563720703  loc loss 10.839996337890625\n",
      "cls loss 449.068359375  loc loss 27.638595581054688\n",
      "cls loss 249.53857421875  loc loss 16.384695053100586\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 35., 27.])\n",
      "cls loss 456.5508728027344  loc loss 25.464399337768555\n",
      "cls loss 518.365966796875  loc loss 36.76786804199219\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 359.3201599121094  loc loss 18.03306007385254\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([42.,  1.])\n",
      "cls loss 446.7301330566406  loc loss 28.60466194152832\n",
      "cls loss 475.39520263671875  loc loss 22.719959259033203\n",
      "cls loss 573.8870849609375  loc loss 29.5766658782959\n",
      "cls loss 664.3271484375  loc loss 35.66521453857422\n",
      "cls loss 536.9368896484375  loc loss 30.818424224853516\n",
      "cls loss 368.978759765625  loc loss 24.333038330078125\n",
      "cls loss 306.4977111816406  loc loss 22.742431640625\n",
      "cls loss 178.93711853027344  loc loss 8.414515495300293\n",
      "cls loss 355.7556457519531  loc loss 19.77191162109375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 1., 1.])\n",
      "cls loss 333.5628356933594  loc loss 21.151708602905273\n",
      "cls loss 404.68768310546875  loc loss 26.7523193359375\n",
      "cls loss 387.76739501953125  loc loss 24.18004608154297\n",
      "cls loss 308.7879638671875  loc loss 22.943788528442383\n",
      "cls loss 379.2525634765625  loc loss 25.924591064453125\n",
      "cls loss 402.1821594238281  loc loss 29.948040008544922\n",
      "cls loss 592.8074951171875  loc loss 35.58481979370117\n",
      "cls loss 524.3057250976562  loc loss 39.73042297363281\n",
      "cls loss 474.6316223144531  loc loss 29.8170166015625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 399.203857421875  loc loss 26.72850799560547\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 528.0980224609375  loc loss 20.304149627685547\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([81.])\n",
      "cls loss 609.9537353515625  loc loss 32.020545959472656\n",
      "cls loss 338.560546875  loc loss 22.693134307861328\n",
      "cls loss 265.0450134277344  loc loss 12.683145523071289\n",
      "cls loss 356.50537109375  loc loss 19.765562057495117\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3.,  1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 19.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 19.])\n",
      "cls loss 507.6768798828125  loc loss 33.802433013916016\n",
      "cls loss 266.884765625  loc loss 15.82371997833252\n",
      "cls loss 294.3331604003906  loc loss 17.176618576049805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 583.539794921875  loc loss 41.629371643066406\n",
      "cls loss 282.5845947265625  loc loss 18.061601638793945\n",
      "cls loss 360.1655578613281  loc loss 22.141460418701172\n",
      "cls loss 456.10546875  loc loss 31.308876037597656\n",
      "cls loss 329.4403381347656  loc loss 24.959203720092773\n",
      "cls loss 445.04888916015625  loc loss 25.800945281982422\n",
      "cls loss 491.56597900390625  loc loss 32.8443717956543\n",
      "cls loss 667.6522216796875  loc loss 56.52907943725586\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 81.])\n",
      "cls loss 455.9289245605469  loc loss 21.702295303344727\n",
      "cls loss 446.68646240234375  loc loss 21.703006744384766\n",
      "cls loss 444.73828125  loc loss 22.753618240356445\n",
      "cls loss 364.9929504394531  loc loss 16.76473045349121\n",
      "cls loss 343.95965576171875  loc loss 17.831857681274414\n",
      "cls loss 367.0938720703125  loc loss 25.822492599487305\n",
      "cls loss 254.454345703125  loc loss 18.927467346191406\n",
      "cls loss 217.50506591796875  loc loss 15.189983367919922\n",
      "cls loss 279.6209716796875  loc loss 20.275888442993164\n",
      "cls loss 383.3070068359375  loc loss 26.13075828552246\n",
      "cls loss 346.2276306152344  loc loss 28.264305114746094\n",
      "cls loss 369.4623718261719  loc loss 25.320262908935547\n",
      "cls loss 213.84521484375  loc loss 14.321468353271484\n",
      "cls loss 772.9044799804688  loc loss 48.81111526489258\n",
      "cls loss 429.1849060058594  loc loss 28.864885330200195\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 375.4594421386719  loc loss 19.297000885009766\n",
      "cls loss 423.94219970703125  loc loss 27.1401309967041\n",
      "cls loss 315.3222961425781  loc loss 21.49795913696289\n",
      "cls loss 510.3790283203125  loc loss 36.12001419067383\n",
      "cls loss 507.201416015625  loc loss 30.419885635375977\n",
      "cls loss 492.06536865234375  loc loss 28.846126556396484\n",
      "cls loss 365.6285705566406  loc loss 23.190261840820312\n",
      "cls loss 331.9627685546875  loc loss 17.068967819213867\n",
      "cls loss 441.73046875  loc loss 25.41925621032715\n",
      "cls loss 502.6257629394531  loc loss 32.01287078857422\n",
      "cls loss 435.98040771484375  loc loss 24.654216766357422\n",
      "cls loss 566.1880493164062  loc loss 37.481285095214844\n",
      "cls loss 591.3331298828125  loc loss 42.827392578125\n",
      "cls loss 411.92669677734375  loc loss 28.217931747436523\n",
      "cls loss 587.863525390625  loc loss 45.823490142822266\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1., 38., 47.,  1.,  1.,  1.,  1.,  1., 62.])\n",
      "cls loss 365.7571105957031  loc loss 18.793556213378906\n",
      "cls loss 432.8337707519531  loc loss 32.543174743652344\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 474.31646728515625  loc loss 29.211294174194336\n",
      "cls loss 556.494873046875  loc loss 40.11424255371094\n",
      "cls loss 361.9014892578125  loc loss 17.771697998046875\n",
      "cls loss 446.19158935546875  loc loss 34.64696502685547\n",
      "cls loss 430.23187255859375  loc loss 25.07872200012207\n",
      "cls loss 258.01495361328125  loc loss 9.032172203063965\n",
      "cls loss 398.8015441894531  loc loss 21.36106300354004\n",
      "cls loss 347.0971374511719  loc loss 13.774491310119629\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1., 35.])\n",
      "cls loss 356.28607177734375  loc loss 19.602035522460938\n",
      "cls loss 562.82275390625  loc loss 27.187570571899414\n",
      "cls loss 552.5855712890625  loc loss 31.766315460205078\n",
      "cls loss 476.561767578125  loc loss 36.85954666137695\n",
      "cls loss 385.78466796875  loc loss 28.12508201599121\n",
      "cls loss 496.22821044921875  loc loss 38.72887420654297\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 269.13812255859375  loc loss 16.47970962524414\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 365.99560546875  loc loss 17.028026580810547\n",
      "cls loss 606.401611328125  loc loss 37.63181686401367\n",
      "cls loss 771.09326171875  loc loss 61.74540328979492\n",
      "cls loss 381.54327392578125  loc loss 20.849910736083984\n",
      "cls loss 323.720703125  loc loss 20.321931838989258\n",
      "cls loss 356.2912902832031  loc loss 17.826345443725586\n",
      "cls loss 411.16229248046875  loc loss 21.617733001708984\n",
      "cls loss 377.38250732421875  loc loss 14.080772399902344\n",
      "cls loss 648.3659057617188  loc loss 40.010887145996094\n",
      "cls loss 561.0166015625  loc loss 31.182571411132812\n",
      "cls loss 235.7504119873047  loc loss 16.456687927246094\n",
      "cls loss 483.21807861328125  loc loss 27.41576385498047\n",
      "cls loss 618.62548828125  loc loss 46.242454528808594\n",
      "cls loss 477.6390686035156  loc loss 31.723533630371094\n",
      "cls loss 391.4869384765625  loc loss 24.085939407348633\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.])\n",
      "cls loss 389.9490966796875  loc loss 27.986709594726562\n",
      "cls loss 386.2201843261719  loc loss 25.140987396240234\n",
      "cls loss 481.7653503417969  loc loss 30.854867935180664\n",
      "cls loss 787.3773193359375  loc loss 60.755828857421875\n",
      "cls loss 282.4222412109375  loc loss 16.147363662719727\n",
      "cls loss 376.19232177734375  loc loss 25.425907135009766\n",
      "cls loss 304.86529541015625  loc loss 19.145286560058594\n",
      "cls loss 341.2330017089844  loc loss 25.62116241455078\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 21., 21., 21.])\n",
      "cls loss 348.87542724609375  loc loss 22.392467498779297\n",
      "cls loss 361.041259765625  loc loss 18.487661361694336\n",
      "cls loss 374.7266845703125  loc loss 25.07609748840332\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 35.])\n",
      "cls loss 533.6044921875  loc loss 29.602222442626953\n",
      "cls loss 193.11962890625  loc loss 9.787572860717773\n",
      "cls loss 367.5360107421875  loc loss 19.253915786743164\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 322.5787048339844  loc loss 13.373971939086914\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 38., 38.,  9., 38.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1.,  1.])\n",
      "cls loss 347.33746337890625  loc loss 21.30377197265625\n",
      "cls loss 567.4541015625  loc loss 34.510250091552734\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 2.,  1., 77., 31., 10., 10.,  1.,  4., 10.])\n",
      "cls loss 254.52105712890625  loc loss 12.495789527893066\n",
      "cls loss 503.21551513671875  loc loss 33.595218658447266\n",
      "cls loss 1058.430908203125  loc loss 61.169219970703125\n",
      "cls loss 320.3399658203125  loc loss 22.32577133178711\n",
      "cls loss 448.283203125  loc loss 33.58925247192383\n",
      "cls loss 313.9139099121094  loc loss 16.49338150024414\n",
      "cls loss 291.50042724609375  loc loss 16.19103240966797\n",
      "cls loss 417.32843017578125  loc loss 24.56844711303711\n",
      "cls loss 427.0592041015625  loc loss 26.086109161376953\n",
      "cls loss 400.92181396484375  loc loss 29.887964248657227\n",
      "cls loss 362.05633544921875  loc loss 16.687570571899414\n",
      "cls loss 384.0039367675781  loc loss 20.079069137573242\n",
      "cls loss 693.8115234375  loc loss 40.30899429321289\n",
      "cls loss 653.7811279296875  loc loss 34.84883117675781\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1., 42., 42., 42., 42., 42., 42.,  1.,\n",
      "         1.,  1.,  1., 42.,  1.,  1., 42.,  1.])\n",
      "cls loss 349.7775573730469  loc loss 24.05847930908203\n",
      "cls loss 508.7703857421875  loc loss 28.080636978149414\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.])\n",
      "cls loss 226.39593505859375  loc loss 11.462599754333496\n",
      "cls loss 501.40057373046875  loc loss 30.804704666137695\n",
      "cls loss 369.29010009765625  loc loss 27.355226516723633\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([11.])\n",
      "cls loss 222.1659393310547  loc loss 13.82763671875\n",
      "cls loss 241.6071319580078  loc loss 13.828563690185547\n",
      "cls loss 266.28887939453125  loc loss 14.323996543884277\n",
      "cls loss 470.867919921875  loc loss 32.114070892333984\n",
      "cls loss 384.5906066894531  loc loss 24.365249633789062\n",
      "cls loss 399.495849609375  loc loss 27.91780662536621\n",
      "cls loss 555.5100708007812  loc loss 31.302547454833984\n",
      "cls loss 306.1713562011719  loc loss 18.065425872802734\n",
      "cls loss 679.4857788085938  loc loss 42.122798919677734\n",
      "cls loss 378.0478210449219  loc loss 19.59075164794922\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 372.36627197265625  loc loss 18.42327308654785\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1., 38., 38., 42.])\n",
      "cls loss 505.54888916015625  loc loss 27.440629959106445\n",
      "cls loss 456.31878662109375  loc loss 22.723121643066406\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 358.373779296875  loc loss 21.337005615234375\n",
      "cls loss 719.2318115234375  loc loss 45.739925384521484\n",
      "cls loss 423.8036193847656  loc loss 26.379716873168945\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10.,  3.,  3.,  6.,  8.,  8.,  1.,  1.,  1., 10.])\n",
      "cls loss 325.7046203613281  loc loss 16.512968063354492\n",
      "cls loss 209.216796875  loc loss 8.2515869140625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10.,  3.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 314.16119384765625  loc loss 18.209989547729492\n",
      "cls loss 157.6411590576172  loc loss 9.360725402832031\n",
      "cls loss 380.9405822753906  loc loss 27.660964965820312\n",
      "cls loss 491.1618347167969  loc loss 30.264516830444336\n",
      "cls loss 342.5050048828125  loc loss 21.41274642944336\n",
      "cls loss 180.7099609375  loc loss 13.42741584777832\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 34.])\n",
      "cls loss 517.9459228515625  loc loss 38.23112869262695\n",
      "cls loss 677.9083251953125  loc loss 50.155208587646484\n",
      "cls loss 420.95257568359375  loc loss 30.64146614074707\n",
      "cls loss 349.250732421875  loc loss 24.153564453125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.,  1.])\n",
      "cls loss 427.4125061035156  loc loss 16.405895233154297\n",
      "cls loss 710.3362426757812  loc loss 42.255130767822266\n",
      "cls loss 944.6832885742188  loc loss 52.52440643310547\n",
      "cls loss 756.8860473632812  loc loss 36.773162841796875\n",
      "cls loss 422.1319885253906  loc loss 21.368894577026367\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 443.5096130371094  loc loss 27.4926700592041\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10.])\n",
      "cls loss 274.1312255859375  loc loss 16.611061096191406\n",
      "cls loss 409.6138916015625  loc loss 20.836883544921875\n",
      "cls loss 387.0474853515625  loc loss 23.65109634399414\n",
      "cls loss 249.50613403320312  loc loss 16.028060913085938\n",
      "cls loss 356.68389892578125  loc loss 22.922143936157227\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21.,\n",
      "        21.])\n",
      "cls loss 425.8005676269531  loc loss 26.94943618774414\n",
      "cls loss 382.47265625  loc loss 21.934032440185547\n",
      "cls loss 249.1815643310547  loc loss 11.652735710144043\n",
      "cls loss 571.19091796875  loc loss 35.7934684753418\n",
      "cls loss 419.4991149902344  loc loss 27.644302368164062\n",
      "cls loss 316.6700439453125  loc loss 15.97376537322998\n",
      "cls loss 652.9803466796875  loc loss 38.883609771728516\n",
      "cls loss 747.064208984375  loc loss 52.257965087890625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15., 85.])\n",
      "cls loss 520.974365234375  loc loss 27.785837173461914\n",
      "cls loss 550.318115234375  loc loss 35.06499481201172\n",
      "cls loss 553.3201293945312  loc loss 33.51231002807617\n",
      "cls loss 507.1124267578125  loc loss 24.11128044128418\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 8., 8.])\n",
      "cls loss 321.69110107421875  loc loss 11.778739929199219\n",
      "cls loss 290.6681213378906  loc loss 22.394203186035156\n",
      "cls loss 359.26104736328125  loc loss 22.030284881591797\n",
      "cls loss 306.0334777832031  loc loss 17.446739196777344\n",
      "cls loss 353.665283203125  loc loss 21.821277618408203\n",
      "cls loss 494.503173828125  loc loss 29.22721290588379\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1., 35., 27., 27.,  1., 27.,  1.])\n",
      "cls loss 549.3966674804688  loc loss 45.55316925048828\n",
      "cls loss 347.704345703125  loc loss 18.62097930908203\n",
      "cls loss 374.0985107421875  loc loss 26.667762756347656\n",
      "cls loss 362.2403259277344  loc loss 30.305912017822266\n",
      "cls loss 338.4085693359375  loc loss 20.985549926757812\n",
      "cls loss 363.62518310546875  loc loss 27.458011627197266\n",
      "cls loss 356.4418640136719  loc loss 27.485916137695312\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  2.,  2.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  2.,  2.])\n",
      "cls loss 187.02365112304688  loc loss 8.617465019226074\n",
      "cls loss 622.10302734375  loc loss 37.42089080810547\n",
      "cls loss 387.4028015136719  loc loss 18.258920669555664\n",
      "cls loss 757.7272338867188  loc loss 45.577789306640625\n",
      "cls loss 269.533935546875  loc loss 13.589154243469238\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 19., 19., 19., 16.])\n",
      "cls loss 289.4273376464844  loc loss 10.412740707397461\n",
      "cls loss 220.46319580078125  loc loss 8.601433753967285\n",
      "cls loss 358.946533203125  loc loss 16.447969436645508\n",
      "cls loss 458.6661376953125  loc loss 28.607322692871094\n",
      "cls loss 171.453857421875  loc loss 14.329768180847168\n",
      "cls loss 512.4210205078125  loc loss 39.54743194580078\n",
      "cls loss 380.886962890625  loc loss 25.156076431274414\n",
      "cls loss 371.4407958984375  loc loss 25.50384521484375\n",
      "cls loss 497.15386962890625  loc loss 33.197303771972656\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 495.5639343261719  loc loss 24.573139190673828\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 707.8515014648438  loc loss 61.16059875488281\n",
      "cls loss 931.3090209960938  loc loss 82.62966918945312\n",
      "cls loss 435.731689453125  loc loss 27.447315216064453\n",
      "cls loss 404.0501403808594  loc loss 24.815414428710938\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3.,  3.,  3.,  3.,  3., 10.])\n",
      "cls loss 200.67713928222656  loc loss 13.527103424072266\n",
      "cls loss 486.4564208984375  loc loss 21.311595916748047\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 1., 1., 1., 3., 3., 3., 3.])\n",
      "cls loss 409.3994445800781  loc loss 18.783058166503906\n",
      "cls loss 890.3388061523438  loc loss 43.13511657714844\n",
      "cls loss 644.7196655273438  loc loss 31.009323120117188\n",
      "cls loss 399.6334228515625  loc loss 20.23301887512207\n",
      "cls loss 550.7080078125  loc loss 35.45454406738281\n",
      "cls loss 312.4507141113281  loc loss 22.782989501953125\n",
      "cls loss 509.5648193359375  loc loss 34.20085906982422\n",
      "cls loss 388.9287414550781  loc loss 36.19877243041992\n",
      "cls loss 374.2275695800781  loc loss 25.16036605834961\n",
      "cls loss 830.5318603515625  loc loss 65.19778442382812\n",
      "cls loss 531.5077514648438  loc loss 40.933921813964844\n",
      "cls loss 329.33233642578125  loc loss 17.73563003540039\n",
      "cls loss 200.0440673828125  loc loss 9.890939712524414\n",
      "cls loss 273.71966552734375  loc loss 13.109044075012207\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3., 10., 10., 10., 10., 10., 10., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10., 10., 10., 10., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 11., 10., 10., 10., 10., 10.,  3.,  3.,  3.,  3.,  3.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 11., 10., 10., 10., 10., 10.,  3.,  3.,  3.,  3.,  3.])\n",
      "cls loss 208.2718505859375  loc loss 10.298273086547852\n",
      "cls loss 300.1822814941406  loc loss 12.940508842468262\n",
      "cls loss 265.7458190917969  loc loss 14.848681449890137\n",
      "cls loss 279.90789794921875  loc loss 11.264848709106445\n",
      "cls loss 362.78594970703125  loc loss 24.80975914001465\n",
      "cls loss 268.2713928222656  loc loss 9.756559371948242\n",
      "cls loss 564.3440551757812  loc loss 31.205581665039062\n",
      "cls loss 567.5614624023438  loc loss 25.838653564453125\n",
      "cls loss 753.1859130859375  loc loss 40.45916748046875\n",
      "cls loss 366.43206787109375  loc loss 22.910316467285156\n",
      "cls loss 588.0589599609375  loc loss 36.81066131591797\n",
      "cls loss 445.12933349609375  loc loss 32.68910598754883\n",
      "cls loss 452.08935546875  loc loss 28.537370681762695\n",
      "cls loss 441.9246826171875  loc loss 29.17797088623047\n",
      "cls loss 554.3505859375  loc loss 37.052833557128906\n",
      "cls loss 543.2963256835938  loc loss 34.64229965209961\n",
      "cls loss 250.64442443847656  loc loss 13.676187515258789\n",
      "cls loss 535.6304931640625  loc loss 35.633201599121094\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 10.,  1., 18.])\n",
      "cls loss 228.85690307617188  loc loss 16.952878952026367\n",
      "cls loss 262.08038330078125  loc loss 12.586294174194336\n",
      "cls loss 512.7974853515625  loc loss 26.745635986328125\n",
      "cls loss 716.5801391601562  loc loss 40.15595626831055\n",
      "cls loss 449.4686279296875  loc loss 27.737585067749023\n",
      "cls loss 688.58251953125  loc loss 31.09020233154297\n",
      "cls loss 531.6746826171875  loc loss 30.855697631835938\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.,  1.,  1.])\n",
      "cls loss 644.628662109375  loc loss 33.03258514404297\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1., 38.,  1.])\n",
      "cls loss 559.0374755859375  loc loss 27.842721939086914\n",
      "cls loss 714.9542846679688  loc loss 51.123294830322266\n",
      "cls loss 377.4780578613281  loc loss 24.7252197265625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 495.9022521972656  loc loss 28.526269912719727\n",
      "cls loss 396.85345458984375  loc loss 23.724042892456055\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3., 10.,  8.,  3., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.])\n",
      "cls loss 451.43017578125  loc loss 26.240087509155273\n",
      "cls loss 303.04296875  loc loss 20.75216293334961\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3.,  3., 11.,  3., 10., 10.,  3.,  3., 10.])\n",
      "cls loss 332.692138671875  loc loss 18.63199234008789\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3., 10., 10., 10.])\n",
      "cls loss 396.19769287109375  loc loss 21.023895263671875\n",
      "cls loss 289.453369140625  loc loss 20.98164176940918\n",
      "cls loss 413.40008544921875  loc loss 29.080408096313477\n",
      "cls loss 583.2366943359375  loc loss 35.59654998779297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 378.3319091796875  loc loss 25.41381072998047\n",
      "cls loss 308.0753173828125  loc loss 23.21116065979004\n",
      "cls loss 414.9703369140625  loc loss 22.207889556884766\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 9.,  9., 85., 85.])\n",
      "cls loss 368.3554992675781  loc loss 15.262436866760254\n",
      "cls loss 465.0780029296875  loc loss 27.330556869506836\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 655.150390625  loc loss 38.59601593017578\n",
      "cls loss 550.8468627929688  loc loss 22.395950317382812\n",
      "cls loss 646.33203125  loc loss 41.98879623413086\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10., 10., 10., 10.])\n",
      "cls loss 419.564208984375  loc loss 23.845458984375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([13.])\n",
      "cls loss 606.82275390625  loc loss 46.854705810546875\n",
      "cls loss 162.08013916015625  loc loss 9.744175910949707\n",
      "cls loss 238.11158752441406  loc loss 13.402849197387695\n",
      "cls loss 301.12689208984375  loc loss 20.25501251220703\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19.,  1.,  1.,  1., 19., 19.])\n",
      "cls loss 329.2626037597656  loc loss 24.430828094482422\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 278.5963134765625  loc loss 19.844141006469727\n",
      "cls loss 444.30853271484375  loc loss 29.240642547607422\n",
      "cls loss 323.5181884765625  loc loss 17.64243507385254\n",
      "cls loss 465.61407470703125  loc loss 23.493013381958008\n",
      "cls loss 485.79718017578125  loc loss 34.702911376953125\n",
      "cls loss 378.4393615722656  loc loss 21.26593780517578\n",
      "cls loss 633.90185546875  loc loss 40.99114227294922\n",
      "cls loss 239.6305694580078  loc loss 9.396425247192383\n",
      "cls loss 417.01898193359375  loc loss 27.682044982910156\n",
      "cls loss 362.8360595703125  loc loss 19.071203231811523\n",
      "cls loss 411.1143798828125  loc loss 19.016916275024414\n",
      "cls loss 527.1474609375  loc loss 28.583402633666992\n",
      "cls loss 410.42425537109375  loc loss 19.661956787109375\n",
      "cls loss 594.001953125  loc loss 39.942352294921875\n",
      "cls loss 373.60137939453125  loc loss 22.620773315429688\n",
      "cls loss 459.841552734375  loc loss 33.89609909057617\n",
      "cls loss 666.2215576171875  loc loss 41.99174499511719\n",
      "cls loss 360.2257080078125  loc loss 28.377376556396484\n",
      "cls loss 427.32904052734375  loc loss 25.050464630126953\n",
      "cls loss 500.0760498046875  loc loss 40.12229537963867\n",
      "cls loss 587.8439331054688  loc loss 41.881649017333984\n",
      "cls loss 659.420166015625  loc loss 40.27509689331055\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 5.])\n",
      "cls loss 175.5052032470703  loc loss 9.171070098876953\n",
      "cls loss 259.50250244140625  loc loss 10.37136173248291\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 13.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 6., 8., 8.])\n",
      "cls loss 203.52366638183594  loc loss 10.445380210876465\n",
      "cls loss 309.9146728515625  loc loss 12.775712013244629\n",
      "cls loss 543.996337890625  loc loss 33.25835037231445\n",
      "cls loss 226.18496704101562  loc loss 12.016012191772461\n",
      "cls loss 443.6602783203125  loc loss 30.929065704345703\n",
      "cls loss 701.233154296875  loc loss 46.84208679199219\n",
      "cls loss 425.76934814453125  loc loss 27.757375717163086\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([42., 42.,  1.,  1.,  1.,  1.,  1.,  1.,  1., 42., 42.])\n",
      "cls loss 463.5263977050781  loc loss 22.875152587890625\n",
      "cls loss 571.571533203125  loc loss 43.27253723144531\n",
      "cls loss 512.4744873046875  loc loss 34.49204635620117\n",
      "cls loss 315.2951354980469  loc loss 20.03972816467285\n",
      "cls loss 418.3227844238281  loc loss 22.80171775817871\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 641.2239379882812  loc loss 39.240570068359375\n",
      "cls loss 517.9647827148438  loc loss 33.85676574707031\n",
      "cls loss 301.48492431640625  loc loss 15.724930763244629\n",
      "cls loss 264.1083068847656  loc loss 14.685761451721191\n",
      "cls loss 350.4551696777344  loc loss 22.122478485107422\n",
      "cls loss 482.922119140625  loc loss 31.055639266967773\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15.])\n",
      "cls loss 236.58963012695312  loc loss 8.352675437927246\n",
      "cls loss 422.7216796875  loc loss 24.89322280883789\n",
      "cls loss 369.18536376953125  loc loss 23.53652000427246\n",
      "cls loss 661.005615234375  loc loss 39.8489990234375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19.,  7.])\n",
      "cls loss 307.48248291015625  loc loss 17.847471237182617\n",
      "cls loss 628.814453125  loc loss 43.69496536254883\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 561.7479858398438  loc loss 29.14676284790039\n",
      "cls loss 520.4379272460938  loc loss 34.3199462890625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([38., 38.,  1., 18.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1., 18., 18.,  1.])\n",
      "cls loss 347.45684814453125  loc loss 19.496868133544922\n",
      "cls loss 333.6443786621094  loc loss 17.71758270263672\n",
      "cls loss 656.4073486328125  loc loss 47.10179138183594\n",
      "cls loss 466.373291015625  loc loss 33.34622573852539\n",
      "cls loss 392.6844177246094  loc loss 27.241111755371094\n",
      "cls loss 268.294921875  loc loss 19.89470863342285\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.])\n",
      "cls loss 166.04051208496094  loc loss 6.852038383483887\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([32.])\n",
      "cls loss 426.22930908203125  loc loss 22.291019439697266\n",
      "cls loss 378.9905700683594  loc loss 24.708492279052734\n",
      "cls loss 461.78399658203125  loc loss 34.986671447753906\n",
      "cls loss 417.8853759765625  loc loss 25.21276092529297\n",
      "cls loss 359.0948181152344  loc loss 20.33281707763672\n",
      "cls loss 573.82958984375  loc loss 32.77438735961914\n",
      "cls loss 668.0881958007812  loc loss 43.623779296875\n",
      "cls loss 482.59765625  loc loss 35.461700439453125\n",
      "cls loss 360.5747375488281  loc loss 23.133724212646484\n",
      "cls loss 581.6283569335938  loc loss 41.071224212646484\n",
      "cls loss 380.7146301269531  loc loss 21.756961822509766\n",
      "cls loss 687.033935546875  loc loss 45.26905822753906\n",
      "cls loss 446.45391845703125  loc loss 25.750701904296875\n",
      "cls loss 366.66650390625  loc loss 30.82241439819336\n",
      "cls loss 288.8040771484375  loc loss 15.492359161376953\n",
      "cls loss 338.360107421875  loc loss 22.431108474731445\n",
      "cls loss 499.10498046875  loc loss 34.06047058105469\n",
      "cls loss 568.4192504882812  loc loss 41.68672180175781\n",
      "cls loss 334.2274169921875  loc loss 21.388870239257812\n",
      "cls loss 536.608642578125  loc loss 39.3330192565918\n",
      "cls loss 645.4512329101562  loc loss 42.712608337402344\n",
      "cls loss 241.43838500976562  loc loss 14.891195297241211\n",
      "cls loss 625.9232177734375  loc loss 42.92218017578125\n",
      "cls loss 464.6672058105469  loc loss 31.64027976989746\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 601.6318969726562  loc loss 47.54286193847656\n",
      "cls loss 257.97064208984375  loc loss 12.291099548339844\n",
      "cls loss 390.86785888671875  loc loss 25.78004264831543\n",
      "cls loss 397.3685302734375  loc loss 29.177776336669922\n",
      "cls loss 331.0514221191406  loc loss 22.89463996887207\n",
      "cls loss 196.62948608398438  loc loss 11.176640510559082\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 9., 9., 1., 9., 9., 9., 9., 1., 9.])\n",
      "cls loss 889.41552734375  loc loss 61.67416000366211\n",
      "cls loss 486.0014953613281  loc loss 27.09304428100586\n",
      "cls loss 751.5917358398438  loc loss 56.65279769897461\n",
      "cls loss 296.2641296386719  loc loss 23.290264129638672\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 42., 42.])\n",
      "cls loss 480.0118408203125  loc loss 38.671627044677734\n",
      "cls loss 487.7286682128906  loc loss 42.53734588623047\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  2.,  1.,  1.,  1., 38.,\n",
      "         1.,  1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 38., 38., 38.,  1., 38., 38., 38.,  1.,  1., 38.,  1.,\n",
      "         1.])\n",
      "cls loss 282.81048583984375  loc loss 23.201698303222656\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  8.,  8.])\n",
      "cls loss 678.1012573242188  loc loss 50.27493667602539\n",
      "cls loss 677.36474609375  loc loss 53.50499725341797\n",
      "cls loss 257.03375244140625  loc loss 16.556907653808594\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([4., 1., 1., 4.])\n",
      "cls loss 409.5895690917969  loc loss 26.150558471679688\n",
      "cls loss 520.5751953125  loc loss 31.93102264404297\n",
      "cls loss 206.4306640625  loc loss 11.36237907409668\n",
      "cls loss 259.4935607910156  loc loss 18.03757667541504\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([51.,  1.])\n",
      "cls loss 187.81204223632812  loc loss 10.18596076965332\n",
      "cls loss 265.0942687988281  loc loss 20.54499053955078\n",
      "cls loss 555.114990234375  loc loss 30.445171356201172\n",
      "cls loss 515.3497314453125  loc loss 41.681514739990234\n",
      "cls loss 784.7049560546875  loc loss 42.51239013671875\n",
      "cls loss 943.4545288085938  loc loss 61.76985549926758\n",
      "cls loss 389.6861572265625  loc loss 24.597558975219727\n",
      "cls loss 566.6835327148438  loc loss 42.34186553955078\n",
      "cls loss 614.741455078125  loc loss 43.579978942871094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 438.2806396484375  loc loss 30.682533264160156\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  3.,  1.,  1.,  1.,  3.,  1.,  1.,\n",
      "         1.,  1.,  1.])\n",
      "cls loss 476.8710632324219  loc loss 23.055561065673828\n",
      "cls loss 514.8042602539062  loc loss 32.65467834472656\n",
      "cls loss 490.0070495605469  loc loss 30.895837783813477\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "cls loss 419.9007873535156  loc loss 26.24600601196289\n",
      "cls loss 229.94032287597656  loc loss 19.282093048095703\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3.])\n",
      "cls loss 189.9947052001953  loc loss 11.133856773376465\n",
      "cls loss 334.467529296875  loc loss 20.856510162353516\n",
      "cls loss 318.7559814453125  loc loss 22.286823272705078\n",
      "cls loss 579.2923583984375  loc loss 37.73603439331055\n",
      "cls loss 267.428955078125  loc loss 20.962604522705078\n",
      "cls loss 303.5693054199219  loc loss 25.658966064453125\n",
      "cls loss 880.0504150390625  loc loss 63.2042121887207\n",
      "cls loss 388.0351257324219  loc loss 29.926748275756836\n",
      "cls loss 287.76495361328125  loc loss 22.14957046508789\n",
      "cls loss 342.29034423828125  loc loss 20.145143508911133\n",
      "cls loss 310.7266845703125  loc loss 24.401824951171875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 576.5997314453125  loc loss 41.37972640991211\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  9., 64., 64., 64., 64., 64., 64., 64., 64., 64.,  9.,  9.,  9.,\n",
      "         9.])\n",
      "cls loss 265.87615966796875  loc loss 15.431224822998047\n",
      "cls loss 829.6594848632812  loc loss 64.24247741699219\n",
      "cls loss 442.5122375488281  loc loss 28.853364944458008\n",
      "cls loss 536.3846435546875  loc loss 36.81900405883789\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.,  3.,  3.])\n",
      "cls loss 332.4564514160156  loc loss 19.278648376464844\n",
      "cls loss 366.45721435546875  loc loss 28.253549575805664\n",
      "cls loss 385.8873596191406  loc loss 28.87944221496582\n",
      "cls loss 396.7613525390625  loc loss 26.501827239990234\n",
      "cls loss 456.163330078125  loc loss 31.119768142700195\n",
      "cls loss 453.8242492675781  loc loss 29.74855613708496\n",
      "cls loss 407.0599060058594  loc loss 28.170326232910156\n",
      "cls loss 414.20013427734375  loc loss 23.10634422302246\n",
      "cls loss 520.292724609375  loc loss 34.674156188964844\n",
      "cls loss 377.5040283203125  loc loss 24.004846572875977\n",
      "cls loss 290.43798828125  loc loss 15.752861976623535\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21.])\n",
      "cls loss 236.86773681640625  loc loss 16.277992248535156\n",
      "cls loss 339.1766662597656  loc loss 29.834630966186523\n",
      "cls loss 498.549072265625  loc loss 35.43296813964844\n",
      "cls loss 251.58863830566406  loc loss 16.1579532623291\n",
      "cls loss 411.3611145019531  loc loss 28.356271743774414\n",
      "cls loss 766.6150512695312  loc loss 41.378273010253906\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 42., 42.,  1.,  1.])\n",
      "cls loss 462.41180419921875  loc loss 25.70397186279297\n",
      "cls loss 305.6043395996094  loc loss 17.8669490814209\n",
      "cls loss 444.30987548828125  loc loss 26.41415786743164\n",
      "cls loss 575.3154907226562  loc loss 41.93980407714844\n",
      "cls loss 358.591064453125  loc loss 20.231962203979492\n",
      "cls loss 552.143798828125  loc loss 37.21639633178711\n",
      "cls loss 482.3329162597656  loc loss 34.10205078125\n",
      "cls loss 461.51409912109375  loc loss 29.75970458984375\n",
      "cls loss 373.5797119140625  loc loss 23.772357940673828\n",
      "cls loss 299.8221435546875  loc loss 21.318349838256836\n",
      "cls loss 238.71453857421875  loc loss 11.16444206237793\n",
      "cls loss 378.248779296875  loc loss 24.37729263305664\n",
      "cls loss 569.5364990234375  loc loss 37.08760070800781\n",
      "cls loss 417.5301513671875  loc loss 25.251911163330078\n",
      "cls loss 398.0854187011719  loc loss 29.82331657409668\n",
      "cls loss 440.30987548828125  loc loss 26.631702423095703\n",
      "cls loss 654.5140380859375  loc loss 48.90927505493164\n",
      "cls loss 524.9163818359375  loc loss 34.58740234375\n",
      "cls loss 581.5888061523438  loc loss 30.30647087097168\n",
      "cls loss 366.33123779296875  loc loss 15.855680465698242\n",
      "cls loss 508.75762939453125  loc loss 29.133195877075195\n",
      "cls loss 472.41168212890625  loc loss 25.464384078979492\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 5., 5., 5., 5., 5., 5.])\n",
      "cls loss 284.35186767578125  loc loss 17.436614990234375\n",
      "cls loss 385.5512390136719  loc loss 19.78399658203125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([13.])\n",
      "cls loss 264.86614990234375  loc loss 12.408493995666504\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([44., 10.,  1.,  1.,  1.])\n",
      "cls loss 236.00454711914062  loc loss 15.682621002197266\n",
      "cls loss 420.02508544921875  loc loss 23.709747314453125\n",
      "cls loss 382.90618896484375  loc loss 21.00546646118164\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19., 19., 19., 19., 19., 19., 19.])\n",
      "cls loss 402.6050109863281  loc loss 25.83660125732422\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([56.])\n",
      "cls loss 843.516845703125  loc loss 55.73727798461914\n",
      "cls loss 536.6390380859375  loc loss 39.58246612548828\n",
      "cls loss 678.4176025390625  loc loss 43.849552154541016\n",
      "cls loss 648.7872314453125  loc loss 50.28327178955078\n",
      "cls loss 385.57598876953125  loc loss 23.03675079345703\n",
      "cls loss 667.2451171875  loc loss 43.130699157714844\n",
      "cls loss 381.17755126953125  loc loss 25.608823776245117\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 36.])\n",
      "cls loss 514.0121459960938  loc loss 22.71940803527832\n",
      "cls loss 436.3910827636719  loc loss 26.43286895751953\n",
      "cls loss 411.51934814453125  loc loss 23.637643814086914\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5.])\n",
      "cls loss 487.72552490234375  loc loss 27.04963493347168\n",
      "cls loss 268.41729736328125  loc loss 12.296453475952148\n",
      "cls loss 594.246826171875  loc loss 32.04390335083008\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "cls loss 526.024169921875  loc loss 31.076496124267578\n",
      "cls loss 471.3489990234375  loc loss 31.019390106201172\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 504.3255615234375  loc loss 31.769819259643555\n",
      "cls loss 556.2452392578125  loc loss 36.76526641845703\n",
      "cls loss 479.40234375  loc loss 40.335670471191406\n",
      "cls loss 339.47802734375  loc loss 21.670902252197266\n",
      "cls loss 379.28741455078125  loc loss 27.833839416503906\n",
      "cls loss 397.41937255859375  loc loss 23.457670211791992\n",
      "cls loss 678.231201171875  loc loss 33.088741302490234\n",
      "cls loss 270.1617736816406  loc loss 13.891664505004883\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 11., 15., 10., 10., 10., 10., 10.])\n",
      "cls loss 600.2518310546875  loc loss 39.6874885559082\n",
      "cls loss 362.9897155761719  loc loss 27.127281188964844\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3.])\n",
      "cls loss 379.963134765625  loc loss 27.746692657470703\n",
      "cls loss 369.1980895996094  loc loss 18.64144515991211\n",
      "cls loss 429.25732421875  loc loss 18.532297134399414\n",
      "cls loss 541.681640625  loc loss 22.530488967895508\n",
      "cls loss 248.40621948242188  loc loss 11.513362884521484\n",
      "cls loss 468.0331115722656  loc loss 27.356481552124023\n",
      "cls loss 517.3224487304688  loc loss 30.332277297973633\n",
      "cls loss 442.5233459472656  loc loss 27.815658569335938\n",
      "cls loss 986.35302734375  loc loss 62.49679183959961\n",
      "cls loss 638.1328735351562  loc loss 40.974552154541016\n",
      "cls loss 401.9119567871094  loc loss 27.479389190673828\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  9.,  9.,  9.,  6.,  6., 85., 85.,  8.,  1.,  1.,  1.,  1.,\n",
      "         6.,  6.])\n",
      "cls loss 280.7991943359375  loc loss 21.7125301361084\n",
      "cls loss 692.3246459960938  loc loss 47.9015998840332\n",
      "cls loss 817.99462890625  loc loss 47.86599349975586\n",
      "cls loss 534.0386962890625  loc loss 35.62631607055664\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10.,  3.,  3., 10.])\n",
      "cls loss 325.0028076171875  loc loss 18.189430236816406\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([7.])\n",
      "cls loss 420.2286376953125  loc loss 27.661174774169922\n",
      "cls loss 428.17669677734375  loc loss 26.197715759277344\n",
      "cls loss 445.0523681640625  loc loss 36.42856216430664\n",
      "cls loss 731.967041015625  loc loss 48.1693229675293\n",
      "cls loss 426.679931640625  loc loss 26.190654754638672\n",
      "cls loss 664.5478515625  loc loss 37.961631774902344\n",
      "cls loss 793.934326171875  loc loss 43.14928436279297\n",
      "cls loss 527.99267578125  loc loss 28.06296157836914\n",
      "cls loss 577.144287109375  loc loss 33.072731018066406\n",
      "cls loss 432.41046142578125  loc loss 28.179861068725586\n",
      "cls loss 608.7544555664062  loc loss 43.41770935058594\n",
      "cls loss 458.06463623046875  loc loss 29.206737518310547\n",
      "cls loss 327.38629150390625  loc loss 21.58574104309082\n",
      "cls loss 537.1875  loc loss 40.48646545410156\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([62.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([62.])\n",
      "cls loss 234.76535034179688  loc loss 11.83505916595459\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 395.292236328125  loc loss 28.966035842895508\n",
      "cls loss 397.057373046875  loc loss 26.283958435058594\n",
      "cls loss 261.6199951171875  loc loss 12.915512084960938\n",
      "cls loss 539.5224609375  loc loss 34.765228271484375\n",
      "cls loss 544.668701171875  loc loss 30.80010414123535\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([28.])\n",
      "cls loss 683.6732177734375  loc loss 31.525753021240234\n",
      "cls loss 519.6074829101562  loc loss 32.90193557739258\n",
      "cls loss 517.2667236328125  loc loss 35.89063262939453\n",
      "cls loss 607.9610595703125  loc loss 33.96962356567383\n",
      "cls loss 931.9208984375  loc loss 48.06461715698242\n",
      "cls loss 493.3223571777344  loc loss 26.284839630126953\n",
      "cls loss 676.8685913085938  loc loss 30.88701057434082\n",
      "cls loss 521.18359375  loc loss 35.97426986694336\n",
      "cls loss 774.3330688476562  loc loss 57.81870651245117\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([81.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 470.32855224609375  loc loss 19.49050521850586\n",
      "cls loss 357.83642578125  loc loss 19.088924407958984\n",
      "cls loss 260.9906005859375  loc loss 20.16402244567871\n",
      "cls loss 235.95791625976562  loc loss 10.63720989227295\n",
      "cls loss 273.19281005859375  loc loss 21.652687072753906\n",
      "cls loss 338.5731201171875  loc loss 21.60085678100586\n",
      "cls loss 345.1638488769531  loc loss 25.75316619873047\n",
      "cls loss 516.829833984375  loc loss 42.15058898925781\n",
      "cls loss 604.8736572265625  loc loss 36.41794967651367\n",
      "cls loss 1065.683837890625  loc loss 71.51143646240234\n",
      "cls loss 418.4002380371094  loc loss 20.825740814208984\n",
      "cls loss 519.1346435546875  loc loss 38.17970657348633\n",
      "cls loss 380.68145751953125  loc loss 22.292797088623047\n",
      "cls loss 550.6777954101562  loc loss 27.313339233398438\n",
      "cls loss 470.75579833984375  loc loss 24.7767276763916\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([44., 44.])\n",
      "cls loss 470.1579895019531  loc loss 19.00507164001465\n",
      "cls loss 492.00335693359375  loc loss 28.504627227783203\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15.])\n",
      "cls loss 492.27618408203125  loc loss 23.418798446655273\n",
      "cls loss 243.98464965820312  loc loss 14.557439804077148\n",
      "cls loss 431.43682861328125  loc loss 30.708675384521484\n",
      "cls loss 252.39453125  loc loss 12.954635620117188\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([1., 3., 3.])\n",
      "cls loss 281.636474609375  loc loss 18.005224227905273\n",
      "cls loss 206.20599365234375  loc loss 10.113432884216309\n",
      "cls loss 415.45220947265625  loc loss 27.647750854492188\n",
      "cls loss 477.9731140136719  loc loss 26.168437957763672\n",
      "cls loss 410.60028076171875  loc loss 27.318058013916016\n",
      "cls loss 341.25531005859375  loc loss 22.768062591552734\n",
      "cls loss 371.78997802734375  loc loss 26.861968994140625\n",
      "cls loss 491.12451171875  loc loss 31.53640365600586\n",
      "cls loss 334.79351806640625  loc loss 22.592029571533203\n",
      "cls loss 427.65570068359375  loc loss 33.987449645996094\n",
      "cls loss 297.5552978515625  loc loss 19.777542114257812\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 568.0450439453125  loc loss 32.870033264160156\n",
      "cls loss 716.143798828125  loc loss 29.988391876220703\n",
      "cls loss 602.898193359375  loc loss 38.35138702392578\n",
      "cls loss 595.606201171875  loc loss 44.1588134765625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10., 10., 10.,  1.,  1.,  1.,  1.,  1.,  1.,  8.,  8.,\n",
      "         1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10., 10., 10.,  1.,  1.,  1.,  1.,  1.,  1.,  8.,  8.,\n",
      "         1.])\n",
      "cls loss 480.06427001953125  loc loss 23.580608367919922\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 3., 3., 3.])\n",
      "cls loss 475.4501037597656  loc loss 25.814237594604492\n",
      "cls loss 283.21844482421875  loc loss 17.985641479492188\n",
      "cls loss 210.83883666992188  loc loss 11.03026008605957\n",
      "cls loss 416.0971374511719  loc loss 33.04431915283203\n",
      "cls loss 306.93389892578125  loc loss 15.691146850585938\n",
      "cls loss 369.5932312011719  loc loss 28.45160484313965\n",
      "cls loss 414.120849609375  loc loss 34.00341033935547\n",
      "cls loss 572.1204833984375  loc loss 46.3031120300293\n",
      "cls loss 499.5455322265625  loc loss 27.57378578186035\n",
      "cls loss 452.72528076171875  loc loss 25.35384750366211\n",
      "cls loss 476.66754150390625  loc loss 31.035526275634766\n",
      "cls loss 341.6500549316406  loc loss 25.063095092773438\n",
      "cls loss 693.3057861328125  loc loss 49.41503143310547\n",
      "cls loss 305.6293029785156  loc loss 17.754194259643555\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 568.50927734375  loc loss 32.92525100708008\n",
      "cls loss 251.2344512939453  loc loss 11.480972290039062\n",
      "cls loss 631.2178955078125  loc loss 44.632320404052734\n",
      "cls loss 322.411376953125  loc loss 20.50112533569336\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 34.])\n",
      "cls loss 534.1596069335938  loc loss 29.900157928466797\n",
      "cls loss 292.08782958984375  loc loss 17.14112663269043\n",
      "cls loss 569.8538818359375  loc loss 31.416370391845703\n",
      "cls loss 191.778076171875  loc loss 13.478503227233887\n",
      "cls loss 424.6956481933594  loc loss 26.613189697265625\n",
      "cls loss 408.81451416015625  loc loss 32.81534957885742\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 38.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16., 16., 16.,  9.,  9.,  9., 16., 16., 16., 85.,  9.])\n",
      "cls loss 422.3043212890625  loc loss 26.391862869262695\n",
      "cls loss 458.65960693359375  loc loss 35.1902961730957\n",
      "cls loss 617.6417236328125  loc loss 40.57971954345703\n",
      "cls loss 965.46044921875  loc loss 59.867706298828125\n",
      "cls loss 245.30996704101562  loc loss 14.061561584472656\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3., 10.,  8.,  8., 10., 10., 10.,  3.,  3., 14.])\n",
      "cls loss 277.81512451171875  loc loss 15.612444877624512\n",
      "cls loss 502.15740966796875  loc loss 32.483402252197266\n",
      "cls loss 204.8193359375  loc loss 9.279474258422852\n",
      "cls loss 368.419677734375  loc loss 16.92413330078125\n",
      "cls loss 508.3547668457031  loc loss 33.30670166015625\n",
      "cls loss 448.8614501953125  loc loss 26.376468658447266\n",
      "cls loss 268.5421142578125  loc loss 13.961432456970215\n",
      "cls loss 363.72381591796875  loc loss 16.029939651489258\n",
      "cls loss 587.369140625  loc loss 29.225513458251953\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42., 42.,  1.])\n",
      "cls loss 561.4681396484375  loc loss 29.34072494506836\n",
      "cls loss 412.85272216796875  loc loss 21.047895431518555\n",
      "cls loss 509.9674072265625  loc loss 37.863643646240234\n",
      "cls loss 575.173828125  loc loss 34.89997100830078\n",
      "cls loss 395.50225830078125  loc loss 23.761507034301758\n",
      "cls loss 482.7498779296875  loc loss 34.5185432434082\n",
      "cls loss 295.0821838378906  loc loss 19.664051055908203\n",
      "cls loss 313.06829833984375  loc loss 22.804100036621094\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20.])\n",
      "cls loss 221.593017578125  loc loss 13.07653522491455\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([11.])\n",
      "cls loss 327.61285400390625  loc loss 14.635212898254395\n",
      "cls loss 180.1811065673828  loc loss 11.662259101867676\n",
      "cls loss 489.9387512207031  loc loss 36.13382339477539\n",
      "cls loss 211.30291748046875  loc loss 10.626007080078125\n",
      "cls loss 439.1442565917969  loc loss 26.935880661010742\n",
      "cls loss 236.15049743652344  loc loss 16.099092483520508\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 35., 27.])\n",
      "cls loss 434.2386474609375  loc loss 24.779569625854492\n",
      "cls loss 511.8017883300781  loc loss 36.14342498779297\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 341.93780517578125  loc loss 17.5295352935791\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([42.,  1.])\n",
      "cls loss 438.90234375  loc loss 27.716106414794922\n",
      "cls loss 476.77447509765625  loc loss 22.313152313232422\n",
      "cls loss 617.3153686523438  loc loss 29.05499267578125\n",
      "cls loss 716.0359497070312  loc loss 34.74349594116211\n",
      "cls loss 581.8665771484375  loc loss 30.24851417541504\n",
      "cls loss 404.7572937011719  loc loss 23.67055892944336\n",
      "cls loss 328.03729248046875  loc loss 22.338226318359375\n",
      "cls loss 188.64068603515625  loc loss 8.283963203430176\n",
      "cls loss 351.76336669921875  loc loss 19.349483489990234\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 1., 1.])\n",
      "cls loss 330.5660400390625  loc loss 20.882652282714844\n",
      "cls loss 400.96990966796875  loc loss 26.194522857666016\n",
      "cls loss 385.1235046386719  loc loss 23.643152236938477\n",
      "cls loss 309.2947998046875  loc loss 22.408954620361328\n",
      "cls loss 387.1728820800781  loc loss 25.21623992919922\n",
      "cls loss 406.1234130859375  loc loss 29.391231536865234\n",
      "cls loss 590.278076171875  loc loss 34.977012634277344\n",
      "cls loss 505.845458984375  loc loss 38.99250411987305\n",
      "cls loss 442.148681640625  loc loss 29.178577423095703\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 350.7265930175781  loc loss 25.963239669799805\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 486.38507080078125  loc loss 19.928295135498047\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([81.])\n",
      "cls loss 596.108154296875  loc loss 30.929386138916016\n",
      "cls loss 349.1949768066406  loc loss 22.154132843017578\n",
      "cls loss 315.70751953125  loc loss 12.322935104370117\n",
      "cls loss 400.70751953125  loc loss 19.636924743652344\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3.,  1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 19.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 19.])\n",
      "cls loss 563.962890625  loc loss 33.26091003417969\n",
      "cls loss 285.67144775390625  loc loss 15.70761489868164\n",
      "cls loss 309.8193359375  loc loss 16.86855125427246\n",
      "cls loss 566.8096923828125  loc loss 41.10898208618164\n",
      "cls loss 278.09735107421875  loc loss 17.75537872314453\n",
      "cls loss 352.67193603515625  loc loss 21.5863037109375\n",
      "cls loss 437.134765625  loc loss 30.457645416259766\n",
      "cls loss 326.6251525878906  loc loss 24.237594604492188\n",
      "cls loss 438.90264892578125  loc loss 25.071392059326172\n",
      "cls loss 476.52191162109375  loc loss 31.95815086364746\n",
      "cls loss 641.8057250976562  loc loss 55.42061996459961\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 81.])\n",
      "cls loss 424.66998291015625  loc loss 21.100406646728516\n",
      "cls loss 400.864501953125  loc loss 21.307954788208008\n",
      "cls loss 398.97735595703125  loc loss 22.566457748413086\n",
      "cls loss 330.67352294921875  loc loss 16.574527740478516\n",
      "cls loss 314.57904052734375  loc loss 17.611745834350586\n",
      "cls loss 382.1922302246094  loc loss 25.361730575561523\n",
      "cls loss 279.552490234375  loc loss 18.51994514465332\n",
      "cls loss 231.24508666992188  loc loss 14.766084671020508\n",
      "cls loss 320.8856506347656  loc loss 19.876934051513672\n",
      "cls loss 414.59307861328125  loc loss 25.380081176757812\n",
      "cls loss 402.518310546875  loc loss 27.379350662231445\n",
      "cls loss 371.6476745605469  loc loss 24.71831512451172\n",
      "cls loss 215.1951904296875  loc loss 13.97724437713623\n",
      "cls loss 759.906982421875  loc loss 47.93354034423828\n",
      "cls loss 418.1468811035156  loc loss 28.09593391418457\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 375.0296630859375  loc loss 18.783843994140625\n",
      "cls loss 420.8406982421875  loc loss 26.657489776611328\n",
      "cls loss 294.0941467285156  loc loss 21.305835723876953\n",
      "cls loss 470.74200439453125  loc loss 35.69258499145508\n",
      "cls loss 475.14849853515625  loc loss 29.781795501708984\n",
      "cls loss 416.989501953125  loc loss 28.09917640686035\n",
      "cls loss 323.60205078125  loc loss 22.753082275390625\n",
      "cls loss 298.6127014160156  loc loss 16.69761085510254\n",
      "cls loss 436.75146484375  loc loss 24.386829376220703\n",
      "cls loss 520.6187133789062  loc loss 31.346342086791992\n",
      "cls loss 471.96490478515625  loc loss 24.04133415222168\n",
      "cls loss 626.1265869140625  loc loss 36.63093948364258\n",
      "cls loss 643.6806640625  loc loss 42.2388801574707\n",
      "cls loss 456.5632629394531  loc loss 27.767578125\n",
      "cls loss 622.2656860351562  loc loss 45.135520935058594\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1., 38., 47.,  1.,  1.,  1.,  1.,  1., 62.])\n",
      "cls loss 371.2913818359375  loc loss 18.33711814880371\n",
      "cls loss 432.0008544921875  loc loss 31.804649353027344\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 465.43597412109375  loc loss 28.50467872619629\n",
      "cls loss 541.5181884765625  loc loss 39.39573669433594\n",
      "cls loss 353.8071594238281  loc loss 17.149208068847656\n",
      "cls loss 437.7669372558594  loc loss 33.59482192993164\n",
      "cls loss 415.6781005859375  loc loss 24.363264083862305\n",
      "cls loss 232.653564453125  loc loss 8.510852813720703\n",
      "cls loss 345.33953857421875  loc loss 20.717119216918945\n",
      "cls loss 308.697998046875  loc loss 13.350821495056152\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1., 35.])\n",
      "cls loss 331.14984130859375  loc loss 19.399642944335938\n",
      "cls loss 524.8251342773438  loc loss 26.837501525878906\n",
      "cls loss 533.8165283203125  loc loss 31.472150802612305\n",
      "cls loss 485.6513671875  loc loss 36.200042724609375\n",
      "cls loss 432.4336853027344  loc loss 27.544694900512695\n",
      "cls loss 541.259521484375  loc loss 37.8554801940918\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 294.0205078125  loc loss 15.98126220703125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 414.994140625  loc loss 16.567371368408203\n",
      "cls loss 613.4699096679688  loc loss 35.98921585083008\n",
      "cls loss 772.2672119140625  loc loss 60.60786437988281\n",
      "cls loss 384.572509765625  loc loss 20.208309173583984\n",
      "cls loss 324.4527587890625  loc loss 19.85947608947754\n",
      "cls loss 335.54986572265625  loc loss 17.4581356048584\n",
      "cls loss 372.7620544433594  loc loss 20.838626861572266\n",
      "cls loss 312.0409240722656  loc loss 13.823949813842773\n",
      "cls loss 587.3986206054688  loc loss 38.64480972290039\n",
      "cls loss 494.4354248046875  loc loss 30.32717514038086\n",
      "cls loss 227.271484375  loc loss 15.973417282104492\n",
      "cls loss 462.07720947265625  loc loss 26.74341583251953\n",
      "cls loss 607.0198974609375  loc loss 45.116363525390625\n",
      "cls loss 472.16265869140625  loc loss 30.948165893554688\n",
      "cls loss 424.13592529296875  loc loss 23.669076919555664\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.])\n",
      "cls loss 388.14874267578125  loc loss 27.415592193603516\n",
      "cls loss 411.58575439453125  loc loss 24.789539337158203\n",
      "cls loss 489.2134704589844  loc loss 29.959251403808594\n",
      "cls loss 804.56103515625  loc loss 59.497314453125\n",
      "cls loss 289.8359375  loc loss 15.556892395019531\n",
      "cls loss 380.9266052246094  loc loss 24.681312561035156\n",
      "cls loss 301.27313232421875  loc loss 18.41793441772461\n",
      "cls loss 341.836181640625  loc loss 24.57906150817871\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 21., 21., 21.])\n",
      "cls loss 328.6244201660156  loc loss 21.85039520263672\n",
      "cls loss 331.7039794921875  loc loss 17.888227462768555\n",
      "cls loss 354.78887939453125  loc loss 24.444820404052734\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 35.])\n",
      "cls loss 478.57000732421875  loc loss 28.903057098388672\n",
      "cls loss 180.52603149414062  loc loss 9.708731651306152\n",
      "cls loss 324.377685546875  loc loss 18.675630569458008\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 307.7914733886719  loc loss 13.00351333618164\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 38., 38.,  9., 38.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1.,  1.])\n",
      "cls loss 346.4906005859375  loc loss 20.687984466552734\n",
      "cls loss 575.0715942382812  loc loss 33.58354568481445\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 2.,  1., 77., 31., 10., 10.,  1.,  4., 10.])\n",
      "cls loss 269.9909362792969  loc loss 12.097594261169434\n",
      "cls loss 527.40087890625  loc loss 32.19099807739258\n",
      "cls loss 1058.5576171875  loc loss 59.42041015625\n",
      "cls loss 320.1443176269531  loc loss 22.12902069091797\n",
      "cls loss 443.3825988769531  loc loss 33.01267623901367\n",
      "cls loss 309.03131103515625  loc loss 16.11550521850586\n",
      "cls loss 289.14056396484375  loc loss 15.80949592590332\n",
      "cls loss 400.1665344238281  loc loss 23.942604064941406\n",
      "cls loss 402.2088623046875  loc loss 25.516170501708984\n",
      "cls loss 381.48724365234375  loc loss 29.08185577392578\n",
      "cls loss 326.00128173828125  loc loss 16.404254913330078\n",
      "cls loss 338.16790771484375  loc loss 19.611671447753906\n",
      "cls loss 651.5225830078125  loc loss 39.269683837890625\n",
      "cls loss 614.6221923828125  loc loss 34.085411071777344\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1., 42., 42., 42., 42., 42., 42.,  1.,\n",
      "         1.,  1.,  1., 42.,  1.,  1., 42.,  1.])\n",
      "cls loss 341.86676025390625  loc loss 23.68359375\n",
      "cls loss 510.5096435546875  loc loss 27.22277069091797\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.])\n",
      "cls loss 228.86053466796875  loc loss 11.121499061584473\n",
      "cls loss 505.2353515625  loc loss 30.11493492126465\n",
      "cls loss 371.1787109375  loc loss 26.39276885986328\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([11.])\n",
      "cls loss 224.97463989257812  loc loss 13.500210762023926\n",
      "cls loss 246.94891357421875  loc loss 13.392715454101562\n",
      "cls loss 276.3306884765625  loc loss 13.612665176391602\n",
      "cls loss 468.93408203125  loc loss 31.347869873046875\n",
      "cls loss 367.9781494140625  loc loss 23.459213256835938\n",
      "cls loss 391.73614501953125  loc loss 27.376615524291992\n",
      "cls loss 546.2242431640625  loc loss 30.830293655395508\n",
      "cls loss 294.7442626953125  loc loss 17.715850830078125\n",
      "cls loss 645.3002319335938  loc loss 41.34883117675781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 312.0234375  loc loss 18.827186584472656\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 299.60821533203125  loc loss 17.925735473632812\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1., 38., 38., 42.])\n",
      "cls loss 434.52593994140625  loc loss 26.415802001953125\n",
      "cls loss 409.111083984375  loc loss 22.37152099609375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 361.3973388671875  loc loss 21.061782836914062\n",
      "cls loss 759.8831787109375  loc loss 44.96953582763672\n",
      "cls loss 422.1124267578125  loc loss 26.03105354309082\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10.,  3.,  3.,  6.,  8.,  8.,  1.,  1.,  1., 10.])\n",
      "cls loss 320.89886474609375  loc loss 16.165435791015625\n",
      "cls loss 214.94705200195312  loc loss 8.104032516479492\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10.,  3.])\n",
      "cls loss 300.8446350097656  loc loss 18.063232421875\n",
      "cls loss 149.7035369873047  loc loss 9.113574028015137\n",
      "cls loss 375.7154235839844  loc loss 26.945938110351562\n",
      "cls loss 468.7405700683594  loc loss 29.680965423583984\n",
      "cls loss 333.96612548828125  loc loss 20.72280502319336\n",
      "cls loss 179.4646453857422  loc loss 13.212846755981445\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 34.])\n",
      "cls loss 506.51007080078125  loc loss 36.99208450317383\n",
      "cls loss 668.0860595703125  loc loss 48.92100524902344\n",
      "cls loss 411.5501708984375  loc loss 30.117122650146484\n",
      "cls loss 336.0195007324219  loc loss 23.50620460510254\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.,  1.])\n",
      "cls loss 376.4613037109375  loc loss 16.048776626586914\n",
      "cls loss 642.6487426757812  loc loss 41.58866500854492\n",
      "cls loss 881.625  loc loss 51.82281494140625\n",
      "cls loss 708.426513671875  loc loss 35.42726516723633\n",
      "cls loss 408.02667236328125  loc loss 20.726390838623047\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 445.46337890625  loc loss 26.751163482666016\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10.])\n",
      "cls loss 289.45257568359375  loc loss 15.921201705932617\n",
      "cls loss 412.36309814453125  loc loss 20.59048843383789\n",
      "cls loss 393.935546875  loc loss 23.19605255126953\n",
      "cls loss 253.45947265625  loc loss 15.847297668457031\n",
      "cls loss 350.6147155761719  loc loss 22.364524841308594\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21.,\n",
      "        21.])\n",
      "cls loss 429.86474609375  loc loss 26.416704177856445\n",
      "cls loss 368.2906494140625  loc loss 21.296707153320312\n",
      "cls loss 242.18222045898438  loc loss 11.45456600189209\n",
      "cls loss 564.0729370117188  loc loss 35.16853713989258\n",
      "cls loss 410.462158203125  loc loss 27.07298469543457\n",
      "cls loss 305.386474609375  loc loss 15.278214454650879\n",
      "cls loss 643.7323608398438  loc loss 37.7862548828125\n",
      "cls loss 719.4124145507812  loc loss 50.98369216918945\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15., 85.])\n",
      "cls loss 493.422607421875  loc loss 27.14058494567871\n",
      "cls loss 480.238037109375  loc loss 34.49562454223633\n",
      "cls loss 506.46124267578125  loc loss 33.013519287109375\n",
      "cls loss 417.54083251953125  loc loss 23.756284713745117\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 8., 8.])\n",
      "cls loss 311.23394775390625  loc loss 11.34317684173584\n",
      "cls loss 290.12420654296875  loc loss 21.908092498779297\n",
      "cls loss 370.80035400390625  loc loss 21.37213897705078\n",
      "cls loss 327.41796875  loc loss 16.97429084777832\n",
      "cls loss 345.4965515136719  loc loss 20.889917373657227\n",
      "cls loss 497.3228454589844  loc loss 28.65383529663086\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1., 35., 27., 27.,  1., 27.,  1.])\n",
      "cls loss 549.5828857421875  loc loss 43.811065673828125\n",
      "cls loss 332.30950927734375  loc loss 17.769222259521484\n",
      "cls loss 353.2819519042969  loc loss 26.170841217041016\n",
      "cls loss 346.9375  loc loss 29.58794593811035\n",
      "cls loss 328.22381591796875  loc loss 20.330963134765625\n",
      "cls loss 354.1495666503906  loc loss 26.809391021728516\n",
      "cls loss 345.13043212890625  loc loss 26.836393356323242\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  2.,  2.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  2.,  2.])\n",
      "cls loss 166.74188232421875  loc loss 8.441567420959473\n",
      "cls loss 559.4129638671875  loc loss 36.68125915527344\n",
      "cls loss 342.08892822265625  loc loss 17.498964309692383\n",
      "cls loss 627.53662109375  loc loss 44.84469223022461\n",
      "cls loss 246.7314453125  loc loss 13.423133850097656\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 19., 19., 19., 16.])\n",
      "cls loss 258.41265869140625  loc loss 9.827555656433105\n",
      "cls loss 224.6583709716797  loc loss 8.394342422485352\n",
      "cls loss 365.16015625  loc loss 15.916691780090332\n",
      "cls loss 480.21002197265625  loc loss 28.013442993164062\n",
      "cls loss 194.87112426757812  loc loss 13.616493225097656\n",
      "cls loss 505.5050048828125  loc loss 39.00769805908203\n",
      "cls loss 377.08734130859375  loc loss 24.44579315185547\n",
      "cls loss 381.5047607421875  loc loss 25.313020706176758\n",
      "cls loss 486.4599609375  loc loss 32.802616119384766\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 484.22052001953125  loc loss 24.23895263671875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 692.4515380859375  loc loss 59.262542724609375\n",
      "cls loss 909.1064453125  loc loss 80.7692642211914\n",
      "cls loss 427.46533203125  loc loss 26.441997528076172\n",
      "cls loss 393.24822998046875  loc loss 24.175640106201172\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3.,  3.,  3.,  3.,  3., 10.])\n",
      "cls loss 181.32472229003906  loc loss 13.102392196655273\n",
      "cls loss 423.2350158691406  loc loss 21.009674072265625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 1., 1., 1., 3., 3., 3., 3.])\n",
      "cls loss 355.4935302734375  loc loss 18.356616973876953\n",
      "cls loss 733.6661376953125  loc loss 42.78312683105469\n",
      "cls loss 614.1160278320312  loc loss 30.454801559448242\n",
      "cls loss 399.861328125  loc loss 20.171140670776367\n",
      "cls loss 559.3253173828125  loc loss 35.406639099121094\n",
      "cls loss 328.7727966308594  loc loss 22.215351104736328\n",
      "cls loss 523.56689453125  loc loss 33.74605178833008\n",
      "cls loss 385.2677001953125  loc loss 35.40353012084961\n",
      "cls loss 361.0124206542969  loc loss 24.73576545715332\n",
      "cls loss 798.8077392578125  loc loss 63.89772033691406\n",
      "cls loss 513.2537841796875  loc loss 40.69784927368164\n",
      "cls loss 323.2091064453125  loc loss 17.667898178100586\n",
      "cls loss 194.0213623046875  loc loss 9.787995338439941\n",
      "cls loss 262.6495361328125  loc loss 13.21352767944336\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3., 10., 10., 10., 10., 10., 10., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10., 10., 10., 10., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 11., 10., 10., 10., 10., 10.,  3.,  3.,  3.,  3.,  3.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 11., 10., 10., 10., 10., 10.,  3.,  3.,  3.,  3.,  3.])\n",
      "cls loss 199.12957763671875  loc loss 10.203564643859863\n",
      "cls loss 283.4335632324219  loc loss 12.584822654724121\n",
      "cls loss 247.61843872070312  loc loss 14.399881362915039\n",
      "cls loss 243.35411071777344  loc loss 11.039275169372559\n",
      "cls loss 320.23309326171875  loc loss 24.42660140991211\n",
      "cls loss 235.59230041503906  loc loss 9.59830093383789\n",
      "cls loss 509.0574645996094  loc loss 30.735971450805664\n",
      "cls loss 483.9246826171875  loc loss 25.38359260559082\n",
      "cls loss 697.3020629882812  loc loss 39.66256332397461\n",
      "cls loss 359.998291015625  loc loss 22.649702072143555\n",
      "cls loss 607.37890625  loc loss 36.470829010009766\n",
      "cls loss 453.9355163574219  loc loss 32.29548645019531\n",
      "cls loss 445.94287109375  loc loss 27.98046875\n",
      "cls loss 426.5006103515625  loc loss 28.734710693359375\n",
      "cls loss 542.4124755859375  loc loss 36.58134078979492\n",
      "cls loss 525.7772216796875  loc loss 34.259708404541016\n",
      "cls loss 246.21023559570312  loc loss 13.477002143859863\n",
      "cls loss 522.8194580078125  loc loss 34.982643127441406\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 10.,  1., 18.])\n",
      "cls loss 223.11459350585938  loc loss 16.481063842773438\n",
      "cls loss 255.84852600097656  loc loss 12.477673530578613\n",
      "cls loss 484.50494384765625  loc loss 26.60080337524414\n",
      "cls loss 698.00439453125  loc loss 39.61878967285156\n",
      "cls loss 420.7601013183594  loc loss 27.44860076904297\n",
      "cls loss 645.5008544921875  loc loss 30.338451385498047\n",
      "cls loss 503.87152099609375  loc loss 30.300159454345703\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.,  1.,  1.])\n",
      "cls loss 575.0838623046875  loc loss 32.476173400878906\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1., 38.,  1.])\n",
      "cls loss 516.5140380859375  loc loss 27.277544021606445\n",
      "cls loss 717.5429077148438  loc loss 50.187503814697266\n",
      "cls loss 381.7900695800781  loc loss 24.402135848999023\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 505.2755432128906  loc loss 27.937368392944336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 407.65960693359375  loc loss 23.328868865966797\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3., 10.,  8.,  3., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.])\n",
      "cls loss 448.867431640625  loc loss 25.9260196685791\n",
      "cls loss 302.0262451171875  loc loss 20.301511764526367\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3.,  3., 11.,  3., 10., 10.,  3.,  3., 10.])\n",
      "cls loss 313.1832275390625  loc loss 18.446407318115234\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3., 10., 10., 10.])\n",
      "cls loss 385.9307861328125  loc loss 20.576539993286133\n",
      "cls loss 289.1685791015625  loc loss 20.522743225097656\n",
      "cls loss 402.3248596191406  loc loss 28.23170280456543\n",
      "cls loss 578.9029541015625  loc loss 34.87390899658203\n",
      "cls loss 374.59075927734375  loc loss 24.804969787597656\n",
      "cls loss 300.29522705078125  loc loss 22.586393356323242\n",
      "cls loss 383.3269348144531  loc loss 21.700748443603516\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 9.,  9., 85., 85.])\n",
      "cls loss 337.20440673828125  loc loss 14.873506546020508\n",
      "cls loss 437.55010986328125  loc loss 26.744075775146484\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 641.822021484375  loc loss 37.72944641113281\n",
      "cls loss 535.2276611328125  loc loss 21.988529205322266\n",
      "cls loss 629.3184204101562  loc loss 41.062904357910156\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10., 10., 10., 10.])\n",
      "cls loss 412.40362548828125  loc loss 23.336698532104492\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([13.])\n",
      "cls loss 602.6472778320312  loc loss 45.514766693115234\n",
      "cls loss 158.93997192382812  loc loss 9.410807609558105\n",
      "cls loss 239.43292236328125  loc loss 13.081046104431152\n",
      "cls loss 302.906982421875  loc loss 19.692007064819336\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19.,  1.,  1.,  1., 19., 19.])\n",
      "cls loss 326.9305419921875  loc loss 23.522785186767578\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 270.6861572265625  loc loss 19.108491897583008\n",
      "cls loss 424.86212158203125  loc loss 28.50750732421875\n",
      "cls loss 318.28253173828125  loc loss 17.34762191772461\n",
      "cls loss 456.4135437011719  loc loss 22.975006103515625\n",
      "cls loss 481.8204650878906  loc loss 34.08414840698242\n",
      "cls loss 367.73345947265625  loc loss 20.934003829956055\n",
      "cls loss 616.7775268554688  loc loss 40.29686737060547\n",
      "cls loss 222.56057739257812  loc loss 9.056096076965332\n",
      "cls loss 401.88018798828125  loc loss 26.604511260986328\n",
      "cls loss 346.913330078125  loc loss 18.518068313598633\n",
      "cls loss 385.0875244140625  loc loss 18.318248748779297\n",
      "cls loss 505.886474609375  loc loss 27.517295837402344\n",
      "cls loss 400.50311279296875  loc loss 18.816978454589844\n",
      "cls loss 576.9884643554688  loc loss 38.96845245361328\n",
      "cls loss 368.0152587890625  loc loss 22.118112564086914\n",
      "cls loss 458.6799621582031  loc loss 33.460914611816406\n",
      "cls loss 664.18701171875  loc loss 40.966064453125\n",
      "cls loss 357.1976013183594  loc loss 27.86300277709961\n",
      "cls loss 427.0255126953125  loc loss 24.485986709594727\n",
      "cls loss 496.60711669921875  loc loss 39.58504867553711\n",
      "cls loss 588.885498046875  loc loss 40.856483459472656\n",
      "cls loss 652.6275634765625  loc loss 39.47488784790039\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 5.])\n",
      "cls loss 169.00509643554688  loc loss 8.94797420501709\n",
      "cls loss 254.6333770751953  loc loss 10.17149829864502\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 13.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 6., 8., 8.])\n",
      "cls loss 199.2658233642578  loc loss 10.228254318237305\n",
      "cls loss 285.05712890625  loc loss 12.578635215759277\n",
      "cls loss 527.7530517578125  loc loss 32.363006591796875\n",
      "cls loss 218.62039184570312  loc loss 11.877950668334961\n",
      "cls loss 434.63726806640625  loc loss 30.376529693603516\n",
      "cls loss 665.7586669921875  loc loss 46.31757736206055\n",
      "cls loss 418.427734375  loc loss 27.158769607543945\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([42., 42.,  1.,  1.,  1.,  1.,  1.,  1.,  1., 42., 42.])\n",
      "cls loss 449.47900390625  loc loss 22.50226402282715\n",
      "cls loss 560.509521484375  loc loss 42.079925537109375\n",
      "cls loss 509.93804931640625  loc loss 33.93051528930664\n",
      "cls loss 317.9117431640625  loc loss 19.677627563476562\n",
      "cls loss 420.98541259765625  loc loss 22.304956436157227\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 643.4435424804688  loc loss 38.58516311645508\n",
      "cls loss 514.0586547851562  loc loss 33.33811569213867\n",
      "cls loss 304.90789794921875  loc loss 15.428153991699219\n",
      "cls loss 261.66375732421875  loc loss 14.49416732788086\n",
      "cls loss 346.01025390625  loc loss 21.57602310180664\n",
      "cls loss 477.0295715332031  loc loss 30.406862258911133\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15.])\n",
      "cls loss 231.38955688476562  loc loss 8.020132064819336\n",
      "cls loss 410.0753173828125  loc loss 24.320417404174805\n",
      "cls loss 362.4902648925781  loc loss 22.706218719482422\n",
      "cls loss 651.238525390625  loc loss 38.82160949707031\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19.,  7.])\n",
      "cls loss 301.7692565917969  loc loss 17.54865837097168\n",
      "cls loss 612.4686889648438  loc loss 42.81869888305664\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 551.4818115234375  loc loss 28.695417404174805\n",
      "cls loss 509.37799072265625  loc loss 33.44528579711914\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([38., 38.,  1., 18.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1., 18., 18.,  1.])\n",
      "cls loss 337.0767822265625  loc loss 18.991085052490234\n",
      "cls loss 327.0989685058594  loc loss 17.07930564880371\n",
      "cls loss 644.7989501953125  loc loss 45.84961700439453\n",
      "cls loss 461.02886962890625  loc loss 32.24645233154297\n",
      "cls loss 386.77362060546875  loc loss 26.376726150512695\n",
      "cls loss 266.49078369140625  loc loss 19.309438705444336\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.])\n",
      "cls loss 162.852294921875  loc loss 6.73078727722168\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([32.])\n",
      "cls loss 424.5340881347656  loc loss 21.61139488220215\n",
      "cls loss 378.5527038574219  loc loss 24.297677993774414\n",
      "cls loss 457.26922607421875  loc loss 34.00251007080078\n",
      "cls loss 414.6502685546875  loc loss 24.835124969482422\n",
      "cls loss 352.7727966308594  loc loss 19.766952514648438\n",
      "cls loss 561.552490234375  loc loss 31.74002456665039\n",
      "cls loss 658.4207763671875  loc loss 42.01203918457031\n",
      "cls loss 473.99481201171875  loc loss 33.756656646728516\n",
      "cls loss 352.9532470703125  loc loss 22.500049591064453\n",
      "cls loss 575.0850830078125  loc loss 39.333251953125\n",
      "cls loss 378.48199462890625  loc loss 21.311050415039062\n",
      "cls loss 683.501708984375  loc loss 44.236351013183594\n",
      "cls loss 449.58416748046875  loc loss 25.017906188964844\n",
      "cls loss 361.8708801269531  loc loss 29.81564712524414\n",
      "cls loss 284.7012939453125  loc loss 14.697164535522461\n",
      "cls loss 334.7604064941406  loc loss 21.679603576660156\n",
      "cls loss 492.4638671875  loc loss 33.12872314453125\n",
      "cls loss 559.6771240234375  loc loss 40.164432525634766\n",
      "cls loss 332.4676513671875  loc loss 20.975265502929688\n",
      "cls loss 532.367919921875  loc loss 37.90287399291992\n",
      "cls loss 637.675537109375  loc loss 41.23155975341797\n",
      "cls loss 238.3025665283203  loc loss 14.490374565124512\n",
      "cls loss 620.4176025390625  loc loss 41.64384841918945\n",
      "cls loss 461.0390625  loc loss 30.81035614013672\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 596.5372924804688  loc loss 45.55208969116211\n",
      "cls loss 254.5921173095703  loc loss 11.651904106140137\n",
      "cls loss 385.24749755859375  loc loss 24.690994262695312\n",
      "cls loss 393.301513671875  loc loss 28.1638126373291\n",
      "cls loss 326.5214538574219  loc loss 22.19397735595703\n",
      "cls loss 193.18646240234375  loc loss 11.017167091369629\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 9., 9., 1., 9., 9., 9., 9., 1., 9.])\n",
      "cls loss 879.96484375  loc loss 59.665740966796875\n",
      "cls loss 478.157470703125  loc loss 26.116859436035156\n",
      "cls loss 746.4925537109375  loc loss 54.64119338989258\n",
      "cls loss 291.732177734375  loc loss 22.522565841674805\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 42., 42.])\n",
      "cls loss 477.4464111328125  loc loss 37.13530731201172\n",
      "cls loss 483.1296691894531  loc loss 40.558128356933594\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  2.,  1.,  1.,  1., 38.,\n",
      "         1.,  1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 38., 38., 38.,  1., 38., 38., 38.,  1.,  1., 38.,  1.,\n",
      "         1.])\n",
      "cls loss 282.5498046875  loc loss 22.484115600585938\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  8.,  8.])\n",
      "cls loss 671.5435180664062  loc loss 48.153419494628906\n",
      "cls loss 673.3136596679688  loc loss 52.6761589050293\n",
      "cls loss 252.87030029296875  loc loss 16.271869659423828\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([4., 1., 1., 4.])\n",
      "cls loss 403.333251953125  loc loss 25.7322998046875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 515.596923828125  loc loss 31.089941024780273\n",
      "cls loss 205.22598266601562  loc loss 10.980474472045898\n",
      "cls loss 257.69580078125  loc loss 17.279233932495117\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([51.,  1.])\n",
      "cls loss 184.65853881835938  loc loss 9.568352699279785\n",
      "cls loss 262.02545166015625  loc loss 18.85114097595215\n",
      "cls loss 550.9107666015625  loc loss 28.148399353027344\n",
      "cls loss 510.15252685546875  loc loss 37.99299240112305\n",
      "cls loss 775.86669921875  loc loss 40.1573371887207\n",
      "cls loss 929.379638671875  loc loss 60.17000198364258\n",
      "cls loss 385.463623046875  loc loss 24.12898063659668\n",
      "cls loss 561.445068359375  loc loss 41.258644104003906\n",
      "cls loss 610.5751953125  loc loss 41.6600456237793\n",
      "cls loss 436.9583740234375  loc loss 29.333148956298828\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  3.,  1.,  1.,  1.,  3.,  1.,  1.,\n",
      "         1.,  1.,  1.])\n",
      "cls loss 474.1528015136719  loc loss 21.537986755371094\n",
      "cls loss 508.40057373046875  loc loss 29.95993423461914\n",
      "cls loss 489.2588806152344  loc loss 27.446334838867188\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "cls loss 418.0247802734375  loc loss 24.86277198791504\n",
      "cls loss 230.2295684814453  loc loss 18.796323776245117\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3.])\n",
      "cls loss 187.753662109375  loc loss 10.704629898071289\n",
      "cls loss 329.32598876953125  loc loss 20.161544799804688\n",
      "cls loss 316.073974609375  loc loss 21.655961990356445\n",
      "cls loss 571.6048583984375  loc loss 36.95566940307617\n",
      "cls loss 262.24493408203125  loc loss 20.138399124145508\n",
      "cls loss 300.513671875  loc loss 24.75267791748047\n",
      "cls loss 864.8135375976562  loc loss 60.16222381591797\n",
      "cls loss 385.498291015625  loc loss 28.887609481811523\n",
      "cls loss 285.9398193359375  loc loss 20.694355010986328\n",
      "cls loss 338.48138427734375  loc loss 19.410072326660156\n",
      "cls loss 307.9731140136719  loc loss 23.41726303100586\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 572.7467041015625  loc loss 40.278900146484375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  9., 64., 64., 64., 64., 64., 64., 64., 64., 64.,  9.,  9.,  9.,\n",
      "         9.])\n",
      "cls loss 264.11962890625  loc loss 14.36184024810791\n",
      "cls loss 830.4780883789062  loc loss 63.21488952636719\n",
      "cls loss 440.2468566894531  loc loss 28.226606369018555\n",
      "cls loss 531.9161376953125  loc loss 35.62144470214844\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.,  3.,  3.])\n",
      "cls loss 333.53643798828125  loc loss 18.49098014831543\n",
      "cls loss 363.1285095214844  loc loss 26.879535675048828\n",
      "cls loss 381.289306640625  loc loss 27.39044952392578\n",
      "cls loss 392.6891784667969  loc loss 25.841596603393555\n",
      "cls loss 452.4447937011719  loc loss 30.027847290039062\n",
      "cls loss 448.5809631347656  loc loss 29.051959991455078\n",
      "cls loss 401.27545166015625  loc loss 27.36259651184082\n",
      "cls loss 410.591064453125  loc loss 22.570322036743164\n",
      "cls loss 514.0410766601562  loc loss 33.70610809326172\n",
      "cls loss 374.95355224609375  loc loss 23.4486026763916\n",
      "cls loss 286.81201171875  loc loss 15.35262393951416\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21.])\n",
      "cls loss 234.07501220703125  loc loss 15.793665885925293\n",
      "cls loss 335.1640625  loc loss 29.10626220703125\n",
      "cls loss 493.3466796875  loc loss 34.61532974243164\n",
      "cls loss 249.02325439453125  loc loss 15.776590347290039\n",
      "cls loss 406.7465515136719  loc loss 27.610292434692383\n",
      "cls loss 757.3433227539062  loc loss 40.136085510253906\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 42., 42.,  1.,  1.])\n",
      "cls loss 456.56854248046875  loc loss 25.077022552490234\n",
      "cls loss 300.34027099609375  loc loss 17.51296615600586\n",
      "cls loss 435.7401123046875  loc loss 25.77035903930664\n",
      "cls loss 567.0966796875  loc loss 41.58692169189453\n",
      "cls loss 354.05853271484375  loc loss 19.821653366088867\n",
      "cls loss 542.8660278320312  loc loss 36.33306121826172\n",
      "cls loss 475.027099609375  loc loss 33.015132904052734\n",
      "cls loss 458.8273010253906  loc loss 29.434202194213867\n",
      "cls loss 369.80084228515625  loc loss 23.14796257019043\n",
      "cls loss 298.3947448730469  loc loss 20.80234146118164\n",
      "cls loss 235.9249267578125  loc loss 11.02055835723877\n",
      "cls loss 373.8503723144531  loc loss 24.11256980895996\n",
      "cls loss 566.0963134765625  loc loss 36.29368209838867\n",
      "cls loss 414.2324523925781  loc loss 24.82975196838379\n",
      "cls loss 395.8831787109375  loc loss 29.073036193847656\n",
      "cls loss 436.1435546875  loc loss 25.989665985107422\n",
      "cls loss 648.8142700195312  loc loss 47.9924201965332\n",
      "cls loss 520.515869140625  loc loss 34.03769302368164\n",
      "cls loss 571.4915771484375  loc loss 29.825641632080078\n",
      "cls loss 359.0604248046875  loc loss 15.534936904907227\n",
      "cls loss 498.78179931640625  loc loss 28.451303482055664\n",
      "cls loss 460.2649841308594  loc loss 24.907588958740234\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 5., 5., 5., 5., 5., 5.])\n",
      "cls loss 279.0018310546875  loc loss 17.116018295288086\n",
      "cls loss 377.32781982421875  loc loss 19.21428108215332\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([13.])\n",
      "cls loss 260.63372802734375  loc loss 12.026009559631348\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([44., 10.,  1.,  1.,  1.])\n",
      "cls loss 233.3966064453125  loc loss 15.380583763122559\n",
      "cls loss 413.51458740234375  loc loss 23.107906341552734\n",
      "cls loss 379.4341125488281  loc loss 20.627103805541992\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19., 19., 19., 19., 19., 19., 19.])\n",
      "cls loss 397.4623718261719  loc loss 25.248559951782227\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([56.])\n",
      "cls loss 836.5574951171875  loc loss 55.024436950683594\n",
      "cls loss 532.0106201171875  loc loss 39.0111083984375\n",
      "cls loss 673.2965698242188  loc loss 43.04489517211914\n",
      "cls loss 644.6607666015625  loc loss 49.1427116394043\n",
      "cls loss 383.98406982421875  loc loss 22.48870086669922\n",
      "cls loss 661.1995239257812  loc loss 42.174095153808594\n",
      "cls loss 374.65362548828125  loc loss 25.252439498901367\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 36.])\n",
      "cls loss 501.3468017578125  loc loss 22.236116409301758\n",
      "cls loss 421.54486083984375  loc loss 25.752639770507812\n",
      "cls loss 399.66510009765625  loc loss 23.07377052307129\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5.])\n",
      "cls loss 474.15203857421875  loc loss 26.68747329711914\n",
      "cls loss 261.8025207519531  loc loss 12.062434196472168\n",
      "cls loss 587.0098266601562  loc loss 31.353939056396484\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "cls loss 521.7489624023438  loc loss 30.462467193603516\n",
      "cls loss 470.5954284667969  loc loss 30.4018611907959\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 500.60345458984375  loc loss 31.11739730834961\n",
      "cls loss 555.5267333984375  loc loss 35.83332061767578\n",
      "cls loss 477.9381103515625  loc loss 39.79896926879883\n",
      "cls loss 334.01544189453125  loc loss 21.384401321411133\n",
      "cls loss 375.1201171875  loc loss 27.435623168945312\n",
      "cls loss 393.2567138671875  loc loss 23.00250244140625\n",
      "cls loss 669.7125854492188  loc loss 32.366580963134766\n",
      "cls loss 266.85198974609375  loc loss 13.621822357177734\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 11., 15., 10., 10., 10., 10., 10.])\n",
      "cls loss 593.2691040039062  loc loss 38.97057342529297\n",
      "cls loss 358.671875  loc loss 26.76525115966797\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3.])\n",
      "cls loss 373.573974609375  loc loss 27.426986694335938\n",
      "cls loss 362.01007080078125  loc loss 18.1710147857666\n",
      "cls loss 415.7362060546875  loc loss 18.31068229675293\n",
      "cls loss 530.768798828125  loc loss 22.036983489990234\n",
      "cls loss 243.50811767578125  loc loss 11.221146583557129\n",
      "cls loss 454.6916198730469  loc loss 26.785364151000977\n",
      "cls loss 503.9571533203125  loc loss 29.84942626953125\n",
      "cls loss 437.8316650390625  loc loss 27.223630905151367\n",
      "cls loss 981.041748046875  loc loss 61.21880340576172\n",
      "cls loss 637.206298828125  loc loss 40.2885856628418\n",
      "cls loss 399.82098388671875  loc loss 27.072444915771484\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  9.,  9.,  9.,  6.,  6., 85., 85.,  8.,  1.,  1.,  1.,  1.,\n",
      "         6.,  6.])\n",
      "cls loss 274.9737548828125  loc loss 21.4832706451416\n",
      "cls loss 683.0735473632812  loc loss 47.239418029785156\n",
      "cls loss 802.8687133789062  loc loss 47.18650817871094\n",
      "cls loss 518.2943115234375  loc loss 35.183650970458984\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10.,  3.,  3., 10.])\n",
      "cls loss 321.213134765625  loc loss 17.880647659301758\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([7.])\n",
      "cls loss 415.8710632324219  loc loss 26.972898483276367\n",
      "cls loss 418.35565185546875  loc loss 25.765247344970703\n",
      "cls loss 431.74945068359375  loc loss 36.11918258666992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 711.6058959960938  loc loss 47.650882720947266\n",
      "cls loss 412.1419372558594  loc loss 25.83138656616211\n",
      "cls loss 644.778076171875  loc loss 37.25539779663086\n",
      "cls loss 784.09912109375  loc loss 42.32359313964844\n",
      "cls loss 524.6945190429688  loc loss 27.490802764892578\n",
      "cls loss 578.5924072265625  loc loss 32.74212646484375\n",
      "cls loss 431.76885986328125  loc loss 27.7965087890625\n",
      "cls loss 602.015625  loc loss 42.71171951293945\n",
      "cls loss 454.8749694824219  loc loss 28.854021072387695\n",
      "cls loss 325.3468017578125  loc loss 21.23371696472168\n",
      "cls loss 530.3779296875  loc loss 39.626953125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([62.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([62.])\n",
      "cls loss 232.77548217773438  loc loss 11.612640380859375\n",
      "cls loss 384.1247863769531  loc loss 28.39936637878418\n",
      "cls loss 391.8160705566406  loc loss 25.639705657958984\n",
      "cls loss 255.0243682861328  loc loss 12.569053649902344\n",
      "cls loss 526.7661743164062  loc loss 33.93287658691406\n",
      "cls loss 537.0025634765625  loc loss 30.369003295898438\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([28.])\n",
      "cls loss 673.463134765625  loc loss 31.052337646484375\n",
      "cls loss 509.69329833984375  loc loss 32.45314407348633\n",
      "cls loss 504.996337890625  loc loss 35.30583953857422\n",
      "cls loss 584.287841796875  loc loss 33.206974029541016\n",
      "cls loss 887.5651245117188  loc loss 47.09306335449219\n",
      "cls loss 490.743408203125  loc loss 25.914581298828125\n",
      "cls loss 678.0283813476562  loc loss 30.23378562927246\n",
      "cls loss 527.8829345703125  loc loss 35.25713348388672\n",
      "cls loss 780.0284423828125  loc loss 57.127357482910156\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([81.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 471.91827392578125  loc loss 19.04265022277832\n",
      "cls loss 357.1062316894531  loc loss 18.784881591796875\n",
      "cls loss 258.7443542480469  loc loss 19.620834350585938\n",
      "cls loss 233.1639404296875  loc loss 10.486468315124512\n",
      "cls loss 267.8508605957031  loc loss 21.167251586914062\n",
      "cls loss 334.68011474609375  loc loss 21.184886932373047\n",
      "cls loss 342.0317687988281  loc loss 25.022438049316406\n",
      "cls loss 513.435302734375  loc loss 40.96791076660156\n",
      "cls loss 599.797607421875  loc loss 35.55242919921875\n",
      "cls loss 1051.386474609375  loc loss 69.68600463867188\n",
      "cls loss 412.9668273925781  loc loss 20.10898208618164\n",
      "cls loss 511.81781005859375  loc loss 37.60247039794922\n",
      "cls loss 371.28570556640625  loc loss 21.878047943115234\n",
      "cls loss 526.7994995117188  loc loss 26.734683990478516\n",
      "cls loss 459.295166015625  loc loss 24.25615119934082\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([44., 44.])\n",
      "cls loss 451.3466796875  loc loss 18.49707794189453\n",
      "cls loss 489.4571533203125  loc loss 27.45166015625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15.])\n",
      "cls loss 485.63909912109375  loc loss 22.355070114135742\n",
      "cls loss 253.61634826660156  loc loss 13.852375984191895\n",
      "cls loss 432.7477111816406  loc loss 29.33926773071289\n",
      "cls loss 253.68994140625  loc loss 12.643214225769043\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([1., 3., 3.])\n",
      "cls loss 279.84051513671875  loc loss 17.412010192871094\n",
      "cls loss 203.40045166015625  loc loss 9.809203147888184\n",
      "cls loss 401.80609130859375  loc loss 27.030595779418945\n",
      "cls loss 468.08905029296875  loc loss 25.370630264282227\n",
      "cls loss 402.96514892578125  loc loss 27.010784149169922\n",
      "cls loss 334.59619140625  loc loss 22.215499877929688\n",
      "cls loss 367.89434814453125  loc loss 26.067323684692383\n",
      "cls loss 487.04034423828125  loc loss 31.050697326660156\n",
      "cls loss 329.0803527832031  loc loss 22.147891998291016\n",
      "cls loss 420.5782165527344  loc loss 32.97863006591797\n",
      "cls loss 289.9635009765625  loc loss 18.968677520751953\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 554.2138671875  loc loss 31.683006286621094\n",
      "cls loss 693.1689453125  loc loss 28.5487060546875\n",
      "cls loss 592.9210205078125  loc loss 37.367698669433594\n",
      "cls loss 587.187744140625  loc loss 43.29271697998047\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10., 10., 10.,  1.,  1.,  1.,  1.,  1.,  1.,  8.,  8.,\n",
      "         1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10., 10., 10.,  1.,  1.,  1.,  1.,  1.,  1.,  8.,  8.,\n",
      "         1.])\n",
      "cls loss 467.2994689941406  loc loss 23.123897552490234\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 3., 3., 3.])\n",
      "cls loss 474.078125  loc loss 25.43865203857422\n",
      "cls loss 282.15826416015625  loc loss 17.865520477294922\n",
      "cls loss 212.34889221191406  loc loss 10.775490760803223\n",
      "cls loss 416.6990051269531  loc loss 32.117584228515625\n",
      "cls loss 307.3143310546875  loc loss 14.896360397338867\n",
      "cls loss 374.56988525390625  loc loss 27.449722290039062\n",
      "cls loss 418.939208984375  loc loss 32.2794189453125\n",
      "cls loss 566.8389282226562  loc loss 44.11629867553711\n",
      "cls loss 495.91278076171875  loc loss 26.376583099365234\n",
      "cls loss 447.48870849609375  loc loss 24.656368255615234\n",
      "cls loss 469.569091796875  loc loss 30.443910598754883\n",
      "cls loss 337.94000244140625  loc loss 24.729352951049805\n",
      "cls loss 685.865478515625  loc loss 48.770591735839844\n",
      "cls loss 295.2506103515625  loc loss 17.174949645996094\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 559.7591552734375  loc loss 32.253971099853516\n",
      "cls loss 240.33795166015625  loc loss 10.671551704406738\n",
      "cls loss 615.264892578125  loc loss 42.61784362792969\n",
      "cls loss 315.758544921875  loc loss 19.782367706298828\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 34.])\n",
      "cls loss 526.1776123046875  loc loss 28.392507553100586\n",
      "cls loss 292.7703857421875  loc loss 16.664875030517578\n",
      "cls loss 570.7284545898438  loc loss 30.066951751708984\n",
      "cls loss 199.55992126464844  loc loss 12.94230842590332\n",
      "cls loss 425.5076599121094  loc loss 25.569847106933594\n",
      "cls loss 406.892333984375  loc loss 32.076934814453125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 38.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16., 16., 16.,  9.,  9.,  9., 16., 16., 16., 85.,  9.])\n",
      "cls loss 422.28302001953125  loc loss 25.61139678955078\n",
      "cls loss 455.62957763671875  loc loss 34.43143844604492\n",
      "cls loss 611.2543334960938  loc loss 39.65904235839844\n",
      "cls loss 958.4278564453125  loc loss 58.923744201660156\n",
      "cls loss 241.41073608398438  loc loss 13.865846633911133\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3., 10.,  8.,  8., 10., 10., 10.,  3.,  3., 14.])\n",
      "cls loss 270.116943359375  loc loss 15.317657470703125\n",
      "cls loss 493.835693359375  loc loss 32.05451583862305\n",
      "cls loss 200.31689453125  loc loss 8.957075119018555\n",
      "cls loss 359.6181640625  loc loss 16.34687614440918\n",
      "cls loss 494.26214599609375  loc loss 32.20732116699219\n",
      "cls loss 429.92669677734375  loc loss 25.41048240661621\n",
      "cls loss 255.60365295410156  loc loss 13.609478950500488\n",
      "cls loss 345.80841064453125  loc loss 15.80714225769043\n",
      "cls loss 573.2479248046875  loc loss 28.62989616394043\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42., 42.,  1.])\n",
      "cls loss 548.6207275390625  loc loss 28.749038696289062\n",
      "cls loss 426.1693115234375  loc loss 20.83826446533203\n",
      "cls loss 518.7411499023438  loc loss 37.33059310913086\n",
      "cls loss 580.36279296875  loc loss 34.264610290527344\n",
      "cls loss 394.26190185546875  loc loss 23.34150505065918\n",
      "cls loss 476.70416259765625  loc loss 34.04278564453125\n",
      "cls loss 288.3803405761719  loc loss 19.295726776123047\n",
      "cls loss 309.36700439453125  loc loss 22.46395492553711\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20.])\n",
      "cls loss 219.34059143066406  loc loss 12.947763442993164\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([11.])\n",
      "cls loss 321.9813537597656  loc loss 14.406590461730957\n",
      "cls loss 178.05841064453125  loc loss 11.348396301269531\n",
      "cls loss 484.9385986328125  loc loss 35.48625946044922\n",
      "cls loss 207.4034881591797  loc loss 10.461155891418457\n",
      "cls loss 431.18865966796875  loc loss 26.464046478271484\n",
      "cls loss 231.74868774414062  loc loss 15.854408264160156\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 35., 27.])\n",
      "cls loss 427.0874328613281  loc loss 24.21919059753418\n",
      "cls loss 505.16064453125  loc loss 35.648162841796875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 332.93658447265625  loc loss 17.124744415283203\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([42.,  1.])\n",
      "cls loss 430.4288024902344  loc loss 26.904760360717773\n",
      "cls loss 460.3675842285156  loc loss 21.897411346435547\n",
      "cls loss 586.053955078125  loc loss 28.562942504882812\n",
      "cls loss 711.7640991210938  loc loss 33.91037368774414\n",
      "cls loss 586.238525390625  loc loss 29.779598236083984\n",
      "cls loss 409.6200256347656  loc loss 23.131990432739258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 331.3111572265625  loc loss 21.8561954498291\n",
      "cls loss 191.27474975585938  loc loss 8.153790473937988\n",
      "cls loss 347.1820373535156  loc loss 18.9111328125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 1., 1.])\n",
      "cls loss 327.046142578125  loc loss 20.572322845458984\n",
      "cls loss 395.66680908203125  loc loss 25.65465545654297\n",
      "cls loss 380.3616943359375  loc loss 23.147037506103516\n",
      "cls loss 304.4305114746094  loc loss 21.94390296936035\n",
      "cls loss 381.8699035644531  loc loss 24.60643768310547\n",
      "cls loss 402.6992492675781  loc loss 28.886886596679688\n",
      "cls loss 585.981201171875  loc loss 34.36021041870117\n",
      "cls loss 502.8818664550781  loc loss 38.085479736328125\n",
      "cls loss 436.38983154296875  loc loss 28.560543060302734\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 341.77960205078125  loc loss 25.156435012817383\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 480.18511962890625  loc loss 19.46054458618164\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([81.])\n",
      "cls loss 583.3948974609375  loc loss 29.885025024414062\n",
      "cls loss 342.2537841796875  loc loss 21.671640396118164\n",
      "cls loss 308.34832763671875  loc loss 12.028670310974121\n",
      "cls loss 396.46832275390625  loc loss 19.594833374023438\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3.,  1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 19.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 19.])\n",
      "cls loss 558.667236328125  loc loss 32.772987365722656\n",
      "cls loss 286.5205078125  loc loss 15.579602241516113\n",
      "cls loss 310.07147216796875  loc loss 16.545000076293945\n",
      "cls loss 562.9957885742188  loc loss 40.50782012939453\n",
      "cls loss 276.3526916503906  loc loss 17.41458511352539\n",
      "cls loss 349.1033630371094  loc loss 21.068500518798828\n",
      "cls loss 432.83734130859375  loc loss 29.60934066772461\n",
      "cls loss 323.9085998535156  loc loss 23.586820602416992\n",
      "cls loss 436.1367492675781  loc loss 24.424846649169922\n",
      "cls loss 472.2356872558594  loc loss 31.192190170288086\n",
      "cls loss 637.1974487304688  loc loss 54.4743766784668\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 81.])\n",
      "cls loss 422.7922058105469  loc loss 20.596582412719727\n",
      "cls loss 392.48565673828125  loc loss 20.956050872802734\n",
      "cls loss 391.984130859375  loc loss 22.341333389282227\n",
      "cls loss 322.69683837890625  loc loss 16.385704040527344\n",
      "cls loss 300.6036071777344  loc loss 17.339298248291016\n",
      "cls loss 368.75506591796875  loc loss 24.83454704284668\n",
      "cls loss 272.67547607421875  loc loss 18.056333541870117\n",
      "cls loss 229.29830932617188  loc loss 14.393917083740234\n",
      "cls loss 315.776123046875  loc loss 19.40445327758789\n",
      "cls loss 410.4754943847656  loc loss 24.66504669189453\n",
      "cls loss 400.0296936035156  loc loss 26.6153564453125\n",
      "cls loss 369.1702880859375  loc loss 24.04256820678711\n",
      "cls loss 215.43417358398438  loc loss 13.66624641418457\n",
      "cls loss 753.882568359375  loc loss 47.05989074707031\n",
      "cls loss 412.44989013671875  loc loss 27.324127197265625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 370.49896240234375  loc loss 18.292160034179688\n",
      "cls loss 414.61016845703125  loc loss 26.19165802001953\n",
      "cls loss 290.1598815917969  loc loss 21.058349609375\n",
      "cls loss 467.7041015625  loc loss 35.28208541870117\n",
      "cls loss 468.6195068359375  loc loss 29.092571258544922\n",
      "cls loss 412.34222412109375  loc loss 27.272489547729492\n",
      "cls loss 318.25579833984375  loc loss 22.26961326599121\n",
      "cls loss 292.489501953125  loc loss 16.372623443603516\n",
      "cls loss 424.6211242675781  loc loss 23.42173957824707\n",
      "cls loss 509.15283203125  loc loss 30.667537689208984\n",
      "cls loss 459.76251220703125  loc loss 23.490659713745117\n",
      "cls loss 610.745361328125  loc loss 35.898460388183594\n",
      "cls loss 637.92333984375  loc loss 41.78736877441406\n",
      "cls loss 445.23822021484375  loc loss 27.35647201538086\n",
      "cls loss 624.0913696289062  loc loss 44.66984558105469\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1., 38., 47.,  1.,  1.,  1.,  1.,  1., 62.])\n",
      "cls loss 373.6617126464844  loc loss 17.885820388793945\n",
      "cls loss 433.29736328125  loc loss 31.076904296875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 465.96630859375  loc loss 27.837066650390625\n",
      "cls loss 535.4818115234375  loc loss 38.694847106933594\n",
      "cls loss 348.66827392578125  loc loss 16.58548927307129\n",
      "cls loss 430.905517578125  loc loss 32.69286346435547\n",
      "cls loss 409.60113525390625  loc loss 23.717082977294922\n",
      "cls loss 226.82469177246094  loc loss 8.11283016204834\n",
      "cls loss 339.76458740234375  loc loss 20.097192764282227\n",
      "cls loss 302.4627990722656  loc loss 13.012782096862793\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1., 35.])\n",
      "cls loss 327.29144287109375  loc loss 19.186010360717773\n",
      "cls loss 517.5120849609375  loc loss 26.38880157470703\n",
      "cls loss 523.6317138671875  loc loss 31.167360305786133\n",
      "cls loss 473.6416931152344  loc loss 35.4996452331543\n",
      "cls loss 416.90606689453125  loc loss 27.047691345214844\n",
      "cls loss 530.5023803710938  loc loss 37.00893783569336\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 290.21539306640625  loc loss 15.486043930053711\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 410.97021484375  loc loss 16.220901489257812\n",
      "cls loss 609.551025390625  loc loss 34.63859558105469\n",
      "cls loss 768.5299072265625  loc loss 59.56922912597656\n",
      "cls loss 380.8373718261719  loc loss 19.687808990478516\n",
      "cls loss 323.3457336425781  loc loss 19.42850112915039\n",
      "cls loss 332.109375  loc loss 17.06610870361328\n",
      "cls loss 369.83056640625  loc loss 20.233821868896484\n",
      "cls loss 313.45849609375  loc loss 13.570795059204102\n",
      "cls loss 584.3626708984375  loc loss 37.525081634521484\n",
      "cls loss 492.3013610839844  loc loss 29.463224411010742\n",
      "cls loss 223.0643768310547  loc loss 15.538925170898438\n",
      "cls loss 455.9768371582031  loc loss 26.132143020629883\n",
      "cls loss 601.004638671875  loc loss 44.058380126953125\n",
      "cls loss 461.5634765625  loc loss 30.23394775390625\n",
      "cls loss 412.1604919433594  loc loss 23.27667999267578\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.])\n",
      "cls loss 383.6705322265625  loc loss 26.89512062072754\n",
      "cls loss 404.5146484375  loc loss 24.424724578857422\n",
      "cls loss 484.82965087890625  loc loss 29.03753662109375\n",
      "cls loss 797.2379150390625  loc loss 58.24885177612305\n",
      "cls loss 287.19915771484375  loc loss 15.028075218200684\n",
      "cls loss 378.54278564453125  loc loss 23.986740112304688\n",
      "cls loss 299.1004638671875  loc loss 17.765026092529297\n",
      "cls loss 339.53399658203125  loc loss 23.595596313476562\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 21., 21., 21.])\n",
      "cls loss 325.342529296875  loc loss 21.38007354736328\n",
      "cls loss 332.5107421875  loc loss 17.415395736694336\n",
      "cls loss 351.23052978515625  loc loss 23.853805541992188\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 35.])\n",
      "cls loss 474.3272705078125  loc loss 28.203590393066406\n",
      "cls loss 178.45938110351562  loc loss 9.568230628967285\n",
      "cls loss 322.515380859375  loc loss 18.140111923217773\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 304.24603271484375  loc loss 12.601816177368164\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 38., 38.,  9., 38.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1.,  1.])\n",
      "cls loss 341.65875244140625  loc loss 20.087369918823242\n",
      "cls loss 565.6888427734375  loc loss 32.71766662597656\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 2.,  1., 77., 31., 10., 10.,  1.,  4., 10.])\n",
      "cls loss 262.6988830566406  loc loss 11.786138534545898\n",
      "cls loss 517.4652099609375  loc loss 30.883480072021484\n",
      "cls loss 1043.83056640625  loc loss 57.725341796875\n",
      "cls loss 317.69927978515625  loc loss 21.90159034729004\n",
      "cls loss 440.821533203125  loc loss 32.32945251464844\n",
      "cls loss 303.652099609375  loc loss 15.673054695129395\n",
      "cls loss 287.01470947265625  loc loss 15.462302207946777\n",
      "cls loss 400.633056640625  loc loss 23.42290687561035\n",
      "cls loss 400.0821533203125  loc loss 24.99169158935547\n",
      "cls loss 379.7908630371094  loc loss 28.362407684326172\n",
      "cls loss 323.6094970703125  loc loss 16.19748878479004\n",
      "cls loss 336.82855224609375  loc loss 19.158283233642578\n",
      "cls loss 648.1123046875  loc loss 38.3388786315918\n",
      "cls loss 609.8656005859375  loc loss 33.26168441772461\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1., 42., 42., 42., 42., 42., 42.,  1.,\n",
      "         1.,  1.,  1., 42.,  1.,  1., 42.,  1.])\n",
      "cls loss 338.367919921875  loc loss 23.378189086914062\n",
      "cls loss 506.0946044921875  loc loss 26.479022979736328\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 222.1063232421875  loc loss 10.837201118469238\n",
      "cls loss 499.34820556640625  loc loss 29.564258575439453\n",
      "cls loss 368.37384033203125  loc loss 25.609949111938477\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([11.])\n",
      "cls loss 219.61412048339844  loc loss 13.24535083770752\n",
      "cls loss 244.154541015625  loc loss 13.056282997131348\n",
      "cls loss 268.6943359375  loc loss 13.098069190979004\n",
      "cls loss 465.6961975097656  loc loss 30.487075805664062\n",
      "cls loss 364.5145263671875  loc loss 22.674835205078125\n",
      "cls loss 389.7589416503906  loc loss 26.652515411376953\n",
      "cls loss 543.2452392578125  loc loss 30.30440902709961\n",
      "cls loss 294.5132141113281  loc loss 17.345306396484375\n",
      "cls loss 644.8982543945312  loc loss 40.6359977722168\n",
      "cls loss 313.7292175292969  loc loss 18.254974365234375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 301.2772216796875  loc loss 17.542335510253906\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1., 38., 38., 42.])\n",
      "cls loss 431.7670593261719  loc loss 25.479543685913086\n",
      "cls loss 402.1511535644531  loc loss 21.939517974853516\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 348.025634765625  loc loss 20.722476959228516\n",
      "cls loss 740.2025146484375  loc loss 44.0128288269043\n",
      "cls loss 417.2317199707031  loc loss 25.576885223388672\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10.,  3.,  3.,  6.,  8.,  8.,  1.,  1.,  1., 10.])\n",
      "cls loss 316.84130859375  loc loss 15.791373252868652\n",
      "cls loss 213.73922729492188  loc loss 7.884815216064453\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10.,  3.])\n",
      "cls loss 297.2095031738281  loc loss 17.889732360839844\n",
      "cls loss 147.90274047851562  loc loss 8.885969161987305\n",
      "cls loss 371.72369384765625  loc loss 26.254987716674805\n",
      "cls loss 461.79315185546875  loc loss 29.166080474853516\n",
      "cls loss 331.6371765136719  loc loss 20.231781005859375\n",
      "cls loss 177.69509887695312  loc loss 12.994969367980957\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 34.])\n",
      "cls loss 501.92437744140625  loc loss 36.05013656616211\n",
      "cls loss 664.5038452148438  loc loss 47.82083511352539\n",
      "cls loss 410.1055908203125  loc loss 29.554916381835938\n",
      "cls loss 332.736328125  loc loss 22.760515213012695\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.,  1.])\n",
      "cls loss 375.14349365234375  loc loss 15.68976879119873\n",
      "cls loss 634.1201171875  loc loss 40.86949157714844\n",
      "cls loss 875.7348022460938  loc loss 51.16644287109375\n",
      "cls loss 703.1907958984375  loc loss 34.49745559692383\n",
      "cls loss 401.72479248046875  loc loss 20.198436737060547\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 437.2530212402344  loc loss 25.858266830444336\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10.])\n",
      "cls loss 281.4477844238281  loc loss 15.126708984375\n",
      "cls loss 407.8034973144531  loc loss 20.147903442382812\n",
      "cls loss 389.14947509765625  loc loss 22.461278915405273\n",
      "cls loss 249.1844940185547  loc loss 15.404393196105957\n",
      "cls loss 346.73236083984375  loc loss 21.72027587890625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21.,\n",
      "        21.])\n",
      "cls loss 423.5699157714844  loc loss 25.94233512878418\n",
      "cls loss 363.8840637207031  loc loss 20.744861602783203\n",
      "cls loss 240.67735290527344  loc loss 11.301837921142578\n",
      "cls loss 559.35546875  loc loss 34.654170989990234\n",
      "cls loss 406.5224914550781  loc loss 26.349409103393555\n",
      "cls loss 302.3133544921875  loc loss 14.62669849395752\n",
      "cls loss 637.2411499023438  loc loss 36.56929397583008\n",
      "cls loss 714.8792114257812  loc loss 49.63733673095703\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15., 85.])\n",
      "cls loss 491.120849609375  loc loss 26.58924102783203\n",
      "cls loss 477.287109375  loc loss 33.9854621887207\n",
      "cls loss 499.5302429199219  loc loss 32.482627868652344\n",
      "cls loss 407.97222900390625  loc loss 23.46753692626953\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 8., 8.])\n",
      "cls loss 306.4332275390625  loc loss 10.965006828308105\n",
      "cls loss 285.8144836425781  loc loss 21.477964401245117\n",
      "cls loss 366.3597412109375  loc loss 20.58557891845703\n",
      "cls loss 323.30462646484375  loc loss 16.523990631103516\n",
      "cls loss 341.8985595703125  loc loss 19.8404483795166\n",
      "cls loss 493.9286193847656  loc loss 27.79844093322754\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1., 35., 27., 27.,  1., 27.,  1.])\n",
      "cls loss 540.3567504882812  loc loss 42.195186614990234\n",
      "cls loss 329.8838195800781  loc loss 17.138168334960938\n",
      "cls loss 348.35882568359375  loc loss 25.604276657104492\n",
      "cls loss 345.341064453125  loc loss 28.98147964477539\n",
      "cls loss 323.7044372558594  loc loss 19.8652286529541\n",
      "cls loss 351.27178955078125  loc loss 26.208940505981445\n",
      "cls loss 343.90301513671875  loc loss 26.098325729370117\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  2.,  2.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  2.,  2.])\n",
      "cls loss 165.4597625732422  loc loss 8.213805198669434\n",
      "cls loss 555.6077880859375  loc loss 35.42842483520508\n",
      "cls loss 338.0621337890625  loc loss 16.54418182373047\n",
      "cls loss 619.2764282226562  loc loss 43.68690490722656\n",
      "cls loss 242.9393768310547  loc loss 13.179305076599121\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 19., 19., 19., 16.])\n",
      "cls loss 253.08311462402344  loc loss 9.342320442199707\n",
      "cls loss 221.49871826171875  loc loss 8.225173950195312\n",
      "cls loss 359.86370849609375  loc loss 15.540233612060547\n",
      "cls loss 473.7597961425781  loc loss 27.624614715576172\n",
      "cls loss 190.50592041015625  loc loss 13.036026000976562\n",
      "cls loss 499.58660888671875  loc loss 38.146705627441406\n",
      "cls loss 370.8668212890625  loc loss 23.53263282775879\n",
      "cls loss 378.9494323730469  loc loss 24.731687545776367\n",
      "cls loss 484.019287109375  loc loss 31.848697662353516\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 480.3458251953125  loc loss 23.550823211669922\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 688.7053833007812  loc loss 57.603919982910156\n",
      "cls loss 899.150390625  loc loss 78.98687744140625\n",
      "cls loss 424.1004638671875  loc loss 25.564525604248047\n",
      "cls loss 391.3738708496094  loc loss 23.632028579711914\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3.,  3.,  3.,  3.,  3., 10.])\n",
      "cls loss 181.26902770996094  loc loss 12.727775573730469\n",
      "cls loss 420.5720520019531  loc loss 20.328184127807617\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 1., 1., 1., 3., 3., 3., 3.])\n",
      "cls loss 352.92486572265625  loc loss 17.600399017333984\n",
      "cls loss 716.0369262695312  loc loss 41.742427825927734\n",
      "cls loss 598.311767578125  loc loss 29.481708526611328\n",
      "cls loss 389.53387451171875  loc loss 19.60735511779785\n",
      "cls loss 552.5499267578125  loc loss 34.97314453125\n",
      "cls loss 323.45782470703125  loc loss 21.563446044921875\n",
      "cls loss 521.201416015625  loc loss 33.355167388916016\n",
      "cls loss 384.4689025878906  loc loss 34.539268493652344\n",
      "cls loss 356.453857421875  loc loss 24.145957946777344\n",
      "cls loss 793.0093383789062  loc loss 62.33695602416992\n",
      "cls loss 508.2611083984375  loc loss 39.854698181152344\n",
      "cls loss 321.4208984375  loc loss 17.41599464416504\n",
      "cls loss 192.39346313476562  loc loss 9.532773971557617\n",
      "cls loss 259.0672302246094  loc loss 12.97065544128418\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3., 10., 10., 10., 10., 10., 10., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10., 10., 10., 10., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 11., 10., 10., 10., 10., 10.,  3.,  3.,  3.,  3.,  3.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 11., 10., 10., 10., 10., 10.,  3.,  3.,  3.,  3.,  3.])\n",
      "cls loss 196.6678466796875  loc loss 9.966136932373047\n",
      "cls loss 279.98345947265625  loc loss 12.178030014038086\n",
      "cls loss 246.1966552734375  loc loss 14.014381408691406\n",
      "cls loss 239.3676300048828  loc loss 10.802777290344238\n",
      "cls loss 316.62445068359375  loc loss 23.976224899291992\n",
      "cls loss 231.212646484375  loc loss 9.495535850524902\n",
      "cls loss 502.3040466308594  loc loss 30.12712287902832\n",
      "cls loss 475.5644226074219  loc loss 24.565784454345703\n",
      "cls loss 687.0371704101562  loc loss 38.531700134277344\n",
      "cls loss 354.33868408203125  loc loss 22.33246421813965\n",
      "cls loss 598.9715576171875  loc loss 35.86267852783203\n",
      "cls loss 447.9532165527344  loc loss 31.585853576660156\n",
      "cls loss 443.24407958984375  loc loss 27.487987518310547\n",
      "cls loss 423.4544677734375  loc loss 28.358970642089844\n",
      "cls loss 539.9530029296875  loc loss 35.95213317871094\n",
      "cls loss 521.5695190429688  loc loss 33.993934631347656\n",
      "cls loss 244.970458984375  loc loss 13.252423286437988\n",
      "cls loss 520.7454833984375  loc loss 34.069026947021484\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 10.,  1., 18.])\n",
      "cls loss 221.16348266601562  loc loss 15.975497245788574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 253.78656005859375  loc loss 12.394359588623047\n",
      "cls loss 479.50482177734375  loc loss 26.30818748474121\n",
      "cls loss 690.1140747070312  loc loss 39.07251739501953\n",
      "cls loss 414.5789489746094  loc loss 27.26600456237793\n",
      "cls loss 637.8524780273438  loc loss 29.532421112060547\n",
      "cls loss 498.2342834472656  loc loss 29.779844284057617\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.,  1.,  1.])\n",
      "cls loss 567.2933349609375  loc loss 31.908435821533203\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1., 38.,  1.])\n",
      "cls loss 502.0480041503906  loc loss 26.820987701416016\n",
      "cls loss 702.6168212890625  loc loss 49.276145935058594\n",
      "cls loss 377.50701904296875  loc loss 24.09777069091797\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 501.6348571777344  loc loss 27.34566307067871\n",
      "cls loss 405.0107421875  loc loss 22.96117401123047\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3., 10.,  8.,  3., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.])\n",
      "cls loss 445.3664855957031  loc loss 25.549560546875\n",
      "cls loss 299.1595458984375  loc loss 19.938608169555664\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3.,  3., 11.,  3., 10., 10.,  3.,  3., 10.])\n",
      "cls loss 305.859375  loc loss 18.1398983001709\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3., 10., 10., 10.])\n",
      "cls loss 379.2901611328125  loc loss 20.086196899414062\n",
      "cls loss 287.2215576171875  loc loss 20.19717788696289\n",
      "cls loss 395.95465087890625  loc loss 27.67546844482422\n",
      "cls loss 572.9874267578125  loc loss 34.13284683227539\n",
      "cls loss 372.395263671875  loc loss 24.338787078857422\n",
      "cls loss 298.6748046875  loc loss 22.100540161132812\n",
      "cls loss 377.9443664550781  loc loss 21.266836166381836\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 9.,  9., 85., 85.])\n",
      "cls loss 331.39141845703125  loc loss 14.449976921081543\n",
      "cls loss 428.3574523925781  loc loss 26.284088134765625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 630.9802856445312  loc loss 36.81108474731445\n",
      "cls loss 526.123291015625  loc loss 21.553049087524414\n",
      "cls loss 617.3236083984375  loc loss 40.2174072265625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10., 10., 10., 10.])\n",
      "cls loss 402.5851135253906  loc loss 22.922279357910156\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([13.])\n",
      "cls loss 596.6474609375  loc loss 44.39126205444336\n",
      "cls loss 157.66436767578125  loc loss 9.165234565734863\n",
      "cls loss 238.74176025390625  loc loss 12.742401123046875\n",
      "cls loss 303.3314514160156  loc loss 19.322872161865234\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19.,  1.,  1.,  1., 19., 19.])\n",
      "cls loss 327.2225341796875  loc loss 22.672874450683594\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 268.4228515625  loc loss 18.448532104492188\n",
      "cls loss 418.94390869140625  loc loss 27.778684616088867\n",
      "cls loss 316.0181884765625  loc loss 17.02838134765625\n",
      "cls loss 451.82843017578125  loc loss 22.461029052734375\n",
      "cls loss 480.5704345703125  loc loss 33.481239318847656\n",
      "cls loss 364.86395263671875  loc loss 20.601924896240234\n",
      "cls loss 609.3646240234375  loc loss 39.798160552978516\n",
      "cls loss 216.75479125976562  loc loss 8.782800674438477\n",
      "cls loss 395.6589050292969  loc loss 25.830482482910156\n",
      "cls loss 338.52777099609375  loc loss 17.963930130004883\n",
      "cls loss 374.33123779296875  loc loss 17.785139083862305\n",
      "cls loss 496.2629699707031  loc loss 26.468563079833984\n",
      "cls loss 393.1834716796875  loc loss 18.179489135742188\n",
      "cls loss 565.1243896484375  loc loss 37.674766540527344\n",
      "cls loss 362.271240234375  loc loss 21.523109436035156\n",
      "cls loss 457.154052734375  loc loss 32.903564453125\n",
      "cls loss 662.06005859375  loc loss 40.072391510009766\n",
      "cls loss 354.78509521484375  loc loss 27.137678146362305\n",
      "cls loss 426.22589111328125  loc loss 23.934328079223633\n",
      "cls loss 497.04681396484375  loc loss 38.955108642578125\n",
      "cls loss 590.3147583007812  loc loss 39.853797912597656\n",
      "cls loss 649.0459594726562  loc loss 38.609375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 5.])\n",
      "cls loss 166.6675262451172  loc loss 8.729936599731445\n",
      "cls loss 251.2691650390625  loc loss 10.008736610412598\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 13.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 6., 8., 8.])\n",
      "cls loss 196.2249298095703  loc loss 10.051578521728516\n",
      "cls loss 273.7570495605469  loc loss 12.305597305297852\n",
      "cls loss 514.6122436523438  loc loss 31.543270111083984\n",
      "cls loss 213.98939514160156  loc loss 11.727542877197266\n",
      "cls loss 430.47344970703125  loc loss 29.776527404785156\n",
      "cls loss 652.5535888671875  loc loss 45.59535598754883\n",
      "cls loss 414.9245910644531  loc loss 26.559484481811523\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([42., 42.,  1.,  1.,  1.,  1.,  1.,  1.,  1., 42., 42.])\n",
      "cls loss 442.3480224609375  loc loss 21.98881721496582\n",
      "cls loss 554.830810546875  loc loss 41.029136657714844\n",
      "cls loss 507.3753662109375  loc loss 33.32394790649414\n",
      "cls loss 317.80096435546875  loc loss 19.361919403076172\n",
      "cls loss 420.5730895996094  loc loss 21.843198776245117\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 643.1259765625  loc loss 37.945064544677734\n",
      "cls loss 512.4180908203125  loc loss 32.864463806152344\n",
      "cls loss 304.7920227050781  loc loss 15.169631958007812\n",
      "cls loss 260.7771911621094  loc loss 14.333930969238281\n",
      "cls loss 344.2384033203125  loc loss 21.006439208984375\n",
      "cls loss 472.45098876953125  loc loss 29.661531448364258\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15.])\n",
      "cls loss 228.18548583984375  loc loss 7.675863742828369\n",
      "cls loss 403.41754150390625  loc loss 23.63665008544922\n",
      "cls loss 357.4625549316406  loc loss 21.870302200317383\n",
      "cls loss 643.1829833984375  loc loss 38.0474739074707\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19.,  7.])\n",
      "cls loss 297.32122802734375  loc loss 17.23362922668457\n",
      "cls loss 600.2103271484375  loc loss 41.8105583190918\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 543.0679931640625  loc loss 28.246623992919922\n",
      "cls loss 504.38861083984375  loc loss 32.7579231262207\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([38., 38.,  1., 18.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1., 18., 18.,  1.])\n",
      "cls loss 331.78839111328125  loc loss 18.533260345458984\n",
      "cls loss 323.15106201171875  loc loss 16.496597290039062\n",
      "cls loss 637.984375  loc loss 44.5427360534668\n",
      "cls loss 458.67755126953125  loc loss 31.05870246887207\n",
      "cls loss 382.4482421875  loc loss 25.626075744628906\n",
      "cls loss 265.54803466796875  loc loss 18.77800750732422\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.])\n",
      "cls loss 160.79510498046875  loc loss 6.596952438354492\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([32.])\n",
      "cls loss 420.98333740234375  loc loss 21.11823081970215\n",
      "cls loss 374.76153564453125  loc loss 23.83715057373047\n",
      "cls loss 453.9190368652344  loc loss 33.13352966308594\n",
      "cls loss 409.858154296875  loc loss 24.47557258605957\n",
      "cls loss 347.68524169921875  loc loss 19.162796020507812\n",
      "cls loss 553.3576049804688  loc loss 30.84872055053711\n",
      "cls loss 651.64404296875  loc loss 40.634002685546875\n",
      "cls loss 468.5703125  loc loss 32.440818786621094\n",
      "cls loss 349.16656494140625  loc loss 21.883968353271484\n",
      "cls loss 570.4638671875  loc loss 37.827545166015625\n",
      "cls loss 376.4259033203125  loc loss 20.78612518310547\n",
      "cls loss 678.7452392578125  loc loss 43.27578353881836\n",
      "cls loss 448.7313232421875  loc loss 24.341751098632812\n",
      "cls loss 358.4356384277344  loc loss 28.95879554748535\n",
      "cls loss 281.5650634765625  loc loss 14.024740219116211\n",
      "cls loss 331.48370361328125  loc loss 21.021554946899414\n",
      "cls loss 482.31536865234375  loc loss 32.36091613769531\n",
      "cls loss 551.614013671875  loc loss 38.78706359863281\n",
      "cls loss 330.74603271484375  loc loss 20.496292114257812\n",
      "cls loss 527.2611083984375  loc loss 36.8204345703125\n",
      "cls loss 631.8819580078125  loc loss 39.63860321044922\n",
      "cls loss 235.6953887939453  loc loss 14.099950790405273\n",
      "cls loss 614.642822265625  loc loss 40.521575927734375\n",
      "cls loss 457.75146484375  loc loss 30.048322677612305\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 593.2835693359375  loc loss 44.12299346923828\n",
      "cls loss 251.69119262695312  loc loss 11.116580963134766\n",
      "cls loss 381.37127685546875  loc loss 23.812341690063477\n",
      "cls loss 389.43341064453125  loc loss 27.35161018371582\n",
      "cls loss 323.813720703125  loc loss 21.46430206298828\n",
      "cls loss 190.479736328125  loc loss 10.839303970336914\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 9., 9., 1., 9., 9., 9., 9., 1., 9.])\n",
      "cls loss 869.81982421875  loc loss 57.78184509277344\n",
      "cls loss 470.384765625  loc loss 25.263717651367188\n",
      "cls loss 737.001708984375  loc loss 52.84269332885742\n",
      "cls loss 288.0921325683594  loc loss 21.92186737060547\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 42., 42.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 473.37554931640625  loc loss 35.92795944213867\n",
      "cls loss 479.828857421875  loc loss 39.05489730834961\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  2.,  1.,  1.,  1., 38.,\n",
      "         1.,  1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 38., 38., 38.,  1., 38., 38., 38.,  1.,  1., 38.,  1.,\n",
      "         1.])\n",
      "cls loss 282.3179016113281  loc loss 21.863937377929688\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  8.,  8.])\n",
      "cls loss 667.8200073242188  loc loss 46.61506271362305\n",
      "cls loss 672.7802734375  loc loss 52.07781219482422\n",
      "cls loss 249.9656219482422  loc loss 16.018491744995117\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([4., 1., 1., 4.])\n",
      "cls loss 399.90478515625  loc loss 25.2463321685791\n",
      "cls loss 511.233154296875  loc loss 30.385990142822266\n",
      "cls loss 203.302490234375  loc loss 10.655391693115234\n",
      "cls loss 254.7413330078125  loc loss 16.700471878051758\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([51.,  1.])\n",
      "cls loss 181.906982421875  loc loss 9.04610824584961\n",
      "cls loss 259.0313720703125  loc loss 17.467601776123047\n",
      "cls loss 545.2474975585938  loc loss 26.371912002563477\n",
      "cls loss 504.6475524902344  loc loss 35.442108154296875\n",
      "cls loss 770.078125  loc loss 38.505088806152344\n",
      "cls loss 918.539794921875  loc loss 58.88709259033203\n",
      "cls loss 380.18060302734375  loc loss 23.73122215270996\n",
      "cls loss 555.8253784179688  loc loss 40.464500427246094\n",
      "cls loss 605.699462890625  loc loss 40.17814254760742\n",
      "cls loss 434.6609191894531  loc loss 28.136672973632812\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  3.,  1.,  1.,  1.,  3.,  1.,  1.,\n",
      "         1.,  1.,  1.])\n",
      "cls loss 471.8240966796875  loc loss 20.464881896972656\n",
      "cls loss 504.59771728515625  loc loss 28.108478546142578\n",
      "cls loss 489.4261169433594  loc loss 25.285221099853516\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "cls loss 416.585205078125  loc loss 23.89232635498047\n",
      "cls loss 230.40975952148438  loc loss 18.367835998535156\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3.])\n",
      "cls loss 186.44581604003906  loc loss 10.375020980834961\n",
      "cls loss 326.17376708984375  loc loss 19.572250366210938\n",
      "cls loss 313.68792724609375  loc loss 21.007408142089844\n",
      "cls loss 566.6298828125  loc loss 36.058563232421875\n",
      "cls loss 258.11944580078125  loc loss 19.42108726501465\n",
      "cls loss 297.5643005371094  loc loss 23.951141357421875\n",
      "cls loss 853.0069580078125  loc loss 57.868709564208984\n",
      "cls loss 382.6356506347656  loc loss 28.280349731445312\n",
      "cls loss 284.150634765625  loc loss 19.917591094970703\n",
      "cls loss 335.787841796875  loc loss 18.884788513183594\n",
      "cls loss 305.5322570800781  loc loss 22.825586318969727\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 568.74169921875  loc loss 39.388065338134766\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  9., 64., 64., 64., 64., 64., 64., 64., 64., 64.,  9.,  9.,  9.,\n",
      "         9.])\n",
      "cls loss 261.94970703125  loc loss 13.7732572555542\n",
      "cls loss 829.7794799804688  loc loss 61.94234848022461\n",
      "cls loss 438.1029357910156  loc loss 27.646728515625\n",
      "cls loss 527.08154296875  loc loss 34.591773986816406\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.,  3.,  3.])\n",
      "cls loss 332.1429443359375  loc loss 17.939376831054688\n",
      "cls loss 359.453857421875  loc loss 25.726505279541016\n",
      "cls loss 378.36602783203125  loc loss 26.473873138427734\n",
      "cls loss 388.39410400390625  loc loss 25.39158058166504\n",
      "cls loss 448.35845947265625  loc loss 29.389055252075195\n",
      "cls loss 444.7405700683594  loc loss 28.33252716064453\n",
      "cls loss 397.9072265625  loc loss 26.676219940185547\n",
      "cls loss 406.790283203125  loc loss 22.097026824951172\n",
      "cls loss 508.4892578125  loc loss 32.930877685546875\n",
      "cls loss 372.2628479003906  loc loss 22.94927215576172\n",
      "cls loss 283.58416748046875  loc loss 15.02099609375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21.])\n",
      "cls loss 231.76541137695312  loc loss 15.355010032653809\n",
      "cls loss 331.75360107421875  loc loss 28.458477020263672\n",
      "cls loss 489.66552734375  loc loss 34.01232147216797\n",
      "cls loss 247.40383911132812  loc loss 15.403912544250488\n",
      "cls loss 402.96160888671875  loc loss 26.973405838012695\n",
      "cls loss 749.297119140625  loc loss 39.29067611694336\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 42., 42.,  1.,  1.])\n",
      "cls loss 451.59527587890625  loc loss 24.462379455566406\n",
      "cls loss 295.652587890625  loc loss 17.17647933959961\n",
      "cls loss 427.4334716796875  loc loss 25.053958892822266\n",
      "cls loss 559.6795654296875  loc loss 41.01457214355469\n",
      "cls loss 350.166015625  loc loss 19.409774780273438\n",
      "cls loss 536.0804443359375  loc loss 35.514259338378906\n",
      "cls loss 469.11151123046875  loc loss 32.088558197021484\n",
      "cls loss 455.4500732421875  loc loss 29.0001163482666\n",
      "cls loss 366.75225830078125  loc loss 22.73023796081543\n",
      "cls loss 296.2571716308594  loc loss 20.288105010986328\n",
      "cls loss 233.9686737060547  loc loss 10.765159606933594\n",
      "cls loss 370.4131164550781  loc loss 23.86304473876953\n",
      "cls loss 563.2608642578125  loc loss 35.71303939819336\n",
      "cls loss 410.662109375  loc loss 24.48480224609375\n",
      "cls loss 393.43115234375  loc loss 28.722366333007812\n",
      "cls loss 431.95196533203125  loc loss 25.54553985595703\n",
      "cls loss 642.33740234375  loc loss 47.00613021850586\n",
      "cls loss 516.076171875  loc loss 33.29585266113281\n",
      "cls loss 564.2520751953125  loc loss 29.480133056640625\n",
      "cls loss 354.99932861328125  loc loss 15.365079879760742\n",
      "cls loss 492.61785888671875  loc loss 28.073877334594727\n",
      "cls loss 452.23614501953125  loc loss 24.615047454833984\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 5., 5., 5., 5., 5., 5.])\n",
      "cls loss 274.95648193359375  loc loss 16.655324935913086\n",
      "cls loss 369.6402587890625  loc loss 18.78227424621582\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([13.])\n",
      "cls loss 257.5451354980469  loc loss 11.818719863891602\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([44., 10.,  1.,  1.,  1.])\n",
      "cls loss 230.73599243164062  loc loss 15.259547233581543\n",
      "cls loss 407.6395263671875  loc loss 22.667499542236328\n",
      "cls loss 376.0632019042969  loc loss 20.40745735168457\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19., 19., 19., 19., 19., 19., 19.])\n",
      "cls loss 393.14129638671875  loc loss 24.445619583129883\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([56.])\n",
      "cls loss 829.77197265625  loc loss 54.21147918701172\n",
      "cls loss 527.7330932617188  loc loss 38.06003952026367\n",
      "cls loss 668.3271484375  loc loss 42.3664436340332\n",
      "cls loss 640.1802368164062  loc loss 48.0993537902832\n",
      "cls loss 382.5958251953125  loc loss 22.024499893188477\n",
      "cls loss 656.256591796875  loc loss 41.536460876464844\n",
      "cls loss 370.3961181640625  loc loss 24.99365997314453\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 36.])\n",
      "cls loss 493.4295654296875  loc loss 21.83411979675293\n",
      "cls loss 412.2416687011719  loc loss 25.175926208496094\n",
      "cls loss 391.5823974609375  loc loss 22.747011184692383\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5.])\n",
      "cls loss 464.8581848144531  loc loss 26.223848342895508\n",
      "cls loss 255.84075927734375  loc loss 11.81733226776123\n",
      "cls loss 579.7462158203125  loc loss 30.637788772583008\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "cls loss 515.482421875  loc loss 29.87230682373047\n",
      "cls loss 467.76129150390625  loc loss 30.06875228881836\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 496.098388671875  loc loss 30.520103454589844\n",
      "cls loss 554.00732421875  loc loss 34.887428283691406\n",
      "cls loss 475.7889099121094  loc loss 39.23480224609375\n",
      "cls loss 330.3003845214844  loc loss 21.18301010131836\n",
      "cls loss 371.0450439453125  loc loss 26.609752655029297\n",
      "cls loss 389.52960205078125  loc loss 22.486278533935547\n",
      "cls loss 662.199462890625  loc loss 31.844160079956055\n",
      "cls loss 263.7799377441406  loc loss 13.447646141052246\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 11., 15., 10., 10., 10., 10., 10.])\n",
      "cls loss 588.3509521484375  loc loss 38.55451583862305\n",
      "cls loss 355.70782470703125  loc loss 26.41827964782715\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3.])\n",
      "cls loss 369.9322509765625  loc loss 27.154953002929688\n",
      "cls loss 358.3489990234375  loc loss 17.758920669555664\n",
      "cls loss 407.2208557128906  loc loss 18.26483917236328\n",
      "cls loss 522.4302978515625  loc loss 21.743942260742188\n",
      "cls loss 238.45074462890625  loc loss 11.03420639038086\n",
      "cls loss 441.353515625  loc loss 26.296764373779297\n",
      "cls loss 492.8199157714844  loc loss 29.599679946899414\n",
      "cls loss 429.23724365234375  loc loss 26.74203872680664\n",
      "cls loss 971.1021118164062  loc loss 59.869590759277344\n",
      "cls loss 635.115234375  loc loss 39.702579498291016\n",
      "cls loss 397.5184326171875  loc loss 26.597013473510742\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  9.,  9.,  9.,  6.,  6., 85., 85.,  8.,  1.,  1.,  1.,  1.,\n",
      "         6.,  6.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 270.3373107910156  loc loss 21.08829689025879\n",
      "cls loss 674.4440307617188  loc loss 46.132896423339844\n",
      "cls loss 790.174560546875  loc loss 46.40116882324219\n",
      "cls loss 506.6995849609375  loc loss 34.73591995239258\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10.,  3.,  3., 10.])\n",
      "cls loss 317.45379638671875  loc loss 17.557992935180664\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([7.])\n",
      "cls loss 412.0986328125  loc loss 26.246173858642578\n",
      "cls loss 410.44207763671875  loc loss 25.217988967895508\n",
      "cls loss 425.00286865234375  loc loss 35.5938835144043\n",
      "cls loss 701.705322265625  loc loss 47.27191162109375\n",
      "cls loss 402.9559631347656  loc loss 25.437238693237305\n",
      "cls loss 629.8555908203125  loc loss 36.715065002441406\n",
      "cls loss 772.4927978515625  loc loss 41.417015075683594\n",
      "cls loss 514.5309448242188  loc loss 26.95780372619629\n",
      "cls loss 570.5220947265625  loc loss 32.16168975830078\n",
      "cls loss 424.20208740234375  loc loss 27.25034523010254\n",
      "cls loss 596.1026000976562  loc loss 42.171485900878906\n",
      "cls loss 451.43310546875  loc loss 28.406211853027344\n",
      "cls loss 323.03424072265625  loc loss 20.921611785888672\n",
      "cls loss 524.5363159179688  loc loss 38.757205963134766\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([62.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([62.])\n",
      "cls loss 231.40106201171875  loc loss 11.421097755432129\n",
      "cls loss 375.55194091796875  loc loss 27.981510162353516\n",
      "cls loss 386.24835205078125  loc loss 25.095800399780273\n",
      "cls loss 249.9319610595703  loc loss 12.357967376708984\n",
      "cls loss 519.3154296875  loc loss 33.3320198059082\n",
      "cls loss 530.7138671875  loc loss 29.924894332885742\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([28.])\n",
      "cls loss 667.5826416015625  loc loss 30.695228576660156\n",
      "cls loss 501.4588623046875  loc loss 31.913108825683594\n",
      "cls loss 497.56475830078125  loc loss 34.666141510009766\n",
      "cls loss 570.7818603515625  loc loss 32.533138275146484\n",
      "cls loss 857.6212158203125  loc loss 46.31293487548828\n",
      "cls loss 482.85107421875  loc loss 25.38232421875\n",
      "cls loss 666.3209838867188  loc loss 29.776840209960938\n",
      "cls loss 521.2156372070312  loc loss 34.754661560058594\n",
      "cls loss 777.609130859375  loc loss 56.692787170410156\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([81.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 468.783203125  loc loss 18.664804458618164\n",
      "cls loss 355.6700134277344  loc loss 18.547883987426758\n",
      "cls loss 256.689208984375  loc loss 19.228572845458984\n",
      "cls loss 230.88052368164062  loc loss 10.406209945678711\n",
      "cls loss 263.5552673339844  loc loss 20.882671356201172\n",
      "cls loss 330.175537109375  loc loss 20.904294967651367\n",
      "cls loss 338.2255859375  loc loss 24.375564575195312\n",
      "cls loss 507.3453369140625  loc loss 40.1002082824707\n",
      "cls loss 595.289794921875  loc loss 34.96027374267578\n",
      "cls loss 1035.9627685546875  loc loss 68.325439453125\n",
      "cls loss 407.70294189453125  loc loss 19.68607521057129\n",
      "cls loss 508.04461669921875  loc loss 37.161399841308594\n",
      "cls loss 365.8063659667969  loc loss 21.675262451171875\n",
      "cls loss 513.1085205078125  loc loss 26.353076934814453\n",
      "cls loss 451.5512390136719  loc loss 23.895742416381836\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([44., 44.])\n",
      "cls loss 435.80926513671875  loc loss 18.10184097290039\n",
      "cls loss 478.65771484375  loc loss 26.74344825744629\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15.])\n",
      "cls loss 465.405029296875  loc loss 21.97740936279297\n",
      "cls loss 252.612060546875  loc loss 13.440550804138184\n",
      "cls loss 428.70648193359375  loc loss 28.202701568603516\n",
      "cls loss 252.00547790527344  loc loss 12.252002716064453\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([1., 3., 3.])\n",
      "cls loss 278.22503662109375  loc loss 16.877798080444336\n",
      "cls loss 201.0120086669922  loc loss 9.545352935791016\n",
      "cls loss 391.21337890625  loc loss 26.329212188720703\n",
      "cls loss 461.05535888671875  loc loss 24.705867767333984\n",
      "cls loss 395.8777770996094  loc loss 26.676008224487305\n",
      "cls loss 328.42034912109375  loc loss 21.685991287231445\n",
      "cls loss 363.15679931640625  loc loss 25.39495849609375\n",
      "cls loss 482.12652587890625  loc loss 30.69963836669922\n",
      "cls loss 323.53375244140625  loc loss 21.799728393554688\n",
      "cls loss 416.61199951171875  loc loss 31.8609619140625\n",
      "cls loss 289.22100830078125  loc loss 18.12533950805664\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 548.316650390625  loc loss 30.66750717163086\n",
      "cls loss 680.6829223632812  loc loss 27.43864631652832\n",
      "cls loss 583.3948974609375  loc loss 36.51206588745117\n",
      "cls loss 578.4607543945312  loc loss 42.57166290283203\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10., 10., 10.,  1.,  1.,  1.,  1.,  1.,  1.,  8.,  8.,\n",
      "         1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10., 10., 10.,  1.,  1.,  1.,  1.,  1.,  1.,  8.,  8.,\n",
      "         1.])\n",
      "cls loss 456.434814453125  loc loss 22.684789657592773\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 3., 3., 3.])\n",
      "cls loss 464.753173828125  loc loss 25.079147338867188\n",
      "cls loss 279.73223876953125  loc loss 17.729734420776367\n",
      "cls loss 211.61367797851562  loc loss 10.57524585723877\n",
      "cls loss 415.068603515625  loc loss 31.14423942565918\n",
      "cls loss 304.9903564453125  loc loss 14.198790550231934\n",
      "cls loss 375.52227783203125  loc loss 26.299869537353516\n",
      "cls loss 419.6199645996094  loc loss 30.948627471923828\n",
      "cls loss 561.9127807617188  loc loss 41.928226470947266\n",
      "cls loss 492.1064758300781  loc loss 25.3311710357666\n",
      "cls loss 443.36956787109375  loc loss 24.06062126159668\n",
      "cls loss 463.79931640625  loc loss 30.08489418029785\n",
      "cls loss 333.90509033203125  loc loss 24.414226531982422\n",
      "cls loss 681.0950927734375  loc loss 48.037315368652344\n",
      "cls loss 289.8577575683594  loc loss 16.377134323120117\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 554.380859375  loc loss 31.279136657714844\n",
      "cls loss 234.83560180664062  loc loss 9.901052474975586\n",
      "cls loss 605.149658203125  loc loss 40.80622863769531\n",
      "cls loss 309.7525634765625  loc loss 19.04424285888672\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 34.])\n",
      "cls loss 516.3985595703125  loc loss 27.339658737182617\n",
      "cls loss 287.50067138671875  loc loss 16.350059509277344\n",
      "cls loss 563.9359130859375  loc loss 29.20819091796875\n",
      "cls loss 200.659912109375  loc loss 12.402483940124512\n",
      "cls loss 421.33428955078125  loc loss 24.601531982421875\n",
      "cls loss 405.09454345703125  loc loss 31.586767196655273\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 38.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16., 16., 16.,  9.,  9.,  9., 16., 16., 16., 85.,  9.])\n",
      "cls loss 420.7259216308594  loc loss 24.941335678100586\n",
      "cls loss 452.8487854003906  loc loss 33.624298095703125\n",
      "cls loss 607.0685424804688  loc loss 38.839866638183594\n",
      "cls loss 951.3807373046875  loc loss 57.95415496826172\n",
      "cls loss 238.66220092773438  loc loss 13.572569847106934\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3., 10.,  8.,  8., 10., 10., 10.,  3.,  3., 14.])\n",
      "cls loss 265.15814208984375  loc loss 15.027785301208496\n",
      "cls loss 486.57049560546875  loc loss 31.45423698425293\n",
      "cls loss 198.32315063476562  loc loss 8.779114723205566\n",
      "cls loss 355.3363037109375  loc loss 15.753021240234375\n",
      "cls loss 487.90325927734375  loc loss 31.43692970275879\n",
      "cls loss 420.9647521972656  loc loss 24.644575119018555\n",
      "cls loss 248.3106689453125  loc loss 13.274950981140137\n",
      "cls loss 335.3727111816406  loc loss 15.386340141296387\n",
      "cls loss 562.0776977539062  loc loss 28.039344787597656\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42., 42.,  1.])\n",
      "cls loss 530.137939453125  loc loss 28.16368865966797\n",
      "cls loss 426.557861328125  loc loss 20.54363441467285\n",
      "cls loss 520.001220703125  loc loss 36.73202133178711\n",
      "cls loss 579.80126953125  loc loss 33.625640869140625\n",
      "cls loss 392.5994873046875  loc loss 22.826858520507812\n",
      "cls loss 472.4298095703125  loc loss 33.4610710144043\n",
      "cls loss 283.9877624511719  loc loss 18.93629264831543\n",
      "cls loss 306.250244140625  loc loss 22.188100814819336\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20.])\n",
      "cls loss 217.67843627929688  loc loss 12.824909210205078\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([11.])\n",
      "cls loss 317.375732421875  loc loss 14.141143798828125\n",
      "cls loss 176.51992797851562  loc loss 11.211761474609375\n",
      "cls loss 479.8123779296875  loc loss 34.89277267456055\n",
      "cls loss 204.14273071289062  loc loss 10.213156700134277\n",
      "cls loss 424.7088623046875  loc loss 25.96123504638672\n",
      "cls loss 229.13853454589844  loc loss 15.568868637084961\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 35., 27.])\n",
      "cls loss 423.04864501953125  loc loss 23.59978485107422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 499.0090026855469  loc loss 35.0666618347168\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 328.20452880859375  loc loss 16.7407283782959\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([42.,  1.])\n",
      "cls loss 425.112548828125  loc loss 26.200490951538086\n",
      "cls loss 452.6831970214844  loc loss 21.47188949584961\n",
      "cls loss 568.759765625  loc loss 28.132152557373047\n",
      "cls loss 702.6748046875  loc loss 32.98101806640625\n",
      "cls loss 576.3033447265625  loc loss 29.127857208251953\n",
      "cls loss 402.7883605957031  loc loss 22.534740447998047\n",
      "cls loss 327.292724609375  loc loss 21.32567596435547\n",
      "cls loss 190.56390380859375  loc loss 7.994697570800781\n",
      "cls loss 342.4897766113281  loc loss 18.56508445739746\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 1., 1.])\n",
      "cls loss 323.49041748046875  loc loss 20.188610076904297\n",
      "cls loss 392.16064453125  loc loss 25.160980224609375\n",
      "cls loss 376.6943664550781  loc loss 22.779682159423828\n",
      "cls loss 300.050048828125  loc loss 21.44646453857422\n",
      "cls loss 376.08929443359375  loc loss 24.27473258972168\n",
      "cls loss 397.14666748046875  loc loss 28.436506271362305\n",
      "cls loss 580.8203125  loc loss 33.77275085449219\n",
      "cls loss 499.9118957519531  loc loss 37.25407791137695\n",
      "cls loss 432.5768127441406  loc loss 28.091222763061523\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 339.17559814453125  loc loss 24.458087921142578\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 480.347412109375  loc loss 19.044679641723633\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([81.])\n",
      "cls loss 577.1859130859375  loc loss 28.920122146606445\n",
      "cls loss 337.40863037109375  loc loss 21.275609970092773\n",
      "cls loss 301.39215087890625  loc loss 11.769631385803223\n",
      "cls loss 388.207275390625  loc loss 19.455015182495117\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3.,  1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 19.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 19.])\n",
      "cls loss 547.7636108398438  loc loss 32.39105987548828\n",
      "cls loss 282.207275390625  loc loss 15.387171745300293\n",
      "cls loss 306.15411376953125  loc loss 16.190282821655273\n",
      "cls loss 558.8123779296875  loc loss 39.88911437988281\n",
      "cls loss 274.0191650390625  loc loss 17.09126853942871\n",
      "cls loss 345.50390625  loc loss 20.54043960571289\n",
      "cls loss 430.37420654296875  loc loss 28.62502098083496\n",
      "cls loss 321.4659118652344  loc loss 23.048786163330078\n",
      "cls loss 434.27532958984375  loc loss 23.814537048339844\n",
      "cls loss 468.6722412109375  loc loss 30.5211124420166\n",
      "cls loss 633.458251953125  loc loss 53.54084014892578\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 81.])\n",
      "cls loss 420.4365234375  loc loss 20.202341079711914\n",
      "cls loss 388.8475341796875  loc loss 20.562604904174805\n",
      "cls loss 389.4704895019531  loc loss 22.043787002563477\n",
      "cls loss 320.60595703125  loc loss 16.154817581176758\n",
      "cls loss 296.64935302734375  loc loss 17.009464263916016\n",
      "cls loss 364.10369873046875  loc loss 24.336978912353516\n",
      "cls loss 267.60321044921875  loc loss 17.560073852539062\n",
      "cls loss 227.16062927246094  loc loss 13.995687484741211\n",
      "cls loss 307.00921630859375  loc loss 18.86528205871582\n",
      "cls loss 401.4964599609375  loc loss 23.990829467773438\n",
      "cls loss 388.55072021484375  loc loss 25.834152221679688\n",
      "cls loss 363.916748046875  loc loss 23.425397872924805\n",
      "cls loss 213.87254333496094  loc loss 13.389265060424805\n",
      "cls loss 748.1936645507812  loc loss 46.33310317993164\n",
      "cls loss 407.50384521484375  loc loss 26.683944702148438\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 366.3280029296875  loc loss 17.820796966552734\n",
      "cls loss 409.24578857421875  loc loss 25.73295021057129\n",
      "cls loss 287.3365478515625  loc loss 20.638290405273438\n",
      "cls loss 465.1506042480469  loc loss 34.63340759277344\n",
      "cls loss 463.88775634765625  loc loss 28.509796142578125\n",
      "cls loss 410.4427490234375  loc loss 26.460086822509766\n",
      "cls loss 314.90032958984375  loc loss 21.764497756958008\n",
      "cls loss 289.68365478515625  loc loss 16.072311401367188\n",
      "cls loss 420.4998779296875  loc loss 22.547590255737305\n",
      "cls loss 504.4144592285156  loc loss 30.046506881713867\n",
      "cls loss 451.493896484375  loc loss 22.997844696044922\n",
      "cls loss 600.120361328125  loc loss 35.19688034057617\n",
      "cls loss 631.146240234375  loc loss 41.265377044677734\n",
      "cls loss 435.0467834472656  loc loss 26.868852615356445\n",
      "cls loss 615.5872802734375  loc loss 44.148468017578125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1., 38., 47.,  1.,  1.,  1.,  1.,  1., 62.])\n",
      "cls loss 370.08984375  loc loss 17.44851303100586\n",
      "cls loss 430.7752685546875  loc loss 30.406591415405273\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 463.96282958984375  loc loss 27.32931137084961\n",
      "cls loss 532.1536865234375  loc loss 38.060943603515625\n",
      "cls loss 345.694091796875  loc loss 16.127002716064453\n",
      "cls loss 425.2610168457031  loc loss 31.919015884399414\n",
      "cls loss 404.9387512207031  loc loss 23.22801399230957\n",
      "cls loss 223.36886596679688  loc loss 7.8718767166137695\n",
      "cls loss 337.16998291015625  loc loss 19.595264434814453\n",
      "cls loss 299.91357421875  loc loss 12.717988014221191\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1., 35.])\n",
      "cls loss 325.7945556640625  loc loss 18.986169815063477\n",
      "cls loss 512.0235595703125  loc loss 25.996091842651367\n",
      "cls loss 519.6469116210938  loc loss 30.830244064331055\n",
      "cls loss 468.1694641113281  loc loss 34.85005569458008\n",
      "cls loss 409.74993896484375  loc loss 26.614490509033203\n",
      "cls loss 521.9807739257812  loc loss 36.22489547729492\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 286.49957275390625  loc loss 15.062196731567383\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 403.74627685546875  loc loss 16.013402938842773\n",
      "cls loss 602.4822387695312  loc loss 33.678977966308594\n",
      "cls loss 761.9127197265625  loc loss 58.6544303894043\n",
      "cls loss 376.0539245605469  loc loss 19.29355812072754\n",
      "cls loss 320.69854736328125  loc loss 19.022823333740234\n",
      "cls loss 329.3042297363281  loc loss 16.69964027404785\n",
      "cls loss 368.1134948730469  loc loss 19.716127395629883\n",
      "cls loss 314.06036376953125  loc loss 13.334033966064453\n",
      "cls loss 582.2401123046875  loc loss 36.71671676635742\n",
      "cls loss 490.26025390625  loc loss 28.77107048034668\n",
      "cls loss 220.27589416503906  loc loss 15.220520973205566\n",
      "cls loss 451.0058288574219  loc loss 25.61040687561035\n",
      "cls loss 598.42724609375  loc loss 43.148109436035156\n",
      "cls loss 456.4862060546875  loc loss 29.597248077392578\n",
      "cls loss 406.962646484375  loc loss 22.83443832397461\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.])\n",
      "cls loss 380.3916320800781  loc loss 26.346511840820312\n",
      "cls loss 399.1891784667969  loc loss 24.113000869750977\n",
      "cls loss 479.4291076660156  loc loss 28.282629013061523\n",
      "cls loss 790.4910278320312  loc loss 57.1887092590332\n",
      "cls loss 283.833251953125  loc loss 14.594423294067383\n",
      "cls loss 375.336669921875  loc loss 23.34214973449707\n",
      "cls loss 295.87445068359375  loc loss 17.18428611755371\n",
      "cls loss 336.8658447265625  loc loss 22.677122116088867\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 21., 21., 21.])\n",
      "cls loss 321.2841491699219  loc loss 20.945720672607422\n",
      "cls loss 332.3937072753906  loc loss 16.958721160888672\n",
      "cls loss 347.578369140625  loc loss 23.260772705078125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 35.])\n",
      "cls loss 471.4544677734375  loc loss 27.44374656677246\n",
      "cls loss 176.503662109375  loc loss 9.408507347106934\n",
      "cls loss 321.74951171875  loc loss 17.728412628173828\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 301.648193359375  loc loss 12.227804183959961\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 38., 38.,  9., 38.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1.,  1.])\n",
      "cls loss 337.9439697265625  loc loss 19.628843307495117\n",
      "cls loss 559.9026489257812  loc loss 31.855072021484375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 2.,  1., 77., 31., 10., 10.,  1.,  4., 10.])\n",
      "cls loss 258.1374816894531  loc loss 11.465381622314453\n",
      "cls loss 510.7708435058594  loc loss 29.70081329345703\n",
      "cls loss 1030.200927734375  loc loss 56.376319885253906\n",
      "cls loss 315.60107421875  loc loss 21.572847366333008\n",
      "cls loss 437.1617126464844  loc loss 31.546937942504883\n",
      "cls loss 298.69232177734375  loc loss 15.106618881225586\n",
      "cls loss 284.3076171875  loc loss 15.05146598815918\n",
      "cls loss 397.7521057128906  loc loss 22.97684097290039\n",
      "cls loss 396.20098876953125  loc loss 24.665861129760742\n",
      "cls loss 376.26483154296875  loc loss 27.796220779418945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 320.43450927734375  loc loss 15.877534866333008\n",
      "cls loss 334.131591796875  loc loss 18.778667449951172\n",
      "cls loss 642.4139404296875  loc loss 37.26103591918945\n",
      "cls loss 604.1488037109375  loc loss 32.45048141479492\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1., 42., 42., 42., 42., 42., 42.,  1.,\n",
      "         1.,  1.,  1., 42.,  1.,  1., 42.,  1.])\n",
      "cls loss 335.0711669921875  loc loss 22.913440704345703\n",
      "cls loss 502.6473693847656  loc loss 25.75474739074707\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.])\n",
      "cls loss 218.39637756347656  loc loss 10.475793838500977\n",
      "cls loss 495.93548583984375  loc loss 29.09682273864746\n",
      "cls loss 366.4730224609375  loc loss 24.86236572265625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([11.])\n",
      "cls loss 216.85968017578125  loc loss 13.010870933532715\n",
      "cls loss 242.45913696289062  loc loss 12.683029174804688\n",
      "cls loss 264.527099609375  loc loss 12.569853782653809\n",
      "cls loss 462.70208740234375  loc loss 29.498748779296875\n",
      "cls loss 361.5956726074219  loc loss 21.749361038208008\n",
      "cls loss 387.99365234375  loc loss 25.910306930541992\n",
      "cls loss 541.3809204101562  loc loss 29.6512451171875\n",
      "cls loss 293.7217712402344  loc loss 17.006959915161133\n",
      "cls loss 643.6392822265625  loc loss 40.00566864013672\n",
      "cls loss 313.8408508300781  loc loss 17.733800888061523\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 300.397216796875  loc loss 17.215776443481445\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1., 38., 38., 42.])\n",
      "cls loss 426.4517822265625  loc loss 24.577743530273438\n",
      "cls loss 394.0082702636719  loc loss 21.4512939453125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 339.54278564453125  loc loss 20.316022872924805\n",
      "cls loss 725.92919921875  loc loss 43.02842330932617\n",
      "cls loss 413.00006103515625  loc loss 25.038475036621094\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10.,  3.,  3.,  6.,  8.,  8.,  1.,  1.,  1., 10.])\n",
      "cls loss 313.0933532714844  loc loss 15.475492477416992\n",
      "cls loss 212.20849609375  loc loss 7.664041519165039\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10.,  3.])\n",
      "cls loss 293.9418640136719  loc loss 17.709148406982422\n",
      "cls loss 146.44113159179688  loc loss 8.669171333312988\n",
      "cls loss 369.078125  loc loss 25.595487594604492\n",
      "cls loss 455.9310302734375  loc loss 28.65237808227539\n",
      "cls loss 329.4210510253906  loc loss 19.66087532043457\n",
      "cls loss 176.65908813476562  loc loss 12.777718544006348\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 34.])\n",
      "cls loss 497.51531982421875  loc loss 34.92543029785156\n",
      "cls loss 661.3179931640625  loc loss 46.5003776550293\n",
      "cls loss 408.748046875  loc loss 28.907100677490234\n",
      "cls loss 330.53192138671875  loc loss 22.030155181884766\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.,  1.])\n",
      "cls loss 373.181640625  loc loss 15.333504676818848\n",
      "cls loss 626.6197509765625  loc loss 40.355430603027344\n",
      "cls loss 868.3311157226562  loc loss 50.5659065246582\n",
      "cls loss 694.5736083984375  loc loss 33.46190643310547\n",
      "cls loss 395.978759765625  loc loss 19.614944458007812\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 429.0663146972656  loc loss 25.077844619750977\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10.])\n",
      "cls loss 276.23870849609375  loc loss 14.553529739379883\n",
      "cls loss 403.48638916015625  loc loss 19.908123016357422\n",
      "cls loss 384.7706298828125  loc loss 21.94845962524414\n",
      "cls loss 245.6834259033203  loc loss 15.111560821533203\n",
      "cls loss 343.21746826171875  loc loss 21.233884811401367\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21.,\n",
      "        21.])\n",
      "cls loss 417.68292236328125  loc loss 25.506221771240234\n",
      "cls loss 359.8575439453125  loc loss 20.18609046936035\n",
      "cls loss 239.23724365234375  loc loss 11.132265090942383\n",
      "cls loss 554.5090942382812  loc loss 34.19865417480469\n",
      "cls loss 402.6084899902344  loc loss 25.907594680786133\n",
      "cls loss 299.884521484375  loc loss 14.079952239990234\n",
      "cls loss 632.0369873046875  loc loss 35.67969512939453\n",
      "cls loss 711.3077392578125  loc loss 48.49073028564453\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15., 85.])\n",
      "cls loss 489.18182373046875  loc loss 26.057897567749023\n",
      "cls loss 475.1477966308594  loc loss 33.51384353637695\n",
      "cls loss 493.20355224609375  loc loss 32.0425910949707\n",
      "cls loss 398.86761474609375  loc loss 23.05255126953125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 8., 8.])\n",
      "cls loss 300.80169677734375  loc loss 10.656437873840332\n",
      "cls loss 281.4059143066406  loc loss 20.92591667175293\n",
      "cls loss 361.40496826171875  loc loss 20.032001495361328\n",
      "cls loss 318.4233093261719  loc loss 16.245115280151367\n",
      "cls loss 337.85552978515625  loc loss 19.003986358642578\n",
      "cls loss 490.2648620605469  loc loss 27.244325637817383\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1., 35., 27., 27.,  1., 27.,  1.])\n",
      "cls loss 532.4683837890625  loc loss 41.108192443847656\n",
      "cls loss 327.73614501953125  loc loss 16.638408660888672\n",
      "cls loss 343.73388671875  loc loss 25.14305877685547\n",
      "cls loss 343.65350341796875  loc loss 28.360572814941406\n",
      "cls loss 319.65496826171875  loc loss 19.49054718017578\n",
      "cls loss 349.1716613769531  loc loss 25.56191062927246\n",
      "cls loss 342.9047546386719  loc loss 25.43936538696289\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  2.,  2.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  2.,  2.])\n",
      "cls loss 164.53549194335938  loc loss 8.073421478271484\n",
      "cls loss 552.7149047851562  loc loss 34.549049377441406\n",
      "cls loss 335.63763427734375  loc loss 15.911836624145508\n",
      "cls loss 613.864990234375  loc loss 42.778968811035156\n",
      "cls loss 239.73745727539062  loc loss 12.970878601074219\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 19., 19., 19., 16.])\n",
      "cls loss 248.78582763671875  loc loss 8.968790054321289\n",
      "cls loss 218.50277709960938  loc loss 8.127159118652344\n",
      "cls loss 354.6786193847656  loc loss 15.196070671081543\n",
      "cls loss 465.75341796875  loc loss 27.25528335571289\n",
      "cls loss 185.79786682128906  loc loss 12.586111068725586\n",
      "cls loss 492.8796081542969  loc loss 37.495445251464844\n",
      "cls loss 364.66741943359375  loc loss 22.818071365356445\n",
      "cls loss 375.61834716796875  loc loss 24.325780868530273\n",
      "cls loss 481.35308837890625  loc loss 31.062652587890625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 476.24615478515625  loc loss 22.874300003051758\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 684.9813232421875  loc loss 56.078834533691406\n",
      "cls loss 890.2435302734375  loc loss 77.4659423828125\n",
      "cls loss 420.5736083984375  loc loss 24.79580307006836\n",
      "cls loss 390.12738037109375  loc loss 23.134124755859375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3.,  3.,  3.,  3.,  3., 10.])\n",
      "cls loss 182.22946166992188  loc loss 12.315350532531738\n",
      "cls loss 420.297119140625  loc loss 19.766246795654297\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 1., 1., 1., 3., 3., 3., 3.])\n",
      "cls loss 351.55511474609375  loc loss 16.971284866333008\n",
      "cls loss 703.4193115234375  loc loss 40.79987335205078\n",
      "cls loss 586.3487548828125  loc loss 28.577869415283203\n",
      "cls loss 378.65338134765625  loc loss 18.94781494140625\n",
      "cls loss 545.6058959960938  loc loss 34.54562759399414\n",
      "cls loss 317.9718933105469  loc loss 21.042387008666992\n",
      "cls loss 516.8230590820312  loc loss 32.98013687133789\n",
      "cls loss 382.89208984375  loc loss 33.79899215698242\n",
      "cls loss 352.1438293457031  loc loss 23.55699348449707\n",
      "cls loss 787.4635620117188  loc loss 60.91645812988281\n",
      "cls loss 504.2777099609375  loc loss 39.03738021850586\n",
      "cls loss 320.0568542480469  loc loss 17.05442237854004\n",
      "cls loss 191.3170166015625  loc loss 9.326498985290527\n",
      "cls loss 256.1771240234375  loc loss 12.66249942779541\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3., 10., 10., 10., 10., 10., 10., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10., 10., 10., 10., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 11., 10., 10., 10., 10., 10.,  3.,  3.,  3.,  3.,  3.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 11., 10., 10., 10., 10., 10.,  3.,  3.,  3.,  3.,  3.])\n",
      "cls loss 194.80726623535156  loc loss 9.652706146240234\n",
      "cls loss 277.7132263183594  loc loss 11.882692337036133\n",
      "cls loss 245.90362548828125  loc loss 13.741742134094238\n",
      "cls loss 237.6180877685547  loc loss 10.550529479980469\n",
      "cls loss 315.5252685546875  loc loss 23.59276580810547\n",
      "cls loss 228.78555297851562  loc loss 9.398929595947266\n",
      "cls loss 498.3631286621094  loc loss 29.516088485717773\n",
      "cls loss 471.3992614746094  loc loss 23.83951759338379\n",
      "cls loss 679.09130859375  loc loss 37.62082290649414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 349.32196044921875  loc loss 21.99396514892578\n",
      "cls loss 589.8770751953125  loc loss 35.1405029296875\n",
      "cls loss 441.2090759277344  loc loss 30.91301155090332\n",
      "cls loss 440.0078125  loc loss 26.919971466064453\n",
      "cls loss 420.1824951171875  loc loss 27.896503448486328\n",
      "cls loss 536.5069580078125  loc loss 35.34531784057617\n",
      "cls loss 517.0499877929688  loc loss 33.592803955078125\n",
      "cls loss 243.577392578125  loc loss 13.101872444152832\n",
      "cls loss 518.9135131835938  loc loss 33.13006591796875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 10.,  1., 18.])\n",
      "cls loss 219.67987060546875  loc loss 15.495344161987305\n",
      "cls loss 252.5715789794922  loc loss 12.272659301757812\n",
      "cls loss 476.6602783203125  loc loss 26.053722381591797\n",
      "cls loss 683.4868774414062  loc loss 38.47716522216797\n",
      "cls loss 410.2121276855469  loc loss 26.791358947753906\n",
      "cls loss 633.1773071289062  loc loss 28.689661026000977\n",
      "cls loss 494.37921142578125  loc loss 29.139612197875977\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.,  1.,  1.])\n",
      "cls loss 563.1384887695312  loc loss 31.214080810546875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1., 38.,  1.])\n",
      "cls loss 491.3583068847656  loc loss 26.348825454711914\n",
      "cls loss 690.6630859375  loc loss 48.323577880859375\n",
      "cls loss 372.8203430175781  loc loss 23.730253219604492\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 496.1681823730469  loc loss 26.74838638305664\n",
      "cls loss 400.39141845703125  loc loss 22.681095123291016\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3., 10.,  8.,  3., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.])\n",
      "cls loss 441.1752014160156  loc loss 25.08786964416504\n",
      "cls loss 295.5872802734375  loc loss 19.618160247802734\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3.,  3., 11.,  3., 10., 10.,  3.,  3., 10.])\n",
      "cls loss 298.5569152832031  loc loss 17.884052276611328\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3., 10., 10., 10.])\n",
      "cls loss 373.48663330078125  loc loss 19.572917938232422\n",
      "cls loss 284.75726318359375  loc loss 19.68168067932129\n",
      "cls loss 390.9687194824219  loc loss 27.04487419128418\n",
      "cls loss 567.8580322265625  loc loss 33.60946273803711\n",
      "cls loss 370.55120849609375  loc loss 23.865501403808594\n",
      "cls loss 297.66754150390625  loc loss 21.5753231048584\n",
      "cls loss 375.64044189453125  loc loss 20.909725189208984\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 9.,  9., 85., 85.])\n",
      "cls loss 328.25390625  loc loss 14.10302734375\n",
      "cls loss 422.62158203125  loc loss 25.866226196289062\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 622.4344482421875  loc loss 36.005794525146484\n",
      "cls loss 518.333984375  loc loss 21.087257385253906\n",
      "cls loss 606.3345336914062  loc loss 39.36614227294922\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10., 10., 10., 10.])\n",
      "cls loss 394.6456298828125  loc loss 22.570772171020508\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([13.])\n",
      "cls loss 590.6795043945312  loc loss 43.22572326660156\n",
      "cls loss 156.24166870117188  loc loss 9.018460273742676\n",
      "cls loss 237.38201904296875  loc loss 12.353425979614258\n",
      "cls loss 302.54974365234375  loc loss 18.917510986328125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19.,  1.,  1.,  1., 19., 19.])\n",
      "cls loss 327.150146484375  loc loss 22.031679153442383\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 267.0673828125  loc loss 17.98016357421875\n",
      "cls loss 414.8607177734375  loc loss 27.2296142578125\n",
      "cls loss 313.9833984375  loc loss 16.798627853393555\n",
      "cls loss 448.059326171875  loc loss 21.934633255004883\n",
      "cls loss 478.8858642578125  loc loss 32.913692474365234\n",
      "cls loss 363.04290771484375  loc loss 20.31047248840332\n",
      "cls loss 603.7987060546875  loc loss 39.127254486083984\n",
      "cls loss 213.15133666992188  loc loss 8.544754028320312\n",
      "cls loss 391.1820373535156  loc loss 25.134292602539062\n",
      "cls loss 332.8282165527344  loc loss 17.51337242126465\n",
      "cls loss 367.249267578125  loc loss 17.31659698486328\n",
      "cls loss 489.9149169921875  loc loss 25.842504501342773\n",
      "cls loss 386.9381408691406  loc loss 17.54134178161621\n",
      "cls loss 554.9857177734375  loc loss 36.66970443725586\n",
      "cls loss 357.1763000488281  loc loss 20.977863311767578\n",
      "cls loss 454.2379150390625  loc loss 32.27825927734375\n",
      "cls loss 657.8965454101562  loc loss 39.117774963378906\n",
      "cls loss 352.5168762207031  loc loss 26.536693572998047\n",
      "cls loss 424.780029296875  loc loss 23.45587158203125\n",
      "cls loss 497.4625244140625  loc loss 38.44112014770508\n",
      "cls loss 591.278076171875  loc loss 39.051116943359375\n",
      "cls loss 646.0852661132812  loc loss 37.82840347290039\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 5.])\n",
      "cls loss 164.82818603515625  loc loss 8.551900863647461\n",
      "cls loss 248.45266723632812  loc loss 9.815507888793945\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 13.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 6., 8., 8.])\n",
      "cls loss 193.62945556640625  loc loss 9.856229782104492\n",
      "cls loss 265.82550048828125  loc loss 12.06464672088623\n",
      "cls loss 505.15338134765625  loc loss 30.74009895324707\n",
      "cls loss 210.3874053955078  loc loss 11.576032638549805\n",
      "cls loss 427.56915283203125  loc loss 29.246517181396484\n",
      "cls loss 644.1314697265625  loc loss 44.90703201293945\n",
      "cls loss 411.95562744140625  loc loss 26.03623390197754\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([42., 42.,  1.,  1.,  1.,  1.,  1.,  1.,  1., 42., 42.])\n",
      "cls loss 436.83929443359375  loc loss 21.48155975341797\n",
      "cls loss 550.02001953125  loc loss 40.22229766845703\n",
      "cls loss 504.4825439453125  loc loss 32.67782974243164\n",
      "cls loss 316.8175048828125  loc loss 19.036176681518555\n",
      "cls loss 418.4662780761719  loc loss 21.487525939941406\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 641.586669921875  loc loss 37.359413146972656\n",
      "cls loss 510.6399230957031  loc loss 32.408241271972656\n",
      "cls loss 303.3565673828125  loc loss 14.907583236694336\n",
      "cls loss 259.372802734375  loc loss 14.164152145385742\n",
      "cls loss 342.2540283203125  loc loss 20.613981246948242\n",
      "cls loss 467.81878662109375  loc loss 29.047243118286133\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15.])\n",
      "cls loss 225.59413146972656  loc loss 7.394927024841309\n",
      "cls loss 398.230712890625  loc loss 22.968215942382812\n",
      "cls loss 353.95751953125  loc loss 21.129430770874023\n",
      "cls loss 636.582275390625  loc loss 37.3890266418457\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19.,  7.])\n",
      "cls loss 293.53497314453125  loc loss 16.923938751220703\n",
      "cls loss 589.602294921875  loc loss 41.05437469482422\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 535.591552734375  loc loss 27.76138687133789\n",
      "cls loss 500.2361145019531  loc loss 32.104103088378906\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([38., 38.,  1., 18.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1., 18., 18.,  1.])\n",
      "cls loss 328.84033203125  loc loss 18.132139205932617\n",
      "cls loss 320.02423095703125  loc loss 16.012447357177734\n",
      "cls loss 632.503662109375  loc loss 43.40105438232422\n",
      "cls loss 455.6501159667969  loc loss 30.074478149414062\n",
      "cls loss 378.4595947265625  loc loss 24.938167572021484\n",
      "cls loss 264.3572998046875  loc loss 18.304916381835938\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.])\n",
      "cls loss 158.50552368164062  loc loss 6.524747848510742\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([32.])\n",
      "cls loss 416.36199951171875  loc loss 20.609277725219727\n",
      "cls loss 370.2319641113281  loc loss 23.368436813354492\n",
      "cls loss 450.7520751953125  loc loss 32.250179290771484\n",
      "cls loss 404.7333984375  loc loss 24.144807815551758\n",
      "cls loss 343.166259765625  loc loss 18.724605560302734\n",
      "cls loss 547.022216796875  loc loss 30.1663761138916\n",
      "cls loss 645.6853637695312  loc loss 39.448970794677734\n",
      "cls loss 463.75531005859375  loc loss 31.22606658935547\n",
      "cls loss 346.1063537597656  loc loss 21.292644500732422\n",
      "cls loss 566.043701171875  loc loss 36.63936996459961\n",
      "cls loss 374.2794189453125  loc loss 20.233003616333008\n",
      "cls loss 674.0928955078125  loc loss 42.291725158691406\n",
      "cls loss 447.2214660644531  loc loss 23.791149139404297\n",
      "cls loss 355.61187744140625  loc loss 28.354145050048828\n",
      "cls loss 278.1811218261719  loc loss 13.506658554077148\n",
      "cls loss 328.4574890136719  loc loss 20.368135452270508\n",
      "cls loss 474.2538757324219  loc loss 31.57308578491211\n",
      "cls loss 544.0391845703125  loc loss 37.40745544433594\n",
      "cls loss 328.2919616699219  loc loss 19.95102882385254\n",
      "cls loss 521.6826171875  loc loss 35.726165771484375\n",
      "cls loss 625.8834228515625  loc loss 38.4047966003418\n",
      "cls loss 232.63168334960938  loc loss 13.777790069580078\n",
      "cls loss 608.98828125  loc loss 39.49500274658203\n",
      "cls loss 454.4428405761719  loc loss 29.31234359741211\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 589.7831420898438  loc loss 42.78264617919922\n",
      "cls loss 249.0204315185547  loc loss 10.647546768188477\n",
      "cls loss 378.4327392578125  loc loss 22.915359497070312\n",
      "cls loss 385.89300537109375  loc loss 26.58333396911621\n",
      "cls loss 322.16339111328125  loc loss 20.749048233032227\n",
      "cls loss 188.32540893554688  loc loss 10.708597183227539\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 9., 9., 1., 9., 9., 9., 9., 1., 9.])\n",
      "cls loss 861.2308349609375  loc loss 56.05196762084961\n",
      "cls loss 464.4866027832031  loc loss 24.47789764404297\n",
      "cls loss 727.8564453125  loc loss 51.170562744140625\n",
      "cls loss 284.384521484375  loc loss 21.32810401916504\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 42., 42.])\n",
      "cls loss 468.38690185546875  loc loss 34.72482681274414\n",
      "cls loss 475.9495544433594  loc loss 37.45988082885742\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  2.,  1.,  1.,  1., 38.,\n",
      "         1.,  1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 38., 38., 38.,  1., 38., 38., 38.,  1.,  1., 38.,  1.,\n",
      "         1.])\n",
      "cls loss 281.47821044921875  loc loss 21.350849151611328\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  8.,  8.])\n",
      "cls loss 663.509521484375  loc loss 45.43002700805664\n",
      "cls loss 671.6961669921875  loc loss 51.57289505004883\n",
      "cls loss 247.10006713867188  loc loss 15.746400833129883\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([4., 1., 1., 4.])\n",
      "cls loss 396.7388916015625  loc loss 24.696575164794922\n",
      "cls loss 506.907958984375  loc loss 29.52161407470703\n",
      "cls loss 201.43215942382812  loc loss 10.355010986328125\n",
      "cls loss 252.1476593017578  loc loss 16.15242576599121\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([51.,  1.])\n",
      "cls loss 179.515380859375  loc loss 8.597518920898438\n",
      "cls loss 256.3895568847656  loc loss 16.394878387451172\n",
      "cls loss 540.6541748046875  loc loss 25.163043975830078\n",
      "cls loss 499.5448913574219  loc loss 33.679473876953125\n",
      "cls loss 766.599853515625  loc loss 37.130977630615234\n",
      "cls loss 909.52490234375  loc loss 57.74614334106445\n",
      "cls loss 374.9700012207031  loc loss 23.298391342163086\n",
      "cls loss 550.1958618164062  loc loss 39.78581619262695\n",
      "cls loss 600.7816162109375  loc loss 38.81348419189453\n",
      "cls loss 431.11798095703125  loc loss 27.027414321899414\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  3.,  1.,  1.,  1.,  3.,  1.,  1.,\n",
      "         1.,  1.,  1.])\n",
      "cls loss 468.04669189453125  loc loss 19.692825317382812\n",
      "cls loss 499.30072021484375  loc loss 26.897594451904297\n",
      "cls loss 488.28741455078125  loc loss 23.923015594482422\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "cls loss 414.6515808105469  loc loss 23.143142700195312\n",
      "cls loss 230.23129272460938  loc loss 18.00263786315918\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3.])\n",
      "cls loss 185.4116668701172  loc loss 10.104142189025879\n",
      "cls loss 323.54278564453125  loc loss 18.942392349243164\n",
      "cls loss 311.9643249511719  loc loss 20.340717315673828\n",
      "cls loss 562.289794921875  loc loss 35.01451873779297\n",
      "cls loss 254.6676483154297  loc loss 18.81031036376953\n",
      "cls loss 295.01593017578125  loc loss 23.23641014099121\n",
      "cls loss 842.041259765625  loc loss 55.992645263671875\n",
      "cls loss 379.91632080078125  loc loss 27.7899112701416\n",
      "cls loss 282.6670227050781  loc loss 19.442773818969727\n",
      "cls loss 333.22332763671875  loc loss 18.474163055419922\n",
      "cls loss 303.2505187988281  loc loss 22.284746170043945\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 564.4835205078125  loc loss 38.53279495239258\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  9., 64., 64., 64., 64., 64., 64., 64., 64., 64.,  9.,  9.,  9.,\n",
      "         9.])\n",
      "cls loss 259.5860595703125  loc loss 13.29593276977539\n",
      "cls loss 826.6968383789062  loc loss 60.40351867675781\n",
      "cls loss 435.47198486328125  loc loss 27.160184860229492\n",
      "cls loss 521.6368408203125  loc loss 33.59439468383789\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.,  3.,  3.])\n",
      "cls loss 329.12884521484375  loc loss 17.499422073364258\n",
      "cls loss 355.33099365234375  loc loss 24.741044998168945\n",
      "cls loss 374.99200439453125  loc loss 25.752464294433594\n",
      "cls loss 384.35162353515625  loc loss 25.016145706176758\n",
      "cls loss 444.4410400390625  loc loss 28.832929611206055\n",
      "cls loss 441.7991943359375  loc loss 27.610380172729492\n",
      "cls loss 395.5754699707031  loc loss 26.074249267578125\n",
      "cls loss 403.22705078125  loc loss 21.60895347595215\n",
      "cls loss 503.57037353515625  loc loss 32.28018569946289\n",
      "cls loss 369.5720520019531  loc loss 22.353307723999023\n",
      "cls loss 280.4952697753906  loc loss 14.75716495513916\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21.])\n",
      "cls loss 229.626708984375  loc loss 14.983314514160156\n",
      "cls loss 328.4742431640625  loc loss 27.823474884033203\n",
      "cls loss 486.4927978515625  loc loss 33.545501708984375\n",
      "cls loss 246.10986328125  loc loss 15.008477210998535\n",
      "cls loss 399.496337890625  loc loss 26.256366729736328\n",
      "cls loss 741.370849609375  loc loss 38.52690887451172\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 42., 42.,  1.,  1.])\n",
      "cls loss 447.1057434082031  loc loss 23.929777145385742\n",
      "cls loss 291.2634582519531  loc loss 16.84238052368164\n",
      "cls loss 419.5386962890625  loc loss 24.400402069091797\n",
      "cls loss 552.7904663085938  loc loss 40.34478759765625\n",
      "cls loss 346.36822509765625  loc loss 19.05548858642578\n",
      "cls loss 530.07080078125  loc loss 34.864845275878906\n",
      "cls loss 463.88006591796875  loc loss 31.254669189453125\n",
      "cls loss 451.787353515625  loc loss 28.53443717956543\n",
      "cls loss 363.9028625488281  loc loss 22.387819290161133\n",
      "cls loss 293.9252624511719  loc loss 19.76488494873047\n",
      "cls loss 231.96310424804688  loc loss 10.625956535339355\n",
      "cls loss 367.64862060546875  loc loss 23.59307098388672\n",
      "cls loss 560.44873046875  loc loss 34.93334197998047\n",
      "cls loss 407.1753845214844  loc loss 24.124353408813477\n",
      "cls loss 391.03973388671875  loc loss 27.849130630493164\n",
      "cls loss 428.10186767578125  loc loss 25.019399642944336\n",
      "cls loss 636.154052734375  loc loss 46.053955078125\n",
      "cls loss 512.1343994140625  loc loss 32.82024383544922\n",
      "cls loss 557.8099365234375  loc loss 29.090595245361328\n",
      "cls loss 351.09161376953125  loc loss 14.970394134521484\n",
      "cls loss 487.3819885253906  loc loss 27.40583038330078\n",
      "cls loss 444.85113525390625  loc loss 24.2257080078125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 5., 5., 5., 5., 5., 5.])\n",
      "cls loss 271.22882080078125  loc loss 16.33008575439453\n",
      "cls loss 362.53192138671875  loc loss 18.423606872558594\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([13.])\n",
      "cls loss 254.7445526123047  loc loss 11.511225700378418\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([44., 10.,  1.,  1.,  1.])\n",
      "cls loss 228.11883544921875  loc loss 14.998966217041016\n",
      "cls loss 402.08941650390625  loc loss 22.192140579223633\n",
      "cls loss 372.4079895019531  loc loss 19.939937591552734\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19., 19., 19., 19., 19., 19., 19.])\n",
      "cls loss 388.72601318359375  loc loss 23.779335021972656\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([56.])\n",
      "cls loss 822.8011474609375  loc loss 53.54754638671875\n",
      "cls loss 523.5213012695312  loc loss 37.718231201171875\n",
      "cls loss 663.5341796875  loc loss 41.5445556640625\n",
      "cls loss 635.5950927734375  loc loss 47.298004150390625\n",
      "cls loss 381.6911926269531  loc loss 21.50067710876465\n",
      "cls loss 652.2699584960938  loc loss 40.77693176269531\n",
      "cls loss 367.67864990234375  loc loss 24.786712646484375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 36.])\n",
      "cls loss 487.2147216796875  loc loss 21.394460678100586\n",
      "cls loss 405.6038818359375  loc loss 24.54166603088379\n",
      "cls loss 384.8252868652344  loc loss 22.227399826049805\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5.])\n",
      "cls loss 456.2002868652344  loc loss 25.882200241088867\n",
      "cls loss 249.8255615234375  loc loss 11.609273910522461\n",
      "cls loss 571.6895751953125  loc loss 30.08261489868164\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "cls loss 507.5137634277344  loc loss 29.409597396850586\n",
      "cls loss 463.99554443359375  loc loss 29.374954223632812\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 491.4181213378906  loc loss 29.94791603088379\n",
      "cls loss 552.14013671875  loc loss 34.06044006347656\n",
      "cls loss 473.38702392578125  loc loss 38.67178726196289\n",
      "cls loss 327.3826904296875  loc loss 20.819318771362305\n",
      "cls loss 367.4442443847656  loc loss 26.39576530456543\n",
      "cls loss 386.0234375  loc loss 22.199726104736328\n",
      "cls loss 654.3206787109375  loc loss 31.216928482055664\n",
      "cls loss 260.73919677734375  loc loss 13.226451873779297\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 11., 15., 10., 10., 10., 10., 10.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 584.307373046875  loc loss 37.7862434387207\n",
      "cls loss 353.1195983886719  loc loss 25.972829818725586\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3.])\n",
      "cls loss 367.30322265625  loc loss 26.80445098876953\n",
      "cls loss 355.53240966796875  loc loss 17.434968948364258\n",
      "cls loss 400.0657958984375  loc loss 18.036691665649414\n",
      "cls loss 514.653564453125  loc loss 21.134031295776367\n",
      "cls loss 233.2064208984375  loc loss 10.659794807434082\n",
      "cls loss 428.0465087890625  loc loss 25.732357025146484\n",
      "cls loss 482.73095703125  loc loss 29.159988403320312\n",
      "cls loss 420.02239990234375  loc loss 26.23354721069336\n",
      "cls loss 959.532958984375  loc loss 58.83605194091797\n",
      "cls loss 631.3549194335938  loc loss 39.1477165222168\n",
      "cls loss 394.9486083984375  loc loss 26.237768173217773\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  9.,  9.,  9.,  6.,  6., 85., 85.,  8.,  1.,  1.,  1.,  1.,\n",
      "         6.,  6.])\n",
      "cls loss 266.2651672363281  loc loss 20.84149742126465\n",
      "cls loss 666.8876953125  loc loss 45.632694244384766\n",
      "cls loss 779.6974487304688  loc loss 45.9039306640625\n",
      "cls loss 497.54913330078125  loc loss 34.339599609375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10.,  3.,  3., 10.])\n",
      "cls loss 313.9450378417969  loc loss 17.26624870300293\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([7.])\n",
      "cls loss 408.7607421875  loc loss 25.798933029174805\n",
      "cls loss 403.3939208984375  loc loss 24.913908004760742\n",
      "cls loss 420.5955810546875  loc loss 35.244667053222656\n",
      "cls loss 694.8466796875  loc loss 46.45478439331055\n",
      "cls loss 395.44189453125  loc loss 25.053340911865234\n",
      "cls loss 617.2479248046875  loc loss 36.00372314453125\n",
      "cls loss 760.826416015625  loc loss 40.50456237792969\n",
      "cls loss 503.1224060058594  loc loss 26.441253662109375\n",
      "cls loss 558.9895629882812  loc loss 31.809192657470703\n",
      "cls loss 415.27740478515625  loc loss 26.937110900878906\n",
      "cls loss 590.3258056640625  loc loss 41.26127243041992\n",
      "cls loss 447.9444274902344  loc loss 27.91667938232422\n",
      "cls loss 320.6706237792969  loc loss 20.561084747314453\n",
      "cls loss 519.551025390625  loc loss 37.885807037353516\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([62.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([62.])\n",
      "cls loss 230.3555908203125  loc loss 11.202661514282227\n",
      "cls loss 368.8278503417969  loc loss 27.418006896972656\n",
      "cls loss 380.97210693359375  loc loss 24.51861572265625\n",
      "cls loss 245.30438232421875  loc loss 11.985955238342285\n",
      "cls loss 514.1082763671875  loc loss 32.73516845703125\n",
      "cls loss 524.967041015625  loc loss 29.37347412109375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([28.])\n",
      "cls loss 663.0779418945312  loc loss 30.070585250854492\n",
      "cls loss 494.40728759765625  loc loss 31.232791900634766\n",
      "cls loss 491.6100158691406  loc loss 33.82276153564453\n",
      "cls loss 560.7254638671875  loc loss 31.721996307373047\n",
      "cls loss 834.8623657226562  loc loss 45.37007141113281\n",
      "cls loss 473.6221618652344  loc loss 24.958526611328125\n",
      "cls loss 650.3084106445312  loc loss 29.102468490600586\n",
      "cls loss 510.74920654296875  loc loss 34.05447769165039\n",
      "cls loss 771.9426879882812  loc loss 55.75713348388672\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([81.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 463.95550537109375  loc loss 18.212879180908203\n",
      "cls loss 353.8126220703125  loc loss 18.191007614135742\n",
      "cls loss 254.8881072998047  loc loss 18.704345703125\n",
      "cls loss 228.86749267578125  loc loss 10.24277114868164\n",
      "cls loss 259.78863525390625  loc loss 20.270160675048828\n",
      "cls loss 325.7535095214844  loc loss 20.608943939208984\n",
      "cls loss 334.1993103027344  loc loss 23.921249389648438\n",
      "cls loss 500.18560791015625  loc loss 39.38701248168945\n",
      "cls loss 591.3348388671875  loc loss 34.32596206665039\n",
      "cls loss 1021.2823486328125  loc loss 66.83718872070312\n",
      "cls loss 402.87615966796875  loc loss 19.023969650268555\n",
      "cls loss 505.89093017578125  loc loss 36.56722640991211\n",
      "cls loss 361.36639404296875  loc loss 21.243045806884766\n",
      "cls loss 501.79119873046875  loc loss 25.704334259033203\n",
      "cls loss 443.5025634765625  loc loss 23.45928955078125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([44., 44.])\n",
      "cls loss 420.7923889160156  loc loss 17.79754638671875\n",
      "cls loss 465.391357421875  loc loss 26.330774307250977\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15.])\n",
      "cls loss 444.4970703125  loc loss 21.204341888427734\n",
      "cls loss 248.48077392578125  loc loss 12.952886581420898\n",
      "cls loss 423.04443359375  loc loss 27.3231201171875\n",
      "cls loss 249.560546875  loc loss 12.036192893981934\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([1., 3., 3.])\n",
      "cls loss 276.6109619140625  loc loss 16.394798278808594\n",
      "cls loss 198.6043243408203  loc loss 9.350281715393066\n",
      "cls loss 382.3812255859375  loc loss 26.17992401123047\n",
      "cls loss 454.9354248046875  loc loss 24.22772979736328\n",
      "cls loss 389.28472900390625  loc loss 26.45829200744629\n",
      "cls loss 323.5286865234375  loc loss 21.018680572509766\n",
      "cls loss 358.228515625  loc loss 24.656740188598633\n",
      "cls loss 476.971923828125  loc loss 30.25654411315918\n",
      "cls loss 318.21795654296875  loc loss 21.376123428344727\n",
      "cls loss 413.4960632324219  loc loss 31.280527114868164\n",
      "cls loss 290.24798583984375  loc loss 17.488985061645508\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 544.5546264648438  loc loss 29.86702537536621\n",
      "cls loss 670.9923095703125  loc loss 26.54804801940918\n",
      "cls loss 574.2696533203125  loc loss 35.924591064453125\n",
      "cls loss 569.8966064453125  loc loss 41.752281188964844\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10., 10., 10.,  1.,  1.,  1.,  1.,  1.,  1.,  8.,  8.,\n",
      "         1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10., 10., 10.,  1.,  1.,  1.,  1.,  1.,  1.,  8.,  8.,\n",
      "         1.])\n",
      "cls loss 447.20465087890625  loc loss 22.288156509399414\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 3., 3., 3.])\n",
      "cls loss 454.42559814453125  loc loss 24.507598876953125\n",
      "cls loss 276.75445556640625  loc loss 17.475971221923828\n",
      "cls loss 209.9704132080078  loc loss 10.356528282165527\n",
      "cls loss 412.3218078613281  loc loss 30.375551223754883\n",
      "cls loss 301.43524169921875  loc loss 13.654038429260254\n",
      "cls loss 374.66436767578125  loc loss 25.339309692382812\n",
      "cls loss 418.365234375  loc loss 29.794836044311523\n",
      "cls loss 557.035400390625  loc loss 40.70342254638672\n",
      "cls loss 488.02618408203125  loc loss 24.856182098388672\n",
      "cls loss 439.3860168457031  loc loss 23.710355758666992\n",
      "cls loss 458.442138671875  loc loss 29.651187896728516\n",
      "cls loss 329.8011474609375  loc loss 24.007598876953125\n",
      "cls loss 676.8119506835938  loc loss 47.354949951171875\n",
      "cls loss 285.6903076171875  loc loss 16.17694091796875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 549.2506713867188  loc loss 30.973634719848633\n",
      "cls loss 230.82119750976562  loc loss 9.575672149658203\n",
      "cls loss 596.5487060546875  loc loss 39.710941314697266\n",
      "cls loss 304.2544250488281  loc loss 18.606117248535156\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 34.])\n",
      "cls loss 507.31878662109375  loc loss 26.21561050415039\n",
      "cls loss 281.04779052734375  loc loss 15.936261177062988\n",
      "cls loss 554.8924560546875  loc loss 28.3056697845459\n",
      "cls loss 199.36703491210938  loc loss 12.059990882873535\n",
      "cls loss 415.6185607910156  loc loss 23.843624114990234\n",
      "cls loss 402.7298583984375  loc loss 31.17122459411621\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 38.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16., 16., 16.,  9.,  9.,  9., 16., 16., 16., 85.,  9.])\n",
      "cls loss 418.0997009277344  loc loss 24.297256469726562\n",
      "cls loss 450.00921630859375  loc loss 32.90928649902344\n",
      "cls loss 603.4974365234375  loc loss 38.00133514404297\n",
      "cls loss 944.3931274414062  loc loss 56.74290466308594\n",
      "cls loss 236.38858032226562  loc loss 13.37342643737793\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3., 10.,  8.,  8., 10., 10., 10.,  3.,  3., 14.])\n",
      "cls loss 260.9854736328125  loc loss 14.855792045593262\n",
      "cls loss 479.7935791015625  loc loss 30.86211585998535\n",
      "cls loss 197.12176513671875  loc loss 8.519765853881836\n",
      "cls loss 352.0091552734375  loc loss 15.494474411010742\n",
      "cls loss 483.4232177734375  loc loss 30.633407592773438\n",
      "cls loss 414.4977111816406  loc loss 23.970706939697266\n",
      "cls loss 242.97084045410156  loc loss 13.032506942749023\n",
      "cls loss 327.8184509277344  loc loss 15.187076568603516\n",
      "cls loss 552.891845703125  loc loss 27.461912155151367\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42., 42.,  1.])\n",
      "cls loss 513.529052734375  loc loss 27.46062660217285\n",
      "cls loss 422.2847900390625  loc loss 20.18389320373535\n",
      "cls loss 517.7012939453125  loc loss 36.06419372558594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 576.4440307617188  loc loss 33.07524490356445\n",
      "cls loss 390.3789978027344  loc loss 22.4384822845459\n",
      "cls loss 468.7279052734375  loc loss 32.99993133544922\n",
      "cls loss 280.25665283203125  loc loss 18.610401153564453\n",
      "cls loss 303.3187255859375  loc loss 21.88994789123535\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20.])\n",
      "cls loss 216.32742309570312  loc loss 12.595454216003418\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([11.])\n",
      "cls loss 313.301513671875  loc loss 13.938283920288086\n",
      "cls loss 175.3389892578125  loc loss 10.957509994506836\n",
      "cls loss 474.65057373046875  loc loss 34.400840759277344\n",
      "cls loss 201.08224487304688  loc loss 10.065947532653809\n",
      "cls loss 418.7743835449219  loc loss 25.52443504333496\n",
      "cls loss 227.42596435546875  loc loss 15.33087158203125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 35., 27.])\n",
      "cls loss 420.06988525390625  loc loss 23.06865692138672\n",
      "cls loss 493.7406005859375  loc loss 34.60812759399414\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 325.0765380859375  loc loss 16.34396743774414\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([42.,  1.])\n",
      "cls loss 421.010986328125  loc loss 25.495134353637695\n",
      "cls loss 447.4533386230469  loc loss 21.172266006469727\n",
      "cls loss 556.234130859375  loc loss 27.673425674438477\n",
      "cls loss 692.5936279296875  loc loss 32.238441467285156\n",
      "cls loss 562.9967041015625  loc loss 28.69115447998047\n",
      "cls loss 393.282470703125  loc loss 22.018909454345703\n",
      "cls loss 320.6119079589844  loc loss 20.77653694152832\n",
      "cls loss 188.34902954101562  loc loss 7.817587852478027\n",
      "cls loss 337.74981689453125  loc loss 18.159454345703125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 1., 1.])\n",
      "cls loss 320.07757568359375  loc loss 19.82893180847168\n",
      "cls loss 389.33984375  loc loss 24.67742919921875\n",
      "cls loss 373.6629638671875  loc loss 22.366535186767578\n",
      "cls loss 295.9880676269531  loc loss 21.05587387084961\n",
      "cls loss 370.2347717285156  loc loss 23.857372283935547\n",
      "cls loss 390.899169921875  loc loss 28.01042938232422\n",
      "cls loss 575.5064697265625  loc loss 33.179405212402344\n",
      "cls loss 497.369140625  loc loss 36.32439422607422\n",
      "cls loss 429.8262939453125  loc loss 27.49689483642578\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 338.7095031738281  loc loss 23.824220657348633\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 482.2449645996094  loc loss 18.639244079589844\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([81.])\n",
      "cls loss 572.8783569335938  loc loss 28.194442749023438\n",
      "cls loss 332.99267578125  loc loss 20.899572372436523\n",
      "cls loss 293.5173034667969  loc loss 11.570087432861328\n",
      "cls loss 378.4088134765625  loc loss 19.278583526611328\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3.,  1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 19.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 19.])\n",
      "cls loss 534.5590209960938  loc loss 31.772188186645508\n",
      "cls loss 276.43377685546875  loc loss 15.178864479064941\n",
      "cls loss 300.8232727050781  loc loss 15.84339714050293\n",
      "cls loss 554.4046630859375  loc loss 39.168846130371094\n",
      "cls loss 271.1480712890625  loc loss 16.791189193725586\n",
      "cls loss 341.914794921875  loc loss 20.129716873168945\n",
      "cls loss 428.58782958984375  loc loss 27.864398956298828\n",
      "cls loss 319.2337646484375  loc loss 22.589866638183594\n",
      "cls loss 432.763427734375  loc loss 23.256086349487305\n",
      "cls loss 465.70428466796875  loc loss 29.970355987548828\n",
      "cls loss 630.4893798828125  loc loss 52.83967208862305\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 81.])\n",
      "cls loss 418.2132873535156  loc loss 19.79654312133789\n",
      "cls loss 386.9991455078125  loc loss 20.223068237304688\n",
      "cls loss 388.2187805175781  loc loss 21.717987060546875\n",
      "cls loss 320.0981750488281  loc loss 15.938986778259277\n",
      "cls loss 294.260498046875  loc loss 16.642148971557617\n",
      "cls loss 360.7928466796875  loc loss 23.86142921447754\n",
      "cls loss 262.45880126953125  loc loss 17.08147621154785\n",
      "cls loss 224.65362548828125  loc loss 13.704887390136719\n",
      "cls loss 297.3804626464844  loc loss 18.424604415893555\n",
      "cls loss 391.80780029296875  loc loss 23.399749755859375\n",
      "cls loss 375.3592834472656  loc loss 25.35714340209961\n",
      "cls loss 357.7027587890625  loc loss 22.83415985107422\n",
      "cls loss 211.6015625  loc loss 13.138467788696289\n",
      "cls loss 742.2618408203125  loc loss 45.35013961791992\n",
      "cls loss 402.9842529296875  loc loss 26.15320587158203\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 362.264404296875  loc loss 17.423690795898438\n",
      "cls loss 404.23626708984375  loc loss 25.24716567993164\n",
      "cls loss 285.33526611328125  loc loss 20.375574111938477\n",
      "cls loss 463.16680908203125  loc loss 34.09651184082031\n",
      "cls loss 460.4056396484375  loc loss 27.778451919555664\n",
      "cls loss 410.6432189941406  loc loss 25.67987823486328\n",
      "cls loss 312.39764404296875  loc loss 21.3947696685791\n",
      "cls loss 287.998046875  loc loss 15.790346145629883\n",
      "cls loss 417.76947021484375  loc loss 21.771806716918945\n",
      "cls loss 500.90087890625  loc loss 29.48526954650879\n",
      "cls loss 443.43017578125  loc loss 22.48893165588379\n",
      "cls loss 588.553955078125  loc loss 34.45624923706055\n",
      "cls loss 623.1527709960938  loc loss 40.731903076171875\n",
      "cls loss 425.30670166015625  loc loss 26.343069076538086\n",
      "cls loss 604.380615234375  loc loss 43.482261657714844\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1., 38., 47.,  1.,  1.,  1.,  1.,  1., 62.])\n",
      "cls loss 364.62933349609375  loc loss 17.094057083129883\n",
      "cls loss 427.1055908203125  loc loss 29.742752075195312\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 461.1986083984375  loc loss 26.693201065063477\n",
      "cls loss 529.4232788085938  loc loss 37.395713806152344\n",
      "cls loss 343.23736572265625  loc loss 15.711004257202148\n",
      "cls loss 420.05462646484375  loc loss 31.285301208496094\n",
      "cls loss 401.0770568847656  loc loss 22.80620574951172\n",
      "cls loss 221.23255920410156  loc loss 7.562429904937744\n",
      "cls loss 336.2330322265625  loc loss 19.1012020111084\n",
      "cls loss 298.8822326660156  loc loss 12.490787506103516\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1., 35.])\n",
      "cls loss 325.06011962890625  loc loss 18.753517150878906\n",
      "cls loss 507.25152587890625  loc loss 25.495723724365234\n",
      "cls loss 517.333251953125  loc loss 30.270463943481445\n",
      "cls loss 463.667724609375  loc loss 34.201934814453125\n",
      "cls loss 403.4269104003906  loc loss 26.29812240600586\n",
      "cls loss 513.19189453125  loc loss 35.50152587890625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 282.07269287109375  loc loss 14.595458030700684\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 395.588134765625  loc loss 15.746747970581055\n",
      "cls loss 594.2255249023438  loc loss 32.763214111328125\n",
      "cls loss 753.9766845703125  loc loss 57.64011001586914\n",
      "cls loss 370.5438232421875  loc loss 18.898662567138672\n",
      "cls loss 317.6176452636719  loc loss 18.701013565063477\n",
      "cls loss 327.01983642578125  loc loss 16.32701873779297\n",
      "cls loss 367.07659912109375  loc loss 19.206146240234375\n",
      "cls loss 314.482421875  loc loss 13.095911979675293\n",
      "cls loss 580.9619140625  loc loss 35.906646728515625\n",
      "cls loss 488.6984558105469  loc loss 28.001150131225586\n",
      "cls loss 217.99588012695312  loc loss 14.899537086486816\n",
      "cls loss 446.7210693359375  loc loss 25.2825927734375\n",
      "cls loss 596.8653564453125  loc loss 42.30320739746094\n",
      "cls loss 452.72802734375  loc loss 29.07537841796875\n",
      "cls loss 403.10833740234375  loc loss 22.621864318847656\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.])\n",
      "cls loss 377.4274597167969  loc loss 26.00118064880371\n",
      "cls loss 394.0540771484375  loc loss 23.730876922607422\n",
      "cls loss 473.17877197265625  loc loss 27.421653747558594\n",
      "cls loss 783.340576171875  loc loss 56.138607025146484\n",
      "cls loss 280.3350830078125  loc loss 14.178361892700195\n",
      "cls loss 371.90887451171875  loc loss 22.84391212463379\n",
      "cls loss 292.50262451171875  loc loss 16.705623626708984\n",
      "cls loss 333.9667053222656  loc loss 22.0952205657959\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 21., 21., 21.])\n",
      "cls loss 317.46685791015625  loc loss 20.530723571777344\n",
      "cls loss 332.4997253417969  loc loss 16.653751373291016\n",
      "cls loss 344.28741455078125  loc loss 22.69052505493164\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 35.])\n",
      "cls loss 469.1108093261719  loc loss 26.94051170349121\n",
      "cls loss 174.66403198242188  loc loss 9.226046562194824\n",
      "cls loss 321.20172119140625  loc loss 17.312591552734375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 299.57635498046875  loc loss 11.889373779296875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 38., 38.,  9., 38.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1.,  1.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 334.4124755859375  loc loss 19.21918487548828\n",
      "cls loss 554.8059692382812  loc loss 31.083171844482422\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 2.,  1., 77., 31., 10., 10.,  1.,  4., 10.])\n",
      "cls loss 254.06251525878906  loc loss 11.216949462890625\n",
      "cls loss 505.0230712890625  loc loss 29.040815353393555\n",
      "cls loss 1016.4306640625  loc loss 55.14546203613281\n",
      "cls loss 313.4659118652344  loc loss 21.388885498046875\n",
      "cls loss 433.14727783203125  loc loss 30.827272415161133\n",
      "cls loss 293.881103515625  loc loss 14.644966125488281\n",
      "cls loss 281.4365234375  loc loss 14.755194664001465\n",
      "cls loss 394.0007629394531  loc loss 22.556808471679688\n",
      "cls loss 392.0684814453125  loc loss 24.2626895904541\n",
      "cls loss 372.43255615234375  loc loss 27.203367233276367\n",
      "cls loss 317.34490966796875  loc loss 15.659228324890137\n",
      "cls loss 331.5155334472656  loc loss 18.457029342651367\n",
      "cls loss 636.8231201171875  loc loss 36.485286712646484\n",
      "cls loss 598.469482421875  loc loss 31.755863189697266\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1., 42., 42., 42., 42., 42., 42.,  1.,\n",
      "         1.,  1.,  1., 42.,  1.,  1., 42.,  1.])\n",
      "cls loss 331.9280090332031  loc loss 22.603212356567383\n",
      "cls loss 499.31243896484375  loc loss 25.182262420654297\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.])\n",
      "cls loss 215.5207061767578  loc loss 10.195791244506836\n",
      "cls loss 492.9464416503906  loc loss 28.591949462890625\n",
      "cls loss 364.575439453125  loc loss 24.31827735900879\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([11.])\n",
      "cls loss 214.64051818847656  loc loss 12.768277168273926\n",
      "cls loss 240.8876953125  loc loss 12.425372123718262\n",
      "cls loss 261.1747741699219  loc loss 12.253350257873535\n",
      "cls loss 459.9407043457031  loc loss 28.63906478881836\n",
      "cls loss 358.90509033203125  loc loss 21.120241165161133\n",
      "cls loss 386.313720703125  loc loss 25.176124572753906\n",
      "cls loss 540.1692504882812  loc loss 29.048614501953125\n",
      "cls loss 292.7750244140625  loc loss 16.681074142456055\n",
      "cls loss 642.010009765625  loc loss 39.28810119628906\n",
      "cls loss 313.6064758300781  loc loss 17.334491729736328\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 298.7008056640625  loc loss 16.86695671081543\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1., 38., 38., 42.])\n",
      "cls loss 421.2792663574219  loc loss 23.87063217163086\n",
      "cls loss 386.50244140625  loc loss 20.993267059326172\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 332.8016052246094  loc loss 19.867156982421875\n",
      "cls loss 713.3351440429688  loc loss 41.98893737792969\n",
      "cls loss 409.12408447265625  loc loss 24.51935577392578\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10.,  3.,  3.,  6.,  8.,  8.,  1.,  1.,  1., 10.])\n",
      "cls loss 309.4781188964844  loc loss 15.16051959991455\n",
      "cls loss 210.51661682128906  loc loss 7.493717670440674\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10.,  3.])\n",
      "cls loss 290.8648986816406  loc loss 17.49957847595215\n",
      "cls loss 144.82284545898438  loc loss 8.42411994934082\n",
      "cls loss 366.9189758300781  loc loss 25.03680419921875\n",
      "cls loss 450.82659912109375  loc loss 28.182361602783203\n",
      "cls loss 327.3251953125  loc loss 19.26451873779297\n",
      "cls loss 175.85275268554688  loc loss 12.583251953125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 34.])\n",
      "cls loss 493.6546630859375  loc loss 34.0673828125\n",
      "cls loss 658.2945556640625  loc loss 45.512062072753906\n",
      "cls loss 407.0836486816406  loc loss 28.276548385620117\n",
      "cls loss 328.61669921875  loc loss 21.457000732421875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.,  1.])\n",
      "cls loss 371.064697265625  loc loss 15.065340995788574\n",
      "cls loss 620.66845703125  loc loss 39.74077606201172\n",
      "cls loss 861.359619140625  loc loss 49.7974853515625\n",
      "cls loss 685.8548583984375  loc loss 32.78040313720703\n",
      "cls loss 390.75018310546875  loc loss 19.069730758666992\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 421.00213623046875  loc loss 24.195301055908203\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10.])\n",
      "cls loss 271.6308288574219  loc loss 13.77691650390625\n",
      "cls loss 399.0534973144531  loc loss 19.521522521972656\n",
      "cls loss 380.1203918457031  loc loss 21.21615982055664\n",
      "cls loss 242.30551147460938  loc loss 14.652153968811035\n",
      "cls loss 339.64862060546875  loc loss 20.728200912475586\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21.,\n",
      "        21.])\n",
      "cls loss 411.953369140625  loc loss 25.096031188964844\n",
      "cls loss 356.16107177734375  loc loss 19.710784912109375\n",
      "cls loss 237.75579833984375  loc loss 10.99242115020752\n",
      "cls loss 549.4246215820312  loc loss 33.5953369140625\n",
      "cls loss 398.84088134765625  loc loss 25.259918212890625\n",
      "cls loss 297.6685791015625  loc loss 13.623878479003906\n",
      "cls loss 627.303466796875  loc loss 34.733245849609375\n",
      "cls loss 708.1377563476562  loc loss 47.33904266357422\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15., 85.])\n",
      "cls loss 487.479736328125  loc loss 25.54479217529297\n",
      "cls loss 474.1895751953125  loc loss 32.91856384277344\n",
      "cls loss 487.54217529296875  loc loss 31.414470672607422\n",
      "cls loss 390.9219055175781  loc loss 22.61856460571289\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 8., 8.])\n",
      "cls loss 295.2873229980469  loc loss 10.407049179077148\n",
      "cls loss 276.840087890625  loc loss 20.53849220275879\n",
      "cls loss 356.047119140625  loc loss 19.42348289489746\n",
      "cls loss 312.826416015625  loc loss 15.920772552490234\n",
      "cls loss 333.408447265625  loc loss 18.242046356201172\n",
      "cls loss 486.4184265136719  loc loss 26.49298858642578\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1., 35., 27., 27.,  1., 27.,  1.])\n",
      "cls loss 524.7315063476562  loc loss 39.968650817871094\n",
      "cls loss 325.55841064453125  loc loss 16.20977020263672\n",
      "cls loss 339.2621154785156  loc loss 24.57967185974121\n",
      "cls loss 341.85211181640625  loc loss 27.843338012695312\n",
      "cls loss 315.98126220703125  loc loss 19.146833419799805\n",
      "cls loss 347.64068603515625  loc loss 25.08287239074707\n",
      "cls loss 342.39984130859375  loc loss 24.791166305541992\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  2.,  2.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  2.,  2.])\n",
      "cls loss 164.25863647460938  loc loss 7.905420780181885\n",
      "cls loss 550.9307861328125  loc loss 33.59132766723633\n",
      "cls loss 334.0394287109375  loc loss 15.291050910949707\n",
      "cls loss 610.5216064453125  loc loss 41.889163970947266\n",
      "cls loss 236.8163299560547  loc loss 12.762523651123047\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 19., 19., 19., 16.])\n",
      "cls loss 244.6571044921875  loc loss 8.723608016967773\n",
      "cls loss 215.22792053222656  loc loss 8.066864967346191\n",
      "cls loss 349.24322509765625  loc loss 14.85243034362793\n",
      "cls loss 457.24835205078125  loc loss 26.877410888671875\n",
      "cls loss 180.79891967773438  loc loss 12.151074409484863\n",
      "cls loss 486.2366027832031  loc loss 36.62086868286133\n",
      "cls loss 358.9310302734375  loc loss 22.010969161987305\n",
      "cls loss 371.59332275390625  loc loss 23.70751953125\n",
      "cls loss 478.4903869628906  loc loss 30.214447021484375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 472.14990234375  loc loss 22.251615524291992\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 681.09130859375  loc loss 54.99021530151367\n",
      "cls loss 882.5448608398438  loc loss 76.01709747314453\n",
      "cls loss 417.12353515625  loc loss 24.09568214416504\n",
      "cls loss 389.269775390625  loc loss 22.686893463134766\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3.,  3.,  3.,  3.,  3., 10.])\n",
      "cls loss 183.61834716796875  loc loss 12.059422492980957\n",
      "cls loss 421.423583984375  loc loss 19.331026077270508\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 1., 1., 1., 3., 3., 3., 3.])\n",
      "cls loss 350.600830078125  loc loss 16.426891326904297\n",
      "cls loss 692.5550537109375  loc loss 40.102386474609375\n",
      "cls loss 575.186279296875  loc loss 27.949079513549805\n",
      "cls loss 367.73040771484375  loc loss 18.4930362701416\n",
      "cls loss 539.0307006835938  loc loss 34.083560943603516\n",
      "cls loss 312.5516357421875  loc loss 20.54141616821289\n",
      "cls loss 511.3358154296875  loc loss 32.54247283935547\n",
      "cls loss 380.8595886230469  loc loss 33.25154113769531\n",
      "cls loss 347.8795166015625  loc loss 23.2778263092041\n",
      "cls loss 781.9923706054688  loc loss 59.869937896728516\n",
      "cls loss 500.693603515625  loc loss 38.26728057861328\n",
      "cls loss 318.84716796875  loc loss 16.59999656677246\n",
      "cls loss 190.41946411132812  loc loss 9.109926223754883\n",
      "cls loss 253.66653442382812  loc loss 12.29600715637207\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3., 10., 10., 10., 10., 10., 10., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10., 10., 10., 10., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 11., 10., 10., 10., 10., 10.,  3.,  3.,  3.,  3.,  3.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 11., 10., 10., 10., 10., 10.,  3.,  3.,  3.,  3.,  3.])\n",
      "cls loss 193.19610595703125  loc loss 9.336057662963867\n",
      "cls loss 275.8535461425781  loc loss 11.493436813354492\n",
      "cls loss 246.13670349121094  loc loss 13.508320808410645\n",
      "cls loss 236.84144592285156  loc loss 10.353708267211914\n",
      "cls loss 315.671630859375  loc loss 23.200389862060547\n",
      "cls loss 227.26303100585938  loc loss 9.34585189819336\n",
      "cls loss 495.26806640625  loc loss 29.077476501464844\n",
      "cls loss 468.52484130859375  loc loss 23.16438102722168\n",
      "cls loss 671.6041259765625  loc loss 36.926231384277344\n",
      "cls loss 344.3929443359375  loc loss 21.64142608642578\n",
      "cls loss 580.79443359375  loc loss 34.592185974121094\n",
      "cls loss 434.5386657714844  loc loss 30.26517105102539\n",
      "cls loss 436.811279296875  loc loss 26.54237937927246\n",
      "cls loss 416.9138488769531  loc loss 27.575267791748047\n",
      "cls loss 532.7322387695312  loc loss 34.60503387451172\n",
      "cls loss 512.3369750976562  loc loss 33.15470504760742\n",
      "cls loss 242.12498474121094  loc loss 12.870372772216797\n",
      "cls loss 516.794677734375  loc loss 32.23725891113281\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 10.,  1., 18.])\n",
      "cls loss 218.3541717529297  loc loss 15.088519096374512\n",
      "cls loss 251.88909912109375  loc loss 12.14525032043457\n",
      "cls loss 475.1343078613281  loc loss 25.758617401123047\n",
      "cls loss 677.6903076171875  loc loss 37.846954345703125\n",
      "cls loss 406.8021240234375  loc loss 26.4476261138916\n",
      "cls loss 629.2597045898438  loc loss 27.999719619750977\n",
      "cls loss 491.12860107421875  loc loss 28.496828079223633\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.,  1.,  1.])\n",
      "cls loss 559.3754272460938  loc loss 30.628158569335938\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1., 38.,  1.])\n",
      "cls loss 481.1988525390625  loc loss 25.88733673095703\n",
      "cls loss 679.875  loc loss 47.380332946777344\n",
      "cls loss 368.00006103515625  loc loss 23.429636001586914\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 490.01214599609375  loc loss 26.216102600097656\n",
      "cls loss 395.04925537109375  loc loss 22.28028106689453\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3., 10.,  8.,  3., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.])\n",
      "cls loss 436.65435791015625  loc loss 24.645456314086914\n",
      "cls loss 292.1611328125  loc loss 19.304553985595703\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3.,  3., 11.,  3., 10., 10.,  3.,  3., 10.])\n",
      "cls loss 291.98974609375  loc loss 17.559709548950195\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3., 10., 10., 10.])\n",
      "cls loss 368.291259765625  loc loss 19.073871612548828\n",
      "cls loss 282.3243408203125  loc loss 19.337879180908203\n",
      "cls loss 386.81317138671875  loc loss 26.615524291992188\n",
      "cls loss 563.3491821289062  loc loss 33.109439849853516\n",
      "cls loss 368.69097900390625  loc loss 23.402896881103516\n",
      "cls loss 296.4900207519531  loc loss 21.167421340942383\n",
      "cls loss 374.2157287597656  loc loss 20.579917907714844\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 9.,  9., 85., 85.])\n",
      "cls loss 325.5756530761719  loc loss 13.78357982635498\n",
      "cls loss 417.9132080078125  loc loss 25.427736282348633\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 614.474853515625  loc loss 35.34275436401367\n",
      "cls loss 511.1470947265625  loc loss 20.645875930786133\n",
      "cls loss 595.8763427734375  loc loss 38.61017990112305\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10., 10., 10., 10.])\n",
      "cls loss 387.11651611328125  loc loss 22.13591194152832\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([13.])\n",
      "cls loss 585.1361083984375  loc loss 42.21103286743164\n",
      "cls loss 154.94091796875  loc loss 8.87952709197998\n",
      "cls loss 235.8300018310547  loc loss 12.043875694274902\n",
      "cls loss 301.2575378417969  loc loss 18.698959350585938\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19.,  1.,  1.,  1., 19., 19.])\n",
      "cls loss 327.0114440917969  loc loss 21.577167510986328\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 265.9159851074219  loc loss 17.592784881591797\n",
      "cls loss 411.183349609375  loc loss 26.713768005371094\n",
      "cls loss 311.9659423828125  loc loss 16.5515193939209\n",
      "cls loss 444.6761779785156  loc loss 21.45758056640625\n",
      "cls loss 477.134033203125  loc loss 32.305503845214844\n",
      "cls loss 361.4970703125  loc loss 20.04119110107422\n",
      "cls loss 598.4334716796875  loc loss 38.71601867675781\n",
      "cls loss 209.96339416503906  loc loss 8.396484375\n",
      "cls loss 386.9019775390625  loc loss 24.744430541992188\n",
      "cls loss 327.61395263671875  loc loss 17.10689353942871\n",
      "cls loss 361.00555419921875  loc loss 16.923206329345703\n",
      "cls loss 483.891357421875  loc loss 25.214736938476562\n",
      "cls loss 380.86956787109375  loc loss 17.032024383544922\n",
      "cls loss 546.44140625  loc loss 35.59656524658203\n",
      "cls loss 352.74639892578125  loc loss 20.452804565429688\n",
      "cls loss 451.2309265136719  loc loss 31.611854553222656\n",
      "cls loss 653.600830078125  loc loss 38.25753402709961\n",
      "cls loss 350.5826721191406  loc loss 25.884437561035156\n",
      "cls loss 423.11004638671875  loc loss 23.023862838745117\n",
      "cls loss 498.3254699707031  loc loss 37.844085693359375\n",
      "cls loss 591.7807006835938  loc loss 38.250633239746094\n",
      "cls loss 643.339111328125  loc loss 37.072425842285156\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 5.])\n",
      "cls loss 162.662841796875  loc loss 8.355451583862305\n",
      "cls loss 245.5450897216797  loc loss 9.602916717529297\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 13.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 6., 8., 8.])\n",
      "cls loss 190.99063110351562  loc loss 9.675915718078613\n",
      "cls loss 258.5158386230469  loc loss 11.756959915161133\n",
      "cls loss 497.1318054199219  loc loss 30.03300666809082\n",
      "cls loss 207.11602783203125  loc loss 11.35124397277832\n",
      "cls loss 425.18243408203125  loc loss 28.626928329467773\n",
      "cls loss 636.9021606445312  loc loss 44.11689758300781\n",
      "cls loss 409.046875  loc loss 25.531177520751953\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([42., 42.,  1.,  1.,  1.,  1.,  1.,  1.,  1., 42., 42.])\n",
      "cls loss 431.64483642578125  loc loss 20.973114013671875\n",
      "cls loss 545.5737915039062  loc loss 39.5081672668457\n",
      "cls loss 501.4737243652344  loc loss 32.118038177490234\n",
      "cls loss 315.73388671875  loc loss 18.674150466918945\n",
      "cls loss 416.1443786621094  loc loss 21.134824752807617\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 639.3967895507812  loc loss 36.820011138916016\n",
      "cls loss 508.8746337890625  loc loss 31.913190841674805\n",
      "cls loss 301.9501953125  loc loss 14.699504852294922\n",
      "cls loss 257.9936828613281  loc loss 14.008365631103516\n",
      "cls loss 340.61627197265625  loc loss 20.2880802154541\n",
      "cls loss 463.3459167480469  loc loss 28.400306701660156\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15.])\n",
      "cls loss 223.5277099609375  loc loss 7.153575897216797\n",
      "cls loss 393.86004638671875  loc loss 22.36845588684082\n",
      "cls loss 350.605224609375  loc loss 20.50150489807129\n",
      "cls loss 630.2939453125  loc loss 36.730125427246094\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19.,  7.])\n",
      "cls loss 289.8512268066406  loc loss 16.61583137512207\n",
      "cls loss 579.6065673828125  loc loss 40.23203659057617\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 528.25390625  loc loss 27.245635986328125\n",
      "cls loss 495.95831298828125  loc loss 31.574073791503906\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([38., 38.,  1., 18.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1., 18., 18.,  1.])\n",
      "cls loss 326.09735107421875  loc loss 17.76418685913086\n",
      "cls loss 317.2880859375  loc loss 15.647794723510742\n",
      "cls loss 627.5328369140625  loc loss 42.322601318359375\n",
      "cls loss 452.58740234375  loc loss 29.148841857910156\n",
      "cls loss 375.1016845703125  loc loss 24.350242614746094\n",
      "cls loss 263.01055908203125  loc loss 17.838520050048828\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.])\n",
      "cls loss 156.28561401367188  loc loss 6.428220748901367\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([32.])\n",
      "cls loss 411.59271240234375  loc loss 20.16205406188965\n",
      "cls loss 365.79425048828125  loc loss 22.89139747619629\n",
      "cls loss 447.74066162109375  loc loss 31.51595687866211\n",
      "cls loss 399.5915222167969  loc loss 23.762474060058594\n",
      "cls loss 339.03692626953125  loc loss 18.175731658935547\n",
      "cls loss 541.4326171875  loc loss 29.4475040435791\n",
      "cls loss 639.9542236328125  loc loss 38.49454116821289\n",
      "cls loss 458.8968200683594  loc loss 30.34004020690918\n",
      "cls loss 343.40069580078125  loc loss 20.802194595336914\n",
      "cls loss 561.7843017578125  loc loss 35.67768096923828\n",
      "cls loss 371.791259765625  loc loss 19.70919418334961\n",
      "cls loss 669.4608154296875  loc loss 41.39510726928711\n",
      "cls loss 444.97894287109375  loc loss 23.25823402404785\n",
      "cls loss 353.057861328125  loc loss 27.746726989746094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 275.1120910644531  loc loss 13.083057403564453\n",
      "cls loss 325.52093505859375  loc loss 19.862932205200195\n",
      "cls loss 467.03668212890625  loc loss 31.00717544555664\n",
      "cls loss 537.096923828125  loc loss 36.428741455078125\n",
      "cls loss 326.0559387207031  loc loss 19.521560668945312\n",
      "cls loss 516.072265625  loc loss 34.979408264160156\n",
      "cls loss 620.0218505859375  loc loss 37.278526306152344\n",
      "cls loss 229.42022705078125  loc loss 13.50000286102295\n",
      "cls loss 603.616943359375  loc loss 38.51504135131836\n",
      "cls loss 451.07916259765625  loc loss 28.650163650512695\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 585.906005859375  loc loss 41.69334030151367\n",
      "cls loss 246.05967712402344  loc loss 10.293042182922363\n",
      "cls loss 375.6546630859375  loc loss 22.29510498046875\n",
      "cls loss 382.3790283203125  loc loss 26.087966918945312\n",
      "cls loss 320.7534484863281  loc loss 20.214582443237305\n",
      "cls loss 186.59527587890625  loc loss 10.609326362609863\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 9., 9., 1., 9., 9., 9., 9., 1., 9.])\n",
      "cls loss 853.166259765625  loc loss 54.627838134765625\n",
      "cls loss 459.6114807128906  loc loss 23.754209518432617\n",
      "cls loss 720.02685546875  loc loss 49.8961296081543\n",
      "cls loss 280.8609924316406  loc loss 20.859485626220703\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 42., 42.])\n",
      "cls loss 462.9561462402344  loc loss 33.79901123046875\n",
      "cls loss 471.81109619140625  loc loss 36.313018798828125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  2.,  1.,  1.,  1., 38.,\n",
      "         1.,  1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 38., 38., 38.,  1., 38., 38., 38.,  1.,  1., 38.,  1.,\n",
      "         1.])\n",
      "cls loss 280.1583251953125  loc loss 20.94182586669922\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  8.,  8.])\n",
      "cls loss 658.6573486328125  loc loss 44.46571350097656\n",
      "cls loss 669.9733276367188  loc loss 51.00926208496094\n",
      "cls loss 244.31289672851562  loc loss 15.443819046020508\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([4., 1., 1., 4.])\n",
      "cls loss 393.8254089355469  loc loss 24.19725227355957\n",
      "cls loss 502.52587890625  loc loss 28.822505950927734\n",
      "cls loss 199.45269775390625  loc loss 10.13546371459961\n",
      "cls loss 249.60992431640625  loc loss 15.771831512451172\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([51.,  1.])\n",
      "cls loss 177.35067749023438  loc loss 8.279988288879395\n",
      "cls loss 254.17434692382812  loc loss 15.694424629211426\n",
      "cls loss 536.64013671875  loc loss 24.38640022277832\n",
      "cls loss 494.5717468261719  loc loss 32.50132369995117\n",
      "cls loss 762.8833618164062  loc loss 36.04318618774414\n",
      "cls loss 901.0249633789062  loc loss 56.5887565612793\n",
      "cls loss 370.4910888671875  loc loss 22.867023468017578\n",
      "cls loss 545.481201171875  loc loss 39.250667572021484\n",
      "cls loss 595.8982543945312  loc loss 37.772159576416016\n",
      "cls loss 427.2945251464844  loc loss 26.13340950012207\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  3.,  1.,  1.,  1.,  3.,  1.,  1.,\n",
      "         1.,  1.,  1.])\n",
      "cls loss 464.0324401855469  loc loss 19.19948959350586\n",
      "cls loss 493.42047119140625  loc loss 26.081689834594727\n",
      "cls loss 486.1446228027344  loc loss 23.070819854736328\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "cls loss 412.11846923828125  loc loss 22.553686141967773\n",
      "cls loss 229.5902099609375  loc loss 17.615638732910156\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3.])\n",
      "cls loss 183.99586486816406  loc loss 9.881978988647461\n",
      "cls loss 321.10150146484375  loc loss 18.471769332885742\n",
      "cls loss 310.2518005371094  loc loss 19.79460334777832\n",
      "cls loss 558.30322265625  loc loss 34.06999588012695\n",
      "cls loss 251.5390625  loc loss 18.360755920410156\n",
      "cls loss 292.4962463378906  loc loss 22.71615982055664\n",
      "cls loss 832.726806640625  loc loss 54.5419807434082\n",
      "cls loss 377.54302978515625  loc loss 27.338176727294922\n",
      "cls loss 281.195068359375  loc loss 19.058603286743164\n",
      "cls loss 330.8475036621094  loc loss 18.11465072631836\n",
      "cls loss 301.188720703125  loc loss 21.81938362121582\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 560.2166137695312  loc loss 37.68822479248047\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  9., 64., 64., 64., 64., 64., 64., 64., 64., 64.,  9.,  9.,  9.,\n",
      "         9.])\n",
      "cls loss 257.01470947265625  loc loss 12.913192749023438\n",
      "cls loss 822.4437255859375  loc loss 59.04844284057617\n",
      "cls loss 432.7831726074219  loc loss 26.659706115722656\n",
      "cls loss 515.7738037109375  loc loss 32.83424377441406\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.,  3.,  3.])\n",
      "cls loss 325.55157470703125  loc loss 17.1981201171875\n",
      "cls loss 351.073486328125  loc loss 23.968904495239258\n",
      "cls loss 371.63592529296875  loc loss 25.256637573242188\n",
      "cls loss 380.36895751953125  loc loss 24.632999420166016\n",
      "cls loss 440.22137451171875  loc loss 28.434917449951172\n",
      "cls loss 439.2764587402344  loc loss 26.962656021118164\n",
      "cls loss 393.4713134765625  loc loss 25.59418487548828\n",
      "cls loss 399.69586181640625  loc loss 21.20586395263672\n",
      "cls loss 498.95904541015625  loc loss 31.68852996826172\n",
      "cls loss 366.68231201171875  loc loss 21.755334854125977\n",
      "cls loss 277.39373779296875  loc loss 14.499564170837402\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21.])\n",
      "cls loss 227.49209594726562  loc loss 14.639025688171387\n",
      "cls loss 325.1787414550781  loc loss 27.291996002197266\n",
      "cls loss 483.4240417480469  loc loss 33.064552307128906\n",
      "cls loss 244.9745330810547  loc loss 14.658491134643555\n",
      "cls loss 396.21685791015625  loc loss 25.650617599487305\n",
      "cls loss 733.4005737304688  loc loss 37.802024841308594\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 42., 42.,  1.,  1.])\n",
      "cls loss 442.59478759765625  loc loss 23.43718719482422\n",
      "cls loss 287.4599914550781  loc loss 16.54302978515625\n",
      "cls loss 412.7706298828125  loc loss 23.758544921875\n",
      "cls loss 546.5025634765625  loc loss 39.65848159790039\n",
      "cls loss 342.63067626953125  loc loss 18.687793731689453\n",
      "cls loss 524.8416748046875  loc loss 34.201499938964844\n",
      "cls loss 458.89434814453125  loc loss 30.543964385986328\n",
      "cls loss 448.01751708984375  loc loss 28.070358276367188\n",
      "cls loss 361.129150390625  loc loss 22.059497833251953\n",
      "cls loss 291.47900390625  loc loss 19.23076057434082\n",
      "cls loss 229.97511291503906  loc loss 10.636298179626465\n",
      "cls loss 365.14923095703125  loc loss 23.314687728881836\n",
      "cls loss 557.7924194335938  loc loss 34.30082321166992\n",
      "cls loss 403.638427734375  loc loss 23.714845657348633\n",
      "cls loss 388.57696533203125  loc loss 27.676162719726562\n",
      "cls loss 424.42669677734375  loc loss 24.77359962463379\n",
      "cls loss 630.302734375  loc loss 45.18686294555664\n",
      "cls loss 508.2842102050781  loc loss 32.06800079345703\n",
      "cls loss 551.9967651367188  loc loss 28.71878433227539\n",
      "cls loss 347.68804931640625  loc loss 14.897054672241211\n",
      "cls loss 483.13592529296875  loc loss 27.1605167388916\n",
      "cls loss 438.700927734375  loc loss 24.027299880981445\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 5., 5., 5., 5., 5., 5.])\n",
      "cls loss 267.76324462890625  loc loss 15.956313133239746\n",
      "cls loss 355.66619873046875  loc loss 18.01243782043457\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([13.])\n",
      "cls loss 252.03668212890625  loc loss 11.384634017944336\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([44., 10.,  1.,  1.,  1.])\n",
      "cls loss 225.47601318359375  loc loss 15.014201164245605\n",
      "cls loss 396.63140869140625  loc loss 21.80780029296875\n",
      "cls loss 368.4051818847656  loc loss 19.781614303588867\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19., 19., 19., 19., 19., 19., 19.])\n",
      "cls loss 384.3116760253906  loc loss 23.261337280273438\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([56.])\n",
      "cls loss 816.0172729492188  loc loss 52.9166145324707\n",
      "cls loss 519.21630859375  loc loss 36.785648345947266\n",
      "cls loss 658.9524536132812  loc loss 41.08983612060547\n",
      "cls loss 630.9721069335938  loc loss 46.2950325012207\n",
      "cls loss 380.6452941894531  loc loss 21.18612289428711\n",
      "cls loss 648.671875  loc loss 40.371246337890625\n",
      "cls loss 366.15106201171875  loc loss 24.570598602294922\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 36.])\n",
      "cls loss 482.2816162109375  loc loss 21.030054092407227\n",
      "cls loss 400.38031005859375  loc loss 24.1569766998291\n",
      "cls loss 379.2481689453125  loc loss 22.02570915222168\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5.])\n",
      "cls loss 448.81829833984375  loc loss 25.562393188476562\n",
      "cls loss 244.52886962890625  loc loss 11.430073738098145\n",
      "cls loss 563.5552978515625  loc loss 29.631183624267578\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "cls loss 498.8559875488281  loc loss 28.97686004638672\n",
      "cls loss 459.66448974609375  loc loss 29.21497917175293\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 486.5290832519531  loc loss 29.3262996673584\n",
      "cls loss 549.5484619140625  loc loss 33.20918273925781\n",
      "cls loss 470.8037109375  loc loss 38.14443588256836\n",
      "cls loss 325.00201416015625  loc loss 20.704055786132812\n",
      "cls loss 364.15069580078125  loc loss 25.478025436401367\n",
      "cls loss 382.65618896484375  loc loss 21.65853500366211\n",
      "cls loss 646.8016357421875  loc loss 30.92772674560547\n",
      "cls loss 257.97625732421875  loc loss 12.970742225646973\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 11., 15., 10., 10., 10., 10., 10.])\n",
      "cls loss 580.845947265625  loc loss 37.44708251953125\n",
      "cls loss 350.8740234375  loc loss 25.549510955810547\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3.])\n",
      "cls loss 364.9996337890625  loc loss 26.465410232543945\n",
      "cls loss 353.0414123535156  loc loss 17.17821502685547\n",
      "cls loss 393.48248291015625  loc loss 18.08761978149414\n",
      "cls loss 507.37005615234375  loc loss 20.941822052001953\n",
      "cls loss 228.11192321777344  loc loss 10.569753646850586\n",
      "cls loss 415.9182434082031  loc loss 25.244295120239258\n",
      "cls loss 473.4556884765625  loc loss 28.97348403930664\n",
      "cls loss 411.04559326171875  loc loss 25.93862533569336\n",
      "cls loss 948.1724853515625  loc loss 57.52369689941406\n",
      "cls loss 626.859375  loc loss 38.27748107910156\n",
      "cls loss 392.22552490234375  loc loss 25.808860778808594\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  9.,  9.,  9.,  6.,  6., 85., 85.,  8.,  1.,  1.,  1.,  1.,\n",
      "         6.,  6.])\n",
      "cls loss 262.70745849609375  loc loss 20.54442596435547\n",
      "cls loss 660.5040893554688  loc loss 44.3946418762207\n",
      "cls loss 771.5205078125  loc loss 45.325538635253906\n",
      "cls loss 490.1836242675781  loc loss 33.89963150024414\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10.,  3.,  3., 10.])\n",
      "cls loss 310.713623046875  loc loss 17.01679801940918\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([7.])\n",
      "cls loss 405.7159423828125  loc loss 25.070953369140625\n",
      "cls loss 397.3767395019531  loc loss 24.20121955871582\n",
      "cls loss 417.01385498046875  loc loss 34.590965270996094\n",
      "cls loss 688.8516845703125  loc loss 46.09940719604492\n",
      "cls loss 388.898193359375  loc loss 24.663188934326172\n",
      "cls loss 605.974365234375  loc loss 35.77899169921875\n",
      "cls loss 749.4467163085938  loc loss 39.788780212402344\n",
      "cls loss 491.7892761230469  loc loss 26.18724822998047\n",
      "cls loss 546.8162231445312  loc loss 31.429393768310547\n",
      "cls loss 406.40447998046875  loc loss 26.512435913085938\n",
      "cls loss 584.571044921875  loc loss 40.80513000488281\n",
      "cls loss 444.13983154296875  loc loss 27.61224937438965\n",
      "cls loss 318.17950439453125  loc loss 20.305133819580078\n",
      "cls loss 515.1773681640625  loc loss 37.13691711425781\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([62.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([62.])\n",
      "cls loss 229.46327209472656  loc loss 11.066474914550781\n",
      "cls loss 363.2899475097656  loc loss 27.219655990600586\n",
      "cls loss 375.9541320800781  loc loss 23.986230850219727\n",
      "cls loss 241.004150390625  loc loss 11.739563941955566\n",
      "cls loss 510.39910888671875  loc loss 32.11470031738281\n",
      "cls loss 519.7827758789062  loc loss 28.93941307067871\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([28.])\n",
      "cls loss 658.9339599609375  loc loss 29.619293212890625\n",
      "cls loss 488.141845703125  loc loss 31.17247772216797\n",
      "cls loss 486.52435302734375  loc loss 33.21647262573242\n",
      "cls loss 551.8015747070312  loc loss 31.214216232299805\n",
      "cls loss 815.09033203125  loc loss 44.697593688964844\n",
      "cls loss 464.16900634765625  loc loss 24.512170791625977\n",
      "cls loss 633.6280517578125  loc loss 28.839460372924805\n",
      "cls loss 500.07110595703125  loc loss 33.642982482910156\n",
      "cls loss 765.5631103515625  loc loss 55.440799713134766\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([81.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 458.8577575683594  loc loss 17.817054748535156\n",
      "cls loss 351.5516662597656  loc loss 17.922576904296875\n",
      "cls loss 253.0883331298828  loc loss 18.35434913635254\n",
      "cls loss 227.02731323242188  loc loss 10.179339408874512\n",
      "cls loss 256.58209228515625  loc loss 19.863832473754883\n",
      "cls loss 321.7205810546875  loc loss 20.17765235900879\n",
      "cls loss 330.4056396484375  loc loss 23.254993438720703\n",
      "cls loss 493.03033447265625  loc loss 38.7202262878418\n",
      "cls loss 587.8798217773438  loc loss 33.51988983154297\n",
      "cls loss 1008.4531860351562  loc loss 65.66360473632812\n",
      "cls loss 398.474365234375  loc loss 18.799299240112305\n",
      "cls loss 504.41790771484375  loc loss 36.22607421875\n",
      "cls loss 357.2843017578125  loc loss 21.016544342041016\n",
      "cls loss 490.2059020996094  loc loss 25.376007080078125\n",
      "cls loss 434.707763671875  loc loss 23.16907501220703\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([44., 44.])\n",
      "cls loss 405.7147216796875  loc loss 17.351449966430664\n",
      "cls loss 451.7762451171875  loc loss 25.56590461730957\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15.])\n",
      "cls loss 425.905517578125  loc loss 21.19993019104004\n",
      "cls loss 243.94134521484375  loc loss 12.709035873413086\n",
      "cls loss 417.49249267578125  loc loss 26.55649757385254\n",
      "cls loss 247.35952758789062  loc loss 11.762808799743652\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([1., 3., 3.])\n",
      "cls loss 275.1233215332031  loc loss 16.025421142578125\n",
      "cls loss 196.26873779296875  loc loss 9.143057823181152\n",
      "cls loss 375.0668640136719  loc loss 25.61701202392578\n",
      "cls loss 449.087158203125  loc loss 23.796581268310547\n",
      "cls loss 383.103759765625  loc loss 25.966188430786133\n",
      "cls loss 319.7333679199219  loc loss 20.71247673034668\n",
      "cls loss 353.5283508300781  loc loss 24.094478607177734\n",
      "cls loss 472.170166015625  loc loss 29.896085739135742\n",
      "cls loss 313.66375732421875  loc loss 21.04869270324707\n",
      "cls loss 410.7091979980469  loc loss 30.49028778076172\n",
      "cls loss 291.5076599121094  loc loss 17.000167846679688\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 541.1868896484375  loc loss 29.291988372802734\n",
      "cls loss 661.77392578125  loc loss 26.052316665649414\n",
      "cls loss 565.5660400390625  loc loss 35.33919143676758\n",
      "cls loss 561.422119140625  loc loss 41.11762619018555\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10., 10., 10.,  1.,  1.,  1.,  1.,  1.,  1.,  8.,  8.,\n",
      "         1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10., 10., 10.,  1.,  1.,  1.,  1.,  1.,  1.,  8.,  8.,\n",
      "         1.])\n",
      "cls loss 439.4779968261719  loc loss 21.815256118774414\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 3., 3., 3.])\n",
      "cls loss 445.454833984375  loc loss 24.059463500976562\n",
      "cls loss 273.7056579589844  loc loss 17.14239501953125\n",
      "cls loss 208.20700073242188  loc loss 10.196979522705078\n",
      "cls loss 409.4608154296875  loc loss 29.719478607177734\n",
      "cls loss 297.6185302734375  loc loss 13.268111228942871\n",
      "cls loss 373.02960205078125  loc loss 24.466835021972656\n",
      "cls loss 416.41790771484375  loc loss 29.285316467285156\n",
      "cls loss 552.3677978515625  loc loss 39.43585968017578\n",
      "cls loss 484.11773681640625  loc loss 24.249773025512695\n",
      "cls loss 435.62255859375  loc loss 23.43212127685547\n",
      "cls loss 453.4017028808594  loc loss 29.266353607177734\n",
      "cls loss 325.929931640625  loc loss 23.466291427612305\n",
      "cls loss 672.938720703125  loc loss 46.45254135131836\n",
      "cls loss 282.0506286621094  loc loss 15.40819263458252\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 544.0897216796875  loc loss 30.11574935913086\n",
      "cls loss 227.0364532470703  loc loss 9.16541862487793\n",
      "cls loss 588.39599609375  loc loss 38.66411590576172\n",
      "cls loss 299.36865234375  loc loss 18.101177215576172\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 34.])\n",
      "cls loss 499.1495361328125  loc loss 25.9423885345459\n",
      "cls loss 274.46588134765625  loc loss 15.867707252502441\n",
      "cls loss 546.2304077148438  loc loss 27.927444458007812\n",
      "cls loss 197.662841796875  loc loss 11.8270263671875\n",
      "cls loss 409.99310302734375  loc loss 23.151371002197266\n",
      "cls loss 400.2584228515625  loc loss 30.78514862060547\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 38.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16., 16., 16.,  9.,  9.,  9., 16., 16., 16., 85.,  9.])\n",
      "cls loss 415.09454345703125  loc loss 23.771501541137695\n",
      "cls loss 447.15374755859375  loc loss 32.3735237121582\n",
      "cls loss 600.2598876953125  loc loss 37.36923599243164\n",
      "cls loss 937.2462158203125  loc loss 55.95154571533203\n",
      "cls loss 234.32205200195312  loc loss 13.135698318481445\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3., 10.,  8.,  8., 10., 10., 10.,  3.,  3., 14.])\n",
      "cls loss 257.2509765625  loc loss 14.637879371643066\n",
      "cls loss 473.6090393066406  loc loss 30.23219871520996\n",
      "cls loss 196.0450439453125  loc loss 8.344891548156738\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 348.8706970214844  loc loss 14.949889183044434\n",
      "cls loss 479.39715576171875  loc loss 30.308340072631836\n",
      "cls loss 409.084228515625  loc loss 23.459320068359375\n",
      "cls loss 238.79461669921875  loc loss 12.67923641204834\n",
      "cls loss 321.09735107421875  loc loss 14.835946083068848\n",
      "cls loss 544.6421508789062  loc loss 26.77945327758789\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42., 42.,  1.])\n",
      "cls loss 498.9947509765625  loc loss 26.93385887145996\n",
      "cls loss 416.3480224609375  loc loss 19.947792053222656\n",
      "cls loss 514.2302856445312  loc loss 35.48324203491211\n",
      "cls loss 572.0337524414062  loc loss 32.55835723876953\n",
      "cls loss 387.76312255859375  loc loss 21.83978271484375\n",
      "cls loss 465.024658203125  loc loss 32.36402130126953\n",
      "cls loss 276.7567138671875  loc loss 18.285526275634766\n",
      "cls loss 300.4292907714844  loc loss 21.670520782470703\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20.])\n",
      "cls loss 215.10153198242188  loc loss 12.3709077835083\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([11.])\n",
      "cls loss 309.36083984375  loc loss 13.661323547363281\n",
      "cls loss 174.2398681640625  loc loss 10.90015983581543\n",
      "cls loss 469.44586181640625  loc loss 33.76526641845703\n",
      "cls loss 198.20542907714844  loc loss 9.771615028381348\n",
      "cls loss 413.4180603027344  loc loss 25.053176879882812\n",
      "cls loss 225.98170471191406  loc loss 14.998336791992188\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 35., 27.])\n",
      "cls loss 417.5761413574219  loc loss 22.48818016052246\n",
      "cls loss 488.7495422363281  loc loss 33.965999603271484\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 322.6644287109375  loc loss 15.90629768371582\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([42.,  1.])\n",
      "cls loss 417.1766357421875  loc loss 24.944561004638672\n",
      "cls loss 442.8659362792969  loc loss 20.74018096923828\n",
      "cls loss 544.6519165039062  loc loss 27.319400787353516\n",
      "cls loss 682.39453125  loc loss 31.35733413696289\n",
      "cls loss 549.9794921875  loc loss 28.056793212890625\n",
      "cls loss 384.1533203125  loc loss 21.54935073852539\n",
      "cls loss 313.6054992675781  loc loss 20.358753204345703\n",
      "cls loss 185.94522094726562  loc loss 7.658577919006348\n",
      "cls loss 332.9027404785156  loc loss 17.981800079345703\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 1., 1.])\n",
      "cls loss 316.8919372558594  loc loss 19.44142723083496\n",
      "cls loss 386.7384033203125  loc loss 24.30621910095215\n",
      "cls loss 371.19329833984375  loc loss 21.969823837280273\n",
      "cls loss 292.0679931640625  loc loss 20.574678421020508\n",
      "cls loss 364.60260009765625  loc loss 23.566434860229492\n",
      "cls loss 384.7127685546875  loc loss 27.655729293823242\n",
      "cls loss 570.162353515625  loc loss 32.65138626098633\n",
      "cls loss 495.0271911621094  loc loss 35.69595718383789\n",
      "cls loss 427.78424072265625  loc loss 26.971668243408203\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 339.0450134277344  loc loss 23.2058048248291\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 484.097412109375  loc loss 18.294891357421875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([81.])\n",
      "cls loss 567.6766967773438  loc loss 27.39284896850586\n",
      "cls loss 328.2405700683594  loc loss 20.622352600097656\n",
      "cls loss 285.2514343261719  loc loss 11.278519630432129\n",
      "cls loss 368.4376220703125  loc loss 19.04608154296875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3.,  1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 19.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 19.])\n",
      "cls loss 521.4929809570312  loc loss 31.370962142944336\n",
      "cls loss 270.7194519042969  loc loss 14.946795463562012\n",
      "cls loss 295.3275146484375  loc loss 15.473533630371094\n",
      "cls loss 549.9393310546875  loc loss 38.44807815551758\n",
      "cls loss 267.9281921386719  loc loss 16.502397537231445\n",
      "cls loss 338.4852600097656  loc loss 19.62051010131836\n",
      "cls loss 427.11029052734375  loc loss 26.94906997680664\n",
      "cls loss 317.0615539550781  loc loss 22.234060287475586\n",
      "cls loss 431.1084289550781  loc loss 22.84732437133789\n",
      "cls loss 463.1390686035156  loc loss 29.414844512939453\n",
      "cls loss 628.4535522460938  loc loss 52.01198959350586\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 81.])\n",
      "cls loss 416.402587890625  loc loss 19.475669860839844\n",
      "cls loss 385.284423828125  loc loss 19.85787582397461\n",
      "cls loss 387.2027587890625  loc loss 21.31125831604004\n",
      "cls loss 320.004150390625  loc loss 15.645356178283691\n",
      "cls loss 291.28106689453125  loc loss 16.251365661621094\n",
      "cls loss 356.46466064453125  loc loss 23.495849609375\n",
      "cls loss 256.91650390625  loc loss 16.659870147705078\n",
      "cls loss 222.10281372070312  loc loss 13.413101196289062\n",
      "cls loss 287.7740478515625  loc loss 17.982807159423828\n",
      "cls loss 382.6723937988281  loc loss 23.007089614868164\n",
      "cls loss 363.38800048828125  loc loss 24.86302375793457\n",
      "cls loss 352.159423828125  loc loss 22.314245223999023\n",
      "cls loss 209.29598999023438  loc loss 12.939032554626465\n",
      "cls loss 736.180419921875  loc loss 44.544307708740234\n",
      "cls loss 398.678955078125  loc loss 25.7248477935791\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 358.24517822265625  loc loss 17.100025177001953\n",
      "cls loss 399.8581237792969  loc loss 24.70958137512207\n",
      "cls loss 284.11688232421875  loc loss 19.857547760009766\n",
      "cls loss 461.9606628417969  loc loss 33.3491096496582\n",
      "cls loss 457.85552978515625  loc loss 27.27436065673828\n",
      "cls loss 411.67010498046875  loc loss 25.105342864990234\n",
      "cls loss 309.8130187988281  loc loss 21.01555061340332\n",
      "cls loss 285.6069030761719  loc loss 15.559869766235352\n",
      "cls loss 414.0743103027344  loc loss 21.272991180419922\n",
      "cls loss 495.9583740234375  loc loss 29.0938720703125\n",
      "cls loss 435.155517578125  loc loss 22.044254302978516\n",
      "cls loss 576.6053466796875  loc loss 33.792755126953125\n",
      "cls loss 615.224853515625  loc loss 40.08795166015625\n",
      "cls loss 416.4395751953125  loc loss 25.84126853942871\n",
      "cls loss 593.8045654296875  loc loss 42.92763900756836\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1., 38., 47.,  1.,  1.,  1.,  1.,  1., 62.])\n",
      "cls loss 359.2638854980469  loc loss 16.753490447998047\n",
      "cls loss 423.3523864746094  loc loss 29.260826110839844\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 458.5145568847656  loc loss 26.37261390686035\n",
      "cls loss 526.8367309570312  loc loss 36.871734619140625\n",
      "cls loss 341.02532958984375  loc loss 15.420398712158203\n",
      "cls loss 415.14111328125  loc loss 30.58364486694336\n",
      "cls loss 398.05157470703125  loc loss 22.48859405517578\n",
      "cls loss 220.2525634765625  loc loss 7.424598217010498\n",
      "cls loss 336.1825866699219  loc loss 18.67915916442871\n",
      "cls loss 298.2487487792969  loc loss 12.248103141784668\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1., 35.])\n",
      "cls loss 324.6090087890625  loc loss 18.48366928100586\n",
      "cls loss 502.7742919921875  loc loss 25.091344833374023\n",
      "cls loss 514.2328491210938  loc loss 29.80569839477539\n",
      "cls loss 458.500732421875  loc loss 33.596797943115234\n",
      "cls loss 396.4211120605469  loc loss 25.987180709838867\n",
      "cls loss 504.73419189453125  loc loss 34.78207015991211\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 277.5885925292969  loc loss 14.229582786560059\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 387.8565673828125  loc loss 15.539562225341797\n",
      "cls loss 586.459716796875  loc loss 32.03739929199219\n",
      "cls loss 746.5393676757812  loc loss 56.69681167602539\n",
      "cls loss 365.48016357421875  loc loss 18.518802642822266\n",
      "cls loss 314.88214111328125  loc loss 18.304468154907227\n",
      "cls loss 325.3756103515625  loc loss 15.950616836547852\n",
      "cls loss 366.61187744140625  loc loss 18.802825927734375\n",
      "cls loss 315.04010009765625  loc loss 12.868276596069336\n",
      "cls loss 580.1907958984375  loc loss 35.208091735839844\n",
      "cls loss 487.48773193359375  loc loss 27.34849739074707\n",
      "cls loss 215.61920166015625  loc loss 14.667518615722656\n",
      "cls loss 442.56939697265625  loc loss 24.750423431396484\n",
      "cls loss 594.9207153320312  loc loss 41.47693634033203\n",
      "cls loss 448.6285400390625  loc loss 28.460582733154297\n",
      "cls loss 398.5914306640625  loc loss 22.24231719970703\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.])\n",
      "cls loss 374.40673828125  loc loss 25.6308536529541\n",
      "cls loss 388.7359619140625  loc loss 23.371231079101562\n",
      "cls loss 466.7447509765625  loc loss 26.82904624938965\n",
      "cls loss 775.9576416015625  loc loss 55.05598831176758\n",
      "cls loss 276.9942932128906  loc loss 13.812801361083984\n",
      "cls loss 368.47784423828125  loc loss 22.165653228759766\n",
      "cls loss 289.28753662109375  loc loss 16.24872589111328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 331.1430969238281  loc loss 21.541339874267578\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 21., 21., 21.])\n",
      "cls loss 314.69586181640625  loc loss 20.099143981933594\n",
      "cls loss 333.19744873046875  loc loss 16.369739532470703\n",
      "cls loss 341.55682373046875  loc loss 22.179969787597656\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 35.])\n",
      "cls loss 467.22344970703125  loc loss 26.28851318359375\n",
      "cls loss 172.92706298828125  loc loss 9.022392272949219\n",
      "cls loss 320.6733703613281  loc loss 17.003625869750977\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 297.7109069824219  loc loss 11.461612701416016\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 38., 38.,  9., 38.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1.,  1.])\n",
      "cls loss 330.80010986328125  loc loss 18.855379104614258\n",
      "cls loss 549.27587890625  loc loss 30.288368225097656\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 2.,  1., 77., 31., 10., 10.,  1.,  4., 10.])\n",
      "cls loss 249.93756103515625  loc loss 10.868246078491211\n",
      "cls loss 499.20648193359375  loc loss 28.22681427001953\n",
      "cls loss 1002.7034912109375  loc loss 54.34807586669922\n",
      "cls loss 311.15240478515625  loc loss 21.068166732788086\n",
      "cls loss 429.0116882324219  loc loss 30.083703994750977\n",
      "cls loss 289.1614990234375  loc loss 14.135701179504395\n",
      "cls loss 278.7645568847656  loc loss 14.371559143066406\n",
      "cls loss 390.946044921875  loc loss 22.24105453491211\n",
      "cls loss 388.27972412109375  loc loss 24.013309478759766\n",
      "cls loss 368.98638916015625  loc loss 26.754194259643555\n",
      "cls loss 315.03662109375  loc loss 15.332955360412598\n",
      "cls loss 329.0638427734375  loc loss 18.123685836791992\n",
      "cls loss 631.798828125  loc loss 35.60549545288086\n",
      "cls loss 593.0549926757812  loc loss 31.152442932128906\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1., 42., 42., 42., 42., 42., 42.,  1.,\n",
      "         1.,  1.,  1., 42.,  1.,  1., 42.,  1.])\n",
      "cls loss 329.1282958984375  loc loss 22.182571411132812\n",
      "cls loss 496.05157470703125  loc loss 24.56343650817871\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.])\n",
      "cls loss 212.65087890625  loc loss 9.930158615112305\n",
      "cls loss 490.2200622558594  loc loss 28.2047061920166\n",
      "cls loss 362.777587890625  loc loss 23.71033477783203\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([11.])\n",
      "cls loss 212.69163513183594  loc loss 12.464479446411133\n",
      "cls loss 239.337890625  loc loss 12.145997047424316\n",
      "cls loss 257.74737548828125  loc loss 11.851240158081055\n",
      "cls loss 457.33380126953125  loc loss 27.801006317138672\n",
      "cls loss 356.4625244140625  loc loss 20.379531860351562\n",
      "cls loss 384.64263916015625  loc loss 24.666790008544922\n",
      "cls loss 539.1229248046875  loc loss 28.526260375976562\n",
      "cls loss 291.7842102050781  loc loss 16.41817855834961\n",
      "cls loss 640.807861328125  loc loss 38.771278381347656\n",
      "cls loss 313.468994140625  loc loss 16.884624481201172\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 297.05572509765625  loc loss 16.595911026000977\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1., 38., 38., 42.])\n",
      "cls loss 416.2303161621094  loc loss 23.294652938842773\n",
      "cls loss 379.3623352050781  loc loss 20.638885498046875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 326.9638977050781  loc loss 19.545927047729492\n",
      "cls loss 701.1844482421875  loc loss 41.24618148803711\n",
      "cls loss 405.28662109375  loc loss 24.101360321044922\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10.,  3.,  3.,  6.,  8.,  8.,  1.,  1.,  1., 10.])\n",
      "cls loss 305.9451904296875  loc loss 14.926530838012695\n",
      "cls loss 208.8085174560547  loc loss 7.3355021476745605\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10.,  3.])\n",
      "cls loss 287.949951171875  loc loss 17.297836303710938\n",
      "cls loss 143.23939514160156  loc loss 8.266255378723145\n",
      "cls loss 365.1000061035156  loc loss 24.559526443481445\n",
      "cls loss 446.19671630859375  loc loss 27.82489013671875\n",
      "cls loss 325.36138916015625  loc loss 18.7335205078125\n",
      "cls loss 175.15530395507812  loc loss 12.429900169372559\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 34.])\n",
      "cls loss 490.18109130859375  loc loss 33.043861389160156\n",
      "cls loss 655.0709228515625  loc loss 44.437347412109375\n",
      "cls loss 405.457275390625  loc loss 27.722829818725586\n",
      "cls loss 326.72906494140625  loc loss 21.03809928894043\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.,  1.])\n",
      "cls loss 368.95123291015625  loc loss 14.824470520019531\n",
      "cls loss 615.4952392578125  loc loss 39.36936950683594\n",
      "cls loss 854.5681762695312  loc loss 49.072940826416016\n",
      "cls loss 678.1905517578125  loc loss 31.90143394470215\n",
      "cls loss 385.652099609375  loc loss 18.59186553955078\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 412.84271240234375  loc loss 23.684886932373047\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10.])\n",
      "cls loss 266.92718505859375  loc loss 13.567252159118652\n",
      "cls loss 394.2857666015625  loc loss 19.46532440185547\n",
      "cls loss 375.38800048828125  loc loss 20.906038284301758\n",
      "cls loss 239.10089111328125  loc loss 14.591113090515137\n",
      "cls loss 336.097412109375  loc loss 20.386932373046875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21.,\n",
      "        21.])\n",
      "cls loss 406.3067932128906  loc loss 24.672748565673828\n",
      "cls loss 352.8393859863281  loc loss 19.1448917388916\n",
      "cls loss 236.32810974121094  loc loss 10.832473754882812\n",
      "cls loss 544.15234375  loc loss 33.194557189941406\n",
      "cls loss 395.1180725097656  loc loss 25.018991470336914\n",
      "cls loss 295.7540283203125  loc loss 13.295248031616211\n",
      "cls loss 623.0703735351562  loc loss 34.14224624633789\n",
      "cls loss 705.264404296875  loc loss 46.496551513671875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15., 85.])\n",
      "cls loss 485.9244689941406  loc loss 25.054597854614258\n",
      "cls loss 473.38140869140625  loc loss 32.40004348754883\n",
      "cls loss 481.727783203125  loc loss 30.853565216064453\n",
      "cls loss 382.6767883300781  loc loss 22.297134399414062\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 8., 8.])\n",
      "cls loss 289.7759094238281  loc loss 10.177093505859375\n",
      "cls loss 272.2251281738281  loc loss 20.070756912231445\n",
      "cls loss 350.53240966796875  loc loss 18.976924896240234\n",
      "cls loss 307.03179931640625  loc loss 15.65578842163086\n",
      "cls loss 328.99005126953125  loc loss 17.836719512939453\n",
      "cls loss 482.4898376464844  loc loss 26.071678161621094\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1., 35., 27., 27.,  1., 27.,  1.])\n",
      "cls loss 517.593017578125  loc loss 39.42905044555664\n",
      "cls loss 323.203125  loc loss 15.795089721679688\n",
      "cls loss 335.0865478515625  loc loss 24.191377639770508\n",
      "cls loss 340.0632019042969  loc loss 27.225278854370117\n",
      "cls loss 312.360107421875  loc loss 18.77920150756836\n",
      "cls loss 346.551513671875  loc loss 24.55011558532715\n",
      "cls loss 342.4446105957031  loc loss 24.22842788696289\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  2.,  2.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  2.,  2.])\n",
      "cls loss 164.47491455078125  loc loss 7.861059188842773\n",
      "cls loss 549.8118896484375  loc loss 32.97136306762695\n",
      "cls loss 333.09515380859375  loc loss 14.924591064453125\n",
      "cls loss 607.9935302734375  loc loss 41.24700927734375\n",
      "cls loss 233.75286865234375  loc loss 12.637857437133789\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 19., 19., 19., 16.])\n",
      "cls loss 240.23545837402344  loc loss 8.42192554473877\n",
      "cls loss 211.69906616210938  loc loss 7.9764251708984375\n",
      "cls loss 344.0047607421875  loc loss 14.5645112991333\n",
      "cls loss 449.0072326660156  loc loss 26.490772247314453\n",
      "cls loss 176.3281707763672  loc loss 11.848098754882812\n",
      "cls loss 479.8713684082031  loc loss 36.14725112915039\n",
      "cls loss 353.8268127441406  loc loss 21.484289169311523\n",
      "cls loss 367.271240234375  loc loss 23.43568992614746\n",
      "cls loss 475.71282958984375  loc loss 29.568546295166016\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 467.86419677734375  loc loss 21.541221618652344\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 677.2537841796875  loc loss 53.894935607910156\n",
      "cls loss 875.61376953125  loc loss 74.66488647460938\n",
      "cls loss 413.6856384277344  loc loss 23.593149185180664\n",
      "cls loss 388.66156005859375  loc loss 22.293455123901367\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3.,  3.,  3.,  3.,  3., 10.])\n",
      "cls loss 184.99452209472656  loc loss 11.763612747192383\n",
      "cls loss 423.071533203125  loc loss 18.8482666015625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 1., 1., 1., 3., 3., 3., 3.])\n",
      "cls loss 349.5108337402344  loc loss 15.869462966918945\n",
      "cls loss 681.544677734375  loc loss 39.166099548339844\n",
      "cls loss 564.67822265625  loc loss 27.232421875\n",
      "cls loss 357.5106201171875  loc loss 18.037006378173828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 532.583251953125  loc loss 33.547576904296875\n",
      "cls loss 307.8619384765625  loc loss 20.19499969482422\n",
      "cls loss 505.6671447753906  loc loss 32.18961715698242\n",
      "cls loss 378.6875  loc loss 32.52817153930664\n",
      "cls loss 343.7003479003906  loc loss 22.733917236328125\n",
      "cls loss 776.8028564453125  loc loss 58.68766403198242\n",
      "cls loss 497.04278564453125  loc loss 37.44535827636719\n",
      "cls loss 317.8124084472656  loc loss 16.270902633666992\n",
      "cls loss 189.41966247558594  loc loss 8.961920738220215\n",
      "cls loss 251.253662109375  loc loss 12.017640113830566\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3., 10., 10., 10., 10., 10., 10., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10., 10., 10., 10., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 11., 10., 10., 10., 10., 10.,  3.,  3.,  3.,  3.,  3.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 11., 10., 10., 10., 10., 10.,  3.,  3.,  3.,  3.,  3.])\n",
      "cls loss 191.63572692871094  loc loss 9.017230987548828\n",
      "cls loss 274.08819580078125  loc loss 11.193395614624023\n",
      "cls loss 246.5228729248047  loc loss 13.26766300201416\n",
      "cls loss 236.05831909179688  loc loss 10.136305809020996\n",
      "cls loss 315.76495361328125  loc loss 22.850711822509766\n",
      "cls loss 225.9510498046875  loc loss 9.229148864746094\n",
      "cls loss 492.3450927734375  loc loss 28.56687355041504\n",
      "cls loss 465.477783203125  loc loss 22.65872573852539\n",
      "cls loss 663.6397094726562  loc loss 36.136959075927734\n",
      "cls loss 339.35369873046875  loc loss 21.330829620361328\n",
      "cls loss 572.4537353515625  loc loss 33.931434631347656\n",
      "cls loss 428.5709228515625  loc loss 29.843429565429688\n",
      "cls loss 433.8482666015625  loc loss 26.16543960571289\n",
      "cls loss 413.543701171875  loc loss 27.315778732299805\n",
      "cls loss 529.171630859375  loc loss 34.13914489746094\n",
      "cls loss 507.83563232421875  loc loss 32.65503692626953\n",
      "cls loss 240.7661895751953  loc loss 12.775694847106934\n",
      "cls loss 514.5323486328125  loc loss 31.56144905090332\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 10.,  1., 18.])\n",
      "cls loss 216.96917724609375  loc loss 14.733160972595215\n",
      "cls loss 251.5411376953125  loc loss 12.04401683807373\n",
      "cls loss 474.08380126953125  loc loss 25.527000427246094\n",
      "cls loss 672.7906494140625  loc loss 37.43772888183594\n",
      "cls loss 403.79302978515625  loc loss 26.090665817260742\n",
      "cls loss 624.7485961914062  loc loss 27.326213836669922\n",
      "cls loss 487.5960693359375  loc loss 27.964750289916992\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.,  1.,  1.])\n",
      "cls loss 554.931884765625  loc loss 30.107633590698242\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1., 38.,  1.])\n",
      "cls loss 470.9049072265625  loc loss 25.488039016723633\n",
      "cls loss 670.019287109375  loc loss 46.51421356201172\n",
      "cls loss 363.2900085449219  loc loss 22.94668960571289\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 483.7038879394531  loc loss 25.71697998046875\n",
      "cls loss 390.06756591796875  loc loss 22.016355514526367\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3., 10.,  8.,  3., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.])\n",
      "cls loss 432.31195068359375  loc loss 24.266773223876953\n",
      "cls loss 289.0635986328125  loc loss 19.10839080810547\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3.,  3., 11.,  3., 10., 10.,  3.,  3., 10.])\n",
      "cls loss 286.08447265625  loc loss 17.270584106445312\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3., 10., 10., 10.])\n",
      "cls loss 363.7697448730469  loc loss 18.6611270904541\n",
      "cls loss 280.16461181640625  loc loss 18.949995040893555\n",
      "cls loss 383.2193603515625  loc loss 26.003734588623047\n",
      "cls loss 559.3202514648438  loc loss 32.56523895263672\n",
      "cls loss 366.69305419921875  loc loss 22.839263916015625\n",
      "cls loss 294.8223876953125  loc loss 20.585712432861328\n",
      "cls loss 372.6326904296875  loc loss 20.300527572631836\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 9.,  9., 85., 85.])\n",
      "cls loss 322.2601318359375  loc loss 13.527982711791992\n",
      "cls loss 413.12060546875  loc loss 24.98981285095215\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 607.0579833984375  loc loss 34.565956115722656\n",
      "cls loss 504.509765625  loc loss 20.2777099609375\n",
      "cls loss 586.1146240234375  loc loss 37.753631591796875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10., 10., 10., 10.])\n",
      "cls loss 380.1844787597656  loc loss 21.75924301147461\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([13.])\n",
      "cls loss 579.9192504882812  loc loss 41.36143493652344\n",
      "cls loss 153.7436065673828  loc loss 8.783419609069824\n",
      "cls loss 234.37149047851562  loc loss 11.75253677368164\n",
      "cls loss 299.96966552734375  loc loss 18.205303192138672\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19.,  1.,  1.,  1., 19., 19.])\n",
      "cls loss 327.027587890625  loc loss 21.041181564331055\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 264.9608154296875  loc loss 17.03830337524414\n",
      "cls loss 407.54376220703125  loc loss 26.252309799194336\n",
      "cls loss 310.0465393066406  loc loss 16.27798843383789\n",
      "cls loss 441.59576416015625  loc loss 21.099178314208984\n",
      "cls loss 475.35125732421875  loc loss 31.731115341186523\n",
      "cls loss 359.81671142578125  loc loss 19.77935791015625\n",
      "cls loss 592.5355224609375  loc loss 38.11502456665039\n",
      "cls loss 206.68753051757812  loc loss 8.123817443847656\n",
      "cls loss 382.70526123046875  loc loss 24.070833206176758\n",
      "cls loss 322.7978210449219  loc loss 16.831186294555664\n",
      "cls loss 355.319580078125  loc loss 16.596588134765625\n",
      "cls loss 478.3061828613281  loc loss 24.95602798461914\n",
      "cls loss 375.20489501953125  loc loss 16.681123733520508\n",
      "cls loss 539.2528076171875  loc loss 34.82450866699219\n",
      "cls loss 348.8086853027344  loc loss 19.957632064819336\n",
      "cls loss 448.46331787109375  loc loss 31.086441040039062\n",
      "cls loss 649.3958129882812  loc loss 37.53939437866211\n",
      "cls loss 348.8860168457031  loc loss 25.30760955810547\n",
      "cls loss 421.57354736328125  loc loss 22.615327835083008\n",
      "cls loss 499.10418701171875  loc loss 37.35866928100586\n",
      "cls loss 591.6632080078125  loc loss 37.426090240478516\n",
      "cls loss 640.3222045898438  loc loss 36.45764923095703\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 5.])\n",
      "cls loss 159.91256713867188  loc loss 8.176422119140625\n",
      "cls loss 242.41748046875  loc loss 9.402207374572754\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 13.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 6., 8., 8.])\n",
      "cls loss 188.37350463867188  loc loss 9.532432556152344\n",
      "cls loss 251.743408203125  loc loss 11.456857681274414\n",
      "cls loss 489.9855651855469  loc loss 29.342424392700195\n",
      "cls loss 204.09347534179688  loc loss 11.064661026000977\n",
      "cls loss 423.047119140625  loc loss 28.199556350708008\n",
      "cls loss 630.179443359375  loc loss 43.424774169921875\n",
      "cls loss 406.241455078125  loc loss 24.976818084716797\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([42., 42.,  1.,  1.,  1.,  1.,  1.,  1.,  1., 42., 42.])\n",
      "cls loss 426.8690185546875  loc loss 20.525978088378906\n",
      "cls loss 541.5580444335938  loc loss 38.89645767211914\n",
      "cls loss 499.0115966796875  loc loss 31.485736846923828\n",
      "cls loss 314.916015625  loc loss 18.28606414794922\n",
      "cls loss 413.91387939453125  loc loss 20.823726654052734\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 636.9222412109375  loc loss 36.290733337402344\n",
      "cls loss 506.8685302734375  loc loss 31.45811653137207\n",
      "cls loss 300.55645751953125  loc loss 14.458582878112793\n",
      "cls loss 256.4591979980469  loc loss 13.74496841430664\n",
      "cls loss 338.82122802734375  loc loss 19.971656799316406\n",
      "cls loss 458.76116943359375  loc loss 27.828338623046875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15.])\n",
      "cls loss 221.53167724609375  loc loss 6.877458095550537\n",
      "cls loss 389.7723388671875  loc loss 21.760658264160156\n",
      "cls loss 347.4898681640625  loc loss 19.973873138427734\n",
      "cls loss 624.324462890625  loc loss 35.96455001831055\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19.,  7.])\n",
      "cls loss 286.18084716796875  loc loss 16.34379768371582\n",
      "cls loss 570.3317260742188  loc loss 39.45304870605469\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 520.880126953125  loc loss 26.733644485473633\n",
      "cls loss 491.66094970703125  loc loss 31.018932342529297\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([38., 38.,  1., 18.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1., 18., 18.,  1.])\n",
      "cls loss 323.7305908203125  loc loss 17.383907318115234\n",
      "cls loss 314.82635498046875  loc loss 15.294520378112793\n",
      "cls loss 622.9498291015625  loc loss 41.3310661315918\n",
      "cls loss 450.13043212890625  loc loss 28.352916717529297\n",
      "cls loss 371.9418640136719  loc loss 23.87387466430664\n",
      "cls loss 261.68792724609375  loc loss 17.32391357421875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 154.1602020263672  loc loss 6.363687992095947\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([32.])\n",
      "cls loss 406.719970703125  loc loss 19.750764846801758\n",
      "cls loss 361.181884765625  loc loss 22.404085159301758\n",
      "cls loss 444.45281982421875  loc loss 30.872915267944336\n",
      "cls loss 393.8294677734375  loc loss 23.133636474609375\n",
      "cls loss 334.8577575683594  loc loss 17.677871704101562\n",
      "cls loss 535.6095581054688  loc loss 28.876956939697266\n",
      "cls loss 634.6973876953125  loc loss 37.41092300415039\n",
      "cls loss 454.267578125  loc loss 29.469470977783203\n",
      "cls loss 341.0064392089844  loc loss 20.410484313964844\n",
      "cls loss 557.627685546875  loc loss 35.03689956665039\n",
      "cls loss 369.4268798828125  loc loss 19.285863876342773\n",
      "cls loss 665.2037353515625  loc loss 40.626346588134766\n",
      "cls loss 442.7397766113281  loc loss 22.90639305114746\n",
      "cls loss 350.6944274902344  loc loss 27.22486686706543\n",
      "cls loss 271.82781982421875  loc loss 12.769577026367188\n",
      "cls loss 322.68914794921875  loc loss 19.396726608276367\n",
      "cls loss 460.4580078125  loc loss 30.298622131347656\n",
      "cls loss 529.8084716796875  loc loss 35.48860549926758\n",
      "cls loss 323.545654296875  loc loss 19.07030487060547\n",
      "cls loss 510.36004638671875  loc loss 34.16738510131836\n",
      "cls loss 614.202880859375  loc loss 36.616912841796875\n",
      "cls loss 226.20281982421875  loc loss 13.292752265930176\n",
      "cls loss 598.4368896484375  loc loss 37.73520278930664\n",
      "cls loss 447.4991149902344  loc loss 27.937156677246094\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 581.9837036132812  loc loss 40.63444137573242\n",
      "cls loss 243.11842346191406  loc loss 10.000466346740723\n",
      "cls loss 373.04168701171875  loc loss 21.58423614501953\n",
      "cls loss 378.99957275390625  loc loss 25.579463958740234\n",
      "cls loss 319.35772705078125  loc loss 19.690807342529297\n",
      "cls loss 184.94711303710938  loc loss 10.510566711425781\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 9., 9., 1., 9., 9., 9., 9., 1., 9.])\n",
      "cls loss 845.4007568359375  loc loss 53.31996154785156\n",
      "cls loss 455.1066589355469  loc loss 23.20885467529297\n",
      "cls loss 712.0726928710938  loc loss 48.43124771118164\n",
      "cls loss 277.2124938964844  loc loss 20.361690521240234\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 42., 42.])\n",
      "cls loss 457.77197265625  loc loss 32.81333923339844\n",
      "cls loss 467.5667724609375  loc loss 35.264930725097656\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  2.,  1.,  1.,  1., 38.,\n",
      "         1.,  1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 38., 38., 38.,  1., 38., 38., 38.,  1.,  1., 38.,  1.,\n",
      "         1.])\n",
      "cls loss 278.7887268066406  loc loss 20.550121307373047\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  8.,  8.])\n",
      "cls loss 653.8955078125  loc loss 43.65375518798828\n",
      "cls loss 668.1560668945312  loc loss 50.14923858642578\n",
      "cls loss 241.63255310058594  loc loss 15.126924514770508\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([4., 1., 1., 4.])\n",
      "cls loss 390.83428955078125  loc loss 23.682453155517578\n",
      "cls loss 498.1307678222656  loc loss 28.02692413330078\n",
      "cls loss 197.40264892578125  loc loss 9.950756072998047\n",
      "cls loss 247.15577697753906  loc loss 15.41079044342041\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([51.,  1.])\n",
      "cls loss 175.28128051757812  loc loss 8.020539283752441\n",
      "cls loss 252.19119262695312  loc loss 15.29465103149414\n",
      "cls loss 532.3424072265625  loc loss 23.690275192260742\n",
      "cls loss 489.6614685058594  loc loss 31.721532821655273\n",
      "cls loss 759.8311157226562  loc loss 35.01768493652344\n",
      "cls loss 892.9166259765625  loc loss 55.40485382080078\n",
      "cls loss 366.19744873046875  loc loss 22.498140335083008\n",
      "cls loss 540.8961791992188  loc loss 38.558040618896484\n",
      "cls loss 591.0911865234375  loc loss 36.83348846435547\n",
      "cls loss 423.39569091796875  loc loss 25.456892013549805\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  3.,  1.,  1.,  1.,  3.,  1.,  1.,\n",
      "         1.,  1.,  1.])\n",
      "cls loss 460.1822509765625  loc loss 18.77937126159668\n",
      "cls loss 487.4552001953125  loc loss 25.571643829345703\n",
      "cls loss 484.29327392578125  loc loss 22.529823303222656\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "cls loss 409.8117370605469  loc loss 22.066368103027344\n",
      "cls loss 228.8150634765625  loc loss 17.306346893310547\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3.])\n",
      "cls loss 182.55209350585938  loc loss 9.70663070678711\n",
      "cls loss 318.6614685058594  loc loss 17.969274520874023\n",
      "cls loss 308.26959228515625  loc loss 19.310453414916992\n",
      "cls loss 554.2958984375  loc loss 33.33176803588867\n",
      "cls loss 248.54054260253906  loc loss 17.881099700927734\n",
      "cls loss 290.06268310546875  loc loss 22.263992309570312\n",
      "cls loss 823.566650390625  loc loss 53.41429138183594\n",
      "cls loss 374.9361572265625  loc loss 26.87176513671875\n",
      "cls loss 279.5888671875  loc loss 18.65061378479004\n",
      "cls loss 328.6935729980469  loc loss 17.75803565979004\n",
      "cls loss 299.2955627441406  loc loss 21.39287567138672\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 556.3748779296875  loc loss 36.87982177734375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  9., 64., 64., 64., 64., 64., 64., 64., 64., 64.,  9.,  9.,  9.,\n",
      "         9.])\n",
      "cls loss 254.52391052246094  loc loss 12.5756196975708\n",
      "cls loss 817.5462646484375  loc loss 57.91688919067383\n",
      "cls loss 430.12286376953125  loc loss 26.355390548706055\n",
      "cls loss 509.953125  loc loss 32.13048553466797\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.,  3.,  3.])\n",
      "cls loss 322.01251220703125  loc loss 16.876951217651367\n",
      "cls loss 346.8472595214844  loc loss 23.25023651123047\n",
      "cls loss 368.3802795410156  loc loss 24.902801513671875\n",
      "cls loss 376.3636779785156  loc loss 24.31238555908203\n",
      "cls loss 436.1783752441406  loc loss 27.927505493164062\n",
      "cls loss 436.8856201171875  loc loss 26.376266479492188\n",
      "cls loss 391.5335388183594  loc loss 25.230640411376953\n",
      "cls loss 396.40185546875  loc loss 20.878896713256836\n",
      "cls loss 494.7254638671875  loc loss 31.186742782592773\n",
      "cls loss 363.9026184082031  loc loss 21.145938873291016\n",
      "cls loss 274.3741455078125  loc loss 14.250752449035645\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21.])\n",
      "cls loss 225.37725830078125  loc loss 14.28830623626709\n",
      "cls loss 322.00872802734375  loc loss 26.795974731445312\n",
      "cls loss 480.6558837890625  loc loss 32.550174713134766\n",
      "cls loss 243.6611328125  loc loss 14.214776039123535\n",
      "cls loss 393.0958557128906  loc loss 25.10904884338379\n",
      "cls loss 725.3424072265625  loc loss 37.1083869934082\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 42., 42.,  1.,  1.])\n",
      "cls loss 438.29296875  loc loss 23.036819458007812\n",
      "cls loss 283.85894775390625  loc loss 16.31836700439453\n",
      "cls loss 405.8240966796875  loc loss 23.187408447265625\n",
      "cls loss 539.9974975585938  loc loss 38.78440475463867\n",
      "cls loss 338.82330322265625  loc loss 18.365020751953125\n",
      "cls loss 519.8576049804688  loc loss 33.66095733642578\n",
      "cls loss 454.2625732421875  loc loss 29.893856048583984\n",
      "cls loss 444.259521484375  loc loss 27.62795639038086\n",
      "cls loss 358.68212890625  loc loss 21.71858024597168\n",
      "cls loss 288.9478454589844  loc loss 18.710208892822266\n",
      "cls loss 227.93321228027344  loc loss 10.62543773651123\n",
      "cls loss 362.6419677734375  loc loss 23.04845428466797\n",
      "cls loss 555.116455078125  loc loss 33.583866119384766\n",
      "cls loss 400.25543212890625  loc loss 23.304636001586914\n",
      "cls loss 386.16912841796875  loc loss 26.615571975708008\n",
      "cls loss 420.887939453125  loc loss 24.16328239440918\n",
      "cls loss 624.6620483398438  loc loss 44.257808685302734\n",
      "cls loss 504.55029296875  loc loss 31.71932029724121\n",
      "cls loss 546.4430541992188  loc loss 28.26892852783203\n",
      "cls loss 344.3255920410156  loc loss 14.424193382263184\n",
      "cls loss 479.178955078125  loc loss 26.410451889038086\n",
      "cls loss 432.6824645996094  loc loss 23.51777458190918\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 5., 5., 5., 5., 5., 5.])\n",
      "cls loss 264.6431579589844  loc loss 15.625951766967773\n",
      "cls loss 349.4962158203125  loc loss 17.799236297607422\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([13.])\n",
      "cls loss 249.52001953125  loc loss 11.198883056640625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([44., 10.,  1.,  1.,  1.])\n",
      "cls loss 222.83184814453125  loc loss 14.663991928100586\n",
      "cls loss 391.4752502441406  loc loss 21.435237884521484\n",
      "cls loss 364.2012939453125  loc loss 19.216236114501953\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19., 19., 19., 19., 19., 19., 19.])\n",
      "cls loss 379.78948974609375  loc loss 22.72087287902832\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([56.])\n",
      "cls loss 809.2975463867188  loc loss 52.340877532958984\n",
      "cls loss 515.0184936523438  loc loss 36.7120246887207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 654.2949829101562  loc loss 39.97971725463867\n",
      "cls loss 626.3330078125  loc loss 45.78324890136719\n",
      "cls loss 379.3078918457031  loc loss 20.7652530670166\n",
      "cls loss 644.9246826171875  loc loss 39.465545654296875\n",
      "cls loss 364.61700439453125  loc loss 24.49441146850586\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 36.])\n",
      "cls loss 477.45770263671875  loc loss 20.730501174926758\n",
      "cls loss 395.46173095703125  loc loss 23.675411224365234\n",
      "cls loss 373.8211669921875  loc loss 21.53205108642578\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5.])\n",
      "cls loss 441.3955078125  loc loss 25.110916137695312\n",
      "cls loss 239.941650390625  loc loss 11.26185417175293\n",
      "cls loss 556.00048828125  loc loss 29.1608943939209\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "cls loss 491.0732421875  loc loss 28.614910125732422\n",
      "cls loss 455.10430908203125  loc loss 28.351993560791016\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 481.72918701171875  loc loss 29.106403350830078\n",
      "cls loss 546.8165283203125  loc loss 32.54362106323242\n",
      "cls loss 468.3584899902344  loc loss 37.49958038330078\n",
      "cls loss 322.88934326171875  loc loss 20.223262786865234\n",
      "cls loss 361.13812255859375  loc loss 25.696853637695312\n",
      "cls loss 379.28753662109375  loc loss 21.666833877563477\n",
      "cls loss 639.623046875  loc loss 30.5047664642334\n",
      "cls loss 255.1856689453125  loc loss 12.86388111114502\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 11., 15., 10., 10., 10., 10., 10.])\n",
      "cls loss 577.6119995117188  loc loss 36.76544189453125\n",
      "cls loss 348.77960205078125  loc loss 24.981033325195312\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3.])\n",
      "cls loss 362.5599365234375  loc loss 25.969995498657227\n",
      "cls loss 350.01812744140625  loc loss 16.955835342407227\n",
      "cls loss 387.22003173828125  loc loss 17.795673370361328\n",
      "cls loss 500.80523681640625  loc loss 20.258577346801758\n",
      "cls loss 223.53369140625  loc loss 10.054786682128906\n",
      "cls loss 404.9930114746094  loc loss 24.791894912719727\n",
      "cls loss 465.5630187988281  loc loss 28.403057098388672\n",
      "cls loss 403.486572265625  loc loss 25.426708221435547\n",
      "cls loss 937.41943359375  loc loss 56.98695373535156\n",
      "cls loss 621.951171875  loc loss 38.23674392700195\n",
      "cls loss 389.21612548828125  loc loss 25.411457061767578\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  9.,  9.,  9.,  6.,  6., 85., 85.,  8.,  1.,  1.,  1.,  1.,\n",
      "         6.,  6.])\n",
      "cls loss 259.5014953613281  loc loss 20.199506759643555\n",
      "cls loss 655.2406005859375  loc loss 44.548255920410156\n",
      "cls loss 764.98388671875  loc loss 44.91870880126953\n",
      "cls loss 484.0886535644531  loc loss 33.37435531616211\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10.,  3.,  3., 10.])\n",
      "cls loss 307.6362609863281  loc loss 16.661609649658203\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([7.])\n",
      "cls loss 402.76324462890625  loc loss 24.97412872314453\n",
      "cls loss 392.197021484375  loc loss 24.30389404296875\n",
      "cls loss 413.7049255371094  loc loss 34.38899230957031\n",
      "cls loss 683.0521240234375  loc loss 45.212196350097656\n",
      "cls loss 382.63787841796875  loc loss 24.43436050415039\n",
      "cls loss 596.2772216796875  loc loss 34.95586395263672\n",
      "cls loss 738.8695068359375  loc loss 38.986629486083984\n",
      "cls loss 482.33050537109375  loc loss 25.570371627807617\n",
      "cls loss 536.3077392578125  loc loss 30.878189086914062\n",
      "cls loss 399.4815979003906  loc loss 26.213985443115234\n",
      "cls loss 579.1162719726562  loc loss 39.845542907714844\n",
      "cls loss 440.616943359375  loc loss 27.225685119628906\n",
      "cls loss 315.7462463378906  loc loss 19.90879249572754\n",
      "cls loss 511.3429870605469  loc loss 36.405635833740234\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([62.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([62.])\n",
      "cls loss 228.57131958007812  loc loss 10.7243070602417\n",
      "cls loss 358.6111755371094  loc loss 26.60391616821289\n",
      "cls loss 371.58294677734375  loc loss 23.651424407958984\n",
      "cls loss 237.0730743408203  loc loss 11.619247436523438\n",
      "cls loss 506.7474365234375  loc loss 31.694116592407227\n",
      "cls loss 515.0389404296875  loc loss 28.254972457885742\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([28.])\n",
      "cls loss 654.1624755859375  loc loss 29.149986267089844\n",
      "cls loss 482.51123046875  loc loss 29.832420349121094\n",
      "cls loss 481.8775634765625  loc loss 32.264732360839844\n",
      "cls loss 543.7447509765625  loc loss 30.247900009155273\n",
      "cls loss 798.90234375  loc loss 43.79597091674805\n",
      "cls loss 456.36956787109375  loc loss 24.112951278686523\n",
      "cls loss 618.7669677734375  loc loss 28.174795150756836\n",
      "cls loss 490.87261962890625  loc loss 32.79018783569336\n",
      "cls loss 759.6158447265625  loc loss 54.67565155029297\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([81.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 454.2440185546875  loc loss 17.49667739868164\n",
      "cls loss 349.11004638671875  loc loss 17.620559692382812\n",
      "cls loss 251.33587646484375  loc loss 17.90290069580078\n",
      "cls loss 225.16627502441406  loc loss 10.043844223022461\n",
      "cls loss 253.88009643554688  loc loss 19.33453369140625\n",
      "cls loss 318.100341796875  loc loss 20.143959045410156\n",
      "cls loss 326.9704895019531  loc loss 22.919689178466797\n",
      "cls loss 486.7043151855469  loc loss 38.36878967285156\n",
      "cls loss 584.7474365234375  loc loss 33.42290115356445\n",
      "cls loss 997.7999877929688  loc loss 64.41598510742188\n",
      "cls loss 394.394287109375  loc loss 17.893831253051758\n",
      "cls loss 503.0896301269531  loc loss 35.510902404785156\n",
      "cls loss 353.3153076171875  loc loss 20.72060203552246\n",
      "cls loss 479.2283935546875  loc loss 24.7391300201416\n",
      "cls loss 426.4299621582031  loc loss 22.740964889526367\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([44., 44.])\n",
      "cls loss 393.2880859375  loc loss 17.181537628173828\n",
      "cls loss 439.8197021484375  loc loss 25.48455810546875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15.])\n",
      "cls loss 410.973876953125  loc loss 20.212196350097656\n",
      "cls loss 239.71697998046875  loc loss 12.243842124938965\n",
      "cls loss 412.4306335449219  loc loss 25.592126846313477\n",
      "cls loss 245.2685089111328  loc loss 11.529729843139648\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([1., 3., 3.])\n",
      "cls loss 273.5730285644531  loc loss 15.59923267364502\n",
      "cls loss 194.07508850097656  loc loss 9.086649894714355\n",
      "cls loss 369.0701904296875  loc loss 25.408008575439453\n",
      "cls loss 443.79583740234375  loc loss 23.144989013671875\n",
      "cls loss 377.6019287109375  loc loss 25.545425415039062\n",
      "cls loss 316.6756591796875  loc loss 20.00249671936035\n",
      "cls loss 349.1069641113281  loc loss 23.459796905517578\n",
      "cls loss 467.8086853027344  loc loss 29.628284454345703\n",
      "cls loss 309.8951721191406  loc loss 20.561290740966797\n",
      "cls loss 408.07501220703125  loc loss 30.030881881713867\n",
      "cls loss 292.33062744140625  loc loss 16.498043060302734\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 537.5427856445312  loc loss 28.38966178894043\n",
      "cls loss 653.3098754882812  loc loss 25.489728927612305\n",
      "cls loss 557.508544921875  loc loss 34.96427917480469\n",
      "cls loss 553.152587890625  loc loss 40.575077056884766\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10., 10., 10.,  1.,  1.,  1.,  1.,  1.,  1.,  8.,  8.,\n",
      "         1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10., 10., 10.,  1.,  1.,  1.,  1.,  1.,  1.,  8.,  8.,\n",
      "         1.])\n",
      "cls loss 433.0762939453125  loc loss 21.63932228088379\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 3., 3., 3.])\n",
      "cls loss 438.1082458496094  loc loss 23.592103958129883\n",
      "cls loss 270.70806884765625  loc loss 16.958175659179688\n",
      "cls loss 206.43914794921875  loc loss 9.997414588928223\n",
      "cls loss 406.37103271484375  loc loss 29.114704132080078\n",
      "cls loss 293.96630859375  loc loss 12.765440940856934\n",
      "cls loss 370.7191162109375  loc loss 23.859241485595703\n",
      "cls loss 414.1319580078125  loc loss 28.105995178222656\n",
      "cls loss 547.8556518554688  loc loss 38.4522705078125\n",
      "cls loss 480.3357238769531  loc loss 23.958162307739258\n",
      "cls loss 431.9952392578125  loc loss 23.13101577758789\n",
      "cls loss 448.88372802734375  loc loss 28.847980499267578\n",
      "cls loss 322.4735107421875  loc loss 23.336896896362305\n",
      "cls loss 669.2884521484375  loc loss 45.93708801269531\n",
      "cls loss 278.7750549316406  loc loss 15.368080139160156\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 538.97412109375  loc loss 29.656394958496094\n",
      "cls loss 223.33230590820312  loc loss 8.943477630615234\n",
      "cls loss 580.3659057617188  loc loss 38.00016403198242\n",
      "cls loss 294.711669921875  loc loss 17.845781326293945\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 34.])\n",
      "cls loss 491.7864074707031  loc loss 25.096281051635742\n",
      "cls loss 268.47528076171875  loc loss 15.30722713470459\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 538.0910034179688  loc loss 27.007566452026367\n",
      "cls loss 196.2620849609375  loc loss 11.43282413482666\n",
      "cls loss 404.7456359863281  loc loss 22.580677032470703\n",
      "cls loss 397.89630126953125  loc loss 30.258460998535156\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 38.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16., 16., 16.,  9.,  9.,  9., 16., 16., 16., 85.,  9.])\n",
      "cls loss 412.1434326171875  loc loss 23.00229263305664\n",
      "cls loss 444.16461181640625  loc loss 31.393436431884766\n",
      "cls loss 597.177001953125  loc loss 36.50712585449219\n",
      "cls loss 930.2827758789062  loc loss 54.760498046875\n",
      "cls loss 232.25563049316406  loc loss 12.90335464477539\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3., 10.,  8.,  8., 10., 10., 10.,  3.,  3., 14.])\n",
      "cls loss 253.80625915527344  loc loss 14.53125286102295\n",
      "cls loss 468.0991516113281  loc loss 29.921262741088867\n",
      "cls loss 195.06546020507812  loc loss 8.038254737854004\n",
      "cls loss 345.635009765625  loc loss 15.0400390625\n",
      "cls loss 475.5286865234375  loc loss 29.806781768798828\n",
      "cls loss 403.6954650878906  loc loss 22.792896270751953\n",
      "cls loss 234.86483764648438  loc loss 12.457908630371094\n",
      "cls loss 314.66259765625  loc loss 14.389890670776367\n",
      "cls loss 535.8256225585938  loc loss 26.459009170532227\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42., 42.,  1.])\n",
      "cls loss 486.7869873046875  loc loss 26.16267204284668\n",
      "cls loss 410.1205139160156  loc loss 19.536880493164062\n",
      "cls loss 510.65557861328125  loc loss 34.65379333496094\n",
      "cls loss 567.5164184570312  loc loss 32.09221267700195\n",
      "cls loss 385.1318359375  loc loss 21.487075805664062\n",
      "cls loss 461.4541320800781  loc loss 32.05022430419922\n",
      "cls loss 273.47125244140625  loc loss 17.923200607299805\n",
      "cls loss 297.46807861328125  loc loss 21.380510330200195\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20.])\n",
      "cls loss 213.91075134277344  loc loss 12.08343505859375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([11.])\n",
      "cls loss 305.6583251953125  loc loss 13.471269607543945\n",
      "cls loss 173.14654541015625  loc loss 10.66149616241455\n",
      "cls loss 464.40740966796875  loc loss 33.31251907348633\n",
      "cls loss 195.57452392578125  loc loss 9.64659595489502\n",
      "cls loss 408.468017578125  loc loss 24.731361389160156\n",
      "cls loss 224.72940063476562  loc loss 14.857799530029297\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 35., 27.])\n",
      "cls loss 414.9573974609375  loc loss 22.086071014404297\n",
      "cls loss 484.37939453125  loc loss 33.627685546875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 320.32623291015625  loc loss 15.480988502502441\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([42.,  1.])\n",
      "cls loss 413.47900390625  loc loss 24.223424911499023\n",
      "cls loss 437.95538330078125  loc loss 20.502126693725586\n",
      "cls loss 533.0034790039062  loc loss 26.767498016357422\n",
      "cls loss 672.867919921875  loc loss 30.830089569091797\n",
      "cls loss 538.5107421875  loc loss 27.57294464111328\n",
      "cls loss 376.9186706542969  loc loss 20.96607780456543\n",
      "cls loss 307.236083984375  loc loss 19.83283233642578\n",
      "cls loss 183.7296142578125  loc loss 7.460695743560791\n",
      "cls loss 328.1322021484375  loc loss 17.529403686523438\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 1., 1.])\n",
      "cls loss 313.9775085449219  loc loss 19.086111068725586\n",
      "cls loss 384.1644287109375  loc loss 23.95797348022461\n",
      "cls loss 368.66864013671875  loc loss 21.725263595581055\n",
      "cls loss 288.2913818359375  loc loss 20.092952728271484\n",
      "cls loss 359.2724609375  loc loss 23.26949119567871\n",
      "cls loss 379.02716064453125  loc loss 27.266525268554688\n",
      "cls loss 565.218017578125  loc loss 32.13270950317383\n",
      "cls loss 492.8214111328125  loc loss 35.00019836425781\n",
      "cls loss 425.7937927246094  loc loss 26.724058151245117\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 338.46954345703125  loc loss 23.062137603759766\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 483.836669921875  loc loss 17.851158142089844\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([81.])\n",
      "cls loss 560.69580078125  loc loss 26.879472732543945\n",
      "cls loss 323.3524169921875  loc loss 20.24549674987793\n",
      "cls loss 277.1960754394531  loc loss 11.1631498336792\n",
      "cls loss 360.0721435546875  loc loss 18.803373336791992\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3.,  1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 19.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 19.])\n",
      "cls loss 510.68621826171875  loc loss 30.791013717651367\n",
      "cls loss 266.06396484375  loc loss 14.820924758911133\n",
      "cls loss 290.66546630859375  loc loss 15.370039939880371\n",
      "cls loss 545.7344970703125  loc loss 37.8917236328125\n",
      "cls loss 264.5808410644531  loc loss 16.24665069580078\n",
      "cls loss 335.43328857421875  loc loss 19.325830459594727\n",
      "cls loss 425.3198547363281  loc loss 26.29525375366211\n",
      "cls loss 315.11688232421875  loc loss 21.695159912109375\n",
      "cls loss 429.288330078125  loc loss 22.25311279296875\n",
      "cls loss 460.8297119140625  loc loss 29.013010025024414\n",
      "cls loss 626.8671875  loc loss 51.51605987548828\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 81.])\n",
      "cls loss 414.5118713378906  loc loss 19.096330642700195\n",
      "cls loss 382.95538330078125  loc loss 19.634584426879883\n",
      "cls loss 384.85418701171875  loc loss 21.051097869873047\n",
      "cls loss 318.58984375  loc loss 15.412734985351562\n",
      "cls loss 286.6268615722656  loc loss 15.89421272277832\n",
      "cls loss 350.68292236328125  loc loss 23.128833770751953\n",
      "cls loss 251.52841186523438  loc loss 16.30658721923828\n",
      "cls loss 219.83493041992188  loc loss 13.159297943115234\n",
      "cls loss 279.7648620605469  loc loss 17.504114151000977\n",
      "cls loss 375.2947998046875  loc loss 22.555789947509766\n",
      "cls loss 354.3755187988281  loc loss 24.557170867919922\n",
      "cls loss 347.5689392089844  loc loss 21.783803939819336\n",
      "cls loss 207.20574951171875  loc loss 12.782489776611328\n",
      "cls loss 730.15771484375  loc loss 43.727210998535156\n",
      "cls loss 394.81024169921875  loc loss 25.268962860107422\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 354.4366455078125  loc loss 16.76382827758789\n",
      "cls loss 395.81536865234375  loc loss 24.274869918823242\n",
      "cls loss 283.28680419921875  loc loss 19.698322296142578\n",
      "cls loss 461.2581787109375  loc loss 32.72876739501953\n",
      "cls loss 455.4950256347656  loc loss 26.55219841003418\n",
      "cls loss 411.9752197265625  loc loss 24.346946716308594\n",
      "cls loss 306.670654296875  loc loss 20.605499267578125\n",
      "cls loss 282.53253173828125  loc loss 15.224939346313477\n",
      "cls loss 408.8995361328125  loc loss 20.557357788085938\n",
      "cls loss 489.9960632324219  loc loss 28.515342712402344\n",
      "cls loss 426.91009521484375  loc loss 21.655986785888672\n",
      "cls loss 564.6450805664062  loc loss 32.900291442871094\n",
      "cls loss 608.2056884765625  loc loss 39.495391845703125\n",
      "cls loss 409.17816162109375  loc loss 25.178110122680664\n",
      "cls loss 585.7957153320312  loc loss 42.212921142578125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1., 38., 47.,  1.,  1.,  1.,  1.,  1., 62.])\n",
      "cls loss 354.73663330078125  loc loss 16.375856399536133\n",
      "cls loss 420.3475341796875  loc loss 28.64567756652832\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 456.15557861328125  loc loss 25.702198028564453\n",
      "cls loss 523.778564453125  loc loss 36.17838668823242\n",
      "cls loss 338.7965393066406  loc loss 15.043810844421387\n",
      "cls loss 410.41436767578125  loc loss 30.074161529541016\n",
      "cls loss 395.6120300292969  loc loss 22.23659896850586\n",
      "cls loss 219.48289489746094  loc loss 7.250995635986328\n",
      "cls loss 335.9381103515625  loc loss 18.325618743896484\n",
      "cls loss 297.3432312011719  loc loss 12.10348892211914\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1., 35.])\n",
      "cls loss 323.697265625  loc loss 18.32172393798828\n",
      "cls loss 498.3223876953125  loc loss 24.551143646240234\n",
      "cls loss 510.0318908691406  loc loss 29.264781951904297\n",
      "cls loss 452.58837890625  loc loss 33.114952087402344\n",
      "cls loss 389.3904113769531  loc loss 25.515220642089844\n",
      "cls loss 497.301025390625  loc loss 34.31317138671875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 273.6545715332031  loc loss 13.842501640319824\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 382.3321533203125  loc loss 15.253118515014648\n",
      "cls loss 580.0147705078125  loc loss 31.199308395385742\n",
      "cls loss 740.0745849609375  loc loss 55.71815872192383\n",
      "cls loss 360.9858093261719  loc loss 18.232681274414062\n",
      "cls loss 312.39300537109375  loc loss 18.032405853271484\n",
      "cls loss 324.0868835449219  loc loss 15.68875789642334\n",
      "cls loss 366.0855712890625  loc loss 18.438257217407227\n",
      "cls loss 314.8984375  loc loss 12.676959991455078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 579.0465698242188  loc loss 34.424095153808594\n",
      "cls loss 485.72998046875  loc loss 26.7288818359375\n",
      "cls loss 212.98291015625  loc loss 14.440478324890137\n",
      "cls loss 438.4159851074219  loc loss 24.60626792907715\n",
      "cls loss 592.1888427734375  loc loss 40.84383773803711\n",
      "cls loss 443.59783935546875  loc loss 28.069936752319336\n",
      "cls loss 393.7261047363281  loc loss 21.997127532958984\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.])\n",
      "cls loss 371.63592529296875  loc loss 25.249361038208008\n",
      "cls loss 384.04388427734375  loc loss 23.008243560791016\n",
      "cls loss 460.9004821777344  loc loss 25.975887298583984\n",
      "cls loss 769.3861083984375  loc loss 54.09986877441406\n",
      "cls loss 274.0638427734375  loc loss 13.387502670288086\n",
      "cls loss 365.3768005371094  loc loss 21.631832122802734\n",
      "cls loss 286.3512268066406  loc loss 15.855461120605469\n",
      "cls loss 328.466796875  loc loss 21.1263427734375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 21., 21., 21.])\n",
      "cls loss 312.45159912109375  loc loss 19.645599365234375\n",
      "cls loss 333.8634033203125  loc loss 16.09130096435547\n",
      "cls loss 339.16552734375  loc loss 21.74608039855957\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 35.])\n",
      "cls loss 464.64990234375  loc loss 25.724578857421875\n",
      "cls loss 171.24891662597656  loc loss 8.809982299804688\n",
      "cls loss 318.9854431152344  loc loss 16.568361282348633\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 295.5925598144531  loc loss 11.243687629699707\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 38., 38.,  9., 38.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1.,  1.])\n",
      "cls loss 327.23687744140625  loc loss 18.53131103515625\n",
      "cls loss 543.54833984375  loc loss 29.577125549316406\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 2.,  1., 77., 31., 10., 10.,  1.,  4., 10.])\n",
      "cls loss 246.11846923828125  loc loss 10.671671867370605\n",
      "cls loss 494.08013916015625  loc loss 27.664836883544922\n",
      "cls loss 989.887451171875  loc loss 53.04822540283203\n",
      "cls loss 308.9527893066406  loc loss 20.940723419189453\n",
      "cls loss 425.0040588378906  loc loss 29.48552703857422\n",
      "cls loss 284.53741455078125  loc loss 13.890417098999023\n",
      "cls loss 276.0315246582031  loc loss 14.214795112609863\n",
      "cls loss 388.03955078125  loc loss 21.75491714477539\n",
      "cls loss 384.37689208984375  loc loss 23.377992630004883\n",
      "cls loss 365.43548583984375  loc loss 26.040971755981445\n",
      "cls loss 312.69439697265625  loc loss 15.13969612121582\n",
      "cls loss 326.19244384765625  loc loss 17.89594268798828\n",
      "cls loss 626.4766845703125  loc loss 35.243865966796875\n",
      "cls loss 587.2880249023438  loc loss 30.4189510345459\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1., 42., 42., 42., 42., 42., 42.,  1.,\n",
      "         1.,  1.,  1., 42.,  1.,  1., 42.,  1.])\n",
      "cls loss 326.46234130859375  loc loss 22.004018783569336\n",
      "cls loss 492.9264221191406  loc loss 24.1364688873291\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.])\n",
      "cls loss 209.92579650878906  loc loss 9.64665412902832\n",
      "cls loss 487.6083068847656  loc loss 27.7665958404541\n",
      "cls loss 361.0084533691406  loc loss 23.37561798095703\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([11.])\n",
      "cls loss 210.98741149902344  loc loss 12.219082832336426\n",
      "cls loss 237.85531616210938  loc loss 11.98274040222168\n",
      "cls loss 254.78961181640625  loc loss 11.764907836914062\n",
      "cls loss 454.6711120605469  loc loss 27.174678802490234\n",
      "cls loss 354.2381286621094  loc loss 19.9361629486084\n",
      "cls loss 382.97601318359375  loc loss 24.131738662719727\n",
      "cls loss 537.8905639648438  loc loss 27.923208236694336\n",
      "cls loss 290.47479248046875  loc loss 16.005535125732422\n",
      "cls loss 638.861083984375  loc loss 37.842376708984375\n",
      "cls loss 312.5318298339844  loc loss 16.62160873413086\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 294.68511962890625  loc loss 16.267467498779297\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1., 38., 38., 42.])\n",
      "cls loss 410.75604248046875  loc loss 22.69940185546875\n",
      "cls loss 372.63720703125  loc loss 20.334449768066406\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 322.26422119140625  loc loss 19.060039520263672\n",
      "cls loss 690.951416015625  loc loss 40.11231231689453\n",
      "cls loss 401.8221130371094  loc loss 23.600719451904297\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10.,  3.,  3.,  6.,  8.,  8.,  1.,  1.,  1., 10.])\n",
      "cls loss 302.5205078125  loc loss 14.6619873046875\n",
      "cls loss 207.2091064453125  loc loss 7.216964244842529\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10.,  3.])\n",
      "cls loss 285.20782470703125  loc loss 17.0937557220459\n",
      "cls loss 141.5790252685547  loc loss 8.047654151916504\n",
      "cls loss 363.46441650390625  loc loss 24.094406127929688\n",
      "cls loss 441.99456787109375  loc loss 27.285825729370117\n",
      "cls loss 323.4883728027344  loc loss 18.46122169494629\n",
      "cls loss 174.41839599609375  loc loss 12.324143409729004\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 34.])\n",
      "cls loss 486.90179443359375  loc loss 32.57356643676758\n",
      "cls loss 651.8775634765625  loc loss 43.61580276489258\n",
      "cls loss 403.7403564453125  loc loss 27.178173065185547\n",
      "cls loss 324.7984313964844  loc loss 20.539670944213867\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.,  1.])\n",
      "cls loss 366.2786560058594  loc loss 14.597673416137695\n",
      "cls loss 610.0012817382812  loc loss 38.742454528808594\n",
      "cls loss 847.7318115234375  loc loss 48.194618225097656\n",
      "cls loss 671.106689453125  loc loss 31.418493270874023\n",
      "cls loss 380.81024169921875  loc loss 18.1480770111084\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 405.24676513671875  loc loss 22.947710037231445\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10.])\n",
      "cls loss 262.72930908203125  loc loss 12.923043251037598\n",
      "cls loss 389.9365234375  loc loss 19.058326721191406\n",
      "cls loss 370.8561706542969  loc loss 20.15860939025879\n",
      "cls loss 236.2456817626953  loc loss 14.077230453491211\n",
      "cls loss 332.817626953125  loc loss 19.846376419067383\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21.,\n",
      "        21.])\n",
      "cls loss 401.2202453613281  loc loss 24.165843963623047\n",
      "cls loss 349.573974609375  loc loss 18.719966888427734\n",
      "cls loss 234.88168334960938  loc loss 10.70419692993164\n",
      "cls loss 538.767578125  loc loss 32.599708557128906\n",
      "cls loss 391.25885009765625  loc loss 24.321788787841797\n",
      "cls loss 293.8827209472656  loc loss 12.90786361694336\n",
      "cls loss 618.8251953125  loc loss 33.413612365722656\n",
      "cls loss 701.94677734375  loc loss 45.630958557128906\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15., 85.])\n",
      "cls loss 483.37506103515625  loc loss 24.58181381225586\n",
      "cls loss 471.6230773925781  loc loss 31.864582061767578\n",
      "cls loss 475.906005859375  loc loss 30.31674575805664\n",
      "cls loss 374.8545837402344  loc loss 21.97467041015625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 8., 8.])\n",
      "cls loss 285.215576171875  loc loss 9.950362205505371\n",
      "cls loss 268.2339172363281  loc loss 19.736339569091797\n",
      "cls loss 345.8394775390625  loc loss 18.43756675720215\n",
      "cls loss 302.207275390625  loc loss 15.330524444580078\n",
      "cls loss 325.13250732421875  loc loss 17.163000106811523\n",
      "cls loss 479.0753173828125  loc loss 25.357662200927734\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1., 35., 27., 27.,  1., 27.,  1.])\n",
      "cls loss 511.6416931152344  loc loss 38.49549865722656\n",
      "cls loss 320.8960876464844  loc loss 15.496981620788574\n",
      "cls loss 331.0705261230469  loc loss 23.681198120117188\n",
      "cls loss 338.01239013671875  loc loss 26.975500106811523\n",
      "cls loss 308.82958984375  loc loss 18.525259017944336\n",
      "cls loss 345.5187072753906  loc loss 24.253799438476562\n",
      "cls loss 341.871337890625  loc loss 23.691997528076172\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  2.,  2.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  2.,  2.])\n",
      "cls loss 164.42742919921875  loc loss 7.770835876464844\n",
      "cls loss 547.92529296875  loc loss 32.498878479003906\n",
      "cls loss 331.5634765625  loc loss 14.502161026000977\n",
      "cls loss 603.8477783203125  loc loss 40.74956130981445\n",
      "cls loss 230.74050903320312  loc loss 12.4905424118042\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 19., 19., 19., 16.])\n",
      "cls loss 235.99497985839844  loc loss 8.287798881530762\n",
      "cls loss 208.4287109375  loc loss 7.916934013366699\n",
      "cls loss 339.4088134765625  loc loss 14.26066780090332\n",
      "cls loss 442.425537109375  loc loss 26.13219451904297\n",
      "cls loss 172.6291961669922  loc loss 11.521496772766113\n",
      "cls loss 473.96014404296875  loc loss 35.32649612426758\n",
      "cls loss 349.61083984375  loc loss 20.962060928344727\n",
      "cls loss 363.59912109375  loc loss 23.0037841796875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 472.9575500488281  loc loss 29.124685287475586\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 463.4942932128906  loc loss 21.128314971923828\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 673.2089233398438  loc loss 53.08772277832031\n",
      "cls loss 869.3475341796875  loc loss 73.39393615722656\n",
      "cls loss 410.1517333984375  loc loss 23.06009864807129\n",
      "cls loss 387.7220458984375  loc loss 21.828519821166992\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3.,  3.,  3.,  3.,  3., 10.])\n",
      "cls loss 185.55726623535156  loc loss 11.541555404663086\n",
      "cls loss 422.80712890625  loc loss 18.638477325439453\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 1., 1., 1., 3., 3., 3., 3.])\n",
      "cls loss 347.3084716796875  loc loss 15.415970802307129\n",
      "cls loss 670.244140625  loc loss 38.93882751464844\n",
      "cls loss 555.352783203125  loc loss 26.675640106201172\n",
      "cls loss 348.91900634765625  loc loss 17.701168060302734\n",
      "cls loss 526.839599609375  loc loss 33.10636901855469\n",
      "cls loss 304.13934326171875  loc loss 19.870704650878906\n",
      "cls loss 500.88134765625  loc loss 31.5281982421875\n",
      "cls loss 376.61346435546875  loc loss 32.20186996459961\n",
      "cls loss 339.78082275390625  loc loss 22.575387954711914\n",
      "cls loss 771.78759765625  loc loss 57.864646911621094\n",
      "cls loss 493.33612060546875  loc loss 36.727699279785156\n",
      "cls loss 316.6506042480469  loc loss 15.797693252563477\n",
      "cls loss 188.2461395263672  loc loss 8.770499229431152\n",
      "cls loss 248.8385467529297  loc loss 11.91560173034668\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3., 10., 10., 10., 10., 10., 10., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10., 10., 10., 10., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 11., 10., 10., 10., 10., 10.,  3.,  3.,  3.,  3.,  3.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 11., 10., 10., 10., 10., 10.,  3.,  3.,  3.,  3.,  3.])\n",
      "cls loss 190.06781005859375  loc loss 8.711750030517578\n",
      "cls loss 272.0513610839844  loc loss 10.83484172821045\n",
      "cls loss 246.49363708496094  loc loss 13.1149263381958\n",
      "cls loss 234.4759979248047  loc loss 9.927765846252441\n",
      "cls loss 315.08990478515625  loc loss 22.486330032348633\n",
      "cls loss 224.37374877929688  loc loss 9.1259765625\n",
      "cls loss 488.5681457519531  loc loss 28.366344451904297\n",
      "cls loss 461.3587646484375  loc loss 22.129873275756836\n",
      "cls loss 655.1319580078125  loc loss 35.7037239074707\n",
      "cls loss 334.5433349609375  loc loss 20.977985382080078\n",
      "cls loss 565.620361328125  loc loss 33.1300048828125\n",
      "cls loss 423.4482421875  loc loss 28.95826530456543\n",
      "cls loss 431.233154296875  loc loss 25.41544532775879\n",
      "cls loss 410.37939453125  loc loss 26.652008056640625\n",
      "cls loss 526.0586547851562  loc loss 33.276893615722656\n",
      "cls loss 503.5393981933594  loc loss 31.94163703918457\n",
      "cls loss 239.44537353515625  loc loss 12.55348014831543\n",
      "cls loss 512.47216796875  loc loss 30.888858795166016\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 10.,  1., 18.])\n",
      "cls loss 215.56216430664062  loc loss 14.314112663269043\n",
      "cls loss 250.688232421875  loc loss 11.785711288452148\n",
      "cls loss 471.6639404296875  loc loss 24.738510131835938\n",
      "cls loss 668.479736328125  loc loss 36.55226135253906\n",
      "cls loss 400.18487548828125  loc loss 25.15106964111328\n",
      "cls loss 619.3890380859375  loc loss 26.783723831176758\n",
      "cls loss 483.7435302734375  loc loss 27.380826950073242\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.,  1.,  1.])\n",
      "cls loss 550.0028686523438  loc loss 29.55063247680664\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1., 38.,  1.])\n",
      "cls loss 461.3110046386719  loc loss 25.23619842529297\n",
      "cls loss 662.0563354492188  loc loss 45.95695495605469\n",
      "cls loss 359.5175476074219  loc loss 22.67363739013672\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 478.2922668457031  loc loss 25.099199295043945\n",
      "cls loss 385.80206298828125  loc loss 21.60995864868164\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3., 10.,  8.,  3., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.])\n",
      "cls loss 428.1419372558594  loc loss 23.591754913330078\n",
      "cls loss 286.09674072265625  loc loss 18.775436401367188\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3.,  3., 11.,  3., 10., 10.,  3.,  3., 10.])\n",
      "cls loss 280.77923583984375  loc loss 17.182819366455078\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3., 10., 10., 10.])\n",
      "cls loss 359.78839111328125  loc loss 18.56812858581543\n",
      "cls loss 277.83038330078125  loc loss 19.02400779724121\n",
      "cls loss 379.83203125  loc loss 26.278181076049805\n",
      "cls loss 555.302001953125  loc loss 32.72077178955078\n",
      "cls loss 364.40625  loc loss 22.591962814331055\n",
      "cls loss 292.65911865234375  loc loss 20.341304779052734\n",
      "cls loss 370.21502685546875  loc loss 19.83124351501465\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 9.,  9., 85., 85.])\n",
      "cls loss 318.39520263671875  loc loss 13.142016410827637\n",
      "cls loss 408.76806640625  loc loss 24.510150909423828\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 600.1273193359375  loc loss 33.95011901855469\n",
      "cls loss 498.28094482421875  loc loss 20.11872100830078\n",
      "cls loss 577.603515625  loc loss 37.483360290527344\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10., 10., 10., 10.])\n",
      "cls loss 374.12103271484375  loc loss 21.515926361083984\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([13.])\n",
      "cls loss 575.2879028320312  loc loss 40.757102966308594\n",
      "cls loss 152.7005615234375  loc loss 8.593718528747559\n",
      "cls loss 232.9501953125  loc loss 11.45150375366211\n",
      "cls loss 298.70050048828125  loc loss 17.886938095092773\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19.,  1.,  1.,  1., 19., 19.])\n",
      "cls loss 327.1549072265625  loc loss 20.58023452758789\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 264.2166442871094  loc loss 16.97450828552246\n",
      "cls loss 404.165283203125  loc loss 25.600317001342773\n",
      "cls loss 308.1548767089844  loc loss 16.10954475402832\n",
      "cls loss 438.4820861816406  loc loss 20.764060974121094\n",
      "cls loss 473.0260009765625  loc loss 31.084228515625\n",
      "cls loss 357.46881103515625  loc loss 19.4299259185791\n",
      "cls loss 586.1495361328125  loc loss 37.61071014404297\n",
      "cls loss 203.581298828125  loc loss 8.012236595153809\n",
      "cls loss 378.59417724609375  loc loss 23.549530029296875\n",
      "cls loss 318.51275634765625  loc loss 16.34825897216797\n",
      "cls loss 350.362060546875  loc loss 16.342548370361328\n",
      "cls loss 473.13232421875  loc loss 24.068819046020508\n",
      "cls loss 369.9684143066406  loc loss 16.100147247314453\n",
      "cls loss 533.28857421875  loc loss 33.731197357177734\n",
      "cls loss 345.2457580566406  loc loss 19.56039810180664\n",
      "cls loss 445.8243103027344  loc loss 30.456329345703125\n",
      "cls loss 645.456298828125  loc loss 36.485382080078125\n",
      "cls loss 347.3359069824219  loc loss 24.389007568359375\n",
      "cls loss 419.98583984375  loc loss 22.188072204589844\n",
      "cls loss 499.27838134765625  loc loss 36.736324310302734\n",
      "cls loss 590.412109375  loc loss 36.57728958129883\n",
      "cls loss 636.0228271484375  loc loss 35.77366256713867\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 5.])\n",
      "cls loss 156.96780395507812  loc loss 8.041498184204102\n",
      "cls loss 239.39068603515625  loc loss 9.328609466552734\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 13.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 6., 8., 8.])\n",
      "cls loss 185.93246459960938  loc loss 9.497881889343262\n",
      "cls loss 246.38511657714844  loc loss 11.262784957885742\n",
      "cls loss 483.62469482421875  loc loss 28.84830665588379\n",
      "cls loss 201.46990966796875  loc loss 10.917577743530273\n",
      "cls loss 420.83441162109375  loc loss 27.50762939453125\n",
      "cls loss 624.0137939453125  loc loss 42.69688034057617\n",
      "cls loss 403.6605224609375  loc loss 24.510986328125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([42., 42.,  1.,  1.,  1.,  1.,  1.,  1.,  1., 42., 42.])\n",
      "cls loss 422.6791687011719  loc loss 20.17835235595703\n",
      "cls loss 537.8568115234375  loc loss 38.31444549560547\n",
      "cls loss 496.31488037109375  loc loss 30.880538940429688\n",
      "cls loss 313.6925048828125  loc loss 18.034379959106445\n",
      "cls loss 411.04949951171875  loc loss 20.52016258239746\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 633.683837890625  loc loss 35.597965240478516\n",
      "cls loss 504.25238037109375  loc loss 31.120925903320312\n",
      "cls loss 298.54656982421875  loc loss 14.156536102294922\n",
      "cls loss 254.59710693359375  loc loss 13.727561950683594\n",
      "cls loss 336.8643493652344  loc loss 19.650821685791016\n",
      "cls loss 454.44775390625  loc loss 27.138660430908203\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15.])\n",
      "cls loss 219.65069580078125  loc loss 6.80789041519165\n",
      "cls loss 385.91094970703125  loc loss 21.289901733398438\n",
      "cls loss 344.7969970703125  loc loss 19.327350616455078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 618.7650146484375  loc loss 35.64873123168945\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19.,  7.])\n",
      "cls loss 282.6499328613281  loc loss 15.971378326416016\n",
      "cls loss 561.4961547851562  loc loss 38.628578186035156\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 513.4204711914062  loc loss 26.340412139892578\n",
      "cls loss 487.5463562011719  loc loss 30.571762084960938\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([38., 38.,  1., 18.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1., 18., 18.,  1.])\n",
      "cls loss 321.7607421875  loc loss 17.067365646362305\n",
      "cls loss 312.389892578125  loc loss 14.970978736877441\n",
      "cls loss 618.5009765625  loc loss 40.54851531982422\n",
      "cls loss 447.290283203125  loc loss 27.769071578979492\n",
      "cls loss 368.8719787597656  loc loss 23.524211883544922\n",
      "cls loss 260.2243347167969  loc loss 17.121044158935547\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.])\n",
      "cls loss 151.7696533203125  loc loss 6.323335647583008\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([32.])\n",
      "cls loss 401.8624572753906  loc loss 19.484615325927734\n",
      "cls loss 356.8393249511719  loc loss 22.006784439086914\n",
      "cls loss 441.26116943359375  loc loss 30.27851104736328\n",
      "cls loss 387.9649963378906  loc loss 22.904769897460938\n",
      "cls loss 331.0322265625  loc loss 17.193893432617188\n",
      "cls loss 530.325927734375  loc loss 28.36725616455078\n",
      "cls loss 629.81298828125  loc loss 36.67116165161133\n",
      "cls loss 450.01959228515625  loc loss 29.001359939575195\n",
      "cls loss 338.7904357910156  loc loss 20.000465393066406\n",
      "cls loss 553.4258422851562  loc loss 34.19588088989258\n",
      "cls loss 366.8204650878906  loc loss 18.957111358642578\n",
      "cls loss 660.3277587890625  loc loss 39.708377838134766\n",
      "cls loss 439.6407470703125  loc loss 22.21927833557129\n",
      "cls loss 348.123046875  loc loss 26.630577087402344\n",
      "cls loss 268.4078369140625  loc loss 12.53729248046875\n",
      "cls loss 319.9122009277344  loc loss 19.06779670715332\n",
      "cls loss 454.38665771484375  loc loss 30.03626823425293\n",
      "cls loss 522.8314208984375  loc loss 34.92097854614258\n",
      "cls loss 320.77227783203125  loc loss 18.794918060302734\n",
      "cls loss 504.7123718261719  loc loss 33.53199005126953\n",
      "cls loss 608.678466796875  loc loss 35.82707977294922\n",
      "cls loss 223.02984619140625  loc loss 12.951659202575684\n",
      "cls loss 593.78564453125  loc loss 36.86893081665039\n",
      "cls loss 443.96881103515625  loc loss 27.453651428222656\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 577.993896484375  loc loss 39.84551239013672\n",
      "cls loss 240.48309326171875  loc loss 9.824731826782227\n",
      "cls loss 370.7422180175781  loc loss 21.44725227355957\n",
      "cls loss 375.9067687988281  loc loss 25.117000579833984\n",
      "cls loss 318.145263671875  loc loss 19.194808959960938\n",
      "cls loss 183.32644653320312  loc loss 10.376684188842773\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 9., 9., 1., 9., 9., 9., 9., 1., 9.])\n",
      "cls loss 837.36376953125  loc loss 52.06480026245117\n",
      "cls loss 450.87847900390625  loc loss 22.72580909729004\n",
      "cls loss 704.7687377929688  loc loss 47.80127716064453\n",
      "cls loss 273.7797546386719  loc loss 20.228225708007812\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 42., 42.])\n",
      "cls loss 452.7696533203125  loc loss 31.966100692749023\n",
      "cls loss 463.21826171875  loc loss 34.24013137817383\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  2.,  1.,  1.,  1., 38.,\n",
      "         1.,  1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 38., 38., 38.,  1., 38., 38., 38.,  1.,  1., 38.,  1.,\n",
      "         1.])\n",
      "cls loss 277.277099609375  loc loss 20.24173927307129\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  8.,  8.])\n",
      "cls loss 649.196044921875  loc loss 42.909671783447266\n",
      "cls loss 666.2760620117188  loc loss 49.61307144165039\n",
      "cls loss 239.00119018554688  loc loss 14.944466590881348\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([4., 1., 1., 4.])\n",
      "cls loss 387.8296813964844  loc loss 23.41220474243164\n",
      "cls loss 493.540771484375  loc loss 27.71458625793457\n",
      "cls loss 195.36871337890625  loc loss 9.811309814453125\n",
      "cls loss 244.6299285888672  loc loss 15.117362022399902\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([51.,  1.])\n",
      "cls loss 173.3336181640625  loc loss 7.832108974456787\n",
      "cls loss 250.15736389160156  loc loss 14.733295440673828\n",
      "cls loss 527.8275756835938  loc loss 23.30375099182129\n",
      "cls loss 484.87786865234375  loc loss 30.918601989746094\n",
      "cls loss 755.377685546875  loc loss 34.3856201171875\n",
      "cls loss 884.9609375  loc loss 54.623565673828125\n",
      "cls loss 362.50439453125  loc loss 22.11780548095703\n",
      "cls loss 537.2135009765625  loc loss 38.10817337036133\n",
      "cls loss 586.37890625  loc loss 35.80530548095703\n",
      "cls loss 420.0188293457031  loc loss 24.663637161254883\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  3.,  1.,  1.,  1.,  3.,  1.,  1.,\n",
      "         1.,  1.,  1.])\n",
      "cls loss 456.4319763183594  loc loss 18.427507400512695\n",
      "cls loss 481.4775390625  loc loss 24.897695541381836\n",
      "cls loss 482.0113830566406  loc loss 21.736061096191406\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "cls loss 407.2767333984375  loc loss 21.48475456237793\n",
      "cls loss 227.81787109375  loc loss 16.941909790039062\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3.])\n",
      "cls loss 180.98016357421875  loc loss 9.4100980758667\n",
      "cls loss 316.31939697265625  loc loss 17.598352432250977\n",
      "cls loss 305.9744567871094  loc loss 18.81423568725586\n",
      "cls loss 550.2401123046875  loc loss 32.351783752441406\n",
      "cls loss 245.61349487304688  loc loss 17.4137020111084\n",
      "cls loss 287.6236877441406  loc loss 22.00474739074707\n",
      "cls loss 815.4549560546875  loc loss 52.44620132446289\n",
      "cls loss 372.61590576171875  loc loss 26.383365631103516\n",
      "cls loss 277.82281494140625  loc loss 18.503355026245117\n",
      "cls loss 326.575927734375  loc loss 17.591167449951172\n",
      "cls loss 297.54425048828125  loc loss 20.814680099487305\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 552.5895385742188  loc loss 36.19180679321289\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  9., 64., 64., 64., 64., 64., 64., 64., 64., 64.,  9.,  9.,  9.,\n",
      "         9.])\n",
      "cls loss 252.2074432373047  loc loss 12.236613273620605\n",
      "cls loss 812.4527587890625  loc loss 56.45541763305664\n",
      "cls loss 427.54339599609375  loc loss 25.79949378967285\n",
      "cls loss 504.002197265625  loc loss 31.48282814025879\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.,  3.,  3.])\n",
      "cls loss 318.5654602050781  loc loss 16.571992874145508\n",
      "cls loss 342.7483825683594  loc loss 22.76848793029785\n",
      "cls loss 364.95294189453125  loc loss 24.40908432006836\n",
      "cls loss 372.13836669921875  loc loss 23.945377349853516\n",
      "cls loss 431.72265625  loc loss 27.63346290588379\n",
      "cls loss 434.4670715332031  loc loss 25.73989486694336\n",
      "cls loss 389.44677734375  loc loss 24.845195770263672\n",
      "cls loss 393.28857421875  loc loss 20.455333709716797\n",
      "cls loss 490.49884033203125  loc loss 30.689741134643555\n",
      "cls loss 360.9459228515625  loc loss 20.64655303955078\n",
      "cls loss 271.3460693359375  loc loss 14.092312812805176\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21.])\n",
      "cls loss 223.20877075195312  loc loss 14.005193710327148\n",
      "cls loss 318.8046875  loc loss 26.16172981262207\n",
      "cls loss 477.8643798828125  loc loss 32.05393981933594\n",
      "cls loss 242.39739990234375  loc loss 13.914826393127441\n",
      "cls loss 389.9637451171875  loc loss 24.493873596191406\n",
      "cls loss 717.3401489257812  loc loss 36.48822784423828\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 42., 42.,  1.,  1.])\n",
      "cls loss 433.7115478515625  loc loss 22.551624298095703\n",
      "cls loss 280.35638427734375  loc loss 15.967524528503418\n",
      "cls loss 399.3357849121094  loc loss 22.73688507080078\n",
      "cls loss 533.930419921875  loc loss 38.012298583984375\n",
      "cls loss 335.0248718261719  loc loss 17.966079711914062\n",
      "cls loss 515.2892456054688  loc loss 33.00674819946289\n",
      "cls loss 449.9715576171875  loc loss 29.01116371154785\n",
      "cls loss 440.3746337890625  loc loss 27.315269470214844\n",
      "cls loss 356.21234130859375  loc loss 21.345111846923828\n",
      "cls loss 286.32379150390625  loc loss 18.346263885498047\n",
      "cls loss 225.73867797851562  loc loss 10.670862197875977\n",
      "cls loss 360.08056640625  loc loss 22.755386352539062\n",
      "cls loss 552.39453125  loc loss 32.95350646972656\n",
      "cls loss 396.7918701171875  loc loss 22.94420623779297\n",
      "cls loss 383.7698974609375  loc loss 26.767911911010742\n",
      "cls loss 417.5025634765625  loc loss 24.18772315979004\n",
      "cls loss 619.2200927734375  loc loss 43.45335388183594\n",
      "cls loss 500.56658935546875  loc loss 30.966567993164062\n",
      "cls loss 541.224365234375  loc loss 27.767385482788086\n",
      "cls loss 340.9506530761719  loc loss 14.608652114868164\n",
      "cls loss 475.7015686035156  loc loss 26.50115966796875\n",
      "cls loss 426.97113037109375  loc loss 23.338619232177734\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 5., 5., 5., 5., 5., 5.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 261.81219482421875  loc loss 15.323875427246094\n",
      "cls loss 343.3782043457031  loc loss 17.2857608795166\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([13.])\n",
      "cls loss 246.89669799804688  loc loss 11.020883560180664\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([44., 10.,  1.,  1.,  1.])\n",
      "cls loss 219.9988250732422  loc loss 14.875846862792969\n",
      "cls loss 386.35357666015625  loc loss 21.12307357788086\n",
      "cls loss 359.9801025390625  loc loss 19.178796768188477\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19., 19., 19., 19., 19., 19., 19.])\n",
      "cls loss 375.4818420410156  loc loss 22.355573654174805\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([56.])\n",
      "cls loss 802.809326171875  loc loss 52.14228820800781\n",
      "cls loss 511.03399658203125  loc loss 35.688297271728516\n",
      "cls loss 649.7162475585938  loc loss 40.10738754272461\n",
      "cls loss 621.9035034179688  loc loss 44.70448684692383\n",
      "cls loss 378.18402099609375  loc loss 20.615507125854492\n",
      "cls loss 641.5008544921875  loc loss 39.40673828125\n",
      "cls loss 363.4109191894531  loc loss 24.22444725036621\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 36.])\n",
      "cls loss 472.63372802734375  loc loss 20.270946502685547\n",
      "cls loss 390.86419677734375  loc loss 23.399356842041016\n",
      "cls loss 368.616943359375  loc loss 21.585182189941406\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5.])\n",
      "cls loss 434.44403076171875  loc loss 25.12321662902832\n",
      "cls loss 235.59765625  loc loss 11.216446876525879\n",
      "cls loss 548.8939819335938  loc loss 28.715932846069336\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "cls loss 483.342529296875  loc loss 28.121868133544922\n",
      "cls loss 450.6942443847656  loc loss 28.275522232055664\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 476.955078125  loc loss 28.209402084350586\n",
      "cls loss 543.68896484375  loc loss 31.559614181518555\n",
      "cls loss 465.8511962890625  loc loss 37.08341979980469\n",
      "cls loss 320.8626708984375  loc loss 20.096694946289062\n",
      "cls loss 358.2852783203125  loc loss 24.51913070678711\n",
      "cls loss 375.85101318359375  loc loss 20.8594970703125\n",
      "cls loss 632.4048461914062  loc loss 30.31892967224121\n",
      "cls loss 252.41549682617188  loc loss 12.56717300415039\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 11., 15., 10., 10., 10., 10., 10.])\n",
      "cls loss 574.397216796875  loc loss 36.47399139404297\n",
      "cls loss 346.8923034667969  loc loss 24.6614990234375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3.])\n",
      "cls loss 360.2454528808594  loc loss 25.862363815307617\n",
      "cls loss 346.79925537109375  loc loss 16.760692596435547\n",
      "cls loss 380.99615478515625  loc loss 17.817567825317383\n",
      "cls loss 494.3343200683594  loc loss 20.19706153869629\n",
      "cls loss 218.93441772460938  loc loss 10.107077598571777\n",
      "cls loss 394.9039611816406  loc loss 24.7318115234375\n",
      "cls loss 457.86053466796875  loc loss 28.351932525634766\n",
      "cls loss 396.87139892578125  loc loss 25.20083999633789\n",
      "cls loss 927.2985229492188  loc loss 55.69737243652344\n",
      "cls loss 617.0951538085938  loc loss 36.82905578613281\n",
      "cls loss 386.3577575683594  loc loss 25.239704132080078\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  9.,  9.,  9.,  6.,  6., 85., 85.,  8.,  1.,  1.,  1.,  1.,\n",
      "         6.,  6.])\n",
      "cls loss 256.42889404296875  loc loss 20.143571853637695\n",
      "cls loss 650.7734985351562  loc loss 42.82734680175781\n",
      "cls loss 759.530517578125  loc loss 44.7014274597168\n",
      "cls loss 478.6650085449219  loc loss 32.952247619628906\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10.,  3.,  3., 10.])\n",
      "cls loss 304.8054504394531  loc loss 16.503934860229492\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([7.])\n",
      "cls loss 399.79656982421875  loc loss 24.424747467041016\n",
      "cls loss 387.1302490234375  loc loss 23.892738342285156\n",
      "cls loss 409.6941223144531  loc loss 33.602779388427734\n",
      "cls loss 675.9655151367188  loc loss 45.0794563293457\n",
      "cls loss 376.52069091796875  loc loss 23.927453994750977\n",
      "cls loss 587.1608276367188  loc loss 35.28758239746094\n",
      "cls loss 729.3030395507812  loc loss 38.814334869384766\n",
      "cls loss 474.28033447265625  loc loss 25.631452560424805\n",
      "cls loss 527.60498046875  loc loss 30.94037628173828\n",
      "cls loss 393.75701904296875  loc loss 25.90964126586914\n",
      "cls loss 573.765380859375  loc loss 39.51721954345703\n",
      "cls loss 437.09503173828125  loc loss 27.242481231689453\n",
      "cls loss 313.334716796875  loc loss 20.322711944580078\n",
      "cls loss 507.68505859375  loc loss 35.926048278808594\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([62.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([62.])\n",
      "cls loss 227.60638427734375  loc loss 10.919580459594727\n",
      "cls loss 354.4134216308594  loc loss 27.083932876586914\n",
      "cls loss 367.44366455078125  loc loss 23.35141944885254\n",
      "cls loss 233.4735107421875  loc loss 11.161127090454102\n",
      "cls loss 502.9851379394531  loc loss 31.22779083251953\n",
      "cls loss 510.5526428222656  loc loss 28.080196380615234\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([28.])\n",
      "cls loss 648.810546875  loc loss 28.920787811279297\n",
      "cls loss 477.4565124511719  loc loss 33.01647186279297\n",
      "cls loss 477.4632568359375  loc loss 32.06095886230469\n",
      "cls loss 536.076171875  loc loss 30.490554809570312\n",
      "cls loss 784.402587890625  loc loss 43.40571212768555\n",
      "cls loss 449.30914306640625  loc loss 23.98760223388672\n",
      "cls loss 605.7620849609375  loc loss 28.361356735229492\n",
      "cls loss 483.0898132324219  loc loss 33.046382904052734\n",
      "cls loss 754.2174072265625  loc loss 54.13991928100586\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([81.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 449.7790832519531  loc loss 17.47718620300293\n",
      "cls loss 346.54461669921875  loc loss 17.299179077148438\n",
      "cls loss 249.71475219726562  loc loss 17.627033233642578\n",
      "cls loss 223.20774841308594  loc loss 9.954463005065918\n",
      "cls loss 251.6717987060547  loc loss 19.215057373046875\n",
      "cls loss 315.05523681640625  loc loss 19.495798110961914\n",
      "cls loss 323.85394287109375  loc loss 22.673336029052734\n",
      "cls loss 480.761474609375  loc loss 37.95916748046875\n",
      "cls loss 581.46630859375  loc loss 32.34868621826172\n",
      "cls loss 987.829833984375  loc loss 63.99918746948242\n",
      "cls loss 390.73504638671875  loc loss 18.416488647460938\n",
      "cls loss 501.5816345214844  loc loss 35.81861877441406\n",
      "cls loss 349.3789978027344  loc loss 20.583721160888672\n",
      "cls loss 468.77960205078125  loc loss 25.24799919128418\n",
      "cls loss 418.57470703125  loc loss 22.852216720581055\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([44., 44.])\n",
      "cls loss 382.330322265625  loc loss 16.994525909423828\n",
      "cls loss 429.5351257324219  loc loss 25.099063873291016\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15.])\n",
      "cls loss 399.0135498046875  loc loss 21.358478546142578\n",
      "cls loss 236.39031982421875  loc loss 12.24948501586914\n",
      "cls loss 407.76751708984375  loc loss 26.13884925842285\n",
      "cls loss 243.3604736328125  loc loss 11.413464546203613\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([1., 3., 3.])\n",
      "cls loss 272.1395568847656  loc loss 15.535707473754883\n",
      "cls loss 192.06373596191406  loc loss 8.860733985900879\n",
      "cls loss 363.9656677246094  loc loss 25.518512725830078\n",
      "cls loss 438.7171630859375  loc loss 23.399341583251953\n",
      "cls loss 372.6493225097656  loc loss 25.558507919311523\n",
      "cls loss 314.08935546875  loc loss 20.393930435180664\n",
      "cls loss 345.0797119140625  loc loss 23.179447174072266\n",
      "cls loss 463.85614013671875  loc loss 29.420272827148438\n",
      "cls loss 306.48077392578125  loc loss 20.565549850463867\n",
      "cls loss 405.13446044921875  loc loss 29.702951431274414\n",
      "cls loss 291.891357421875  loc loss 16.15379524230957\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 533.69921875  loc loss 28.663455963134766\n",
      "cls loss 644.8167724609375  loc loss 25.223079681396484\n",
      "cls loss 550.4017333984375  loc loss 34.579200744628906\n",
      "cls loss 545.718505859375  loc loss 39.77735900878906\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10., 10., 10.,  1.,  1.,  1.,  1.,  1.,  1.,  8.,  8.,\n",
      "         1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10., 10., 10.,  1.,  1.,  1.,  1.,  1.,  1.,  8.,  8.,\n",
      "         1.])\n",
      "cls loss 427.8094177246094  loc loss 21.241418838500977\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 3., 3., 3.])\n",
      "cls loss 431.97222900390625  loc loss 23.172744750976562\n",
      "cls loss 267.7974853515625  loc loss 16.73629379272461\n",
      "cls loss 204.70294189453125  loc loss 9.867452621459961\n",
      "cls loss 403.3443603515625  loc loss 28.684764862060547\n",
      "cls loss 290.5941162109375  loc loss 12.872308731079102\n",
      "cls loss 367.993896484375  loc loss 23.38372039794922\n",
      "cls loss 411.80224609375  loc loss 28.738162994384766\n",
      "cls loss 543.796630859375  loc loss 38.091835021972656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 476.53131103515625  loc loss 23.511720657348633\n",
      "cls loss 428.5448303222656  loc loss 23.067190170288086\n",
      "cls loss 444.6151123046875  loc loss 28.59222412109375\n",
      "cls loss 319.209716796875  loc loss 22.613454818725586\n",
      "cls loss 665.47998046875  loc loss 44.899723052978516\n",
      "cls loss 275.6457824707031  loc loss 14.911811828613281\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 533.9230346679688  loc loss 29.44868278503418\n",
      "cls loss 219.55996704101562  loc loss 8.83334732055664\n",
      "cls loss 572.5980224609375  loc loss 37.7470703125\n",
      "cls loss 290.2684326171875  loc loss 17.42816734313965\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 34.])\n",
      "cls loss 485.30743408203125  loc loss 25.15093421936035\n",
      "cls loss 263.4746398925781  loc loss 15.465686798095703\n",
      "cls loss 531.1492309570312  loc loss 27.19829750061035\n",
      "cls loss 195.42034912109375  loc loss 11.488442420959473\n",
      "cls loss 400.08416748046875  loc loss 22.004837036132812\n",
      "cls loss 395.5586853027344  loc loss 30.244346618652344\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 38.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16., 16., 16.,  9.,  9.,  9., 16., 16., 16., 85.,  9.])\n",
      "cls loss 409.2506408691406  loc loss 22.924123764038086\n",
      "cls loss 441.27392578125  loc loss 31.480091094970703\n",
      "cls loss 594.006591796875  loc loss 36.31163024902344\n",
      "cls loss 923.369873046875  loc loss 54.33714294433594\n",
      "cls loss 230.15313720703125  loc loss 12.4879732131958\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3., 10.,  8.,  8., 10., 10., 10.,  3.,  3., 14.])\n",
      "cls loss 250.60357666015625  loc loss 14.441378593444824\n",
      "cls loss 462.8305969238281  loc loss 29.04323387145996\n",
      "cls loss 193.97567749023438  loc loss 7.990784168243408\n",
      "cls loss 342.06060791015625  loc loss 14.388664245605469\n",
      "cls loss 471.5205993652344  loc loss 29.387802124023438\n",
      "cls loss 398.2086486816406  loc loss 22.78255844116211\n",
      "cls loss 231.25469970703125  loc loss 12.243111610412598\n",
      "cls loss 308.78973388671875  loc loss 14.39166259765625\n",
      "cls loss 527.471435546875  loc loss 25.637374877929688\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42., 42.,  1.])\n",
      "cls loss 476.82293701171875  loc loss 25.870689392089844\n",
      "cls loss 405.11175537109375  loc loss 19.45764923095703\n",
      "cls loss 507.8460693359375  loc loss 34.52321243286133\n",
      "cls loss 563.4773559570312  loc loss 31.666908264160156\n",
      "cls loss 382.6600646972656  loc loss 20.856670379638672\n",
      "cls loss 457.66558837890625  loc loss 31.258737564086914\n",
      "cls loss 270.1366271972656  loc loss 17.774126052856445\n",
      "cls loss 294.56427001953125  loc loss 21.30413246154785\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20.])\n",
      "cls loss 212.79550170898438  loc loss 11.949323654174805\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([11.])\n",
      "cls loss 302.20904541015625  loc loss 13.113255500793457\n",
      "cls loss 172.02818298339844  loc loss 10.945239067077637\n",
      "cls loss 459.8221435546875  loc loss 32.671783447265625\n",
      "cls loss 193.01307678222656  loc loss 9.45047664642334\n",
      "cls loss 403.6937561035156  loc loss 24.175626754760742\n",
      "cls loss 223.35763549804688  loc loss 14.405646324157715\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 35., 27.])\n",
      "cls loss 412.1769104003906  loc loss 21.570663452148438\n",
      "cls loss 480.302490234375  loc loss 32.880680084228516\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 317.8468017578125  loc loss 15.178425788879395\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([42.,  1.])\n",
      "cls loss 409.836181640625  loc loss 23.8883113861084\n",
      "cls loss 432.9005126953125  loc loss 20.096309661865234\n",
      "cls loss 521.4827270507812  loc loss 26.64850616455078\n",
      "cls loss 664.6814575195312  loc loss 29.969280242919922\n",
      "cls loss 529.50244140625  loc loss 27.367149353027344\n",
      "cls loss 371.63885498046875  loc loss 20.832008361816406\n",
      "cls loss 302.0688781738281  loc loss 19.755626678466797\n",
      "cls loss 181.60597229003906  loc loss 7.295639991760254\n",
      "cls loss 323.6040344238281  loc loss 17.4742488861084\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 1., 1.])\n",
      "cls loss 311.3500061035156  loc loss 18.841489791870117\n",
      "cls loss 381.585205078125  loc loss 23.33261489868164\n",
      "cls loss 366.2763671875  loc loss 21.31281852722168\n",
      "cls loss 284.6360168457031  loc loss 19.998929977416992\n",
      "cls loss 354.6602783203125  loc loss 22.912893295288086\n",
      "cls loss 373.754638671875  loc loss 26.905927658081055\n",
      "cls loss 560.5405883789062  loc loss 31.682693481445312\n",
      "cls loss 490.65179443359375  loc loss 34.149864196777344\n",
      "cls loss 423.70550537109375  loc loss 26.070446014404297\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 337.32867431640625  loc loss 22.144962310791016\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 482.4361572265625  loc loss 17.748340606689453\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([81.])\n",
      "cls loss 553.7483520507812  loc loss 26.33586883544922\n",
      "cls loss 318.81884765625  loc loss 20.013700485229492\n",
      "cls loss 269.7297668457031  loc loss 10.695096015930176\n",
      "cls loss 352.819091796875  loc loss 18.51580047607422\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3.,  1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 19.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 19.])\n",
      "cls loss 501.64208984375  loc loss 30.31969451904297\n",
      "cls loss 262.01568603515625  loc loss 14.497474670410156\n",
      "cls loss 286.5670166015625  loc loss 14.905445098876953\n",
      "cls loss 541.3158569335938  loc loss 37.296661376953125\n",
      "cls loss 261.42779541015625  loc loss 16.0454158782959\n",
      "cls loss 332.21331787109375  loc loss 18.818927764892578\n",
      "cls loss 423.2152404785156  loc loss 25.735761642456055\n",
      "cls loss 313.3188781738281  loc loss 21.590797424316406\n",
      "cls loss 427.3446960449219  loc loss 22.077980041503906\n",
      "cls loss 458.64447021484375  loc loss 28.375829696655273\n",
      "cls loss 625.4619140625  loc loss 50.68326187133789\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 81.])\n",
      "cls loss 412.58050537109375  loc loss 18.84451675415039\n",
      "cls loss 380.06756591796875  loc loss 19.060211181640625\n",
      "cls loss 381.94171142578125  loc loss 20.36756706237793\n",
      "cls loss 316.87750244140625  loc loss 15.153909683227539\n",
      "cls loss 281.3197937011719  loc loss 15.688583374023438\n",
      "cls loss 345.1559753417969  loc loss 22.904212951660156\n",
      "cls loss 246.80368041992188  loc loss 15.977953910827637\n",
      "cls loss 217.89149475097656  loc loss 12.962583541870117\n",
      "cls loss 273.0043640136719  loc loss 17.181026458740234\n",
      "cls loss 369.3639831542969  loc loss 22.228639602661133\n",
      "cls loss 347.78619384765625  loc loss 24.299144744873047\n",
      "cls loss 343.4947204589844  loc loss 21.233198165893555\n",
      "cls loss 205.3042449951172  loc loss 12.554555892944336\n",
      "cls loss 724.4256591796875  loc loss 42.713035583496094\n",
      "cls loss 391.3282165527344  loc loss 24.813405990600586\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 350.8287048339844  loc loss 16.58933448791504\n",
      "cls loss 392.17242431640625  loc loss 23.778553009033203\n",
      "cls loss 282.44927978515625  loc loss 19.12741470336914\n",
      "cls loss 460.55316162109375  loc loss 32.103214263916016\n",
      "cls loss 452.88592529296875  loc loss 26.200885772705078\n",
      "cls loss 411.4304504394531  loc loss 24.084148406982422\n",
      "cls loss 303.25946044921875  loc loss 20.334646224975586\n",
      "cls loss 279.18377685546875  loc loss 15.055821418762207\n",
      "cls loss 403.5728454589844  loc loss 20.192947387695312\n",
      "cls loss 484.23193359375  loc loss 28.248254776000977\n",
      "cls loss 419.7947998046875  loc loss 21.226781845092773\n",
      "cls loss 553.9369506835938  loc loss 32.44044494628906\n",
      "cls loss 602.2802734375  loc loss 38.7205810546875\n",
      "cls loss 403.07440185546875  loc loss 24.796701431274414\n",
      "cls loss 579.1778564453125  loc loss 41.44942092895508\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1., 38., 47.,  1.,  1.,  1.,  1.,  1., 62.])\n",
      "cls loss 350.38629150390625  loc loss 16.100109100341797\n",
      "cls loss 417.2860107421875  loc loss 28.2874755859375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 453.64727783203125  loc loss 25.631961822509766\n",
      "cls loss 520.7008666992188  loc loss 35.61817169189453\n",
      "cls loss 336.50830078125  loc loss 14.78196907043457\n",
      "cls loss 406.1557922363281  loc loss 29.44121742248535\n",
      "cls loss 393.48968505859375  loc loss 21.852991104125977\n",
      "cls loss 218.52793884277344  loc loss 7.062956809997559\n",
      "cls loss 335.47747802734375  loc loss 17.992786407470703\n",
      "cls loss 296.0967102050781  loc loss 11.854549407958984\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1., 35.])\n",
      "cls loss 322.50286865234375  loc loss 17.972002029418945\n",
      "cls loss 493.8599853515625  loc loss 24.21052360534668\n",
      "cls loss 505.8990478515625  loc loss 28.398868560791016\n",
      "cls loss 447.1527099609375  loc loss 32.39108657836914\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 383.3373107910156  loc loss 25.376008987426758\n",
      "cls loss 491.3888244628906  loc loss 33.360198974609375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 270.35015869140625  loc loss 13.655440330505371\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 378.2083740234375  loc loss 15.10312557220459\n",
      "cls loss 574.4346313476562  loc loss 30.966140747070312\n",
      "cls loss 734.1329345703125  loc loss 55.071372985839844\n",
      "cls loss 356.864990234375  loc loss 17.686439514160156\n",
      "cls loss 310.1109619140625  loc loss 17.542295455932617\n",
      "cls loss 322.6771545410156  loc loss 15.470340728759766\n",
      "cls loss 365.29547119140625  loc loss 18.07111930847168\n",
      "cls loss 313.7496337890625  loc loss 12.40460205078125\n",
      "cls loss 577.6307983398438  loc loss 33.896385192871094\n",
      "cls loss 483.02142333984375  loc loss 25.98927879333496\n",
      "cls loss 210.39181518554688  loc loss 14.122286796569824\n",
      "cls loss 433.9510498046875  loc loss 23.79794692993164\n",
      "cls loss 589.2174072265625  loc loss 39.622802734375\n",
      "cls loss 438.4513244628906  loc loss 27.413209915161133\n",
      "cls loss 389.4984436035156  loc loss 21.562002182006836\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.])\n",
      "cls loss 369.198486328125  loc loss 24.927940368652344\n",
      "cls loss 380.286376953125  loc loss 22.621994018554688\n",
      "cls loss 455.58953857421875  loc loss 25.416423797607422\n",
      "cls loss 763.2845458984375  loc loss 52.7739372253418\n",
      "cls loss 271.46551513671875  loc loss 13.153173446655273\n",
      "cls loss 362.34405517578125  loc loss 21.16312026977539\n",
      "cls loss 283.404052734375  loc loss 15.468526840209961\n",
      "cls loss 325.8702697753906  loc loss 20.879161834716797\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 21., 21., 21.])\n",
      "cls loss 310.2340087890625  loc loss 19.236570358276367\n",
      "cls loss 333.9049377441406  loc loss 16.078840255737305\n",
      "cls loss 336.41400146484375  loc loss 21.09969711303711\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 35.])\n",
      "cls loss 460.75042724609375  loc loss 25.43291473388672\n",
      "cls loss 169.42503356933594  loc loss 8.6488618850708\n",
      "cls loss 316.8194885253906  loc loss 16.246353149414062\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 293.4955139160156  loc loss 10.915926933288574\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 38., 38.,  9., 38.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1.,  1.])\n",
      "cls loss 323.71417236328125  loc loss 18.174823760986328\n",
      "cls loss 538.0386352539062  loc loss 28.860645294189453\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 2.,  1., 77., 31., 10., 10.,  1.,  4., 10.])\n",
      "cls loss 242.74891662597656  loc loss 10.283401489257812\n",
      "cls loss 489.6085510253906  loc loss 26.933807373046875\n",
      "cls loss 978.0577392578125  loc loss 52.264915466308594\n",
      "cls loss 306.7826232910156  loc loss 20.52684783935547\n",
      "cls loss 421.1180419921875  loc loss 28.8730525970459\n",
      "cls loss 280.0044250488281  loc loss 13.393030166625977\n",
      "cls loss 273.3226623535156  loc loss 13.7848482131958\n",
      "cls loss 385.0899963378906  loc loss 21.663204193115234\n",
      "cls loss 380.2723693847656  loc loss 23.264501571655273\n",
      "cls loss 362.0262145996094  loc loss 25.6519775390625\n",
      "cls loss 310.27227783203125  loc loss 14.647459030151367\n",
      "cls loss 323.2723693847656  loc loss 17.543994903564453\n",
      "cls loss 621.2446899414062  loc loss 34.540985107421875\n",
      "cls loss 581.5699462890625  loc loss 30.094345092773438\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1., 42., 42., 42., 42., 42., 42.,  1.,\n",
      "         1.,  1.,  1., 42.,  1.,  1., 42.,  1.])\n",
      "cls loss 323.6328430175781  loc loss 21.82785987854004\n",
      "cls loss 489.7466125488281  loc loss 23.720651626586914\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.])\n",
      "cls loss 207.43199157714844  loc loss 9.553033828735352\n",
      "cls loss 485.1592102050781  loc loss 27.305519104003906\n",
      "cls loss 359.25213623046875  loc loss 22.692663192749023\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([11.])\n",
      "cls loss 209.3521728515625  loc loss 11.971874237060547\n",
      "cls loss 236.5886993408203  loc loss 11.789496421813965\n",
      "cls loss 252.13742065429688  loc loss 11.377060890197754\n",
      "cls loss 452.32855224609375  loc loss 26.789634704589844\n",
      "cls loss 352.14312744140625  loc loss 19.45745849609375\n",
      "cls loss 381.54290771484375  loc loss 24.100330352783203\n",
      "cls loss 536.5968017578125  loc loss 28.011850357055664\n",
      "cls loss 288.88726806640625  loc loss 16.035205841064453\n",
      "cls loss 636.4801025390625  loc loss 37.84566879272461\n",
      "cls loss 310.91015625  loc loss 16.203035354614258\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 291.8138427734375  loc loss 16.043163299560547\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1., 38., 38., 42.])\n",
      "cls loss 405.1163330078125  loc loss 22.470935821533203\n",
      "cls loss 366.16925048828125  loc loss 20.207565307617188\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 318.0430908203125  loc loss 19.138845443725586\n",
      "cls loss 681.6812744140625  loc loss 39.94028091430664\n",
      "cls loss 398.5515441894531  loc loss 23.530763626098633\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10.,  3.,  3.,  6.,  8.,  8.,  1.,  1.,  1., 10.])\n",
      "cls loss 299.186279296875  loc loss 14.537575721740723\n",
      "cls loss 205.78582763671875  loc loss 7.1940460205078125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10.,  3.])\n",
      "cls loss 282.4359130859375  loc loss 16.692228317260742\n",
      "cls loss 139.8955535888672  loc loss 7.862761497497559\n",
      "cls loss 362.00616455078125  loc loss 23.908035278320312\n",
      "cls loss 438.1304931640625  loc loss 27.17621421813965\n",
      "cls loss 321.69744873046875  loc loss 17.84145164489746\n",
      "cls loss 173.58956909179688  loc loss 12.173480033874512\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 34.])\n",
      "cls loss 483.76837158203125  loc loss 31.978111267089844\n",
      "cls loss 648.6038818359375  loc loss 42.68415451049805\n",
      "cls loss 401.6781311035156  loc loss 26.847061157226562\n",
      "cls loss 322.739013671875  loc loss 20.302528381347656\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.,  1.])\n",
      "cls loss 362.6459655761719  loc loss 14.500368118286133\n",
      "cls loss 603.7630615234375  loc loss 38.766380310058594\n",
      "cls loss 840.2149658203125  loc loss 47.68636703491211\n",
      "cls loss 664.0067138671875  loc loss 30.72231101989746\n",
      "cls loss 376.2839660644531  loc loss 17.935701370239258\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 397.98114013671875  loc loss 22.706470489501953\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10.])\n",
      "cls loss 259.32098388671875  loc loss 13.117363929748535\n",
      "cls loss 386.10626220703125  loc loss 19.301206588745117\n",
      "cls loss 366.75848388671875  loc loss 20.240753173828125\n",
      "cls loss 233.66905212402344  loc loss 14.383598327636719\n",
      "cls loss 329.8033447265625  loc loss 19.569499969482422\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21.,\n",
      "        21.])\n",
      "cls loss 396.30157470703125  loc loss 23.931529998779297\n",
      "cls loss 346.33642578125  loc loss 18.175235748291016\n",
      "cls loss 233.3858642578125  loc loss 10.5475435256958\n",
      "cls loss 533.4881591796875  loc loss 32.42573547363281\n",
      "cls loss 387.27734375  loc loss 24.363323211669922\n",
      "cls loss 291.7449035644531  loc loss 12.657451629638672\n",
      "cls loss 614.5661010742188  loc loss 32.99990463256836\n",
      "cls loss 697.97705078125  loc loss 44.96187973022461\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15., 85.])\n",
      "cls loss 480.3209228515625  loc loss 24.043251037597656\n",
      "cls loss 469.26776123046875  loc loss 31.34161949157715\n",
      "cls loss 470.2114562988281  loc loss 29.601926803588867\n",
      "cls loss 367.08856201171875  loc loss 21.7078857421875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 8., 8.])\n",
      "cls loss 280.5821838378906  loc loss 9.842214584350586\n",
      "cls loss 264.28778076171875  loc loss 19.159317016601562\n",
      "cls loss 341.36956787109375  loc loss 17.913049697875977\n",
      "cls loss 297.9352722167969  loc loss 15.047450065612793\n",
      "cls loss 321.4500732421875  loc loss 17.03489875793457\n",
      "cls loss 475.7055358886719  loc loss 24.959993362426758\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1., 35., 27., 27.,  1., 27.,  1.])\n",
      "cls loss 506.14093017578125  loc loss 38.338199615478516\n",
      "cls loss 318.44647216796875  loc loss 15.063210487365723\n",
      "cls loss 327.41229248046875  loc loss 23.338642120361328\n",
      "cls loss 335.80975341796875  loc loss 26.359411239624023\n",
      "cls loss 305.39434814453125  loc loss 18.141521453857422\n",
      "cls loss 344.5050964355469  loc loss 23.51259994506836\n",
      "cls loss 341.10919189453125  loc loss 23.14295196533203\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  2.,  2.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  2.,  2.])\n",
      "cls loss 164.1798553466797  loc loss 7.704899311065674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 545.47705078125  loc loss 31.556779861450195\n",
      "cls loss 329.93017578125  loc loss 14.297624588012695\n",
      "cls loss 598.98291015625  loc loss 40.12664794921875\n",
      "cls loss 227.94638061523438  loc loss 12.294517517089844\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 19., 19., 19., 16.])\n",
      "cls loss 232.1313018798828  loc loss 8.02241325378418\n",
      "cls loss 205.38690185546875  loc loss 7.8227033615112305\n",
      "cls loss 334.7281494140625  loc loss 13.980229377746582\n",
      "cls loss 436.724853515625  loc loss 25.55837631225586\n",
      "cls loss 169.59390258789062  loc loss 11.155308723449707\n",
      "cls loss 468.46832275390625  loc loss 34.85934829711914\n",
      "cls loss 345.8277587890625  loc loss 20.53879165649414\n",
      "cls loss 360.2100830078125  loc loss 22.708240509033203\n",
      "cls loss 470.1109619140625  loc loss 28.2487735748291\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 459.0143127441406  loc loss 20.570209503173828\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 669.0147705078125  loc loss 52.1302490234375\n",
      "cls loss 863.4508056640625  loc loss 71.97370910644531\n",
      "cls loss 406.19866943359375  loc loss 22.60028839111328\n",
      "cls loss 386.73760986328125  loc loss 21.571834564208984\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3.,  3.,  3.,  3.,  3., 10.])\n",
      "cls loss 185.63101196289062  loc loss 11.271699905395508\n",
      "cls loss 421.1491394042969  loc loss 18.41391372680664\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 1., 1., 1., 3., 3., 3., 3.])\n",
      "cls loss 344.63751220703125  loc loss 15.283632278442383\n",
      "cls loss 659.1436157226562  loc loss 38.07475662231445\n",
      "cls loss 546.989013671875  loc loss 26.144929885864258\n",
      "cls loss 341.65576171875  loc loss 17.41766929626465\n",
      "cls loss 521.403076171875  loc loss 32.621089935302734\n",
      "cls loss 301.008544921875  loc loss 19.51505470275879\n",
      "cls loss 496.5456848144531  loc loss 31.35387420654297\n",
      "cls loss 374.56524658203125  loc loss 31.569625854492188\n",
      "cls loss 336.0689392089844  loc loss 22.1995849609375\n",
      "cls loss 766.9832153320312  loc loss 56.803367614746094\n",
      "cls loss 489.7391052246094  loc loss 36.33711242675781\n",
      "cls loss 315.34173583984375  loc loss 15.739158630371094\n",
      "cls loss 186.8861083984375  loc loss 8.650727272033691\n",
      "cls loss 246.4589080810547  loc loss 11.578350067138672\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3., 10., 10., 10., 10., 10., 10., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10., 10., 10., 10., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 11., 10., 10., 10., 10., 10.,  3.,  3.,  3.,  3.,  3.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 11., 10., 10., 10., 10., 10.,  3.,  3.,  3.,  3.,  3.])\n",
      "cls loss 188.27175903320312  loc loss 8.6323881149292\n",
      "cls loss 269.54620361328125  loc loss 10.508222579956055\n",
      "cls loss 246.0488739013672  loc loss 12.84802532196045\n",
      "cls loss 232.2545928955078  loc loss 9.730073928833008\n",
      "cls loss 313.643798828125  loc loss 22.199127197265625\n",
      "cls loss 222.4993896484375  loc loss 9.01141357421875\n",
      "cls loss 484.6016845703125  loc loss 27.509151458740234\n",
      "cls loss 456.66387939453125  loc loss 21.822702407836914\n",
      "cls loss 646.6932373046875  loc loss 35.02926254272461\n",
      "cls loss 330.141845703125  loc loss 20.664785385131836\n",
      "cls loss 559.4581909179688  loc loss 32.72859191894531\n",
      "cls loss 419.024169921875  loc loss 28.78489112854004\n",
      "cls loss 428.62347412109375  loc loss 25.44993782043457\n",
      "cls loss 407.1130065917969  loc loss 26.90142059326172\n",
      "cls loss 523.09423828125  loc loss 32.89912414550781\n",
      "cls loss 499.44183349609375  loc loss 31.935260772705078\n",
      "cls loss 238.12745666503906  loc loss 12.349294662475586\n",
      "cls loss 510.5354309082031  loc loss 29.886863708496094\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 10.,  1., 18.])\n",
      "cls loss 214.10922241210938  loc loss 14.100913047790527\n",
      "cls loss 249.51895141601562  loc loss 11.794434547424316\n",
      "cls loss 468.1068115234375  loc loss 25.015338897705078\n",
      "cls loss 663.9320678710938  loc loss 36.60612869262695\n",
      "cls loss 396.026123046875  loc loss 25.744930267333984\n",
      "cls loss 613.1524047851562  loc loss 26.23805046081543\n",
      "cls loss 479.81622314453125  loc loss 26.91903305053711\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.,  1.,  1.])\n",
      "cls loss 544.3812255859375  loc loss 29.134811401367188\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1., 38.,  1.])\n",
      "cls loss 452.5320129394531  loc loss 24.78969383239746\n",
      "cls loss 654.61474609375  loc loss 44.9472770690918\n",
      "cls loss 356.18353271484375  loc loss 22.245861053466797\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 473.3009948730469  loc loss 24.770322799682617\n",
      "cls loss 382.056640625  loc loss 21.34625816345215\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3., 10.,  8.,  3., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.])\n",
      "cls loss 424.0570373535156  loc loss 23.363197326660156\n",
      "cls loss 283.41143798828125  loc loss 18.60167694091797\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3.,  3., 11.,  3., 10., 10.,  3.,  3., 10.])\n",
      "cls loss 276.2090148925781  loc loss 17.150230407714844\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3., 10., 10., 10.])\n",
      "cls loss 356.2125549316406  loc loss 17.83142852783203\n",
      "cls loss 275.64007568359375  loc loss 18.317811965942383\n",
      "cls loss 376.56451416015625  loc loss 25.422286987304688\n",
      "cls loss 551.282470703125  loc loss 32.05699157714844\n",
      "cls loss 361.9717102050781  loc loss 22.055784225463867\n",
      "cls loss 290.0906982421875  loc loss 19.830718994140625\n",
      "cls loss 367.43963623046875  loc loss 19.654420852661133\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 9.,  9., 85., 85.])\n",
      "cls loss 314.08636474609375  loc loss 13.075130462646484\n",
      "cls loss 404.47247314453125  loc loss 24.236997604370117\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 593.795166015625  loc loss 33.341148376464844\n",
      "cls loss 492.6444091796875  loc loss 19.31315803527832\n",
      "cls loss 569.7235107421875  loc loss 36.54529571533203\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10., 10., 10., 10.])\n",
      "cls loss 368.557373046875  loc loss 21.094295501708984\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([13.])\n",
      "cls loss 571.0975341796875  loc loss 40.000308990478516\n",
      "cls loss 151.65521240234375  loc loss 8.54477310180664\n",
      "cls loss 231.57015991210938  loc loss 11.384413719177246\n",
      "cls loss 297.44927978515625  loc loss 17.809242248535156\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19.,  1.,  1.,  1., 19., 19.])\n",
      "cls loss 327.40179443359375  loc loss 20.667993545532227\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 263.56585693359375  loc loss 16.58390998840332\n",
      "cls loss 401.0746154785156  loc loss 25.71369743347168\n",
      "cls loss 306.461181640625  loc loss 15.734822273254395\n",
      "cls loss 435.470703125  loc loss 20.342906951904297\n",
      "cls loss 470.21942138671875  loc loss 30.691503524780273\n",
      "cls loss 354.7059326171875  loc loss 19.3591251373291\n",
      "cls loss 579.5396728515625  loc loss 37.24885177612305\n",
      "cls loss 200.5098876953125  loc loss 7.712515830993652\n",
      "cls loss 374.64739990234375  loc loss 23.541950225830078\n",
      "cls loss 314.58392333984375  loc loss 16.47589683532715\n",
      "cls loss 346.26300048828125  loc loss 15.985148429870605\n",
      "cls loss 468.2210388183594  loc loss 24.283782958984375\n",
      "cls loss 364.98748779296875  loc loss 16.030981063842773\n",
      "cls loss 528.1839599609375  loc loss 33.344356536865234\n",
      "cls loss 341.9512634277344  loc loss 18.98949432373047\n",
      "cls loss 443.3343200683594  loc loss 30.056686401367188\n",
      "cls loss 641.4164428710938  loc loss 36.55253601074219\n",
      "cls loss 345.95318603515625  loc loss 24.314699172973633\n",
      "cls loss 418.20123291015625  loc loss 21.634008407592773\n",
      "cls loss 498.74493408203125  loc loss 36.23370361328125\n",
      "cls loss 588.2918701171875  loc loss 35.844017028808594\n",
      "cls loss 631.5554809570312  loc loss 35.080078125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 5.])\n",
      "cls loss 153.69004821777344  loc loss 7.81259822845459\n",
      "cls loss 236.14224243164062  loc loss 8.976621627807617\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 13.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 6., 8., 8.])\n",
      "cls loss 183.6790771484375  loc loss 9.185751914978027\n",
      "cls loss 241.82275390625  loc loss 11.10129165649414\n",
      "cls loss 477.7886657714844  loc loss 28.216442108154297\n",
      "cls loss 199.0264434814453  loc loss 10.685791015625\n",
      "cls loss 418.52703857421875  loc loss 27.120189666748047\n",
      "cls loss 618.2262573242188  loc loss 42.2227897644043\n",
      "cls loss 401.0548400878906  loc loss 24.024126052856445\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([42., 42.,  1.,  1.,  1.,  1.,  1.,  1.,  1., 42., 42.])\n",
      "cls loss 418.7821350097656  loc loss 19.54201889038086\n",
      "cls loss 534.1851806640625  loc loss 37.5157356262207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 493.855224609375  loc loss 30.353546142578125\n",
      "cls loss 312.62469482421875  loc loss 17.444686889648438\n",
      "cls loss 408.3322448730469  loc loss 20.128673553466797\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 630.1756591796875  loc loss 35.25001907348633\n",
      "cls loss 501.4442138671875  loc loss 30.411495208740234\n",
      "cls loss 296.5406188964844  loc loss 13.871442794799805\n",
      "cls loss 252.56106567382812  loc loss 13.313286781311035\n",
      "cls loss 334.51422119140625  loc loss 19.58026695251465\n",
      "cls loss 449.9059753417969  loc loss 26.639238357543945\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15.])\n",
      "cls loss 217.83663940429688  loc loss 6.521087169647217\n",
      "cls loss 382.1206970214844  loc loss 20.727277755737305\n",
      "cls loss 341.95367431640625  loc loss 19.057146072387695\n",
      "cls loss 613.2752685546875  loc loss 34.8662223815918\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19.,  7.])\n",
      "cls loss 279.1910400390625  loc loss 15.867229461669922\n",
      "cls loss 553.3361206054688  loc loss 38.570682525634766\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 506.1080322265625  loc loss 25.892850875854492\n",
      "cls loss 483.35772705078125  loc loss 30.221431732177734\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([38., 38.,  1., 18.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1., 18., 18.,  1.])\n",
      "cls loss 319.6197509765625  loc loss 16.641834259033203\n",
      "cls loss 309.9585266113281  loc loss 14.83681869506836\n",
      "cls loss 613.40625  loc loss 39.73002624511719\n",
      "cls loss 444.16180419921875  loc loss 26.854135513305664\n",
      "cls loss 365.7752990722656  loc loss 23.055925369262695\n",
      "cls loss 258.7496643066406  loc loss 16.6353702545166\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.])\n",
      "cls loss 149.36199951171875  loc loss 6.257111549377441\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([32.])\n",
      "cls loss 397.13226318359375  loc loss 19.38701629638672\n",
      "cls loss 353.0218811035156  loc loss 21.575424194335938\n",
      "cls loss 438.1653747558594  loc loss 29.738237380981445\n",
      "cls loss 382.42901611328125  loc loss 22.147254943847656\n",
      "cls loss 327.6246337890625  loc loss 16.9056339263916\n",
      "cls loss 525.1215209960938  loc loss 27.93668556213379\n",
      "cls loss 625.1318359375  loc loss 36.066864013671875\n",
      "cls loss 445.94366455078125  loc loss 28.952171325683594\n",
      "cls loss 336.6988220214844  loc loss 19.987180709838867\n",
      "cls loss 549.1895751953125  loc loss 34.46286392211914\n",
      "cls loss 363.96185302734375  loc loss 18.515642166137695\n",
      "cls loss 655.3120727539062  loc loss 39.201351165771484\n",
      "cls loss 436.09393310546875  loc loss 22.009618759155273\n",
      "cls loss 345.3701477050781  loc loss 26.2872371673584\n",
      "cls loss 264.4905700683594  loc loss 12.41126537322998\n",
      "cls loss 317.2388000488281  loc loss 18.860227584838867\n",
      "cls loss 448.8022155761719  loc loss 29.79287338256836\n",
      "cls loss 516.28125  loc loss 34.80226516723633\n",
      "cls loss 318.0939025878906  loc loss 18.59418487548828\n",
      "cls loss 499.30670166015625  loc loss 33.57331085205078\n",
      "cls loss 603.3858032226562  loc loss 35.92076873779297\n",
      "cls loss 219.98281860351562  loc loss 12.994354248046875\n",
      "cls loss 589.3251342773438  loc loss 36.228607177734375\n",
      "cls loss 440.4346923828125  loc loss 26.623565673828125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 574.084716796875  loc loss 39.07807540893555\n",
      "cls loss 237.72642517089844  loc loss 9.589696884155273\n",
      "cls loss 368.1841735839844  loc loss 20.971065521240234\n",
      "cls loss 372.29339599609375  loc loss 24.845500946044922\n",
      "cls loss 316.42431640625  loc loss 19.09678840637207\n",
      "cls loss 181.57611083984375  loc loss 10.251280784606934\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 9., 9., 1., 9., 9., 9., 9., 1., 9.])\n",
      "cls loss 829.2184448242188  loc loss 51.21197509765625\n",
      "cls loss 447.10565185546875  loc loss 22.126522064208984\n",
      "cls loss 697.28125  loc loss 46.47146224975586\n",
      "cls loss 270.43206787109375  loc loss 19.553091049194336\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 42., 42.])\n",
      "cls loss 447.9287109375  loc loss 31.03887176513672\n",
      "cls loss 458.76373291015625  loc loss 33.70188522338867\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  2.,  1.,  1.,  1., 38.,\n",
      "         1.,  1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 38., 38., 38.,  1., 38., 38., 38.,  1.,  1., 38.,  1.,\n",
      "         1.])\n",
      "cls loss 276.0267333984375  loc loss 19.8411808013916\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  8.,  8.])\n",
      "cls loss 644.7831420898438  loc loss 42.11274719238281\n",
      "cls loss 664.4779052734375  loc loss 48.43705368041992\n",
      "cls loss 236.51669311523438  loc loss 14.43195629119873\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([4., 1., 1., 4.])\n",
      "cls loss 384.919189453125  loc loss 22.80677032470703\n",
      "cls loss 488.92828369140625  loc loss 26.899776458740234\n",
      "cls loss 193.4285888671875  loc loss 9.728256225585938\n",
      "cls loss 242.03237915039062  loc loss 15.072443962097168\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([51.,  1.])\n",
      "cls loss 171.4481658935547  loc loss 7.722040176391602\n",
      "cls loss 248.2975311279297  loc loss 14.884098052978516\n",
      "cls loss 522.85693359375  loc loss 22.540393829345703\n",
      "cls loss 480.02886962890625  loc loss 30.820287704467773\n",
      "cls loss 749.6486206054688  loc loss 33.228431701660156\n",
      "cls loss 877.0459594726562  loc loss 53.19384002685547\n",
      "cls loss 359.1731262207031  loc loss 22.60906982421875\n",
      "cls loss 534.3075561523438  loc loss 37.323184967041016\n",
      "cls loss 581.5870361328125  loc loss 35.416893005371094\n",
      "cls loss 417.1313171386719  loc loss 24.751131057739258\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  3.,  1.,  1.,  1.,  3.,  1.,  1.,\n",
      "         1.,  1.,  1.])\n",
      "cls loss 453.11968994140625  loc loss 18.23151397705078\n",
      "cls loss 475.78741455078125  loc loss 24.93683624267578\n",
      "cls loss 479.8367004394531  loc loss 21.63867950439453\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "cls loss 404.5478515625  loc loss 21.124290466308594\n",
      "cls loss 226.5529022216797  loc loss 16.596874237060547\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3.])\n",
      "cls loss 178.86907958984375  loc loss 9.347640037536621\n",
      "cls loss 313.6685791015625  loc loss 17.140125274658203\n",
      "cls loss 303.20709228515625  loc loss 18.835548400878906\n",
      "cls loss 545.9391479492188  loc loss 32.532806396484375\n",
      "cls loss 242.75088500976562  loc loss 17.198455810546875\n",
      "cls loss 285.19171142578125  loc loss 21.63709259033203\n",
      "cls loss 808.42822265625  loc loss 51.73848342895508\n",
      "cls loss 370.44805908203125  loc loss 25.98801040649414\n",
      "cls loss 275.9490051269531  loc loss 17.928504943847656\n",
      "cls loss 324.8023376464844  loc loss 17.306110382080078\n",
      "cls loss 296.05523681640625  loc loss 20.99559211730957\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 548.8563842773438  loc loss 35.620880126953125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  9., 64., 64., 64., 64., 64., 64., 64., 64., 64.,  9.,  9.,  9.,\n",
      "         9.])\n",
      "cls loss 250.01113891601562  loc loss 12.179571151733398\n",
      "cls loss 807.2991943359375  loc loss 56.021236419677734\n",
      "cls loss 425.1072998046875  loc loss 25.943363189697266\n",
      "cls loss 498.1532287597656  loc loss 31.171052932739258\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.,  3.,  3.])\n",
      "cls loss 315.43719482421875  loc loss 16.685165405273438\n",
      "cls loss 338.81103515625  loc loss 22.171607971191406\n",
      "cls loss 361.5247802734375  loc loss 24.70663070678711\n",
      "cls loss 367.676513671875  loc loss 23.83568572998047\n",
      "cls loss 427.08502197265625  loc loss 26.98815155029297\n",
      "cls loss 431.860107421875  loc loss 25.13484001159668\n",
      "cls loss 387.068359375  loc loss 24.510841369628906\n",
      "cls loss 390.27105712890625  loc loss 20.31121063232422\n",
      "cls loss 486.4527893066406  loc loss 30.403762817382812\n",
      "cls loss 357.9228820800781  loc loss 20.22557258605957\n",
      "cls loss 268.475341796875  loc loss 13.89770793914795\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21.])\n",
      "cls loss 221.13882446289062  loc loss 13.768836975097656\n",
      "cls loss 315.85577392578125  loc loss 26.225051879882812\n",
      "cls loss 475.207275390625  loc loss 31.722736358642578\n",
      "cls loss 241.32638549804688  loc loss 13.56035041809082\n",
      "cls loss 386.9078369140625  loc loss 24.573259353637695\n",
      "cls loss 709.3460693359375  loc loss 36.101226806640625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 42., 42.,  1.,  1.])\n",
      "cls loss 429.19415283203125  loc loss 22.430397033691406\n",
      "cls loss 276.8455810546875  loc loss 15.931962013244629\n",
      "cls loss 392.79351806640625  loc loss 22.08291244506836\n",
      "cls loss 527.8740234375  loc loss 37.01655578613281\n",
      "cls loss 331.29010009765625  loc loss 17.847612380981445\n",
      "cls loss 511.052490234375  loc loss 32.70975875854492\n",
      "cls loss 445.8834228515625  loc loss 28.704761505126953\n",
      "cls loss 436.7080078125  loc loss 26.934221267700195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 353.91351318359375  loc loss 21.196548461914062\n",
      "cls loss 283.62005615234375  loc loss 17.94781494140625\n",
      "cls loss 223.54884338378906  loc loss 10.292902946472168\n",
      "cls loss 357.41217041015625  loc loss 22.649219512939453\n",
      "cls loss 549.6831665039062  loc loss 32.890647888183594\n",
      "cls loss 393.37078857421875  loc loss 22.651973724365234\n",
      "cls loss 381.2135009765625  loc loss 25.928361892700195\n",
      "cls loss 414.28125  loc loss 23.244169235229492\n",
      "cls loss 613.987060546875  loc loss 42.80619430541992\n",
      "cls loss 496.7201232910156  loc loss 30.412691116333008\n",
      "cls loss 536.07763671875  loc loss 27.30181884765625\n",
      "cls loss 337.22149658203125  loc loss 13.967937469482422\n",
      "cls loss 472.16070556640625  loc loss 25.718082427978516\n",
      "cls loss 421.21783447265625  loc loss 22.937509536743164\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 5., 5., 5., 5., 5., 5.])\n",
      "cls loss 259.12091064453125  loc loss 15.068153381347656\n",
      "cls loss 337.6224670410156  loc loss 17.25530433654785\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([13.])\n",
      "cls loss 244.62350463867188  loc loss 10.785146713256836\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([44., 10.,  1.,  1.,  1.])\n",
      "cls loss 217.204833984375  loc loss 14.477497100830078\n",
      "cls loss 381.77703857421875  loc loss 20.726890563964844\n",
      "cls loss 355.8833312988281  loc loss 18.502464294433594\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19., 19., 19., 19., 19., 19., 19.])\n",
      "cls loss 371.54473876953125  loc loss 21.868539810180664\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([56.])\n",
      "cls loss 796.5374755859375  loc loss 50.793235778808594\n",
      "cls loss 507.2510681152344  loc loss 35.545833587646484\n",
      "cls loss 645.1495361328125  loc loss 38.50339126586914\n",
      "cls loss 616.9993896484375  loc loss 44.3199577331543\n",
      "cls loss 376.46710205078125  loc loss 20.180322647094727\n",
      "cls loss 637.4532470703125  loc loss 38.34308624267578\n",
      "cls loss 361.6199035644531  loc loss 24.090396881103516\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 36.])\n",
      "cls loss 467.64605712890625  loc loss 20.259780883789062\n",
      "cls loss 386.37066650390625  loc loss 23.054630279541016\n",
      "cls loss 363.88555908203125  loc loss 20.750892639160156\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5.])\n",
      "cls loss 427.3594970703125  loc loss 24.426305770874023\n",
      "cls loss 231.90869140625  loc loss 11.004874229431152\n",
      "cls loss 542.7224731445312  loc loss 28.276187896728516\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "cls loss 476.1551818847656  loc loss 27.966054916381836\n",
      "cls loss 446.63330078125  loc loss 27.28020477294922\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 472.2512512207031  loc loss 28.383020401000977\n",
      "cls loss 540.41357421875  loc loss 31.33199119567871\n",
      "cls loss 463.50146484375  loc loss 36.54180145263672\n",
      "cls loss 318.8890075683594  loc loss 19.65433120727539\n",
      "cls loss 355.54534912109375  loc loss 24.961284637451172\n",
      "cls loss 372.213623046875  loc loss 20.99563217163086\n",
      "cls loss 625.5999755859375  loc loss 29.666414260864258\n",
      "cls loss 249.59674072265625  loc loss 12.408385276794434\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 11., 15., 10., 10., 10., 10., 10.])\n",
      "cls loss 570.4920043945312  loc loss 35.85235595703125\n",
      "cls loss 344.7432861328125  loc loss 24.076950073242188\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3.])\n",
      "cls loss 357.43304443359375  loc loss 25.08678436279297\n",
      "cls loss 343.305419921875  loc loss 16.484716415405273\n",
      "cls loss 375.02142333984375  loc loss 17.479923248291016\n",
      "cls loss 488.908447265625  loc loss 19.47590446472168\n",
      "cls loss 214.86383056640625  loc loss 9.482185363769531\n",
      "cls loss 386.30389404296875  loc loss 23.803449630737305\n",
      "cls loss 451.81085205078125  loc loss 27.515560150146484\n",
      "cls loss 391.8111572265625  loc loss 24.719181060791016\n",
      "cls loss 918.204833984375  loc loss 55.05902099609375\n",
      "cls loss 612.4088745117188  loc loss 37.44975662231445\n",
      "cls loss 383.27081298828125  loc loss 24.622364044189453\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  9.,  9.,  9.,  6.,  6., 85., 85.,  8.,  1.,  1.,  1.,  1.,\n",
      "         6.,  6.])\n",
      "cls loss 253.631591796875  loc loss 19.608531951904297\n",
      "cls loss 646.815185546875  loc loss 43.505428314208984\n",
      "cls loss 754.90234375  loc loss 43.6688346862793\n",
      "cls loss 473.75091552734375  loc loss 32.301727294921875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10.,  3.,  3., 10.])\n",
      "cls loss 301.98150634765625  loc loss 15.979951858520508\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([7.])\n",
      "cls loss 396.6510314941406  loc loss 24.656862258911133\n",
      "cls loss 382.7138671875  loc loss 23.56748390197754\n",
      "cls loss 405.84356689453125  loc loss 33.27079772949219\n",
      "cls loss 669.5573120117188  loc loss 44.080543518066406\n",
      "cls loss 371.05145263671875  loc loss 23.982967376708984\n",
      "cls loss 579.0828857421875  loc loss 34.259883880615234\n",
      "cls loss 720.1259765625  loc loss 37.9654426574707\n",
      "cls loss 467.7625732421875  loc loss 24.637004852294922\n",
      "cls loss 520.13916015625  loc loss 29.866626739501953\n",
      "cls loss 389.27032470703125  loc loss 25.55913734436035\n",
      "cls loss 568.5445556640625  loc loss 38.623165130615234\n",
      "cls loss 433.7982482910156  loc loss 26.739831924438477\n",
      "cls loss 310.7743225097656  loc loss 19.402170181274414\n",
      "cls loss 504.0321044921875  loc loss 35.21580123901367\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([62.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([62.])\n",
      "cls loss 226.41763305664062  loc loss 10.498047828674316\n",
      "cls loss 350.5590515136719  loc loss 26.080154418945312\n",
      "cls loss 363.54425048828125  loc loss 23.300745010375977\n",
      "cls loss 230.1857452392578  loc loss 11.431556701660156\n",
      "cls loss 498.7287902832031  loc loss 30.890493392944336\n",
      "cls loss 506.0395202636719  loc loss 27.1053524017334\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([28.])\n",
      "cls loss 642.672119140625  loc loss 28.432796478271484\n",
      "cls loss 472.49359130859375  loc loss 29.187847137451172\n",
      "cls loss 473.1660461425781  loc loss 30.732044219970703\n",
      "cls loss 529.2365112304688  loc loss 29.418506622314453\n",
      "cls loss 773.2296142578125  loc loss 42.97807693481445\n",
      "cls loss 443.3040771484375  loc loss 23.436147689819336\n",
      "cls loss 594.924560546875  loc loss 27.594650268554688\n",
      "cls loss 476.7740478515625  loc loss 31.713451385498047\n",
      "cls loss 749.3125  loc loss 54.36579895019531\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([81.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 445.49658203125  loc loss 17.1794490814209\n",
      "cls loss 343.73809814453125  loc loss 17.123838424682617\n",
      "cls loss 247.94064331054688  loc loss 17.628572463989258\n",
      "cls loss 221.1482696533203  loc loss 9.68114185333252\n",
      "cls loss 249.57138061523438  loc loss 18.71649932861328\n",
      "cls loss 312.19989013671875  loc loss 19.782047271728516\n",
      "cls loss 320.9614562988281  loc loss 22.36846160888672\n",
      "cls loss 475.4749450683594  loc loss 37.99827194213867\n",
      "cls loss 577.83349609375  loc loss 32.94804382324219\n",
      "cls loss 978.9281616210938  loc loss 62.65389633178711\n",
      "cls loss 387.29510498046875  loc loss 16.93405532836914\n",
      "cls loss 499.98822021484375  loc loss 34.31733322143555\n",
      "cls loss 345.8846740722656  loc loss 20.480459213256836\n",
      "cls loss 459.5624694824219  loc loss 24.425296783447266\n",
      "cls loss 412.2500305175781  loc loss 22.265487670898438\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([44., 44.])\n",
      "cls loss 373.6518859863281  loc loss 17.11367416381836\n",
      "cls loss 421.16754150390625  loc loss 25.041259765625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15.])\n",
      "cls loss 389.77105712890625  loc loss 19.776782989501953\n",
      "cls loss 233.3535614013672  loc loss 11.876338958740234\n",
      "cls loss 403.5601806640625  loc loss 24.26734161376953\n",
      "cls loss 241.23541259765625  loc loss 10.971924781799316\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([1., 3., 3.])\n",
      "cls loss 270.6165466308594  loc loss 15.115262985229492\n",
      "cls loss 190.1096649169922  loc loss 9.006608963012695\n",
      "cls loss 359.777587890625  loc loss 24.924259185791016\n",
      "cls loss 434.20062255859375  loc loss 22.75418472290039\n",
      "cls loss 368.1474914550781  loc loss 24.52792739868164\n",
      "cls loss 311.60009765625  loc loss 19.545997619628906\n",
      "cls loss 341.49737548828125  loc loss 23.03890609741211\n",
      "cls loss 460.257568359375  loc loss 29.470436096191406\n",
      "cls loss 303.5968933105469  loc loss 20.087814331054688\n",
      "cls loss 402.164794921875  loc loss 29.70461654663086\n",
      "cls loss 290.97088623046875  loc loss 16.176618576049805\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 529.98388671875  loc loss 27.403514862060547\n",
      "cls loss 636.7066650390625  loc loss 25.151594161987305\n",
      "cls loss 543.9100952148438  loc loss 34.44478988647461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 539.3928833007812  loc loss 40.04991912841797\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10., 10., 10.,  1.,  1.,  1.,  1.,  1.,  1.,  8.,  8.,\n",
      "         1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10., 10., 10.,  1.,  1.,  1.,  1.,  1.,  1.,  8.,  8.,\n",
      "         1.])\n",
      "cls loss 423.2540588378906  loc loss 21.41288948059082\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 3., 3., 3.])\n",
      "cls loss 426.68402099609375  loc loss 22.90502166748047\n",
      "cls loss 264.99871826171875  loc loss 16.42372703552246\n",
      "cls loss 203.0343780517578  loc loss 9.762999534606934\n",
      "cls loss 400.2980651855469  loc loss 28.27075958251953\n",
      "cls loss 287.2960510253906  loc loss 12.30803394317627\n",
      "cls loss 365.17498779296875  loc loss 22.928329467773438\n",
      "cls loss 409.11358642578125  loc loss 26.91272735595703\n",
      "cls loss 539.729248046875  loc loss 36.98020553588867\n",
      "cls loss 472.939697265625  loc loss 23.560626983642578\n",
      "cls loss 425.03961181640625  loc loss 22.850339889526367\n",
      "cls loss 440.6326599121094  loc loss 28.121309280395508\n",
      "cls loss 316.019775390625  loc loss 23.00672721862793\n",
      "cls loss 661.9578247070312  loc loss 44.69455337524414\n",
      "cls loss 272.7469482421875  loc loss 14.911247253417969\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 529.0096435546875  loc loss 28.447294235229492\n",
      "cls loss 216.02601623535156  loc loss 8.738085746765137\n",
      "cls loss 565.1937255859375  loc loss 38.59564971923828\n",
      "cls loss 286.3609619140625  loc loss 17.28305435180664\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 34.])\n",
      "cls loss 479.6463623046875  loc loss 24.22718048095703\n",
      "cls loss 259.11456298828125  loc loss 14.605623245239258\n",
      "cls loss 524.765869140625  loc loss 26.339988708496094\n",
      "cls loss 194.4139862060547  loc loss 11.109289169311523\n",
      "cls loss 395.1790771484375  loc loss 21.643150329589844\n",
      "cls loss 393.245361328125  loc loss 29.323631286621094\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 38.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16., 16., 16.,  9.,  9.,  9., 16., 16., 16., 85.,  9.])\n",
      "cls loss 406.447265625  loc loss 21.858016967773438\n",
      "cls loss 438.5186462402344  loc loss 30.01337242126465\n",
      "cls loss 591.0993041992188  loc loss 35.38639450073242\n",
      "cls loss 916.8794555664062  loc loss 53.354026794433594\n",
      "cls loss 228.02008056640625  loc loss 12.460710525512695\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3., 10.,  8.,  8., 10., 10., 10.,  3.,  3., 14.])\n",
      "cls loss 247.53561401367188  loc loss 14.735404014587402\n",
      "cls loss 457.9082946777344  loc loss 29.495241165161133\n",
      "cls loss 192.67478942871094  loc loss 7.629469871520996\n",
      "cls loss 338.3406982421875  loc loss 14.65533447265625\n",
      "cls loss 467.589111328125  loc loss 29.11210060119629\n",
      "cls loss 393.2295227050781  loc loss 22.096195220947266\n",
      "cls loss 228.07614135742188  loc loss 12.067960739135742\n",
      "cls loss 303.6221618652344  loc loss 13.679481506347656\n",
      "cls loss 519.6360473632812  loc loss 26.218732833862305\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42., 42.,  1.])\n",
      "cls loss 468.14422607421875  loc loss 25.50569725036621\n",
      "cls loss 400.16448974609375  loc loss 18.97022247314453\n",
      "cls loss 504.90008544921875  loc loss 33.82018280029297\n",
      "cls loss 559.56591796875  loc loss 31.49544906616211\n",
      "cls loss 380.4139709472656  loc loss 20.978878021240234\n",
      "cls loss 454.0458679199219  loc loss 31.375709533691406\n",
      "cls loss 266.9503173828125  loc loss 17.30707550048828\n",
      "cls loss 291.5458984375  loc loss 20.76862907409668\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20.])\n",
      "cls loss 211.6176300048828  loc loss 11.642495155334473\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([11.])\n",
      "cls loss 298.8418884277344  loc loss 13.232437133789062\n",
      "cls loss 170.92037963867188  loc loss 10.443084716796875\n",
      "cls loss 455.19281005859375  loc loss 32.235809326171875\n",
      "cls loss 190.58926391601562  loc loss 9.432234764099121\n",
      "cls loss 398.9771423339844  loc loss 24.1562557220459\n",
      "cls loss 221.9012451171875  loc loss 14.605023384094238\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 35., 27.])\n",
      "cls loss 409.251953125  loc loss 21.28575325012207\n",
      "cls loss 476.3001708984375  loc loss 32.82522964477539\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 315.15753173828125  loc loss 14.929842948913574\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([42.,  1.])\n",
      "cls loss 406.1872863769531  loc loss 23.306774139404297\n",
      "cls loss 428.1898193359375  loc loss 20.067956924438477\n",
      "cls loss 511.3626403808594  loc loss 25.674213409423828\n",
      "cls loss 657.397216796875  loc loss 29.615142822265625\n",
      "cls loss 521.4803466796875  loc loss 26.776702880859375\n",
      "cls loss 367.25970458984375  loc loss 20.29642105102539\n",
      "cls loss 297.47430419921875  loc loss 19.342510223388672\n",
      "cls loss 179.64010620117188  loc loss 7.200239658355713\n",
      "cls loss 319.25054931640625  loc loss 16.90966796875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 1., 1.])\n",
      "cls loss 308.9754638671875  loc loss 18.48920440673828\n",
      "cls loss 379.0013427734375  loc loss 23.374666213989258\n",
      "cls loss 364.01129150390625  loc loss 21.123451232910156\n",
      "cls loss 281.0842590332031  loc loss 19.635549545288086\n",
      "cls loss 350.6357421875  loc loss 22.881267547607422\n",
      "cls loss 368.92095947265625  loc loss 26.725414276123047\n",
      "cls loss 556.226318359375  loc loss 31.30340576171875\n",
      "cls loss 488.1764221191406  loc loss 33.9031867980957\n",
      "cls loss 421.4310302734375  loc loss 25.99628448486328\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 335.33734130859375  loc loss 22.39922332763672\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 479.90380859375  loc loss 17.1356201171875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([81.])\n",
      "cls loss 546.4740600585938  loc loss 25.715255737304688\n",
      "cls loss 314.5970458984375  loc loss 19.58085060119629\n",
      "cls loss 263.37518310546875  loc loss 10.87802505493164\n",
      "cls loss 346.7894287109375  loc loss 18.212453842163086\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3.,  1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 19.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 19.])\n",
      "cls loss 494.2500305175781  loc loss 30.10019302368164\n",
      "cls loss 258.5711364746094  loc loss 14.417625427246094\n",
      "cls loss 283.02880859375  loc loss 15.05831527709961\n",
      "cls loss 536.87255859375  loc loss 36.75154495239258\n",
      "cls loss 258.384521484375  loc loss 15.921014785766602\n",
      "cls loss 329.103515625  loc loss 18.768884658813477\n",
      "cls loss 420.9423828125  loc loss 25.39115333557129\n",
      "cls loss 311.67462158203125  loc loss 20.91093635559082\n",
      "cls loss 425.229248046875  loc loss 21.566024780273438\n",
      "cls loss 456.24432373046875  loc loss 27.990942001342773\n",
      "cls loss 624.0211181640625  loc loss 50.18547439575195\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 81.])\n",
      "cls loss 410.0603332519531  loc loss 18.351890563964844\n",
      "cls loss 376.38323974609375  loc loss 19.12716293334961\n",
      "cls loss 378.4466857910156  loc loss 20.373933792114258\n",
      "cls loss 314.6304931640625  loc loss 14.920166015625\n",
      "cls loss 276.2276916503906  loc loss 15.352517127990723\n",
      "cls loss 340.0315246582031  loc loss 22.374208450317383\n",
      "cls loss 242.87973022460938  loc loss 15.574296951293945\n",
      "cls loss 216.1558837890625  loc loss 12.612449645996094\n",
      "cls loss 267.20721435546875  loc loss 16.784088134765625\n",
      "cls loss 364.5365905761719  loc loss 22.236019134521484\n",
      "cls loss 342.7939147949219  loc loss 23.960641860961914\n",
      "cls loss 339.9292907714844  loc loss 20.695592880249023\n",
      "cls loss 203.55271911621094  loc loss 12.593576431274414\n",
      "cls loss 718.8787841796875  loc loss 42.269386291503906\n",
      "cls loss 388.1485290527344  loc loss 24.484363555908203\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 347.429443359375  loc loss 16.14664077758789\n",
      "cls loss 388.6986083984375  loc loss 23.4814510345459\n",
      "cls loss 281.3084716796875  loc loss 19.06036376953125\n",
      "cls loss 459.28558349609375  loc loss 31.56633758544922\n",
      "cls loss 449.873046875  loc loss 25.991697311401367\n",
      "cls loss 409.4844665527344  loc loss 23.612709045410156\n",
      "cls loss 299.34033203125  loc loss 19.954574584960938\n",
      "cls loss 275.5478820800781  loc loss 14.76861572265625\n",
      "cls loss 398.5625  loc loss 19.62660026550293\n",
      "cls loss 479.27301025390625  loc loss 27.701467514038086\n",
      "cls loss 413.83441162109375  loc loss 20.919353485107422\n",
      "cls loss 544.777587890625  loc loss 31.43634033203125\n",
      "cls loss 597.5164794921875  loc loss 38.27559280395508\n",
      "cls loss 398.1351318359375  loc loss 24.130022048950195\n",
      "cls loss 573.587158203125  loc loss 40.886329650878906\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1., 38., 47.,  1.,  1.,  1.,  1.,  1., 62.])\n",
      "cls loss 346.4498291015625  loc loss 15.803436279296875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 414.2799377441406  loc loss 28.02961540222168\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 451.095703125  loc loss 25.01270866394043\n",
      "cls loss 517.5674438476562  loc loss 35.03702163696289\n",
      "cls loss 334.1749572753906  loc loss 14.441400527954102\n",
      "cls loss 402.0865173339844  loc loss 28.89967918395996\n",
      "cls loss 391.4114990234375  loc loss 21.754308700561523\n",
      "cls loss 217.20046997070312  loc loss 6.9876508712768555\n",
      "cls loss 334.49053955078125  loc loss 17.68164825439453\n",
      "cls loss 294.61505126953125  loc loss 11.904815673828125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1., 35.])\n",
      "cls loss 320.952392578125  loc loss 18.04903793334961\n",
      "cls loss 489.61004638671875  loc loss 23.921703338623047\n",
      "cls loss 501.99053955078125  loc loss 28.243562698364258\n",
      "cls loss 442.0996398925781  loc loss 32.313594818115234\n",
      "cls loss 378.1634826660156  loc loss 24.74482536315918\n",
      "cls loss 486.6146545410156  loc loss 33.428375244140625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 267.4668884277344  loc loss 13.162055015563965\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 374.9082336425781  loc loss 14.89693546295166\n",
      "cls loss 569.4674682617188  loc loss 29.871034622192383\n",
      "cls loss 728.709716796875  loc loss 54.2166862487793\n",
      "cls loss 353.1394348144531  loc loss 17.886999130249023\n",
      "cls loss 307.9092102050781  loc loss 17.37887954711914\n",
      "cls loss 321.1452331542969  loc loss 15.160954475402832\n",
      "cls loss 364.1034240722656  loc loss 17.862991333007812\n",
      "cls loss 312.1083984375  loc loss 12.273056030273438\n",
      "cls loss 575.464111328125  loc loss 33.1137809753418\n",
      "cls loss 479.54583740234375  loc loss 25.57769012451172\n",
      "cls loss 207.69290161132812  loc loss 13.909513473510742\n",
      "cls loss 429.28759765625  loc loss 23.957721710205078\n",
      "cls loss 586.3176879882812  loc loss 39.53419494628906\n",
      "cls loss 433.3272705078125  loc loss 27.020483016967773\n",
      "cls loss 385.6085510253906  loc loss 21.325416564941406\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.])\n",
      "cls loss 366.9330139160156  loc loss 24.55579376220703\n",
      "cls loss 376.9801025390625  loc loss 22.286869049072266\n",
      "cls loss 450.70147705078125  loc loss 24.683242797851562\n",
      "cls loss 757.7500610351562  loc loss 52.09120178222656\n",
      "cls loss 269.1688232421875  loc loss 12.61174201965332\n",
      "cls loss 359.626708984375  loc loss 20.41227149963379\n",
      "cls loss 280.64453125  loc loss 15.089536666870117\n",
      "cls loss 323.3628234863281  loc loss 20.454761505126953\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 21., 21., 21.])\n",
      "cls loss 307.9869384765625  loc loss 18.82593536376953\n",
      "cls loss 333.457275390625  loc loss 15.693496704101562\n",
      "cls loss 333.6380920410156  loc loss 20.795679092407227\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 35.])\n",
      "cls loss 456.3121337890625  loc loss 24.9342041015625\n",
      "cls loss 167.43978881835938  loc loss 8.479387283325195\n",
      "cls loss 314.18316650390625  loc loss 15.939013481140137\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 291.21978759765625  loc loss 10.691274642944336\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 38., 38.,  9., 38.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1.,  1.])\n",
      "cls loss 320.35345458984375  loc loss 17.91965675354004\n",
      "cls loss 532.4299926757812  loc loss 28.253454208374023\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 2.,  1., 77., 31., 10., 10.,  1.,  4., 10.])\n",
      "cls loss 239.67050170898438  loc loss 10.211158752441406\n",
      "cls loss 485.3741149902344  loc loss 26.799179077148438\n",
      "cls loss 967.073486328125  loc loss 51.78757858276367\n",
      "cls loss 304.568603515625  loc loss 20.473995208740234\n",
      "cls loss 417.3368835449219  loc loss 28.181062698364258\n",
      "cls loss 275.7889099121094  loc loss 13.061629295349121\n",
      "cls loss 270.6082763671875  loc loss 13.745076179504395\n",
      "cls loss 382.0643310546875  loc loss 21.05747413635254\n",
      "cls loss 375.9320068359375  loc loss 22.583316802978516\n",
      "cls loss 358.25677490234375  loc loss 24.97501564025879\n",
      "cls loss 307.7962341308594  loc loss 14.621004104614258\n",
      "cls loss 320.0771789550781  loc loss 17.396631240844727\n",
      "cls loss 615.9805908203125  loc loss 33.841556549072266\n",
      "cls loss 575.7786865234375  loc loss 29.253978729248047\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1., 42., 42., 42., 42., 42., 42.,  1.,\n",
      "         1.,  1.,  1., 42.,  1.,  1., 42.,  1.])\n",
      "cls loss 320.9613037109375  loc loss 21.034011840820312\n",
      "cls loss 486.90130615234375  loc loss 23.180742263793945\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.])\n",
      "cls loss 205.1365966796875  loc loss 9.23159408569336\n",
      "cls loss 482.7558288574219  loc loss 26.827896118164062\n",
      "cls loss 357.407470703125  loc loss 22.484790802001953\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([11.])\n",
      "cls loss 207.8052978515625  loc loss 11.737481117248535\n",
      "cls loss 235.25204467773438  loc loss 11.556356430053711\n",
      "cls loss 249.49282836914062  loc loss 11.356345176696777\n",
      "cls loss 449.72442626953125  loc loss 25.793930053710938\n",
      "cls loss 350.10809326171875  loc loss 19.064849853515625\n",
      "cls loss 379.91485595703125  loc loss 23.14002799987793\n",
      "cls loss 534.7056884765625  loc loss 26.93842315673828\n",
      "cls loss 287.19647216796875  loc loss 15.429553031921387\n",
      "cls loss 633.406982421875  loc loss 36.69347381591797\n",
      "cls loss 308.535400390625  loc loss 15.915419578552246\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 288.8235168457031  loc loss 15.712562561035156\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1., 38., 38., 42.])\n",
      "cls loss 399.97735595703125  loc loss 21.993276596069336\n",
      "cls loss 360.5289306640625  loc loss 19.52870750427246\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 314.55242919921875  loc loss 18.25918197631836\n",
      "cls loss 673.7449340820312  loc loss 38.51816940307617\n",
      "cls loss 395.2303161621094  loc loss 22.727134704589844\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10.,  3.,  3.,  6.,  8.,  8.,  1.,  1.,  1., 10.])\n",
      "cls loss 295.9610900878906  loc loss 14.439579963684082\n",
      "cls loss 204.39405822753906  loc loss 6.980247497558594\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10.,  3.])\n",
      "cls loss 279.7001953125  loc loss 17.25048065185547\n",
      "cls loss 138.24354553222656  loc loss 7.960712432861328\n",
      "cls loss 360.72412109375  loc loss 24.080169677734375\n",
      "cls loss 434.5123291015625  loc loss 26.760805130004883\n",
      "cls loss 320.05926513671875  loc loss 17.715986251831055\n",
      "cls loss 172.74200439453125  loc loss 12.1859769821167\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 34.])\n",
      "cls loss 480.8399658203125  loc loss 31.944095611572266\n",
      "cls loss 645.106201171875  loc loss 42.271270751953125\n",
      "cls loss 399.58990478515625  loc loss 26.332855224609375\n",
      "cls loss 320.4779968261719  loc loss 20.10348129272461\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.,  1.])\n",
      "cls loss 359.1844177246094  loc loss 14.368456840515137\n",
      "cls loss 597.9521484375  loc loss 37.874488830566406\n",
      "cls loss 833.2284545898438  loc loss 47.32085418701172\n",
      "cls loss 657.9517822265625  loc loss 30.927410125732422\n",
      "cls loss 372.17669677734375  loc loss 17.323589324951172\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 391.2107238769531  loc loss 22.034780502319336\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10.])\n",
      "cls loss 256.2299499511719  loc loss 12.323104858398438\n",
      "cls loss 382.27557373046875  loc loss 18.837278366088867\n",
      "cls loss 362.78485107421875  loc loss 19.544395446777344\n",
      "cls loss 231.2081298828125  loc loss 13.605979919433594\n",
      "cls loss 326.8458251953125  loc loss 19.159271240234375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21.,\n",
      "        21.])\n",
      "cls loss 391.3970031738281  loc loss 23.279218673706055\n",
      "cls loss 343.3307189941406  loc loss 18.173580169677734\n",
      "cls loss 231.73858642578125  loc loss 10.59790325164795\n",
      "cls loss 528.0978393554688  loc loss 32.15596008300781\n",
      "cls loss 383.36529541015625  loc loss 23.421592712402344\n",
      "cls loss 289.1973876953125  loc loss 12.335746765136719\n",
      "cls loss 610.277587890625  loc loss 32.865928649902344\n",
      "cls loss 693.6634521484375  loc loss 45.1060676574707\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15., 85.])\n",
      "cls loss 476.83819580078125  loc loss 23.974647521972656\n",
      "cls loss 466.8167419433594  loc loss 30.86448860168457\n",
      "cls loss 465.2259521484375  loc loss 29.67570686340332\n",
      "cls loss 360.53564453125  loc loss 21.699655532836914\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 8., 8.])\n",
      "cls loss 276.92144775390625  loc loss 9.672843933105469\n",
      "cls loss 260.8840026855469  loc loss 19.312149047851562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 337.0865173339844  loc loss 17.823686599731445\n",
      "cls loss 293.8968505859375  loc loss 15.040968894958496\n",
      "cls loss 317.65338134765625  loc loss 16.768957138061523\n",
      "cls loss 472.3084716796875  loc loss 24.535987854003906\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1., 35., 27., 27.,  1., 27.,  1.])\n",
      "cls loss 501.1971435546875  loc loss 37.83698272705078\n",
      "cls loss 315.9132080078125  loc loss 14.908108711242676\n",
      "cls loss 323.7661437988281  loc loss 23.36400604248047\n",
      "cls loss 333.43084716796875  loc loss 26.359577178955078\n",
      "cls loss 302.0916442871094  loc loss 17.883943557739258\n",
      "cls loss 343.30413818359375  loc loss 23.746177673339844\n",
      "cls loss 339.88800048828125  loc loss 22.669189453125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  2.,  2.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  2.,  2.])\n",
      "cls loss 163.63551330566406  loc loss 7.669580459594727\n",
      "cls loss 542.5479736328125  loc loss 32.0390739440918\n",
      "cls loss 327.906982421875  loc loss 13.922662734985352\n",
      "cls loss 593.7237548828125  loc loss 40.2311897277832\n",
      "cls loss 225.26873779296875  loc loss 12.47690200805664\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 19., 19., 19., 16.])\n",
      "cls loss 228.89437866210938  loc loss 7.889337062835693\n",
      "cls loss 202.87237548828125  loc loss 7.898200988769531\n",
      "cls loss 330.777587890625  loc loss 13.700507164001465\n",
      "cls loss 432.04766845703125  loc loss 25.454059600830078\n",
      "cls loss 167.0188446044922  loc loss 11.116678237915039\n",
      "cls loss 463.3233642578125  loc loss 34.2481803894043\n",
      "cls loss 342.4203796386719  loc loss 20.308401107788086\n",
      "cls loss 357.1956481933594  loc loss 22.917078018188477\n",
      "cls loss 467.275390625  loc loss 28.545238494873047\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 454.29443359375  loc loss 20.146739959716797\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 664.3262329101562  loc loss 52.076087951660156\n",
      "cls loss 857.6634521484375  loc loss 71.45561218261719\n",
      "cls loss 401.85662841796875  loc loss 22.317340850830078\n",
      "cls loss 385.181640625  loc loss 21.237911224365234\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3.,  3.,  3.,  3.,  3., 10.])\n",
      "cls loss 184.846435546875  loc loss 11.226968765258789\n",
      "cls loss 418.46661376953125  loc loss 18.745656967163086\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 1., 1., 1., 3., 3., 3., 3.])\n",
      "cls loss 341.7681579589844  loc loss 15.223484992980957\n",
      "cls loss 649.3370361328125  loc loss 39.37694549560547\n",
      "cls loss 540.050048828125  loc loss 26.302522659301758\n",
      "cls loss 335.69244384765625  loc loss 17.233659744262695\n",
      "cls loss 516.3648681640625  loc loss 32.23301315307617\n",
      "cls loss 298.29864501953125  loc loss 19.535537719726562\n",
      "cls loss 492.5673828125  loc loss 30.438234329223633\n",
      "cls loss 372.5162353515625  loc loss 31.923500061035156\n",
      "cls loss 332.52154541015625  loc loss 22.268268585205078\n",
      "cls loss 762.214111328125  loc loss 56.828086853027344\n",
      "cls loss 486.16192626953125  loc loss 35.74040985107422\n",
      "cls loss 313.81622314453125  loc loss 15.101137161254883\n",
      "cls loss 185.2198486328125  loc loss 8.494095802307129\n",
      "cls loss 244.10089111328125  loc loss 11.589465141296387\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3., 10., 10., 10., 10., 10., 10., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10., 10., 10., 10., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 11., 10., 10., 10., 10., 10.,  3.,  3.,  3.,  3.,  3.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 11., 10., 10., 10., 10., 10.,  3.,  3.,  3.,  3.,  3.])\n",
      "cls loss 186.29965209960938  loc loss 8.258599281311035\n",
      "cls loss 266.8487854003906  loc loss 10.264388084411621\n",
      "cls loss 245.202392578125  loc loss 12.909568786621094\n",
      "cls loss 229.63015747070312  loc loss 9.55078411102295\n",
      "cls loss 311.65386962890625  loc loss 21.980205535888672\n",
      "cls loss 220.569091796875  loc loss 8.903815269470215\n",
      "cls loss 480.70379638671875  loc loss 27.96662139892578\n",
      "cls loss 452.4402770996094  loc loss 21.749975204467773\n",
      "cls loss 638.96728515625  loc loss 35.23359298706055\n",
      "cls loss 326.5152587890625  loc loss 20.470006942749023\n",
      "cls loss 554.194091796875  loc loss 31.886234283447266\n",
      "cls loss 414.9913635253906  loc loss 28.283958435058594\n",
      "cls loss 425.91162109375  loc loss 24.405010223388672\n",
      "cls loss 403.9862060546875  loc loss 25.84837532043457\n",
      "cls loss 520.0590209960938  loc loss 32.17824172973633\n",
      "cls loss 495.3290710449219  loc loss 30.595792770385742\n",
      "cls loss 236.6204376220703  loc loss 12.267512321472168\n",
      "cls loss 508.7769775390625  loc loss 30.472837448120117\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 10.,  1., 18.])\n",
      "cls loss 212.43768310546875  loc loss 13.7358980178833\n",
      "cls loss 247.8878173828125  loc loss 11.445012092590332\n",
      "cls loss 463.2491455078125  loc loss 23.599266052246094\n",
      "cls loss 659.224609375  loc loss 35.61421203613281\n",
      "cls loss 391.8576965332031  loc loss 23.841869354248047\n",
      "cls loss 607.2168579101562  loc loss 25.77273941040039\n",
      "cls loss 476.4442138671875  loc loss 26.916236877441406\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.,  1.,  1.])\n",
      "cls loss 539.0948486328125  loc loss 28.730712890625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1., 38.,  1.])\n",
      "cls loss 445.12689208984375  loc loss 25.255157470703125\n",
      "cls loss 648.109619140625  loc loss 45.4196891784668\n",
      "cls loss 353.0536193847656  loc loss 22.346529006958008\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 468.51873779296875  loc loss 24.021453857421875\n",
      "cls loss 378.5299987792969  loc loss 21.070270538330078\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3., 10.,  8.,  3., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.])\n",
      "cls loss 420.2506103515625  loc loss 22.76419448852539\n",
      "cls loss 280.83514404296875  loc loss 18.13802146911621\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3.,  3., 11.,  3., 10., 10.,  3.,  3., 10.])\n",
      "cls loss 271.7613830566406  loc loss 17.495010375976562\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3., 10., 10., 10.])\n",
      "cls loss 352.75469970703125  loc loss 18.96055030822754\n",
      "cls loss 273.39031982421875  loc loss 19.30361557006836\n",
      "cls loss 373.39813232421875  loc loss 27.040077209472656\n",
      "cls loss 546.951416015625  loc loss 33.62904357910156\n",
      "cls loss 359.31182861328125  loc loss 22.401229858398438\n",
      "cls loss 287.540771484375  loc loss 20.01136016845703\n",
      "cls loss 364.70611572265625  loc loss 19.222265243530273\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 9.,  9., 85., 85.])\n",
      "cls loss 310.2305603027344  loc loss 12.721543312072754\n",
      "cls loss 400.7776184082031  loc loss 23.747295379638672\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 587.6981201171875  loc loss 32.55017852783203\n",
      "cls loss 487.2995300292969  loc loss 20.12558937072754\n",
      "cls loss 562.8536376953125  loc loss 37.42531967163086\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10., 10., 10., 10.])\n",
      "cls loss 364.21087646484375  loc loss 21.384075164794922\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([13.])\n",
      "cls loss 566.9217529296875  loc loss 40.45869445800781\n",
      "cls loss 150.59896850585938  loc loss 8.318488121032715\n",
      "cls loss 230.10696411132812  loc loss 11.009567260742188\n",
      "cls loss 295.82012939453125  loc loss 17.322879791259766\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19.,  1.,  1.,  1., 19., 19.])\n",
      "cls loss 327.0186767578125  loc loss 19.815330505371094\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 262.7517395019531  loc loss 16.594057083129883\n",
      "cls loss 398.23828125  loc loss 24.980491638183594\n",
      "cls loss 304.64349365234375  loc loss 15.987997055053711\n",
      "cls loss 432.1016845703125  loc loss 20.968435287475586\n",
      "cls loss 466.99774169921875  loc loss 30.008455276489258\n",
      "cls loss 352.01629638671875  loc loss 18.831329345703125\n",
      "cls loss 573.4107666015625  loc loss 36.94432830810547\n",
      "cls loss 197.819580078125  loc loss 7.731032371520996\n",
      "cls loss 370.8716735839844  loc loss 22.924230575561523\n",
      "cls loss 311.3086853027344  loc loss 15.962055206298828\n",
      "cls loss 342.85443115234375  loc loss 15.857123374938965\n",
      "cls loss 463.9018859863281  loc loss 23.578598022460938\n",
      "cls loss 360.34478759765625  loc loss 15.803407669067383\n",
      "cls loss 523.5650634765625  loc loss 32.410400390625\n",
      "cls loss 338.8747863769531  loc loss 18.827762603759766\n",
      "cls loss 440.42767333984375  loc loss 29.255390167236328\n",
      "cls loss 637.0458374023438  loc loss 35.300537109375\n",
      "cls loss 344.31549072265625  loc loss 23.522132873535156\n",
      "cls loss 415.84503173828125  loc loss 21.681137084960938\n",
      "cls loss 497.3682556152344  loc loss 35.769081115722656\n",
      "cls loss 585.4190673828125  loc loss 35.05437469482422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 626.47607421875  loc loss 35.21979904174805\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 5.])\n",
      "cls loss 150.49600219726562  loc loss 7.821998119354248\n",
      "cls loss 233.146484375  loc loss 9.129271507263184\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 13.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 6., 8., 8.])\n",
      "cls loss 181.81387329101562  loc loss 9.368583679199219\n",
      "cls loss 238.42041015625  loc loss 10.68565559387207\n",
      "cls loss 472.2898254394531  loc loss 27.882217407226562\n",
      "cls loss 196.8585968017578  loc loss 10.439873695373535\n",
      "cls loss 416.08563232421875  loc loss 26.747264862060547\n",
      "cls loss 613.5145263671875  loc loss 41.28274917602539\n",
      "cls loss 398.5361328125  loc loss 23.61081314086914\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([42., 42.,  1.,  1.,  1.,  1.,  1.,  1.,  1., 42., 42.])\n",
      "cls loss 415.08770751953125  loc loss 19.705005645751953\n",
      "cls loss 530.2698974609375  loc loss 37.53643035888672\n",
      "cls loss 490.8292236328125  loc loss 29.786073684692383\n",
      "cls loss 310.95074462890625  loc loss 17.534351348876953\n",
      "cls loss 404.93035888671875  loc loss 19.8767032623291\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 625.8480224609375  loc loss 34.85725784301758\n",
      "cls loss 498.019775390625  loc loss 30.519201278686523\n",
      "cls loss 294.10992431640625  loc loss 13.959612846374512\n",
      "cls loss 250.52285766601562  loc loss 13.043935775756836\n",
      "cls loss 332.2996826171875  loc loss 19.117952346801758\n",
      "cls loss 445.71112060546875  loc loss 26.093368530273438\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15.])\n",
      "cls loss 216.2236785888672  loc loss 6.37960958480835\n",
      "cls loss 378.8458251953125  loc loss 20.59162712097168\n",
      "cls loss 339.2791442871094  loc loss 18.74202537536621\n",
      "cls loss 608.2762451171875  loc loss 34.91070556640625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19.,  7.])\n",
      "cls loss 276.04254150390625  loc loss 15.280941009521484\n",
      "cls loss 545.8786010742188  loc loss 37.61990737915039\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 498.65338134765625  loc loss 25.363239288330078\n",
      "cls loss 479.49853515625  loc loss 30.243505477905273\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([38., 38.,  1., 18.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1., 18., 18.,  1.])\n",
      "cls loss 317.8553161621094  loc loss 16.28362274169922\n",
      "cls loss 307.6325988769531  loc loss 14.676033020019531\n",
      "cls loss 608.1583251953125  loc loss 39.1369743347168\n",
      "cls loss 440.1816101074219  loc loss 26.957080841064453\n",
      "cls loss 362.66448974609375  loc loss 23.02566909790039\n",
      "cls loss 257.1166687011719  loc loss 16.252681732177734\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.])\n",
      "cls loss 146.82781982421875  loc loss 6.329164028167725\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([32.])\n",
      "cls loss 392.224609375  loc loss 19.216522216796875\n",
      "cls loss 349.38067626953125  loc loss 21.403972625732422\n",
      "cls loss 434.99249267578125  loc loss 29.403425216674805\n",
      "cls loss 377.28326416015625  loc loss 21.167724609375\n",
      "cls loss 324.564208984375  loc loss 16.467594146728516\n",
      "cls loss 520.5492553710938  loc loss 27.46672248840332\n",
      "cls loss 620.71533203125  loc loss 35.901241302490234\n",
      "cls loss 442.25213623046875  loc loss 28.370708465576172\n",
      "cls loss 334.797119140625  loc loss 19.83655548095703\n",
      "cls loss 544.8449096679688  loc loss 33.853633880615234\n",
      "cls loss 360.71502685546875  loc loss 18.49506950378418\n",
      "cls loss 649.7495727539062  loc loss 38.45238494873047\n",
      "cls loss 431.7870178222656  loc loss 21.360685348510742\n",
      "cls loss 342.5811462402344  loc loss 25.63381576538086\n",
      "cls loss 260.40374755859375  loc loss 12.412379264831543\n",
      "cls loss 314.5074462890625  loc loss 18.88630485534668\n",
      "cls loss 443.43780517578125  loc loss 29.851512908935547\n",
      "cls loss 509.841064453125  loc loss 34.43349838256836\n",
      "cls loss 315.48974609375  loc loss 18.336423873901367\n",
      "cls loss 494.0911865234375  loc loss 32.7738037109375\n",
      "cls loss 598.4571533203125  loc loss 35.748966217041016\n",
      "cls loss 217.1463623046875  loc loss 12.959884643554688\n",
      "cls loss 585.067138671875  loc loss 35.69955062866211\n",
      "cls loss 436.9103698730469  loc loss 26.459444046020508\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 570.1658935546875  loc loss 38.24110412597656\n",
      "cls loss 234.94888305664062  loc loss 9.435256004333496\n",
      "cls loss 365.3442687988281  loc loss 21.37945556640625\n",
      "cls loss 368.5953369140625  loc loss 24.80109977722168\n",
      "cls loss 314.489501953125  loc loss 19.050121307373047\n",
      "cls loss 179.8121337890625  loc loss 10.26179313659668\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 9., 9., 1., 9., 9., 9., 9., 1., 9.])\n",
      "cls loss 821.2992553710938  loc loss 51.66027069091797\n",
      "cls loss 443.36871337890625  loc loss 22.215641021728516\n",
      "cls loss 690.4444580078125  loc loss 46.38209533691406\n",
      "cls loss 267.241455078125  loc loss 19.67477798461914\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 42., 42.])\n",
      "cls loss 443.4096374511719  loc loss 30.590166091918945\n",
      "cls loss 454.3802490234375  loc loss 33.89289093017578\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  2.,  1.,  1.,  1., 38.,\n",
      "         1.,  1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 38., 38., 38.,  1., 38., 38., 38.,  1.,  1., 38.,  1.,\n",
      "         1.])\n",
      "cls loss 274.83624267578125  loc loss 19.520503997802734\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  8.,  8.])\n",
      "cls loss 640.2525634765625  loc loss 42.41569519042969\n",
      "cls loss 662.2503662109375  loc loss 48.14836502075195\n",
      "cls loss 234.113525390625  loc loss 14.385004997253418\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([4., 1., 1., 4.])\n",
      "cls loss 381.66424560546875  loc loss 22.608322143554688\n",
      "cls loss 484.1510314941406  loc loss 26.808826446533203\n",
      "cls loss 191.35597229003906  loc loss 9.608662605285645\n",
      "cls loss 239.39651489257812  loc loss 14.644865036010742\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([51.,  1.])\n",
      "cls loss 169.61526489257812  loc loss 7.496828079223633\n",
      "cls loss 246.49586486816406  loc loss 14.796174049377441\n",
      "cls loss 517.6713256835938  loc loss 22.89266586303711\n",
      "cls loss 475.30792236328125  loc loss 32.14722442626953\n",
      "cls loss 743.0040283203125  loc loss 33.73496627807617\n",
      "cls loss 869.529541015625  loc loss 53.5704345703125\n",
      "cls loss 356.33935546875  loc loss 23.553752899169922\n",
      "cls loss 532.0400390625  loc loss 37.8751220703125\n",
      "cls loss 576.7343139648438  loc loss 35.64729690551758\n",
      "cls loss 414.7883605957031  loc loss 24.291305541992188\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  3.,  1.,  1.,  1.,  3.,  1.,  1.,\n",
      "         1.,  1.,  1.])\n",
      "cls loss 450.20697021484375  loc loss 18.564224243164062\n",
      "cls loss 470.18310546875  loc loss 24.595272064208984\n",
      "cls loss 477.0588073730469  loc loss 21.555862426757812\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "cls loss 401.7115478515625  loc loss 20.65123748779297\n",
      "cls loss 225.1610107421875  loc loss 16.668399810791016\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3.])\n",
      "cls loss 176.78717041015625  loc loss 9.01411247253418\n",
      "cls loss 311.0673522949219  loc loss 17.250146865844727\n",
      "cls loss 300.358642578125  loc loss 18.28827667236328\n",
      "cls loss 541.6515502929688  loc loss 31.781856536865234\n",
      "cls loss 239.90188598632812  loc loss 17.104951858520508\n",
      "cls loss 282.784423828125  loc loss 22.192462921142578\n",
      "cls loss 802.073974609375  loc loss 54.61054229736328\n",
      "cls loss 368.40576171875  loc loss 25.554004669189453\n",
      "cls loss 274.02911376953125  loc loss 18.38042449951172\n",
      "cls loss 322.78717041015625  loc loss 17.38614273071289\n",
      "cls loss 294.7606201171875  loc loss 20.43168830871582\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 545.1431884765625  loc loss 35.92112350463867\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  9., 64., 64., 64., 64., 64., 64., 64., 64., 64.,  9.,  9.,  9.,\n",
      "         9.])\n",
      "cls loss 247.78976440429688  loc loss 11.869074821472168\n",
      "cls loss 801.9293212890625  loc loss 55.271728515625\n",
      "cls loss 422.734619140625  loc loss 25.342836380004883\n",
      "cls loss 492.30010986328125  loc loss 31.35247230529785\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.,  3.,  3.])\n",
      "cls loss 312.61541748046875  loc loss 17.358232498168945\n",
      "cls loss 335.1585998535156  loc loss 23.04343032836914\n",
      "cls loss 358.1933288574219  loc loss 25.02042007446289\n",
      "cls loss 363.083740234375  loc loss 23.488094329833984\n",
      "cls loss 422.53363037109375  loc loss 27.686241149902344\n",
      "cls loss 429.08380126953125  loc loss 25.578889846801758\n",
      "cls loss 384.56005859375  loc loss 25.055648803710938\n",
      "cls loss 387.2720947265625  loc loss 20.568599700927734\n",
      "cls loss 482.45111083984375  loc loss 30.153247833251953\n",
      "cls loss 354.9410705566406  loc loss 20.085500717163086\n",
      "cls loss 265.7101135253906  loc loss 14.184340476989746\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 218.9488525390625  loc loss 13.544544219970703\n",
      "cls loss 313.060791015625  loc loss 25.584632873535156\n",
      "cls loss 472.5841064453125  loc loss 31.308448791503906\n",
      "cls loss 240.06256103515625  loc loss 13.57135009765625\n",
      "cls loss 383.92926025390625  loc loss 24.043437957763672\n",
      "cls loss 701.5772705078125  loc loss 35.66856384277344\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 42., 42.,  1.,  1.])\n",
      "cls loss 424.9344482421875  loc loss 21.664466857910156\n",
      "cls loss 273.68218994140625  loc loss 15.663267135620117\n",
      "cls loss 386.9510803222656  loc loss 21.93215560913086\n",
      "cls loss 522.6129760742188  loc loss 36.89433288574219\n",
      "cls loss 327.7129211425781  loc loss 17.320051193237305\n",
      "cls loss 506.99114990234375  loc loss 32.12489700317383\n",
      "cls loss 442.12786865234375  loc loss 28.04911231994629\n",
      "cls loss 433.1278076171875  loc loss 27.011152267456055\n",
      "cls loss 351.6568603515625  loc loss 20.911773681640625\n",
      "cls loss 280.8972473144531  loc loss 17.84993553161621\n",
      "cls loss 221.2381591796875  loc loss 10.140726089477539\n",
      "cls loss 354.81390380859375  loc loss 22.181535720825195\n",
      "cls loss 547.0194702148438  loc loss 31.805553436279297\n",
      "cls loss 389.85565185546875  loc loss 22.327245712280273\n",
      "cls loss 378.64727783203125  loc loss 25.53644561767578\n",
      "cls loss 411.0543212890625  loc loss 23.873998641967773\n",
      "cls loss 608.8688354492188  loc loss 42.14771270751953\n",
      "cls loss 492.63885498046875  loc loss 29.92905044555664\n",
      "cls loss 530.9774169921875  loc loss 26.604665756225586\n",
      "cls loss 333.71533203125  loc loss 14.412359237670898\n",
      "cls loss 468.968017578125  loc loss 25.74213981628418\n",
      "cls loss 416.02557373046875  loc loss 22.419023513793945\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 5., 5., 5., 5., 5., 5.])\n",
      "cls loss 256.62005615234375  loc loss 14.521577835083008\n",
      "cls loss 332.4974365234375  loc loss 16.902063369750977\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([13.])\n",
      "cls loss 242.39547729492188  loc loss 10.206986427307129\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([44., 10.,  1.,  1.,  1.])\n",
      "cls loss 214.60092163085938  loc loss 14.464086532592773\n",
      "cls loss 377.37957763671875  loc loss 20.446514129638672\n",
      "cls loss 351.7203369140625  loc loss 18.33769416809082\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19., 19., 19., 19., 19., 19., 19.])\n",
      "cls loss 367.55828857421875  loc loss 22.14976692199707\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([56.])\n",
      "cls loss 790.645751953125  loc loss 50.4644775390625\n",
      "cls loss 503.5899658203125  loc loss 35.284339904785156\n",
      "cls loss 640.4722900390625  loc loss 38.04884719848633\n",
      "cls loss 612.0956420898438  loc loss 43.6014404296875\n",
      "cls loss 374.23345947265625  loc loss 20.2069149017334\n",
      "cls loss 633.2200927734375  loc loss 37.949764251708984\n",
      "cls loss 359.50018310546875  loc loss 23.60124397277832\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 36.])\n",
      "cls loss 462.73175048828125  loc loss 20.277629852294922\n",
      "cls loss 382.1808166503906  loc loss 22.81793212890625\n",
      "cls loss 359.50714111328125  loc loss 21.42961883544922\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5.])\n",
      "cls loss 420.387451171875  loc loss 24.421138763427734\n",
      "cls loss 228.61390686035156  loc loss 10.926057815551758\n",
      "cls loss 536.93310546875  loc loss 27.458982467651367\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "cls loss 469.51849365234375  loc loss 27.11450958251953\n",
      "cls loss 442.82135009765625  loc loss 27.110069274902344\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 467.6777038574219  loc loss 27.818498611450195\n",
      "cls loss 537.271728515625  loc loss 30.598491668701172\n",
      "cls loss 461.26361083984375  loc loss 36.0397834777832\n",
      "cls loss 316.9657897949219  loc loss 19.361644744873047\n",
      "cls loss 352.90911865234375  loc loss 23.994274139404297\n",
      "cls loss 368.4881896972656  loc loss 20.285839080810547\n",
      "cls loss 618.952880859375  loc loss 29.550687789916992\n",
      "cls loss 246.75204467773438  loc loss 12.446794509887695\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 11., 15., 10., 10., 10., 10., 10.])\n",
      "cls loss 566.3352661132812  loc loss 36.00712966918945\n",
      "cls loss 342.6098937988281  loc loss 23.54344940185547\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3.])\n",
      "cls loss 354.51165771484375  loc loss 25.199411392211914\n",
      "cls loss 339.7110595703125  loc loss 16.011716842651367\n",
      "cls loss 369.40008544921875  loc loss 17.34579086303711\n",
      "cls loss 483.87322998046875  loc loss 19.292001724243164\n",
      "cls loss 211.08883666992188  loc loss 9.471611976623535\n",
      "cls loss 378.49755859375  loc loss 23.942256927490234\n",
      "cls loss 446.20953369140625  loc loss 27.889511108398438\n",
      "cls loss 387.49639892578125  loc loss 24.38159942626953\n",
      "cls loss 910.0870361328125  loc loss 54.401092529296875\n",
      "cls loss 608.1405029296875  loc loss 36.24736022949219\n",
      "cls loss 380.1572570800781  loc loss 24.334590911865234\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  9.,  9.,  9.,  6.,  6., 85., 85.,  8.,  1.,  1.,  1.,  1.,\n",
      "         6.,  6.])\n",
      "cls loss 250.93545532226562  loc loss 18.975210189819336\n",
      "cls loss 642.9588623046875  loc loss 41.90715026855469\n",
      "cls loss 750.5987548828125  loc loss 43.050357818603516\n",
      "cls loss 468.87017822265625  loc loss 31.9528865814209\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10.,  3.,  3., 10.])\n",
      "cls loss 299.1080322265625  loc loss 15.915740013122559\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([7.])\n",
      "cls loss 393.41619873046875  loc loss 24.042734146118164\n",
      "cls loss 378.2529296875  loc loss 22.96860122680664\n",
      "cls loss 401.97930908203125  loc loss 32.851966857910156\n",
      "cls loss 663.4127197265625  loc loss 44.21121597290039\n",
      "cls loss 366.3162536621094  loc loss 23.336524963378906\n",
      "cls loss 572.2843017578125  loc loss 34.41401290893555\n",
      "cls loss 711.868408203125  loc loss 37.92013168334961\n",
      "cls loss 462.58001708984375  loc loss 25.15231704711914\n",
      "cls loss 513.7193603515625  loc loss 30.40817642211914\n",
      "cls loss 385.57574462890625  loc loss 25.013118743896484\n",
      "cls loss 563.4884643554688  loc loss 38.01239776611328\n",
      "cls loss 430.5711364746094  loc loss 26.469955444335938\n",
      "cls loss 308.0619201660156  loc loss 19.69268798828125\n",
      "cls loss 500.24395751953125  loc loss 34.791099548339844\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([62.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([62.])\n",
      "cls loss 225.0931396484375  loc loss 10.470782279968262\n",
      "cls loss 346.908935546875  loc loss 26.11952018737793\n",
      "cls loss 359.7746276855469  loc loss 22.800600051879883\n",
      "cls loss 227.20460510253906  loc loss 10.549688339233398\n",
      "cls loss 493.86846923828125  loc loss 30.44590187072754\n",
      "cls loss 501.5381164550781  loc loss 27.1807804107666\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([28.])\n",
      "cls loss 636.369873046875  loc loss 27.972171783447266\n",
      "cls loss 467.90557861328125  loc loss 30.82539176940918\n",
      "cls loss 468.7283630371094  loc loss 30.764179229736328\n",
      "cls loss 522.3783569335938  loc loss 29.513477325439453\n",
      "cls loss 763.27783203125  loc loss 42.344970703125\n",
      "cls loss 437.5428466796875  loc loss 22.97209930419922\n",
      "cls loss 585.5269775390625  loc loss 27.28952980041504\n",
      "cls loss 471.552490234375  loc loss 31.89842987060547\n",
      "cls loss 745.0261840820312  loc loss 53.16157913208008\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([81.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 441.64984130859375  loc loss 16.984159469604492\n",
      "cls loss 341.0480651855469  loc loss 16.815574645996094\n",
      "cls loss 246.22256469726562  loc loss 16.893033981323242\n",
      "cls loss 219.07025146484375  loc loss 9.815555572509766\n",
      "cls loss 247.51686096191406  loc loss 18.59469985961914\n",
      "cls loss 309.5757141113281  loc loss 19.102210998535156\n",
      "cls loss 318.2619934082031  loc loss 22.1882381439209\n",
      "cls loss 470.71484375  loc loss 37.13509750366211\n",
      "cls loss 573.7754516601562  loc loss 32.133888244628906\n",
      "cls loss 970.272705078125  loc loss 62.86145782470703\n",
      "cls loss 383.78594970703125  loc loss 17.60757827758789\n",
      "cls loss 498.2635803222656  loc loss 34.62700271606445\n",
      "cls loss 342.58160400390625  loc loss 19.68105125427246\n",
      "cls loss 451.1767578125  loc loss 24.655899047851562\n",
      "cls loss 406.9481201171875  loc loss 22.497190475463867\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([44., 44.])\n",
      "cls loss 366.16143798828125  loc loss 17.015132904052734\n",
      "cls loss 413.87396240234375  loc loss 25.770931243896484\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15.])\n",
      "cls loss 381.47186279296875  loc loss 21.284589767456055\n",
      "cls loss 230.90643310546875  loc loss 12.021784782409668\n",
      "cls loss 399.83941650390625  loc loss 24.869726181030273\n",
      "cls loss 239.13638305664062  loc loss 11.320117950439453\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0)\n",
      "skipping\n",
      "tensor([1., 3., 3.])\n",
      "cls loss 269.0840759277344  loc loss 15.013221740722656\n",
      "cls loss 188.22288513183594  loc loss 8.814847946166992\n",
      "cls loss 355.8753967285156  loc loss 25.023330688476562\n",
      "cls loss 429.89892578125  loc loss 23.23586654663086\n",
      "cls loss 363.860595703125  loc loss 24.761730194091797\n",
      "cls loss 309.19677734375  loc loss 20.735172271728516\n",
      "cls loss 337.9970703125  loc loss 23.041353225708008\n",
      "cls loss 456.92767333984375  loc loss 29.24361801147461\n",
      "cls loss 300.94549560546875  loc loss 20.401351928710938\n",
      "cls loss 398.81085205078125  loc loss 29.08505630493164\n",
      "cls loss 289.10638427734375  loc loss 15.735288619995117\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 525.9708251953125  loc loss 28.525386810302734\n",
      "cls loss 629.0074462890625  loc loss 24.678386688232422\n",
      "cls loss 537.96044921875  loc loss 34.202274322509766\n",
      "cls loss 533.441162109375  loc loss 38.875213623046875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10., 10., 10.,  1.,  1.,  1.,  1.,  1.,  1.,  8.,  8.,\n",
      "         1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10., 10., 10.,  1.,  1.,  1.,  1.,  1.,  1.,  8.,  8.,\n",
      "         1.])\n",
      "cls loss 419.1484069824219  loc loss 20.910926818847656\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 3., 3., 3.])\n",
      "cls loss 421.7707214355469  loc loss 22.37476348876953\n",
      "cls loss 262.35205078125  loc loss 16.641845703125\n",
      "cls loss 201.36410522460938  loc loss 9.682544708251953\n",
      "cls loss 397.4559326171875  loc loss 28.13348388671875\n",
      "cls loss 284.3436279296875  loc loss 12.92337417602539\n",
      "cls loss 362.3536682128906  loc loss 23.318683624267578\n",
      "cls loss 406.47052001953125  loc loss 28.041229248046875\n",
      "cls loss 535.7844848632812  loc loss 37.15055847167969\n",
      "cls loss 469.1197814941406  loc loss 22.92523956298828\n",
      "cls loss 421.50384521484375  loc loss 22.485218048095703\n",
      "cls loss 436.8531494140625  loc loss 27.714439392089844\n",
      "cls loss 313.0893859863281  loc loss 22.204055786132812\n",
      "cls loss 658.3150634765625  loc loss 43.40266418457031\n",
      "cls loss 269.977783203125  loc loss 14.701083183288574\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 524.114990234375  loc loss 28.754465103149414\n",
      "cls loss 212.56480407714844  loc loss 8.740734100341797\n",
      "cls loss 558.1214599609375  loc loss 37.56028747558594\n",
      "cls loss 282.5640563964844  loc loss 17.410001754760742\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 34.])\n",
      "cls loss 474.23541259765625  loc loss 24.838205337524414\n",
      "cls loss 255.4438934326172  loc loss 14.88492488861084\n",
      "cls loss 519.9400634765625  loc loss 26.626731872558594\n",
      "cls loss 193.8389892578125  loc loss 11.279900550842285\n",
      "cls loss 390.90411376953125  loc loss 21.155447006225586\n",
      "cls loss 390.85577392578125  loc loss 29.311216354370117\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 38.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16., 16., 16.,  9.,  9.,  9., 16., 16., 16., 85.,  9.])\n",
      "cls loss 403.37744140625  loc loss 21.901981353759766\n",
      "cls loss 435.511962890625  loc loss 30.517005920410156\n",
      "cls loss 587.8739013671875  loc loss 35.55213928222656\n",
      "cls loss 910.1932373046875  loc loss 52.792964935302734\n",
      "cls loss 225.7835693359375  loc loss 12.001251220703125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3., 10.,  8.,  8., 10., 10., 10.,  3.,  3., 14.])\n",
      "cls loss 244.51577758789062  loc loss 14.30994987487793\n",
      "cls loss 453.2083740234375  loc loss 28.367938995361328\n",
      "cls loss 191.2516326904297  loc loss 7.579485893249512\n",
      "cls loss 334.5282897949219  loc loss 14.146729469299316\n",
      "cls loss 463.6802978515625  loc loss 28.77288055419922\n",
      "cls loss 388.1263122558594  loc loss 21.930675506591797\n",
      "cls loss 224.94619750976562  loc loss 11.760932922363281\n",
      "cls loss 298.86468505859375  loc loss 13.93455982208252\n",
      "cls loss 512.3445434570312  loc loss 24.89149284362793\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42., 42.,  1.])\n",
      "cls loss 460.7529602050781  loc loss 25.074825286865234\n",
      "cls loss 395.54522705078125  loc loss 19.219951629638672\n",
      "cls loss 501.9683837890625  loc loss 33.64642333984375\n",
      "cls loss 555.5665283203125  loc loss 30.654836654663086\n",
      "cls loss 378.17523193359375  loc loss 20.023807525634766\n",
      "cls loss 450.3353271484375  loc loss 30.111572265625\n",
      "cls loss 263.76544189453125  loc loss 17.147279739379883\n",
      "cls loss 288.4773254394531  loc loss 20.78378677368164\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20.])\n",
      "cls loss 210.4189453125  loc loss 11.577939987182617\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([11.])\n",
      "cls loss 295.5865173339844  loc loss 12.666975021362305\n",
      "cls loss 169.77349853515625  loc loss 10.637075424194336\n",
      "cls loss 450.8728942871094  loc loss 31.50687026977539\n",
      "cls loss 188.35366821289062  loc loss 9.096894264221191\n",
      "cls loss 394.2989501953125  loc loss 23.51064682006836\n",
      "cls loss 220.16595458984375  loc loss 14.02022933959961\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 35., 27.])\n",
      "cls loss 405.89923095703125  loc loss 20.835830688476562\n",
      "cls loss 472.2506103515625  loc loss 32.336788177490234\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 312.05633544921875  loc loss 14.758247375488281\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([42.,  1.])\n",
      "cls loss 402.490966796875  loc loss 22.584148406982422\n",
      "cls loss 423.53656005859375  loc loss 19.324108123779297\n",
      "cls loss 501.8076171875  loc loss 25.68103790283203\n",
      "cls loss 651.2831420898438  loc loss 28.95060157775879\n",
      "cls loss 514.8533935546875  loc loss 27.40228843688965\n",
      "cls loss 363.72369384765625  loc loss 21.02642250061035\n",
      "cls loss 293.42059326171875  loc loss 19.820219039916992\n",
      "cls loss 177.81390380859375  loc loss 7.023858070373535\n",
      "cls loss 314.92828369140625  loc loss 16.83670997619629\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 1., 1.])\n",
      "cls loss 306.8849792480469  loc loss 17.99176788330078\n",
      "cls loss 376.2373046875  loc loss 22.579225540161133\n",
      "cls loss 361.85101318359375  loc loss 20.70551109313965\n",
      "cls loss 277.5918273925781  loc loss 19.692262649536133\n",
      "cls loss 347.1455078125  loc loss 22.52787208557129\n",
      "cls loss 364.5916748046875  loc loss 26.32379913330078\n",
      "cls loss 552.061279296875  loc loss 30.995952606201172\n",
      "cls loss 485.47467041015625  loc loss 32.891109466552734\n",
      "cls loss 418.6141357421875  loc loss 25.575458526611328\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 332.471435546875  loc loss 21.68648910522461\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 476.11572265625  loc loss 17.24385643005371\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([81.])\n",
      "cls loss 539.51123046875  loc loss 25.42547035217285\n",
      "cls loss 310.9112548828125  loc loss 19.322111129760742\n",
      "cls loss 258.35821533203125  loc loss 10.357522964477539\n",
      "cls loss 341.99456787109375  loc loss 18.157766342163086\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3.,  1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 19.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 19.])\n",
      "cls loss 488.2445068359375  loc loss 29.489471435546875\n",
      "cls loss 255.50735473632812  loc loss 14.14847469329834\n",
      "cls loss 279.8099060058594  loc loss 14.531486511230469\n",
      "cls loss 532.2444458007812  loc loss 36.43567657470703\n",
      "cls loss 255.63015747070312  loc loss 15.879782676696777\n",
      "cls loss 326.1412353515625  loc loss 18.212156295776367\n",
      "cls loss 418.47247314453125  loc loss 24.788206100463867\n",
      "cls loss 310.079345703125  loc loss 21.164899826049805\n",
      "cls loss 422.82440185546875  loc loss 21.312854766845703\n",
      "cls loss 453.79473876953125  loc loss 27.679325103759766\n",
      "cls loss 622.318359375  loc loss 49.912193298339844\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 81.])\n",
      "cls loss 407.4021301269531  loc loss 18.244525909423828\n",
      "cls loss 372.5711975097656  loc loss 18.520286560058594\n",
      "cls loss 374.80377197265625  loc loss 19.578754425048828\n",
      "cls loss 312.26251220703125  loc loss 14.592690467834473\n",
      "cls loss 271.6907958984375  loc loss 15.341590881347656\n",
      "cls loss 335.84271240234375  loc loss 22.399763107299805\n",
      "cls loss 239.31448364257812  loc loss 15.539775848388672\n",
      "cls loss 214.59536743164062  loc loss 12.512624740600586\n",
      "cls loss 262.4388427734375  loc loss 16.798269271850586\n",
      "cls loss 360.5609436035156  loc loss 21.867450714111328\n",
      "cls loss 338.95703125  loc loss 24.149198532104492\n",
      "cls loss 336.6463317871094  loc loss 20.409042358398438\n",
      "cls loss 201.84518432617188  loc loss 12.462784767150879\n",
      "cls loss 713.4365234375  loc loss 40.82744216918945\n",
      "cls loss 385.2359924316406  loc loss 24.049592971801758\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 344.054443359375  loc loss 16.233360290527344\n",
      "cls loss 385.09674072265625  loc loss 23.2667179107666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 279.65509033203125  loc loss 18.800188064575195\n",
      "cls loss 457.359619140625  loc loss 31.38450050354004\n",
      "cls loss 446.30548095703125  loc loss 25.407440185546875\n",
      "cls loss 406.5423889160156  loc loss 23.506866455078125\n",
      "cls loss 295.25079345703125  loc loss 19.76447105407715\n",
      "cls loss 272.184814453125  loc loss 14.563338279724121\n",
      "cls loss 394.1707458496094  loc loss 19.72808074951172\n",
      "cls loss 475.19720458984375  loc loss 27.747238159179688\n",
      "cls loss 408.6724853515625  loc loss 20.573490142822266\n",
      "cls loss 536.9801635742188  loc loss 31.1512451171875\n",
      "cls loss 594.0834350585938  loc loss 37.665504455566406\n",
      "cls loss 393.83734130859375  loc loss 24.04805564880371\n",
      "cls loss 568.790283203125  loc loss 40.60533142089844\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1., 38., 47.,  1.,  1.,  1.,  1.,  1., 62.])\n",
      "cls loss 342.467529296875  loc loss 15.789966583251953\n",
      "cls loss 411.118408203125  loc loss 27.946630477905273\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 448.138427734375  loc loss 24.771114349365234\n",
      "cls loss 514.2474365234375  loc loss 34.30204391479492\n",
      "cls loss 331.547119140625  loc loss 14.518915176391602\n",
      "cls loss 398.00927734375  loc loss 28.663278579711914\n",
      "cls loss 388.95074462890625  loc loss 21.598814010620117\n",
      "cls loss 215.1748504638672  loc loss 6.851110458374023\n",
      "cls loss 332.9100036621094  loc loss 17.487863540649414\n",
      "cls loss 292.8805847167969  loc loss 11.61166763305664\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1., 35.])\n",
      "cls loss 319.497314453125  loc loss 17.762540817260742\n",
      "cls loss 485.5074462890625  loc loss 23.423044204711914\n",
      "cls loss 498.8308410644531  loc loss 27.396575927734375\n",
      "cls loss 437.8757019042969  loc loss 31.788827896118164\n",
      "cls loss 374.4431457519531  loc loss 24.392850875854492\n",
      "cls loss 483.117431640625  loc loss 32.307769775390625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 264.9783935546875  loc loss 13.151093482971191\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 371.8602294921875  loc loss 14.536529541015625\n",
      "cls loss 564.7020263671875  loc loss 29.830604553222656\n",
      "cls loss 723.6666259765625  loc loss 53.57173156738281\n",
      "cls loss 349.50714111328125  loc loss 17.015535354614258\n",
      "cls loss 305.6396179199219  loc loss 16.78873062133789\n",
      "cls loss 319.2223205566406  loc loss 15.145248413085938\n",
      "cls loss 362.34295654296875  loc loss 17.496929168701172\n",
      "cls loss 310.0853576660156  loc loss 11.942054748535156\n",
      "cls loss 572.878662109375  loc loss 32.557838439941406\n",
      "cls loss 475.3643798828125  loc loss 24.875995635986328\n",
      "cls loss 205.2662353515625  loc loss 13.587059020996094\n",
      "cls loss 424.56512451171875  loc loss 23.03293800354004\n",
      "cls loss 583.4445190429688  loc loss 38.25653839111328\n",
      "cls loss 428.71923828125  loc loss 26.559152603149414\n",
      "cls loss 382.519287109375  loc loss 20.96022605895996\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.])\n",
      "cls loss 364.83544921875  loc loss 24.305307388305664\n",
      "cls loss 374.07415771484375  loc loss 21.880138397216797\n",
      "cls loss 445.9994812011719  loc loss 24.106964111328125\n",
      "cls loss 752.3541259765625  loc loss 50.91651916503906\n",
      "cls loss 266.98681640625  loc loss 12.525381088256836\n",
      "cls loss 356.8790283203125  loc loss 20.124942779541016\n",
      "cls loss 277.7447509765625  loc loss 14.753888130187988\n",
      "cls loss 320.835693359375  loc loss 20.058094024658203\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 21., 21., 21.])\n",
      "cls loss 305.22711181640625  loc loss 18.306081771850586\n",
      "cls loss 332.248779296875  loc loss 15.46705436706543\n",
      "cls loss 330.61041259765625  loc loss 20.08011245727539\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 35.])\n",
      "cls loss 451.538330078125  loc loss 24.814624786376953\n",
      "cls loss 165.36634826660156  loc loss 8.52237606048584\n",
      "cls loss 311.34088134765625  loc loss 15.73196792602539\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 289.06365966796875  loc loss 10.419194221496582\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 38., 38.,  9., 38.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1.,  1.])\n",
      "cls loss 317.0172119140625  loc loss 17.69622039794922\n",
      "cls loss 527.235107421875  loc loss 27.80189323425293\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 2.,  1., 77., 31., 10., 10.,  1.,  4., 10.])\n",
      "cls loss 236.81118774414062  loc loss 9.924032211303711\n",
      "cls loss 481.71044921875  loc loss 26.440980911254883\n",
      "cls loss 956.965576171875  loc loss 50.8443603515625\n",
      "cls loss 302.502197265625  loc loss 20.10000991821289\n",
      "cls loss 413.60882568359375  loc loss 28.10223960876465\n",
      "cls loss 271.660888671875  loc loss 13.118670463562012\n",
      "cls loss 267.94561767578125  loc loss 13.339568138122559\n",
      "cls loss 378.212646484375  loc loss 21.226057052612305\n",
      "cls loss 370.8852844238281  loc loss 22.430484771728516\n",
      "cls loss 354.34454345703125  loc loss 24.519432067871094\n",
      "cls loss 304.9943542480469  loc loss 14.240161895751953\n",
      "cls loss 316.73858642578125  loc loss 17.343664169311523\n",
      "cls loss 610.5328979492188  loc loss 33.63540267944336\n",
      "cls loss 570.4344482421875  loc loss 29.42450714111328\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1., 42., 42., 42., 42., 42., 42.,  1.,\n",
      "         1.,  1.,  1., 42.,  1.,  1., 42.,  1.])\n",
      "cls loss 318.4667663574219  loc loss 21.516124725341797\n",
      "cls loss 484.23529052734375  loc loss 23.05742073059082\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.])\n",
      "cls loss 203.0173797607422  loc loss 9.285094261169434\n",
      "cls loss 480.58489990234375  loc loss 26.586509704589844\n",
      "cls loss 355.6612548828125  loc loss 21.971311569213867\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([11.])\n",
      "cls loss 206.2892303466797  loc loss 11.750775337219238\n",
      "cls loss 234.1708526611328  loc loss 11.393686294555664\n",
      "cls loss 247.1370849609375  loc loss 11.42760944366455\n",
      "cls loss 447.00830078125  loc loss 25.907958984375\n",
      "cls loss 348.18536376953125  loc loss 18.907699584960938\n",
      "cls loss 378.19146728515625  loc loss 23.74925994873047\n",
      "cls loss 532.185546875  loc loss 27.4271240234375\n",
      "cls loss 285.27752685546875  loc loss 15.516056060791016\n",
      "cls loss 629.9561157226562  loc loss 36.772186279296875\n",
      "cls loss 305.69244384765625  loc loss 15.757267951965332\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 285.9031677246094  loc loss 15.348611831665039\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1., 38., 38., 42.])\n",
      "cls loss 395.36224365234375  loc loss 21.672595977783203\n",
      "cls loss 355.4926452636719  loc loss 19.755521774291992\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 311.6609191894531  loc loss 18.55206871032715\n",
      "cls loss 666.79345703125  loc loss 37.981327056884766\n",
      "cls loss 391.8793029785156  loc loss 22.975656509399414\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10.,  3.,  3.,  6.,  8.,  8.,  1.,  1.,  1., 10.])\n",
      "cls loss 292.7579345703125  loc loss 14.32463550567627\n",
      "cls loss 202.9390869140625  loc loss 7.082998275756836\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10.,  3.])\n",
      "cls loss 277.055419921875  loc loss 16.395599365234375\n",
      "cls loss 136.54824829101562  loc loss 7.586756706237793\n",
      "cls loss 359.35821533203125  loc loss 23.896177291870117\n",
      "cls loss 431.01824951171875  loc loss 26.79802131652832\n",
      "cls loss 318.3973693847656  loc loss 17.150583267211914\n",
      "cls loss 171.69113159179688  loc loss 12.087865829467773\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 34.])\n",
      "cls loss 477.7793273925781  loc loss 31.52880859375\n",
      "cls loss 641.6624755859375  loc loss 40.96772766113281\n",
      "cls loss 397.46673583984375  loc loss 26.184648513793945\n",
      "cls loss 318.2905578613281  loc loss 20.590694427490234\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.,  1.])\n",
      "cls loss 355.7525634765625  loc loss 14.564116477966309\n",
      "cls loss 592.4664306640625  loc loss 38.51344299316406\n",
      "cls loss 826.458984375  loc loss 47.434814453125\n",
      "cls loss 652.1954345703125  loc loss 30.185009002685547\n",
      "cls loss 368.1965637207031  loc loss 17.516185760498047\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 384.56036376953125  loc loss 21.876766204833984\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10.])\n",
      "cls loss 253.1553955078125  loc loss 13.35224723815918\n",
      "cls loss 378.5829772949219  loc loss 19.9033145904541\n",
      "cls loss 359.198974609375  loc loss 20.793819427490234\n",
      "cls loss 228.73724365234375  loc loss 14.949337005615234\n",
      "cls loss 324.00048828125  loc loss 19.33513069152832\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21.,\n",
      "        21.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 386.28228759765625  loc loss 24.033924102783203\n",
      "cls loss 340.26678466796875  loc loss 17.83323097229004\n",
      "cls loss 229.99588012695312  loc loss 10.387042999267578\n",
      "cls loss 522.877685546875  loc loss 32.35444641113281\n",
      "cls loss 379.35662841796875  loc loss 24.576749801635742\n",
      "cls loss 286.5924072265625  loc loss 12.393829345703125\n",
      "cls loss 605.8568725585938  loc loss 32.38539123535156\n",
      "cls loss 688.720947265625  loc loss 43.804508209228516\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15., 85.])\n",
      "cls loss 473.0173034667969  loc loss 23.378454208374023\n",
      "cls loss 464.19415283203125  loc loss 30.37677574157715\n",
      "cls loss 460.27313232421875  loc loss 29.277477264404297\n",
      "cls loss 354.658935546875  loc loss 21.78908920288086\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 8., 8.])\n",
      "cls loss 273.4818115234375  loc loss 9.637187004089355\n",
      "cls loss 257.667236328125  loc loss 18.379724502563477\n",
      "cls loss 333.1587829589844  loc loss 17.390045166015625\n",
      "cls loss 290.2308349609375  loc loss 14.800751686096191\n",
      "cls loss 314.0565185546875  loc loss 17.369266510009766\n",
      "cls loss 468.845947265625  loc loss 24.533157348632812\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1., 35., 27., 27.,  1., 27.,  1.])\n",
      "cls loss 496.42333984375  loc loss 38.01241683959961\n",
      "cls loss 313.4618835449219  loc loss 15.047143936157227\n",
      "cls loss 320.3078918457031  loc loss 23.1192684173584\n",
      "cls loss 331.21771240234375  loc loss 26.17447853088379\n",
      "cls loss 298.74627685546875  loc loss 18.059436798095703\n",
      "cls loss 341.910888671875  loc loss 22.965652465820312\n",
      "cls loss 338.3462219238281  loc loss 22.587177276611328\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  2.,  2.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  2.,  2.])\n",
      "cls loss 162.94525146484375  loc loss 7.875842094421387\n",
      "cls loss 539.7167358398438  loc loss 31.595165252685547\n",
      "cls loss 325.83575439453125  loc loss 14.130012512207031\n",
      "cls loss 588.5701293945312  loc loss 40.54257583618164\n",
      "cls loss 222.78619384765625  loc loss 12.500947952270508\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 19., 19., 19., 16.])\n",
      "cls loss 226.00054931640625  loc loss 7.680253028869629\n",
      "cls loss 200.50091552734375  loc loss 7.89571475982666\n",
      "cls loss 326.6983642578125  loc loss 14.069618225097656\n",
      "cls loss 427.74847412109375  loc loss 25.04973602294922\n",
      "cls loss 164.675048828125  loc loss 10.446513175964355\n",
      "cls loss 458.561767578125  loc loss 34.93305206298828\n",
      "cls loss 339.248046875  loc loss 20.4180850982666\n",
      "cls loss 354.3144836425781  loc loss 22.66396713256836\n",
      "cls loss 464.5204162597656  loc loss 27.738269805908203\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 449.6234436035156  loc loss 20.02303695678711\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 659.459228515625  loc loss 51.843406677246094\n",
      "cls loss 851.9619140625  loc loss 70.56755065917969\n",
      "cls loss 397.27947998046875  loc loss 21.913639068603516\n",
      "cls loss 383.2174072265625  loc loss 20.93283462524414\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3.,  3.,  3.,  3.,  3., 10.])\n",
      "cls loss 183.64926147460938  loc loss 11.113256454467773\n",
      "cls loss 415.41546630859375  loc loss 18.34763526916504\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 1., 1., 1., 3., 3., 3., 3.])\n",
      "cls loss 339.2476806640625  loc loss 15.173211097717285\n",
      "cls loss 640.9697265625  loc loss 38.57896423339844\n",
      "cls loss 534.0841064453125  loc loss 25.939167022705078\n",
      "cls loss 330.76129150390625  loc loss 17.61618995666504\n",
      "cls loss 511.7995300292969  loc loss 33.08375930786133\n",
      "cls loss 295.6677551269531  loc loss 19.308473587036133\n",
      "cls loss 488.6501770019531  loc loss 30.62790298461914\n",
      "cls loss 370.5599670410156  loc loss 30.958953857421875\n",
      "cls loss 329.1522216796875  loc loss 21.534168243408203\n",
      "cls loss 757.462158203125  loc loss 56.520870208740234\n",
      "cls loss 482.61309814453125  loc loss 36.640235900878906\n",
      "cls loss 311.9278259277344  loc loss 15.81218433380127\n",
      "cls loss 183.53558349609375  loc loss 8.710005760192871\n",
      "cls loss 241.8724365234375  loc loss 12.048891067504883\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3., 10., 10., 10., 10., 10., 10., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10., 10., 10., 10., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 11., 10., 10., 10., 10., 10.,  3.,  3.,  3.,  3.,  3.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 11., 10., 10., 10., 10., 10.,  3.,  3.,  3.,  3.,  3.])\n",
      "cls loss 184.30227661132812  loc loss 8.633538246154785\n",
      "cls loss 264.1048583984375  loc loss 10.169235229492188\n",
      "cls loss 244.1481170654297  loc loss 12.452874183654785\n",
      "cls loss 227.04412841796875  loc loss 9.42726993560791\n",
      "cls loss 309.6880798339844  loc loss 21.920888900756836\n",
      "cls loss 218.7510986328125  loc loss 8.764458656311035\n",
      "cls loss 477.25543212890625  loc loss 27.480318069458008\n",
      "cls loss 448.49725341796875  loc loss 21.980146408081055\n",
      "cls loss 631.7838134765625  loc loss 34.90750503540039\n",
      "cls loss 323.4923095703125  loc loss 20.473979949951172\n",
      "cls loss 549.3576049804688  loc loss 31.583179473876953\n",
      "cls loss 411.281982421875  loc loss 27.83905601501465\n",
      "cls loss 423.11090087890625  loc loss 24.114164352416992\n",
      "cls loss 400.81634521484375  loc loss 25.873449325561523\n",
      "cls loss 516.7578735351562  loc loss 31.926898956298828\n",
      "cls loss 491.322265625  loc loss 30.86094093322754\n",
      "cls loss 235.0268096923828  loc loss 12.252227783203125\n",
      "cls loss 506.70147705078125  loc loss 29.505558013916016\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 10.,  1., 18.])\n",
      "cls loss 210.54066467285156  loc loss 13.46187686920166\n",
      "cls loss 245.92904663085938  loc loss 11.451397895812988\n",
      "cls loss 457.77496337890625  loc loss 23.270816802978516\n",
      "cls loss 654.4993896484375  loc loss 35.59241485595703\n",
      "cls loss 387.5152893066406  loc loss 24.171649932861328\n",
      "cls loss 601.5765991210938  loc loss 25.202167510986328\n",
      "cls loss 473.4338073730469  loc loss 25.774385452270508\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.,  1.,  1.])\n",
      "cls loss 534.2745971679688  loc loss 28.691171646118164\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1., 38.,  1.])\n",
      "cls loss 438.8143005371094  loc loss 24.196556091308594\n",
      "cls loss 642.0071411132812  loc loss 44.40552520751953\n",
      "cls loss 350.16717529296875  loc loss 21.651887893676758\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 464.03936767578125  loc loss 24.066295623779297\n",
      "cls loss 375.2889099121094  loc loss 20.928510665893555\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3., 10.,  8.,  3., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.])\n",
      "cls loss 416.65283203125  loc loss 22.081653594970703\n",
      "cls loss 278.267333984375  loc loss 17.762676239013672\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3.,  3., 11.,  3., 10., 10.,  3.,  3., 10.])\n",
      "cls loss 267.76007080078125  loc loss 17.186660766601562\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3., 10., 10., 10.])\n",
      "cls loss 349.49285888671875  loc loss 18.101253509521484\n",
      "cls loss 270.9997253417969  loc loss 18.421981811523438\n",
      "cls loss 369.9847106933594  loc loss 25.852476119995117\n",
      "cls loss 542.315673828125  loc loss 32.231834411621094\n",
      "cls loss 356.65093994140625  loc loss 22.245378494262695\n",
      "cls loss 284.9993896484375  loc loss 19.89316177368164\n",
      "cls loss 362.3241882324219  loc loss 19.461097717285156\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 9.,  9., 85., 85.])\n",
      "cls loss 306.5771484375  loc loss 13.144021987915039\n",
      "cls loss 397.56475830078125  loc loss 23.61324691772461\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 582.126220703125  loc loss 32.19453048706055\n",
      "cls loss 482.1119384765625  loc loss 19.142099380493164\n",
      "cls loss 556.4086303710938  loc loss 36.09457778930664\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10., 10., 10., 10.])\n",
      "cls loss 360.3104553222656  loc loss 21.012432098388672\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([13.])\n",
      "cls loss 562.7060546875  loc loss 41.84534454345703\n",
      "cls loss 149.3990936279297  loc loss 8.428780555725098\n",
      "cls loss 228.47314453125  loc loss 11.393244743347168\n",
      "cls loss 294.0286865234375  loc loss 17.607189178466797\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19.,  1.,  1.,  1., 19., 19.])\n",
      "cls loss 326.1918029785156  loc loss 19.987157821655273\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 261.72509765625  loc loss 15.932172775268555\n",
      "cls loss 395.5702209472656  loc loss 25.235355377197266\n",
      "cls loss 302.694091796875  loc loss 15.283591270446777\n",
      "cls loss 428.74493408203125  loc loss 20.263011932373047\n",
      "cls loss 463.65869140625  loc loss 30.25604820251465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 349.4440612792969  loc loss 19.891775131225586\n",
      "cls loss 567.6798095703125  loc loss 37.25940704345703\n",
      "cls loss 195.4852294921875  loc loss 7.599015235900879\n",
      "cls loss 367.2203674316406  loc loss 22.880884170532227\n",
      "cls loss 308.2291259765625  loc loss 16.32953643798828\n",
      "cls loss 339.787841796875  loc loss 15.584464073181152\n",
      "cls loss 459.86090087890625  loc loss 24.044063568115234\n",
      "cls loss 355.7295837402344  loc loss 16.530174255371094\n",
      "cls loss 519.2398681640625  loc loss 32.32170104980469\n",
      "cls loss 335.8936767578125  loc loss 18.613637924194336\n",
      "cls loss 437.18768310546875  loc loss 30.112775802612305\n",
      "cls loss 632.3119506835938  loc loss 37.09914016723633\n",
      "cls loss 342.49609375  loc loss 23.392698287963867\n",
      "cls loss 413.2962646484375  loc loss 21.03864288330078\n",
      "cls loss 495.60894775390625  loc loss 35.20839309692383\n",
      "cls loss 582.547119140625  loc loss 35.08831024169922\n",
      "cls loss 621.3568725585938  loc loss 35.100521087646484\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 5.])\n",
      "cls loss 147.40060424804688  loc loss 7.544926643371582\n",
      "cls loss 230.38555908203125  loc loss 8.713268280029297\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 13.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 6., 8., 8.])\n",
      "cls loss 180.13446044921875  loc loss 8.865774154663086\n",
      "cls loss 235.57020568847656  loc loss 11.00018310546875\n",
      "cls loss 467.0948181152344  loc loss 27.63089370727539\n",
      "cls loss 194.8209228515625  loc loss 10.194925308227539\n",
      "cls loss 413.4864501953125  loc loss 26.663776397705078\n",
      "cls loss 609.18603515625  loc loss 40.692054748535156\n",
      "cls loss 396.10894775390625  loc loss 23.16977882385254\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([42., 42.,  1.,  1.,  1.,  1.,  1.,  1.,  1., 42., 42.])\n",
      "cls loss 411.69573974609375  loc loss 19.275985717773438\n",
      "cls loss 526.301025390625  loc loss 36.53453826904297\n",
      "cls loss 487.80169677734375  loc loss 29.325021743774414\n",
      "cls loss 309.1433410644531  loc loss 16.922266006469727\n",
      "cls loss 401.4093017578125  loc loss 19.709056854248047\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 621.6197509765625  loc loss 34.497535705566406\n",
      "cls loss 494.506591796875  loc loss 29.541236877441406\n",
      "cls loss 291.54248046875  loc loss 13.344741821289062\n",
      "cls loss 248.34764099121094  loc loss 12.956785202026367\n",
      "cls loss 330.1243591308594  loc loss 19.025135040283203\n",
      "cls loss 441.39984130859375  loc loss 26.036422729492188\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15.])\n",
      "cls loss 214.60406494140625  loc loss 6.2480692863464355\n",
      "cls loss 375.4844970703125  loc loss 20.178979873657227\n",
      "cls loss 336.475830078125  loc loss 18.231075286865234\n",
      "cls loss 603.4421997070312  loc loss 33.952110290527344\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19.,  7.])\n",
      "cls loss 273.00274658203125  loc loss 15.389291763305664\n",
      "cls loss 539.04052734375  loc loss 38.86510467529297\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 491.088623046875  loc loss 26.480384826660156\n",
      "cls loss 475.46002197265625  loc loss 29.24439239501953\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([38., 38.,  1., 18.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1., 18., 18.,  1.])\n",
      "cls loss 316.0098876953125  loc loss 16.156766891479492\n",
      "cls loss 305.3428039550781  loc loss 14.757139205932617\n",
      "cls loss 602.9775390625  loc loss 39.96693801879883\n",
      "cls loss 435.75067138671875  loc loss 28.03167152404785\n",
      "cls loss 359.5265808105469  loc loss 24.386215209960938\n",
      "cls loss 255.3477783203125  loc loss 16.563644409179688\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.])\n",
      "cls loss 144.45718383789062  loc loss 6.679350852966309\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([32.])\n",
      "cls loss 387.6488952636719  loc loss 19.144302368164062\n",
      "cls loss 346.20587158203125  loc loss 21.25135612487793\n",
      "cls loss 431.8614196777344  loc loss 29.47293472290039\n",
      "cls loss 372.63531494140625  loc loss 21.24825668334961\n",
      "cls loss 321.7640075683594  loc loss 16.588886260986328\n",
      "cls loss 516.06591796875  loc loss 27.692138671875\n",
      "cls loss 616.562255859375  loc loss 35.61104965209961\n",
      "cls loss 438.9111022949219  loc loss 29.0614013671875\n",
      "cls loss 332.8620300292969  loc loss 20.357486724853516\n",
      "cls loss 540.36669921875  loc loss 36.811954498291016\n",
      "cls loss 357.3983154296875  loc loss 18.413402557373047\n",
      "cls loss 644.1961669921875  loc loss 39.351322174072266\n",
      "cls loss 427.3789978027344  loc loss 21.89188575744629\n",
      "cls loss 339.69183349609375  loc loss 25.93482780456543\n",
      "cls loss 256.32427978515625  loc loss 12.119503021240234\n",
      "cls loss 312.04193115234375  loc loss 18.414005279541016\n",
      "cls loss 438.5163269042969  loc loss 29.495040893554688\n",
      "cls loss 504.288818359375  loc loss 35.60206604003906\n",
      "cls loss 313.0975646972656  loc loss 18.55851936340332\n",
      "cls loss 489.11505126953125  loc loss 33.931434631347656\n",
      "cls loss 593.7138061523438  loc loss 39.94590759277344\n",
      "cls loss 214.46295166015625  loc loss 13.26962661743164\n",
      "cls loss 581.055908203125  loc loss 35.52882766723633\n",
      "cls loss 433.37725830078125  loc loss 25.810672760009766\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 566.1635131835938  loc loss 38.23101806640625\n",
      "cls loss 232.03553771972656  loc loss 9.665115356445312\n",
      "cls loss 362.05450439453125  loc loss 21.037864685058594\n",
      "cls loss 364.51171875  loc loss 24.54474449157715\n",
      "cls loss 312.3341979980469  loc loss 19.56583023071289\n",
      "cls loss 178.03338623046875  loc loss 10.154921531677246\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 9., 9., 1., 9., 9., 9., 9., 1., 9.])\n",
      "cls loss 813.380615234375  loc loss 52.16114807128906\n",
      "cls loss 439.69757080078125  loc loss 22.67672348022461\n",
      "cls loss 683.9490356445312  loc loss 46.74361801147461\n",
      "cls loss 264.1658935546875  loc loss 19.046497344970703\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 42., 42.])\n",
      "cls loss 438.9173889160156  loc loss 30.060453414916992\n",
      "cls loss 450.0653076171875  loc loss 32.79520797729492\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  2.,  1.,  1.,  1., 38.,\n",
      "         1.,  1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 38., 38., 38.,  1., 38., 38., 38.,  1.,  1., 38.,  1.,\n",
      "         1.])\n",
      "cls loss 273.6512451171875  loc loss 19.3170108795166\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  8.,  8.])\n",
      "cls loss 635.72119140625  loc loss 42.02305221557617\n",
      "cls loss 660.0269775390625  loc loss 46.908203125\n",
      "cls loss 231.7001953125  loc loss 14.108957290649414\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([4., 1., 1., 4.])\n",
      "cls loss 378.00390625  loc loss 22.749277114868164\n",
      "cls loss 479.1462097167969  loc loss 26.75299644470215\n",
      "cls loss 189.2299346923828  loc loss 9.696684837341309\n",
      "cls loss 236.81793212890625  loc loss 14.676565170288086\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([51.,  1.])\n",
      "cls loss 167.77896118164062  loc loss 7.81723690032959\n",
      "cls loss 244.51173400878906  loc loss 15.331645965576172\n",
      "cls loss 512.1512451171875  loc loss 22.556882858276367\n",
      "cls loss 470.52862548828125  loc loss 31.83724594116211\n",
      "cls loss 735.8541259765625  loc loss 32.87847900390625\n",
      "cls loss 861.8126220703125  loc loss 51.420188903808594\n",
      "cls loss 353.9793395996094  loc loss 24.617616653442383\n",
      "cls loss 530.4266967773438  loc loss 35.75971221923828\n",
      "cls loss 572.0741577148438  loc loss 34.4744987487793\n",
      "cls loss 412.986328125  loc loss 24.85420036315918\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  3.,  1.,  1.,  1.,  3.,  1.,  1.,\n",
      "         1.,  1.,  1.])\n",
      "cls loss 447.51287841796875  loc loss 18.975561141967773\n",
      "cls loss 465.174560546875  loc loss 25.332263946533203\n",
      "cls loss 474.173095703125  loc loss 22.20757293701172\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "cls loss 398.6490478515625  loc loss 20.968421936035156\n",
      "cls loss 223.46896362304688  loc loss 16.12577247619629\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3.])\n",
      "cls loss 174.53924560546875  loc loss 9.134352684020996\n",
      "cls loss 308.34539794921875  loc loss 17.160348892211914\n",
      "cls loss 297.2557678222656  loc loss 19.041229248046875\n",
      "cls loss 537.4146118164062  loc loss 32.69827651977539\n",
      "cls loss 237.02154541015625  loc loss 16.44190216064453\n",
      "cls loss 280.3072509765625  loc loss 21.429126739501953\n",
      "cls loss 796.48046875  loc loss 51.539554595947266\n",
      "cls loss 366.4437255859375  loc loss 25.457481384277344\n",
      "cls loss 271.9984436035156  loc loss 18.375232696533203\n",
      "cls loss 320.783447265625  loc loss 17.480422973632812\n",
      "cls loss 293.5436706542969  loc loss 20.91933250427246\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 541.6114501953125  loc loss 36.79646682739258\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  9., 64., 64., 64., 64., 64., 64., 64., 64., 64.,  9.,  9.,  9.,\n",
      "         9.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 245.66598510742188  loc loss 12.284069061279297\n",
      "cls loss 796.5494384765625  loc loss 55.15044403076172\n",
      "cls loss 420.44830322265625  loc loss 26.073896408081055\n",
      "cls loss 486.76580810546875  loc loss 31.51771354675293\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.,  3.,  3.])\n",
      "cls loss 309.948486328125  loc loss 16.778533935546875\n",
      "cls loss 331.8162536621094  loc loss 22.468734741210938\n",
      "cls loss 354.8864440917969  loc loss 25.084280014038086\n",
      "cls loss 358.4795227050781  loc loss 24.03420639038086\n",
      "cls loss 417.856201171875  loc loss 26.941028594970703\n",
      "cls loss 426.20416259765625  loc loss 25.250885009765625\n",
      "cls loss 381.8126525878906  loc loss 24.22504997253418\n",
      "cls loss 384.2078857421875  loc loss 20.279464721679688\n",
      "cls loss 478.46307373046875  loc loss 30.215682983398438\n",
      "cls loss 351.87445068359375  loc loss 20.74567413330078\n",
      "cls loss 263.0047912597656  loc loss 14.748139381408691\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21.])\n",
      "cls loss 216.72186279296875  loc loss 13.867697715759277\n",
      "cls loss 310.39556884765625  loc loss 26.112003326416016\n",
      "cls loss 469.64190673828125  loc loss 31.286449432373047\n",
      "cls loss 238.68624877929688  loc loss 13.504383087158203\n",
      "cls loss 380.8548583984375  loc loss 24.828176498413086\n",
      "cls loss 693.7901000976562  loc loss 36.412696838378906\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 42., 42.,  1.,  1.])\n",
      "cls loss 420.54046630859375  loc loss 22.717021942138672\n",
      "cls loss 270.61260986328125  loc loss 15.424535751342773\n",
      "cls loss 381.3818664550781  loc loss 21.70636558532715\n",
      "cls loss 517.4280395507812  loc loss 35.063846588134766\n",
      "cls loss 324.4297180175781  loc loss 17.62466049194336\n",
      "cls loss 503.25347900390625  loc loss 32.4025993347168\n",
      "cls loss 438.6918640136719  loc loss 28.046241760253906\n",
      "cls loss 429.7684326171875  loc loss 26.889188766479492\n",
      "cls loss 349.375  loc loss 21.218114852905273\n",
      "cls loss 278.1710205078125  loc loss 17.958276748657227\n",
      "cls loss 218.88674926757812  loc loss 9.918197631835938\n",
      "cls loss 352.0283508300781  loc loss 22.055614471435547\n",
      "cls loss 544.317626953125  loc loss 32.48088073730469\n",
      "cls loss 386.140380859375  loc loss 22.819461822509766\n",
      "cls loss 376.0162353515625  loc loss 25.792287826538086\n",
      "cls loss 407.80560302734375  loc loss 22.286388397216797\n",
      "cls loss 603.7716064453125  loc loss 42.32417297363281\n",
      "cls loss 488.50311279296875  loc loss 29.20539093017578\n",
      "cls loss 526.0326538085938  loc loss 26.11822509765625\n",
      "cls loss 330.13623046875  loc loss 13.615730285644531\n",
      "cls loss 466.071533203125  loc loss 24.89455795288086\n",
      "cls loss 411.5716552734375  loc loss 22.729877471923828\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 5., 5., 5., 5., 5., 5.])\n",
      "cls loss 254.3334197998047  loc loss 14.524367332458496\n",
      "cls loss 328.02166748046875  loc loss 16.83326530456543\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([13.])\n",
      "cls loss 240.4615478515625  loc loss 9.989665985107422\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([44., 10.,  1.,  1.,  1.])\n",
      "cls loss 212.07650756835938  loc loss 14.274497985839844\n",
      "cls loss 373.3199462890625  loc loss 20.074687957763672\n",
      "cls loss 347.60565185546875  loc loss 17.662826538085938\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19., 19., 19., 19., 19., 19., 19.])\n",
      "cls loss 363.9638671875  loc loss 21.819168090820312\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([56.])\n",
      "cls loss 784.9493408203125  loc loss 50.077064514160156\n",
      "cls loss 500.1249084472656  loc loss 34.609161376953125\n",
      "cls loss 635.8273315429688  loc loss 37.55985641479492\n",
      "cls loss 607.025390625  loc loss 43.79233169555664\n",
      "cls loss 371.4740295410156  loc loss 20.276927947998047\n",
      "cls loss 628.4381713867188  loc loss 37.84850311279297\n",
      "cls loss 356.916748046875  loc loss 23.450454711914062\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 36.])\n",
      "cls loss 457.6793518066406  loc loss 19.558635711669922\n",
      "cls loss 378.2919921875  loc loss 22.782352447509766\n",
      "cls loss 355.6205139160156  loc loss 20.090045928955078\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5.])\n",
      "cls loss 414.61181640625  loc loss 23.927820205688477\n",
      "cls loss 226.0083770751953  loc loss 10.949691772460938\n",
      "cls loss 532.1121826171875  loc loss 27.90244483947754\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "cls loss 463.36688232421875  loc loss 27.676959991455078\n",
      "cls loss 439.26531982421875  loc loss 26.07207679748535\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 463.2522277832031  loc loss 28.021724700927734\n",
      "cls loss 534.0244140625  loc loss 30.639591217041016\n",
      "cls loss 459.08917236328125  loc loss 36.08427429199219\n",
      "cls loss 314.95562744140625  loc loss 19.052461624145508\n",
      "cls loss 350.28082275390625  loc loss 25.138341903686523\n",
      "cls loss 364.61114501953125  loc loss 20.174612045288086\n",
      "cls loss 612.55908203125  loc loss 28.4914608001709\n",
      "cls loss 243.839599609375  loc loss 12.071858406066895\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 11., 15., 10., 10., 10., 10., 10.])\n",
      "cls loss 561.9930419921875  loc loss 35.45083999633789\n",
      "cls loss 340.37335205078125  loc loss 23.471338272094727\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3.])\n",
      "cls loss 351.6666259765625  loc loss 24.89110565185547\n",
      "cls loss 335.92938232421875  loc loss 16.01947593688965\n",
      "cls loss 363.64190673828125  loc loss 16.798725128173828\n",
      "cls loss 479.0809326171875  loc loss 18.793447494506836\n",
      "cls loss 207.53936767578125  loc loss 8.928744316101074\n",
      "cls loss 372.25848388671875  loc loss 23.09595489501953\n",
      "cls loss 441.8214111328125  loc loss 26.745574951171875\n",
      "cls loss 384.3108215332031  loc loss 24.122455596923828\n",
      "cls loss 902.9995727539062  loc loss 54.480010986328125\n",
      "cls loss 604.0357666015625  loc loss 36.65470504760742\n",
      "cls loss 376.93780517578125  loc loss 24.442628860473633\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  9.,  9.,  9.,  6.,  6., 85., 85.,  8.,  1.,  1.,  1.,  1.,\n",
      "         6.,  6.])\n",
      "cls loss 248.54197692871094  loc loss 20.4965763092041\n",
      "cls loss 639.2080688476562  loc loss 42.67433166503906\n",
      "cls loss 746.4124145507812  loc loss 43.05528259277344\n",
      "cls loss 464.28173828125  loc loss 31.05203628540039\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10.,  3.,  3., 10.])\n",
      "cls loss 296.3040466308594  loc loss 15.710429191589355\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([7.])\n",
      "cls loss 390.094482421875  loc loss 24.66896629333496\n",
      "cls loss 374.0817565917969  loc loss 23.18018341064453\n",
      "cls loss 398.2579345703125  loc loss 32.55415344238281\n",
      "cls loss 658.0313110351562  loc loss 43.13955307006836\n",
      "cls loss 362.33917236328125  loc loss 23.20796012878418\n",
      "cls loss 566.447998046875  loc loss 33.291290283203125\n",
      "cls loss 703.84765625  loc loss 37.73383331298828\n",
      "cls loss 458.22637939453125  loc loss 23.84309959411621\n",
      "cls loss 508.16961669921875  loc loss 29.319950103759766\n",
      "cls loss 382.6999206542969  loc loss 24.489826202392578\n",
      "cls loss 558.543701171875  loc loss 37.49999237060547\n",
      "cls loss 427.57666015625  loc loss 26.360774993896484\n",
      "cls loss 305.22930908203125  loc loss 18.756473541259766\n",
      "cls loss 496.50531005859375  loc loss 34.371517181396484\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([62.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([62.])\n",
      "cls loss 223.447265625  loc loss 10.338425636291504\n",
      "cls loss 343.29296875  loc loss 25.78056526184082\n",
      "cls loss 356.0983581542969  loc loss 22.12677764892578\n",
      "cls loss 224.4027099609375  loc loss 10.55415153503418\n",
      "cls loss 488.78289794921875  loc loss 31.066349029541016\n",
      "cls loss 496.9893798828125  loc loss 26.754676818847656\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([28.])\n",
      "cls loss 629.6136474609375  loc loss 27.142993927001953\n",
      "cls loss 463.4415283203125  loc loss 27.937255859375\n",
      "cls loss 464.4617004394531  loc loss 29.743289947509766\n",
      "cls loss 516.4647827148438  loc loss 29.194719314575195\n",
      "cls loss 755.55859375  loc loss 41.648536682128906\n",
      "cls loss 432.9447937011719  loc loss 22.996007919311523\n",
      "cls loss 577.740478515625  loc loss 27.200048446655273\n",
      "cls loss 467.1116638183594  loc loss 31.642332077026367\n",
      "cls loss 740.7606201171875  loc loss 53.09171676635742\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([81.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 438.054931640625  loc loss 16.492116928100586\n",
      "cls loss 338.18414306640625  loc loss 16.465709686279297\n",
      "cls loss 244.36492919921875  loc loss 17.499778747558594\n",
      "cls loss 216.89532470703125  loc loss 9.268430709838867\n",
      "cls loss 245.57908630371094  loc loss 18.89796257019043\n",
      "cls loss 306.9303283691406  loc loss 18.80176544189453\n",
      "cls loss 315.755126953125  loc loss 22.55997085571289\n",
      "cls loss 466.3394775390625  loc loss 37.645294189453125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 569.4347534179688  loc loss 32.191856384277344\n",
      "cls loss 961.7437744140625  loc loss 63.78713607788086\n",
      "cls loss 380.23895263671875  loc loss 17.024757385253906\n",
      "cls loss 496.4641418457031  loc loss 33.2253303527832\n",
      "cls loss 339.6253356933594  loc loss 19.141544342041016\n",
      "cls loss 443.9352722167969  loc loss 24.570751190185547\n",
      "cls loss 402.48907470703125  loc loss 22.99045181274414\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([44., 44.])\n",
      "cls loss 360.38763427734375  loc loss 18.874969482421875\n",
      "cls loss 408.28118896484375  loc loss 26.190349578857422\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15.])\n",
      "cls loss 374.8681640625  loc loss 20.480918884277344\n",
      "cls loss 229.1486053466797  loc loss 12.431157112121582\n",
      "cls loss 396.3293151855469  loc loss 26.652812957763672\n",
      "cls loss 236.99163818359375  loc loss 11.363753318786621\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([1., 3., 3.])\n",
      "cls loss 267.4915771484375  loc loss 15.628844261169434\n",
      "cls loss 186.45095825195312  loc loss 9.563324928283691\n",
      "cls loss 352.3993835449219  loc loss 25.812475204467773\n",
      "cls loss 425.9503173828125  loc loss 23.810562133789062\n",
      "cls loss 359.83660888671875  loc loss 24.311508178710938\n",
      "cls loss 306.7970275878906  loc loss 19.661378860473633\n",
      "cls loss 334.8973388671875  loc loss 23.288414001464844\n",
      "cls loss 453.75762939453125  loc loss 29.840166091918945\n",
      "cls loss 298.38446044921875  loc loss 20.23296356201172\n",
      "cls loss 395.326904296875  loc loss 30.60163688659668\n",
      "cls loss 286.6705017089844  loc loss 17.092430114746094\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 521.7955322265625  loc loss 28.0773983001709\n",
      "cls loss 621.8712158203125  loc loss 25.097545623779297\n",
      "cls loss 532.3477783203125  loc loss 34.391326904296875\n",
      "cls loss 527.9720458984375  loc loss 39.43376541137695\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10., 10., 10.,  1.,  1.,  1.,  1.,  1.,  1.,  8.,  8.,\n",
      "         1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10., 10., 10.,  1.,  1.,  1.,  1.,  1.,  1.,  8.,  8.,\n",
      "         1.])\n",
      "cls loss 415.6351623535156  loc loss 21.869564056396484\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 3., 3., 3.])\n",
      "cls loss 417.18402099609375  loc loss 22.63572120666504\n",
      "cls loss 259.61151123046875  loc loss 16.79837989807129\n",
      "cls loss 199.74374389648438  loc loss 9.999357223510742\n",
      "cls loss 394.6501159667969  loc loss 29.413558959960938\n",
      "cls loss 281.4903564453125  loc loss 13.13104248046875\n",
      "cls loss 359.33837890625  loc loss 24.380542755126953\n",
      "cls loss 403.48907470703125  loc loss 29.334060668945312\n",
      "cls loss 531.989501953125  loc loss 39.48569869995117\n",
      "cls loss 465.326416015625  loc loss 24.692358016967773\n",
      "cls loss 417.9906921386719  loc loss 22.731386184692383\n",
      "cls loss 433.3182373046875  loc loss 27.55556869506836\n",
      "cls loss 309.97503662109375  loc loss 23.228389739990234\n",
      "cls loss 654.9591674804688  loc loss 43.96821212768555\n",
      "cls loss 267.3079528808594  loc loss 16.23221206665039\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 519.100341796875  loc loss 29.55377197265625\n",
      "cls loss 209.25628662109375  loc loss 9.751991271972656\n",
      "cls loss 551.2655639648438  loc loss 41.49750518798828\n",
      "cls loss 278.92315673828125  loc loss 17.83428192138672\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 34.])\n",
      "cls loss 469.04327392578125  loc loss 24.491682052612305\n",
      "cls loss 252.26988220214844  loc loss 14.32226848602295\n",
      "cls loss 515.7886962890625  loc loss 26.675586700439453\n",
      "cls loss 193.29336547851562  loc loss 11.464012145996094\n",
      "cls loss 386.8504333496094  loc loss 21.350614547729492\n",
      "cls loss 388.696044921875  loc loss 28.433576583862305\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 38.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16., 16., 16.,  9.,  9.,  9., 16., 16., 16., 85.,  9.])\n",
      "cls loss 400.5074157714844  loc loss 21.56631088256836\n",
      "cls loss 432.5374755859375  loc loss 29.656572341918945\n",
      "cls loss 584.8604736328125  loc loss 34.19270324707031\n",
      "cls loss 903.8043823242188  loc loss 52.981563568115234\n",
      "cls loss 223.45791625976562  loc loss 12.191595077514648\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3., 10.,  8.,  8., 10., 10., 10.,  3.,  3., 14.])\n",
      "cls loss 241.5061798095703  loc loss 15.536174774169922\n",
      "cls loss 448.34173583984375  loc loss 29.076866149902344\n",
      "cls loss 189.49166870117188  loc loss 7.4012556076049805\n",
      "cls loss 330.50732421875  loc loss 14.58326530456543\n",
      "cls loss 459.6011962890625  loc loss 28.977188110351562\n",
      "cls loss 383.1227722167969  loc loss 22.37667465209961\n",
      "cls loss 222.3025360107422  loc loss 11.932762145996094\n",
      "cls loss 294.744140625  loc loss 13.35165023803711\n",
      "cls loss 505.25579833984375  loc loss 27.014204025268555\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42., 42.,  1.])\n",
      "cls loss 454.815673828125  loc loss 24.85103416442871\n",
      "cls loss 392.09771728515625  loc loss 18.641300201416016\n",
      "cls loss 499.82171630859375  loc loss 34.922306060791016\n",
      "cls loss 552.1801147460938  loc loss 31.41804313659668\n",
      "cls loss 376.0577697753906  loc loss 21.498817443847656\n",
      "cls loss 446.6368103027344  loc loss 31.21033477783203\n",
      "cls loss 260.67938232421875  loc loss 16.9341983795166\n",
      "cls loss 285.4754638671875  loc loss 20.36865234375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20.])\n",
      "cls loss 209.17645263671875  loc loss 11.475936889648438\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([11.])\n",
      "cls loss 292.54925537109375  loc loss 13.202430725097656\n",
      "cls loss 168.53659057617188  loc loss 11.184988975524902\n",
      "cls loss 446.65118408203125  loc loss 32.023555755615234\n",
      "cls loss 186.22052001953125  loc loss 9.647214889526367\n",
      "cls loss 389.5389709472656  loc loss 23.71176528930664\n",
      "cls loss 218.20753479003906  loc loss 14.377035140991211\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 35., 27.])\n",
      "cls loss 402.18316650390625  loc loss 21.225507736206055\n",
      "cls loss 468.24786376953125  loc loss 33.120277404785156\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 308.5822448730469  loc loss 14.954072952270508\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([42.,  1.])\n",
      "cls loss 399.2118835449219  loc loss 22.943012237548828\n",
      "cls loss 419.2747802734375  loc loss 19.32933807373047\n",
      "cls loss 494.25640869140625  loc loss 25.027769088745117\n",
      "cls loss 646.49169921875  loc loss 29.064760208129883\n",
      "cls loss 510.1324462890625  loc loss 28.138683319091797\n",
      "cls loss 361.6845703125  loc loss 20.76654052734375\n",
      "cls loss 290.3385314941406  loc loss 20.261768341064453\n",
      "cls loss 176.040771484375  loc loss 7.296332836151123\n",
      "cls loss 310.778564453125  loc loss 16.452272415161133\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 1., 1.])\n",
      "cls loss 304.90625  loc loss 18.601823806762695\n",
      "cls loss 373.6123352050781  loc loss 23.036624908447266\n",
      "cls loss 359.61712646484375  loc loss 20.545040130615234\n",
      "cls loss 274.33270263671875  loc loss 19.634428024291992\n",
      "cls loss 344.34307861328125  loc loss 22.395404815673828\n",
      "cls loss 360.7702331542969  loc loss 27.005582809448242\n",
      "cls loss 548.0704345703125  loc loss 31.662837982177734\n",
      "cls loss 482.74871826171875  loc loss 33.90442657470703\n",
      "cls loss 415.6890869140625  loc loss 26.037080764770508\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 329.4273376464844  loc loss 22.260616302490234\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 472.0248107910156  loc loss 17.010162353515625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([81.])\n",
      "cls loss 533.8091430664062  loc loss 25.33275032043457\n",
      "cls loss 307.8767395019531  loc loss 18.970260620117188\n",
      "cls loss 254.84539794921875  loc loss 10.547683715820312\n",
      "cls loss 338.1607666015625  loc loss 18.434864044189453\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3.,  1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 19.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 19.])\n",
      "cls loss 483.28765869140625  loc loss 29.751842498779297\n",
      "cls loss 252.8087615966797  loc loss 14.308900833129883\n",
      "cls loss 276.95654296875  loc loss 14.980560302734375\n",
      "cls loss 527.69384765625  loc loss 36.03200912475586\n",
      "cls loss 253.12603759765625  loc loss 15.724843978881836\n",
      "cls loss 323.1676940917969  loc loss 18.48873519897461\n",
      "cls loss 415.75115966796875  loc loss 25.54520034790039\n",
      "cls loss 308.43157958984375  loc loss 20.598304748535156\n",
      "cls loss 420.2027587890625  loc loss 21.348777770996094\n",
      "cls loss 450.7536315917969  loc loss 27.818809509277344\n",
      "cls loss 619.9544677734375  loc loss 50.057037353515625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 81.])\n",
      "cls loss 403.92236328125  loc loss 18.020109176635742\n",
      "cls loss 368.67755126953125  loc loss 19.096885681152344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 371.3172607421875  loc loss 19.487672805786133\n",
      "cls loss 309.8885498046875  loc loss 14.510720252990723\n",
      "cls loss 267.56689453125  loc loss 15.1859130859375\n",
      "cls loss 333.0116271972656  loc loss 22.119876861572266\n",
      "cls loss 236.5304718017578  loc loss 15.381247520446777\n",
      "cls loss 213.2675018310547  loc loss 12.630823135375977\n",
      "cls loss 258.5425720214844  loc loss 17.17662811279297\n",
      "cls loss 357.37493896484375  loc loss 23.059158325195312\n",
      "cls loss 336.5382080078125  loc loss 25.096389770507812\n",
      "cls loss 333.76739501953125  loc loss 19.959230422973633\n",
      "cls loss 200.16668701171875  loc loss 12.65711784362793\n",
      "cls loss 708.3203125  loc loss 40.93244934082031\n",
      "cls loss 382.4608154296875  loc loss 23.90797233581543\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 340.7245178222656  loc loss 16.17402458190918\n",
      "cls loss 381.3583984375  loc loss 23.64089584350586\n",
      "cls loss 277.3011474609375  loc loss 19.424293518066406\n",
      "cls loss 454.46978759765625  loc loss 32.72566604614258\n",
      "cls loss 442.091064453125  loc loss 26.521509170532227\n",
      "cls loss 402.99163818359375  loc loss 24.199100494384766\n",
      "cls loss 291.0439453125  loc loss 20.17379379272461\n",
      "cls loss 269.0645751953125  loc loss 14.650684356689453\n",
      "cls loss 390.9388732910156  loc loss 19.624691009521484\n",
      "cls loss 472.61517333984375  loc loss 27.788469314575195\n",
      "cls loss 404.4454345703125  loc loss 20.58409881591797\n",
      "cls loss 530.5438232421875  loc loss 30.51853370666504\n",
      "cls loss 591.3062744140625  loc loss 38.418479919433594\n",
      "cls loss 390.18310546875  loc loss 23.910106658935547\n",
      "cls loss 564.4122314453125  loc loss 40.75912857055664\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1., 38., 47.,  1.,  1.,  1.,  1.,  1., 62.])\n",
      "cls loss 338.37060546875  loc loss 15.807604789733887\n",
      "cls loss 407.72174072265625  loc loss 28.380352020263672\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 444.7598571777344  loc loss 24.87868881225586\n",
      "cls loss 510.85986328125  loc loss 34.36798858642578\n",
      "cls loss 328.8957824707031  loc loss 14.479437828063965\n",
      "cls loss 394.00390625  loc loss 28.560617446899414\n",
      "cls loss 386.35882568359375  loc loss 22.255447387695312\n",
      "cls loss 212.60169982910156  loc loss 6.595163822174072\n",
      "cls loss 331.05072021484375  loc loss 17.584482192993164\n",
      "cls loss 291.4578552246094  loc loss 11.839162826538086\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1., 35.])\n",
      "cls loss 318.22491455078125  loc loss 17.67315101623535\n",
      "cls loss 481.687744140625  loc loss 23.532817840576172\n",
      "cls loss 496.5411376953125  loc loss 28.076684951782227\n",
      "cls loss 434.15325927734375  loc loss 32.39497375488281\n",
      "cls loss 371.8330078125  loc loss 23.946306228637695\n",
      "cls loss 480.4192199707031  loc loss 33.00594711303711\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 262.813232421875  loc loss 12.778280258178711\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 369.1810302734375  loc loss 14.505321502685547\n",
      "cls loss 559.8731079101562  loc loss 29.586181640625\n",
      "cls loss 718.7183837890625  loc loss 53.68970489501953\n",
      "cls loss 345.6640625  loc loss 17.11012840270996\n",
      "cls loss 303.01995849609375  loc loss 16.935285568237305\n",
      "cls loss 316.69403076171875  loc loss 14.959418296813965\n",
      "cls loss 360.1911315917969  loc loss 17.652772903442383\n",
      "cls loss 307.5458984375  loc loss 12.149312973022461\n",
      "cls loss 570.0584106445312  loc loss 32.43521499633789\n",
      "cls loss 470.9623718261719  loc loss 24.601953506469727\n",
      "cls loss 203.1297607421875  loc loss 13.600799560546875\n",
      "cls loss 420.07415771484375  loc loss 23.511394500732422\n",
      "cls loss 581.359375  loc loss 38.38993835449219\n",
      "cls loss 424.6674499511719  loc loss 26.196407318115234\n",
      "cls loss 380.6206970214844  loc loss 20.786638259887695\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.])\n",
      "cls loss 362.9298095703125  loc loss 24.78296661376953\n",
      "cls loss 371.56732177734375  loc loss 21.837953567504883\n",
      "cls loss 441.29669189453125  loc loss 23.855224609375\n",
      "cls loss 747.1499633789062  loc loss 50.635807037353516\n",
      "cls loss 264.75494384765625  loc loss 11.993181228637695\n",
      "cls loss 353.9493713378906  loc loss 19.35802459716797\n",
      "cls loss 274.653076171875  loc loss 14.579925537109375\n",
      "cls loss 318.2615051269531  loc loss 20.43154525756836\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 21., 21., 21.])\n",
      "cls loss 302.30914306640625  loc loss 18.254398345947266\n",
      "cls loss 330.7121276855469  loc loss 15.594037055969238\n",
      "cls loss 327.4990234375  loc loss 19.998231887817383\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 35.])\n",
      "cls loss 447.1568603515625  loc loss 25.381633758544922\n",
      "cls loss 163.30026245117188  loc loss 8.469133377075195\n",
      "cls loss 308.52288818359375  loc loss 15.665210723876953\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 287.03582763671875  loc loss 10.501132011413574\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 38., 38.,  9., 38.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1.,  1.])\n",
      "cls loss 313.9306945800781  loc loss 17.343334197998047\n",
      "cls loss 522.162109375  loc loss 27.58958625793457\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 2.,  1., 77., 31., 10., 10.,  1.,  4., 10.])\n",
      "cls loss 234.0659942626953  loc loss 9.732975959777832\n",
      "cls loss 478.4815979003906  loc loss 26.185789108276367\n",
      "cls loss 947.6226196289062  loc loss 51.897918701171875\n",
      "cls loss 300.4087219238281  loc loss 20.556819915771484\n",
      "cls loss 409.99993896484375  loc loss 28.516027450561523\n",
      "cls loss 268.00225830078125  loc loss 12.938743591308594\n",
      "cls loss 265.1559753417969  loc loss 13.537841796875\n",
      "cls loss 374.21075439453125  loc loss 20.73055648803711\n",
      "cls loss 365.6454772949219  loc loss 21.956493377685547\n",
      "cls loss 350.4247741699219  loc loss 24.081470489501953\n",
      "cls loss 302.3445129394531  loc loss 14.195693016052246\n",
      "cls loss 313.6997985839844  loc loss 17.321414947509766\n",
      "cls loss 605.9087524414062  loc loss 33.9551887512207\n",
      "cls loss 565.5780029296875  loc loss 29.725561141967773\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1., 42., 42., 42., 42., 42., 42.,  1.,\n",
      "         1.,  1.,  1., 42.,  1.,  1., 42.,  1.])\n",
      "cls loss 316.128662109375  loc loss 20.66893196105957\n",
      "cls loss 481.8315124511719  loc loss 22.878597259521484\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.])\n",
      "cls loss 201.33163452148438  loc loss 9.133070945739746\n",
      "cls loss 478.30517578125  loc loss 26.438228607177734\n",
      "cls loss 353.7628173828125  loc loss 21.519683837890625\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([11.])\n",
      "cls loss 204.66563415527344  loc loss 11.372529029846191\n",
      "cls loss 232.880615234375  loc loss 11.1847562789917\n",
      "cls loss 244.59280395507812  loc loss 11.342978477478027\n",
      "cls loss 443.9595642089844  loc loss 25.288307189941406\n",
      "cls loss 346.1339111328125  loc loss 18.9976749420166\n",
      "cls loss 376.0032958984375  loc loss 22.98858070373535\n",
      "cls loss 528.8764038085938  loc loss 26.826013565063477\n",
      "cls loss 283.1880187988281  loc loss 15.344724655151367\n",
      "cls loss 626.3016967773438  loc loss 35.92512512207031\n",
      "cls loss 303.12091064453125  loc loss 15.303403854370117\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 283.6662292480469  loc loss 14.878392219543457\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1., 38., 38., 42.])\n",
      "cls loss 391.94390869140625  loc loss 21.23824691772461\n",
      "cls loss 351.6988220214844  loc loss 19.020368576049805\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 309.447265625  loc loss 17.75978660583496\n",
      "cls loss 660.91796875  loc loss 37.4425048828125\n",
      "cls loss 388.59710693359375  loc loss 21.991331100463867\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10.,  3.,  3.,  6.,  8.,  8.,  1.,  1.,  1., 10.])\n",
      "cls loss 289.7113037109375  loc loss 14.38186264038086\n",
      "cls loss 201.46566772460938  loc loss 7.0496721267700195\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10.,  3.])\n",
      "cls loss 274.49639892578125  loc loss 17.410795211791992\n",
      "cls loss 134.84066772460938  loc loss 7.962090015411377\n",
      "cls loss 357.6025390625  loc loss 24.267446517944336\n",
      "cls loss 427.5172424316406  loc loss 26.957077026367188\n",
      "cls loss 316.6629333496094  loc loss 17.267803192138672\n",
      "cls loss 170.34190368652344  loc loss 12.333919525146484\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 34.])\n",
      "cls loss 474.5050964355469  loc loss 31.806819915771484\n",
      "cls loss 638.147705078125  loc loss 41.059635162353516\n",
      "cls loss 395.15277099609375  loc loss 25.800048828125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 315.78717041015625  loc loss 21.030651092529297\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.,  1.])\n",
      "cls loss 352.2802429199219  loc loss 14.631739616394043\n",
      "cls loss 587.8307495117188  loc loss 37.841732025146484\n",
      "cls loss 820.5941772460938  loc loss 47.80702209472656\n",
      "cls loss 647.3804321289062  loc loss 31.607973098754883\n",
      "cls loss 364.501953125  loc loss 17.17777442932129\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 378.1750793457031  loc loss 21.17293930053711\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10.])\n",
      "cls loss 250.47412109375  loc loss 12.226666450500488\n",
      "cls loss 375.03375244140625  loc loss 18.78516960144043\n",
      "cls loss 355.7967529296875  loc loss 19.66580581665039\n",
      "cls loss 226.33290100097656  loc loss 14.074119567871094\n",
      "cls loss 321.0877685546875  loc loss 19.382097244262695\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21.,\n",
      "        21.])\n",
      "cls loss 381.22833251953125  loc loss 23.349903106689453\n",
      "cls loss 337.0352478027344  loc loss 18.246265411376953\n",
      "cls loss 228.05288696289062  loc loss 10.877260208129883\n",
      "cls loss 518.1310424804688  loc loss 32.41703796386719\n",
      "cls loss 375.406982421875  loc loss 23.004379272460938\n",
      "cls loss 283.5591125488281  loc loss 11.969107627868652\n",
      "cls loss 601.361572265625  loc loss 32.87620544433594\n",
      "cls loss 683.3399658203125  loc loss 45.32030487060547\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15., 85.])\n",
      "cls loss 469.03253173828125  loc loss 24.150373458862305\n",
      "cls loss 461.71051025390625  loc loss 30.47893524169922\n",
      "cls loss 456.16943359375  loc loss 30.727914810180664\n",
      "cls loss 349.8157653808594  loc loss 23.273887634277344\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 8., 8.])\n",
      "cls loss 270.8380432128906  loc loss 10.00073528289795\n",
      "cls loss 254.96469116210938  loc loss 19.629764556884766\n",
      "cls loss 329.50958251953125  loc loss 17.98314666748047\n",
      "cls loss 286.999755859375  loc loss 15.25983715057373\n",
      "cls loss 310.51654052734375  loc loss 17.266700744628906\n",
      "cls loss 465.4740905761719  loc loss 24.5698299407959\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1., 35., 27., 27.,  1., 27.,  1.])\n",
      "cls loss 492.2464599609375  loc loss 38.445030212402344\n",
      "cls loss 310.82513427734375  loc loss 15.143087387084961\n",
      "cls loss 316.77545166015625  loc loss 23.659912109375\n",
      "cls loss 328.776611328125  loc loss 26.61667823791504\n",
      "cls loss 295.5291442871094  loc loss 19.788230895996094\n",
      "cls loss 340.24493408203125  loc loss 24.195749282836914\n",
      "cls loss 336.278076171875  loc loss 22.60419464111328\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  2.,  2.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  2.,  2.])\n",
      "cls loss 161.82464599609375  loc loss 7.7859206199646\n",
      "cls loss 536.4859008789062  loc loss 32.65153121948242\n",
      "cls loss 323.5220031738281  loc loss 13.989057540893555\n",
      "cls loss 583.71826171875  loc loss 40.478973388671875\n",
      "cls loss 220.70989990234375  loc loss 13.064252853393555\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 19., 19., 19., 16.])\n",
      "cls loss 223.72576904296875  loc loss 8.584633827209473\n",
      "cls loss 198.6632537841797  loc loss 8.722833633422852\n",
      "cls loss 323.1992492675781  loc loss 14.32297134399414\n",
      "cls loss 424.20697021484375  loc loss 25.727266311645508\n",
      "cls loss 162.77476501464844  loc loss 10.795278549194336\n",
      "cls loss 454.1495361328125  loc loss 35.33833694458008\n",
      "cls loss 336.366943359375  loc loss 20.633907318115234\n",
      "cls loss 351.6894836425781  loc loss 23.161775588989258\n",
      "cls loss 461.744384765625  loc loss 28.956050872802734\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 444.68914794921875  loc loss 20.64780616760254\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 654.1490478515625  loc loss 56.117610931396484\n",
      "cls loss 846.294189453125  loc loss 73.12195587158203\n",
      "cls loss 392.4263610839844  loc loss 21.270456314086914\n",
      "cls loss 380.507568359375  loc loss 21.05054473876953\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3.,  3.,  3.,  3.,  3., 10.])\n",
      "cls loss 181.6483154296875  loc loss 11.062494277954102\n",
      "cls loss 411.38177490234375  loc loss 18.70746612548828\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 1., 1., 1., 3., 3., 3., 3.])\n",
      "cls loss 336.6220703125  loc loss 16.08930778503418\n",
      "cls loss 633.921142578125  loc loss 43.697784423828125\n",
      "cls loss 529.54248046875  loc loss 29.793611526489258\n",
      "cls loss 327.32232666015625  loc loss 19.37228775024414\n",
      "cls loss 507.8467102050781  loc loss 34.957481384277344\n",
      "cls loss 293.33746337890625  loc loss 20.231550216674805\n",
      "cls loss 485.290283203125  loc loss 31.28624725341797\n",
      "cls loss 368.59796142578125  loc loss 30.849485397338867\n",
      "cls loss 325.96209716796875  loc loss 21.975570678710938\n",
      "cls loss 752.8858642578125  loc loss 56.74000549316406\n",
      "cls loss 479.220458984375  loc loss 37.146602630615234\n",
      "cls loss 309.8032531738281  loc loss 16.19158935546875\n",
      "cls loss 181.68927001953125  loc loss 9.279767036437988\n",
      "cls loss 239.58877563476562  loc loss 13.963851928710938\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3., 10., 10., 10., 10., 10., 10., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10., 10., 10., 10., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 11., 10., 10., 10., 10., 10.,  3.,  3.,  3.,  3.,  3.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 11., 10., 10., 10., 10., 10.,  3.,  3.,  3.,  3.,  3.])\n",
      "cls loss 182.23220825195312  loc loss 10.250588417053223\n",
      "cls loss 260.9984130859375  loc loss 11.371074676513672\n",
      "cls loss 242.77499389648438  loc loss 12.984195709228516\n",
      "cls loss 224.46954345703125  loc loss 10.138777732849121\n",
      "cls loss 307.36834716796875  loc loss 22.54991340637207\n",
      "cls loss 216.96629333496094  loc loss 9.302417755126953\n",
      "cls loss 474.2782897949219  loc loss 27.960359573364258\n",
      "cls loss 445.2847900390625  loc loss 22.343441009521484\n",
      "cls loss 625.724609375  loc loss 35.26167297363281\n",
      "cls loss 321.0694580078125  loc loss 20.589244842529297\n",
      "cls loss 544.8939208984375  loc loss 33.51095962524414\n",
      "cls loss 407.7229309082031  loc loss 30.32941436767578\n",
      "cls loss 420.2054138183594  loc loss 26.846118927001953\n",
      "cls loss 397.867431640625  loc loss 27.21527862548828\n",
      "cls loss 513.0120239257812  loc loss 32.4781379699707\n",
      "cls loss 487.4517822265625  loc loss 32.692413330078125\n",
      "cls loss 233.20884704589844  loc loss 12.20535659790039\n",
      "cls loss 504.6623840332031  loc loss 29.869993209838867\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 10.,  1., 18.])\n",
      "cls loss 208.4738006591797  loc loss 13.947381973266602\n",
      "cls loss 243.671142578125  loc loss 11.13138198852539\n",
      "cls loss 451.86907958984375  loc loss 23.532215118408203\n",
      "cls loss 649.6260986328125  loc loss 35.92341995239258\n",
      "cls loss 383.0906982421875  loc loss 26.124889373779297\n",
      "cls loss 595.9228515625  loc loss 25.725086212158203\n",
      "cls loss 470.7697448730469  loc loss 27.55693244934082\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.,  1.,  1.])\n",
      "cls loss 529.7479248046875  loc loss 29.758085250854492\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1., 38.,  1.])\n",
      "cls loss 433.9797668457031  loc loss 25.578367233276367\n",
      "cls loss 636.724609375  loc loss 44.889259338378906\n",
      "cls loss 347.7608642578125  loc loss 22.11393165588379\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 459.9549560546875  loc loss 23.75722885131836\n",
      "cls loss 372.5356140136719  loc loss 21.420631408691406\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3., 10.,  8.,  3., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.])\n",
      "cls loss 413.057373046875  loc loss 22.58649444580078\n",
      "cls loss 275.82135009765625  loc loss 17.170673370361328\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3.,  3., 11.,  3., 10., 10.,  3.,  3., 10.])\n",
      "cls loss 263.9443664550781  loc loss 17.360605239868164\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3., 10., 10., 10.])\n",
      "cls loss 346.2071533203125  loc loss 18.305561065673828\n",
      "cls loss 268.38421630859375  loc loss 18.941917419433594\n",
      "cls loss 366.4941101074219  loc loss 27.02454376220703\n",
      "cls loss 537.1011962890625  loc loss 32.728965759277344\n",
      "cls loss 353.7548828125  loc loss 22.329219818115234\n",
      "cls loss 282.2391357421875  loc loss 20.477174758911133\n",
      "cls loss 359.699462890625  loc loss 19.161867141723633\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 9.,  9., 85., 85.])\n",
      "cls loss 303.29931640625  loc loss 12.96374797821045\n",
      "cls loss 394.68682861328125  loc loss 23.261037826538086\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 577.002685546875  loc loss 31.74517059326172\n",
      "cls loss 477.11798095703125  loc loss 18.618806838989258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 550.8790893554688  loc loss 35.791229248046875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10., 10., 10., 10.])\n",
      "cls loss 356.8770446777344  loc loss 20.48944091796875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([13.])\n",
      "cls loss 558.603515625  loc loss 40.2664909362793\n",
      "cls loss 148.24032592773438  loc loss 8.276150703430176\n",
      "cls loss 226.80215454101562  loc loss 11.971944808959961\n",
      "cls loss 291.9219970703125  loc loss 18.744359970092773\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19.,  1.,  1.,  1., 19., 19.])\n",
      "cls loss 324.69854736328125  loc loss 21.123506546020508\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 260.4022521972656  loc loss 16.624202728271484\n",
      "cls loss 392.82769775390625  loc loss 28.741268157958984\n",
      "cls loss 300.5466613769531  loc loss 15.362954139709473\n",
      "cls loss 425.3177185058594  loc loss 20.523530960083008\n",
      "cls loss 460.1552429199219  loc loss 29.634618759155273\n",
      "cls loss 346.96466064453125  loc loss 19.28095817565918\n",
      "cls loss 562.396484375  loc loss 37.14900588989258\n",
      "cls loss 193.4556121826172  loc loss 8.450467109680176\n",
      "cls loss 363.5638732910156  loc loss 24.56634521484375\n",
      "cls loss 305.6396484375  loc loss 17.907915115356445\n",
      "cls loss 336.98724365234375  loc loss 16.375728607177734\n",
      "cls loss 455.93109130859375  loc loss 26.522741317749023\n",
      "cls loss 351.4039306640625  loc loss 16.487585067749023\n",
      "cls loss 515.2587280273438  loc loss 35.20249557495117\n",
      "cls loss 333.1168212890625  loc loss 18.97116470336914\n",
      "cls loss 433.6589660644531  loc loss 29.84131622314453\n",
      "cls loss 627.3170166015625  loc loss 35.78785705566406\n",
      "cls loss 340.2554931640625  loc loss 22.506820678710938\n",
      "cls loss 410.409423828125  loc loss 21.286924362182617\n",
      "cls loss 493.31396484375  loc loss 35.86328887939453\n",
      "cls loss 579.6676025390625  loc loss 36.30347442626953\n",
      "cls loss 616.2266845703125  loc loss 38.64657211303711\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 5.])\n",
      "cls loss 144.43740844726562  loc loss 7.9592461585998535\n",
      "cls loss 227.76107788085938  loc loss 9.809678077697754\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 13.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 6., 8., 8.])\n",
      "cls loss 178.62794494628906  loc loss 9.880197525024414\n",
      "cls loss 232.91815185546875  loc loss 11.639678955078125\n",
      "cls loss 462.0976257324219  loc loss 30.288543701171875\n",
      "cls loss 192.93333435058594  loc loss 10.636247634887695\n",
      "cls loss 410.89849853515625  loc loss 27.06348419189453\n",
      "cls loss 605.638916015625  loc loss 41.820701599121094\n",
      "cls loss 393.80548095703125  loc loss 23.532686233520508\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([42., 42.,  1.,  1.,  1.,  1.,  1.,  1.,  1., 42., 42.])\n",
      "cls loss 408.56365966796875  loc loss 19.588899612426758\n",
      "cls loss 522.1517333984375  loc loss 38.1317138671875\n",
      "cls loss 483.9980163574219  loc loss 29.704187393188477\n",
      "cls loss 306.8205261230469  loc loss 16.819530487060547\n",
      "cls loss 397.40625  loc loss 19.542028427124023\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 616.9768676757812  loc loss 33.78790283203125\n",
      "cls loss 490.62945556640625  loc loss 30.331327438354492\n",
      "cls loss 288.9721984863281  loc loss 13.233954429626465\n",
      "cls loss 246.2428741455078  loc loss 13.065855979919434\n",
      "cls loss 328.0726013183594  loc loss 19.726621627807617\n",
      "cls loss 437.2774658203125  loc loss 27.152408599853516\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15.])\n",
      "cls loss 213.20648193359375  loc loss 6.454797267913818\n",
      "cls loss 372.3021545410156  loc loss 20.40135955810547\n",
      "cls loss 333.80999755859375  loc loss 18.377487182617188\n",
      "cls loss 598.928955078125  loc loss 34.19085693359375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19.,  7.])\n",
      "cls loss 270.01177978515625  loc loss 14.766328811645508\n",
      "cls loss 532.454833984375  loc loss 38.211700439453125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 483.36407470703125  loc loss 24.871213912963867\n",
      "cls loss 471.55218505859375  loc loss 30.02193832397461\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([38., 38.,  1., 18.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1., 18., 18.,  1.])\n",
      "cls loss 314.04364013671875  loc loss 15.853630065917969\n",
      "cls loss 302.91094970703125  loc loss 14.476761817932129\n",
      "cls loss 597.7263793945312  loc loss 38.923274993896484\n",
      "cls loss 430.9295349121094  loc loss 26.449811935424805\n",
      "cls loss 356.57562255859375  loc loss 24.37055015563965\n",
      "cls loss 253.5574493408203  loc loss 16.51494789123535\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.])\n",
      "cls loss 142.11483764648438  loc loss 6.394629955291748\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([32.])\n",
      "cls loss 383.318115234375  loc loss 20.015422821044922\n",
      "cls loss 343.3323974609375  loc loss 22.016695022583008\n",
      "cls loss 428.5513610839844  loc loss 29.675962448120117\n",
      "cls loss 368.8590087890625  loc loss 21.35154914855957\n",
      "cls loss 319.4467468261719  loc loss 15.466724395751953\n",
      "cls loss 512.0571899414062  loc loss 25.86407470703125\n",
      "cls loss 612.5382690429688  loc loss 34.86698913574219\n",
      "cls loss 435.4739074707031  loc loss 28.61804962158203\n",
      "cls loss 330.63470458984375  loc loss 20.613534927368164\n",
      "cls loss 535.5787353515625  loc loss 36.76787567138672\n",
      "cls loss 353.85589599609375  loc loss 19.93512535095215\n",
      "cls loss 638.2959594726562  loc loss 41.06621551513672\n",
      "cls loss 422.65673828125  loc loss 22.739822387695312\n",
      "cls loss 336.5723571777344  loc loss 24.81118392944336\n",
      "cls loss 252.1016082763672  loc loss 13.335643768310547\n",
      "cls loss 309.749267578125  loc loss 17.92863655090332\n",
      "cls loss 434.18646240234375  loc loss 30.144588470458984\n",
      "cls loss 499.6942138671875  loc loss 36.62162780761719\n",
      "cls loss 311.26776123046875  loc loss 19.91706085205078\n",
      "cls loss 484.4949951171875  loc loss 35.524749755859375\n",
      "cls loss 589.3972778320312  loc loss 41.14833068847656\n",
      "cls loss 211.93348693847656  loc loss 14.591829299926758\n",
      "cls loss 577.10986328125  loc loss 40.69261169433594\n",
      "cls loss 430.0661315917969  loc loss 29.7685604095459\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 562.2418823242188  loc loss 43.11375427246094\n",
      "cls loss 228.94451904296875  loc loss 10.418025970458984\n",
      "cls loss 358.42584228515625  loc loss 21.76922607421875\n",
      "cls loss 360.3856201171875  loc loss 24.870105743408203\n",
      "cls loss 309.5984802246094  loc loss 21.01057243347168\n",
      "cls loss 176.34510803222656  loc loss 10.206510543823242\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 9., 9., 1., 9., 9., 9., 9., 1., 9.])\n",
      "cls loss 806.0177001953125  loc loss 62.72991943359375\n",
      "cls loss 436.1991271972656  loc loss 27.159889221191406\n",
      "cls loss 678.5388793945312  loc loss 54.65800857543945\n",
      "cls loss 261.4665832519531  loc loss 21.83361053466797\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 42., 42.])\n",
      "cls loss 434.58880615234375  loc loss 31.85114860534668\n",
      "cls loss 445.90899658203125  loc loss 33.6932373046875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  2.,  1.,  1.,  1., 38.,\n",
      "         1.,  1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 38., 38., 38.,  1., 38., 38., 38.,  1.,  1., 38.,  1.,\n",
      "         1.])\n",
      "cls loss 272.62225341796875  loc loss 20.16563606262207\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  8.,  8.])\n",
      "cls loss 631.2748413085938  loc loss 43.25267791748047\n",
      "cls loss 657.5760498046875  loc loss 47.315093994140625\n",
      "cls loss 229.3011474609375  loc loss 15.22824478149414\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([4., 1., 1., 4.])\n",
      "cls loss 374.0059814453125  loc loss 23.738109588623047\n",
      "cls loss 474.0904541015625  loc loss 31.116573333740234\n",
      "cls loss 187.10403442382812  loc loss 10.626138687133789\n",
      "cls loss 234.16693115234375  loc loss 17.861778259277344\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([51.,  1.])\n",
      "cls loss 166.14669799804688  loc loss 9.286690711975098\n",
      "cls loss 242.5076141357422  loc loss 16.875904083251953\n",
      "cls loss 506.5030212402344  loc loss 26.52480697631836\n",
      "cls loss 465.7066650390625  loc loss 40.1895751953125\n",
      "cls loss 728.1944580078125  loc loss 36.39787292480469\n",
      "cls loss 854.61767578125  loc loss 54.17570495605469\n",
      "cls loss 351.85943603515625  loc loss 22.678913116455078\n",
      "cls loss 529.2418212890625  loc loss 38.853538513183594\n",
      "cls loss 567.6952514648438  loc loss 36.735713958740234\n",
      "cls loss 411.79638671875  loc loss 28.129484176635742\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  3.,  1.,  1.,  1.,  3.,  1.,  1.,\n",
      "         1.,  1.,  1.])\n",
      "cls loss 445.2876281738281  loc loss 19.22918701171875\n",
      "cls loss 460.7321472167969  loc loss 27.080482482910156\n",
      "cls loss 471.18084716796875  loc loss 21.784090042114258\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "cls loss 395.53997802734375  loc loss 21.364500045776367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 221.75177001953125  loc loss 15.684895515441895\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3.])\n",
      "cls loss 172.05648803710938  loc loss 9.18614387512207\n",
      "cls loss 305.57061767578125  loc loss 17.42679786682129\n",
      "cls loss 293.75347900390625  loc loss 19.92884063720703\n",
      "cls loss 533.2280883789062  loc loss 34.801910400390625\n",
      "cls loss 234.3019561767578  loc loss 16.30414581298828\n",
      "cls loss 277.8515625  loc loss 21.419750213623047\n",
      "cls loss 791.3986206054688  loc loss 58.10308837890625\n",
      "cls loss 364.494140625  loc loss 24.302757263183594\n",
      "cls loss 269.85308837890625  loc loss 18.396411895751953\n",
      "cls loss 318.85894775390625  loc loss 17.451929092407227\n",
      "cls loss 292.4588928222656  loc loss 20.40589141845703\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 538.1832275390625  loc loss 37.62266540527344\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  9., 64., 64., 64., 64., 64., 64., 64., 64., 64.,  9.,  9.,  9.,\n",
      "         9.])\n",
      "cls loss 243.68759155273438  loc loss 13.508439064025879\n",
      "cls loss 791.4051513671875  loc loss 57.221107482910156\n",
      "cls loss 418.40997314453125  loc loss 25.81640625\n",
      "cls loss 481.5049133300781  loc loss 30.61229705810547\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.,  3.,  3.])\n",
      "cls loss 307.83978271484375  loc loss 17.04190444946289\n",
      "cls loss 328.6845703125  loc loss 22.59888458251953\n",
      "cls loss 351.4830322265625  loc loss 24.74305534362793\n",
      "cls loss 353.9635314941406  loc loss 23.949369430541992\n",
      "cls loss 412.85675048828125  loc loss 28.47769546508789\n",
      "cls loss 423.03643798828125  loc loss 28.2601261138916\n",
      "cls loss 378.80218505859375  loc loss 26.78437042236328\n",
      "cls loss 381.057861328125  loc loss 20.645402908325195\n",
      "cls loss 474.40911865234375  loc loss 32.14286804199219\n",
      "cls loss 348.65936279296875  loc loss 20.894886016845703\n",
      "cls loss 260.4597473144531  loc loss 14.016886711120605\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21.])\n",
      "cls loss 214.57859802246094  loc loss 13.24921989440918\n",
      "cls loss 307.80267333984375  loc loss 25.807662963867188\n",
      "cls loss 466.7880859375  loc loss 32.177268981933594\n",
      "cls loss 237.42083740234375  loc loss 15.095194816589355\n",
      "cls loss 377.9782409667969  loc loss 26.53675079345703\n",
      "cls loss 686.4835205078125  loc loss 38.04414749145508\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 42., 42.,  1.,  1.])\n",
      "cls loss 416.753173828125  loc loss 22.725879669189453\n",
      "cls loss 267.8299865722656  loc loss 16.028566360473633\n",
      "cls loss 376.427978515625  loc loss 22.37489128112793\n",
      "cls loss 512.7838745117188  loc loss 34.54864501953125\n",
      "cls loss 321.231689453125  loc loss 17.49641227722168\n",
      "cls loss 499.4524230957031  loc loss 32.16519546508789\n",
      "cls loss 435.329345703125  loc loss 29.299715042114258\n",
      "cls loss 426.3883361816406  loc loss 27.315349578857422\n",
      "cls loss 347.1650390625  loc loss 22.553367614746094\n",
      "cls loss 275.5176086425781  loc loss 18.225122451782227\n",
      "cls loss 216.56101989746094  loc loss 10.564008712768555\n",
      "cls loss 349.13446044921875  loc loss 21.869163513183594\n",
      "cls loss 541.6439208984375  loc loss 31.911489486694336\n",
      "cls loss 382.32879638671875  loc loss 21.992599487304688\n",
      "cls loss 373.32830810546875  loc loss 25.28340721130371\n",
      "cls loss 404.561279296875  loc loss 23.243404388427734\n",
      "cls loss 598.92724609375  loc loss 41.978240966796875\n",
      "cls loss 484.29425048828125  loc loss 30.560644149780273\n",
      "cls loss 521.08837890625  loc loss 26.050745010375977\n",
      "cls loss 326.57666015625  loc loss 14.469101905822754\n",
      "cls loss 463.0748291015625  loc loss 25.499055862426758\n",
      "cls loss 407.1808776855469  loc loss 22.577640533447266\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 5., 5., 5., 5., 5., 5.])\n",
      "cls loss 252.09231567382812  loc loss 14.634115219116211\n",
      "cls loss 323.7248840332031  loc loss 17.252389907836914\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([13.])\n",
      "cls loss 238.62542724609375  loc loss 9.772846221923828\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([44., 10.,  1.,  1.,  1.])\n",
      "cls loss 209.43736267089844  loc loss 14.133493423461914\n",
      "cls loss 369.49395751953125  loc loss 20.300495147705078\n",
      "cls loss 343.66900634765625  loc loss 17.55802345275879\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19., 19., 19., 19., 19., 19., 19.])\n",
      "cls loss 360.693603515625  loc loss 22.412582397460938\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([56.])\n",
      "cls loss 779.4060668945312  loc loss 52.833160400390625\n",
      "cls loss 496.67755126953125  loc loss 34.6236686706543\n",
      "cls loss 631.2748413085938  loc loss 38.62191390991211\n",
      "cls loss 601.9047241210938  loc loss 45.12492370605469\n",
      "cls loss 367.89117431640625  loc loss 21.154651641845703\n",
      "cls loss 623.0718994140625  loc loss 38.99343490600586\n",
      "cls loss 353.72344970703125  loc loss 23.32486915588379\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 36.])\n",
      "cls loss 451.67840576171875  loc loss 19.902673721313477\n",
      "cls loss 374.3800964355469  loc loss 23.063566207885742\n",
      "cls loss 351.91534423828125  loc loss 20.446725845336914\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5.])\n",
      "cls loss 409.51470947265625  loc loss 23.921680450439453\n",
      "cls loss 224.1651611328125  loc loss 10.916511535644531\n",
      "cls loss 528.3162841796875  loc loss 29.00640296936035\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "cls loss 457.9718933105469  loc loss 28.792491912841797\n",
      "cls loss 436.07208251953125  loc loss 26.29433250427246\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 459.2385559082031  loc loss 27.668624877929688\n",
      "cls loss 530.8394165039062  loc loss 30.737329483032227\n",
      "cls loss 456.85015869140625  loc loss 36.23336410522461\n",
      "cls loss 312.8467102050781  loc loss 19.016250610351562\n",
      "cls loss 347.66204833984375  loc loss 25.71619415283203\n",
      "cls loss 360.3523254394531  loc loss 20.529661178588867\n",
      "cls loss 606.3955078125  loc loss 29.308839797973633\n",
      "cls loss 240.8271484375  loc loss 11.223226547241211\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 11., 15., 10., 10., 10., 10., 10.])\n",
      "cls loss 557.41357421875  loc loss 35.279197692871094\n",
      "cls loss 337.9579772949219  loc loss 22.53681182861328\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3.])\n",
      "cls loss 348.33929443359375  loc loss 24.700660705566406\n",
      "cls loss 331.9713134765625  loc loss 15.684785842895508\n",
      "cls loss 358.4810791015625  loc loss 16.852746963500977\n",
      "cls loss 475.07257080078125  loc loss 20.134746551513672\n",
      "cls loss 204.36550903320312  loc loss 9.354531288146973\n",
      "cls loss 367.3600158691406  loc loss 24.035404205322266\n",
      "cls loss 438.2528076171875  loc loss 27.703876495361328\n",
      "cls loss 382.135498046875  loc loss 23.825746536254883\n",
      "cls loss 896.5610961914062  loc loss 53.9957389831543\n",
      "cls loss 600.4533081054688  loc loss 35.41608810424805\n",
      "cls loss 373.650146484375  loc loss 24.71882438659668\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  9.,  9.,  9.,  6.,  6., 85., 85.,  8.,  1.,  1.,  1.,  1.,\n",
      "         6.,  6.])\n",
      "cls loss 246.22247314453125  loc loss 20.333009719848633\n",
      "cls loss 635.3975219726562  loc loss 42.80010223388672\n",
      "cls loss 742.0697021484375  loc loss 45.444244384765625\n",
      "cls loss 459.5738220214844  loc loss 32.009891510009766\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10.,  3.,  3., 10.])\n",
      "cls loss 293.4503173828125  loc loss 15.591639518737793\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([7.])\n",
      "cls loss 386.7349548339844  loc loss 24.524133682250977\n",
      "cls loss 369.9832763671875  loc loss 24.373077392578125\n",
      "cls loss 394.49951171875  loc loss 34.083961486816406\n",
      "cls loss 652.971923828125  loc loss 45.4862174987793\n",
      "cls loss 358.8810729980469  loc loss 23.658220291137695\n",
      "cls loss 561.71533203125  loc loss 37.828636169433594\n",
      "cls loss 696.55615234375  loc loss 40.4017448425293\n",
      "cls loss 454.9136047363281  loc loss 26.280885696411133\n",
      "cls loss 503.8748474121094  loc loss 31.01883888244629\n",
      "cls loss 380.5242919921875  loc loss 24.717281341552734\n",
      "cls loss 553.6953735351562  loc loss 38.43690490722656\n",
      "cls loss 424.7667541503906  loc loss 28.41726303100586\n",
      "cls loss 302.23321533203125  loc loss 19.490415573120117\n",
      "cls loss 492.60174560546875  loc loss 37.782981872558594\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([62.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([62.])\n",
      "cls loss 221.51766967773438  loc loss 10.355003356933594\n",
      "cls loss 339.79827880859375  loc loss 26.822551727294922\n",
      "cls loss 352.5662841796875  loc loss 23.428359985351562\n",
      "cls loss 221.9200897216797  loc loss 11.51915168762207\n",
      "cls loss 483.44134521484375  loc loss 31.521080017089844\n",
      "cls loss 492.6230773925781  loc loss 27.063262939453125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([28.])\n",
      "cls loss 622.67822265625  loc loss 27.431676864624023\n",
      "cls loss 459.2010498046875  loc loss 28.890792846679688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 460.5457763671875  loc loss 30.380403518676758\n",
      "cls loss 511.6361389160156  loc loss 29.988460540771484\n",
      "cls loss 750.5709228515625  loc loss 43.822593688964844\n",
      "cls loss 429.05145263671875  loc loss 22.920820236206055\n",
      "cls loss 571.3677978515625  loc loss 27.451980590820312\n",
      "cls loss 463.2841796875  loc loss 31.458141326904297\n",
      "cls loss 736.4164428710938  loc loss 53.83662414550781\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([81.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 434.3477783203125  loc loss 16.88314437866211\n",
      "cls loss 335.1168518066406  loc loss 16.351909637451172\n",
      "cls loss 242.3201904296875  loc loss 16.73311996459961\n",
      "cls loss 214.69639587402344  loc loss 9.171988487243652\n",
      "cls loss 243.67990112304688  loc loss 18.184659957885742\n",
      "cls loss 304.477783203125  loc loss 18.46286392211914\n",
      "cls loss 313.28216552734375  loc loss 21.665512084960938\n",
      "cls loss 462.22161865234375  loc loss 36.674560546875\n",
      "cls loss 564.8677978515625  loc loss 32.65614700317383\n",
      "cls loss 953.3033447265625  loc loss 63.797149658203125\n",
      "cls loss 376.5561828613281  loc loss 17.033479690551758\n",
      "cls loss 494.56231689453125  loc loss 34.11469268798828\n",
      "cls loss 336.83648681640625  loc loss 19.424137115478516\n",
      "cls loss 437.71527099609375  loc loss 22.889183044433594\n",
      "cls loss 398.69580078125  loc loss 22.050119400024414\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([44., 44.])\n",
      "cls loss 355.8822021484375  loc loss 16.19267463684082\n",
      "cls loss 403.92413330078125  loc loss 23.665441513061523\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15.])\n",
      "cls loss 369.4958190917969  loc loss 19.726205825805664\n",
      "cls loss 227.72816467285156  loc loss 12.282909393310547\n",
      "cls loss 393.0771484375  loc loss 26.054224014282227\n",
      "cls loss 234.7540740966797  loc loss 13.380815505981445\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([1., 3., 3.])\n",
      "cls loss 265.8022766113281  loc loss 17.132558822631836\n",
      "cls loss 184.69601440429688  loc loss 10.883352279663086\n",
      "cls loss 349.189697265625  loc loss 27.314594268798828\n",
      "cls loss 422.149658203125  loc loss 26.408645629882812\n",
      "cls loss 355.9320373535156  loc loss 24.15839385986328\n",
      "cls loss 304.31988525390625  loc loss 21.560382843017578\n",
      "cls loss 331.9661865234375  loc loss 22.674945831298828\n",
      "cls loss 451.0180358886719  loc loss 28.7180233001709\n",
      "cls loss 295.8212585449219  loc loss 19.901647567749023\n",
      "cls loss 391.8027038574219  loc loss 32.289798736572266\n",
      "cls loss 283.9193420410156  loc loss 21.285175323486328\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 517.81640625  loc loss 32.496673583984375\n",
      "cls loss 615.165771484375  loc loss 32.899654388427734\n",
      "cls loss 527.3037719726562  loc loss 39.51881408691406\n",
      "cls loss 523.1539306640625  loc loss 40.57439422607422\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10., 10., 10.,  1.,  1.,  1.,  1.,  1.,  1.,  8.,  8.,\n",
      "         1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10., 10., 10.,  1.,  1.,  1.,  1.,  1.,  1.,  8.,  8.,\n",
      "         1.])\n",
      "cls loss 412.4857177734375  loc loss 23.199466705322266\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 3., 3., 3.])\n",
      "cls loss 412.87005615234375  loc loss 21.758596420288086\n",
      "cls loss 256.8887634277344  loc loss 16.130699157714844\n",
      "cls loss 198.08026123046875  loc loss 9.871487617492676\n",
      "cls loss 391.74407958984375  loc loss 31.87337875366211\n",
      "cls loss 278.627685546875  loc loss 16.056495666503906\n",
      "cls loss 356.4364929199219  loc loss 28.14493179321289\n",
      "cls loss 400.1129150390625  loc loss 31.508615493774414\n",
      "cls loss 528.036376953125  loc loss 48.65370559692383\n",
      "cls loss 461.48583984375  loc loss 29.556800842285156\n",
      "cls loss 414.56439208984375  loc loss 29.61443328857422\n",
      "cls loss 429.87176513671875  loc loss 33.276397705078125\n",
      "cls loss 306.9817199707031  loc loss 24.99764633178711\n",
      "cls loss 651.679931640625  loc loss 46.44757843017578\n",
      "cls loss 264.87042236328125  loc loss 15.301729202270508\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 514.1163940429688  loc loss 30.26775550842285\n",
      "cls loss 206.03494262695312  loc loss 11.633257865905762\n",
      "cls loss 544.7416381835938  loc loss 43.2924690246582\n",
      "cls loss 275.28558349609375  loc loss 24.660886764526367\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 34.])\n",
      "cls loss 463.7159118652344  loc loss 36.042354583740234\n",
      "cls loss 249.54220581054688  loc loss 17.906007766723633\n",
      "cls loss 512.0836181640625  loc loss 30.941415786743164\n",
      "cls loss 192.94180297851562  loc loss 14.601337432861328\n",
      "cls loss 382.87652587890625  loc loss 29.73318862915039\n",
      "cls loss 386.50244140625  loc loss 32.32120895385742\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 38.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16., 16., 16.,  9.,  9.,  9., 16., 16., 16., 85.,  9.])\n",
      "cls loss 397.71954345703125  loc loss 25.738006591796875\n",
      "cls loss 429.56695556640625  loc loss 33.620361328125\n",
      "cls loss 581.9415893554688  loc loss 38.92222595214844\n",
      "cls loss 897.5994873046875  loc loss 54.39704895019531\n",
      "cls loss 221.19223022460938  loc loss 12.186480522155762\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3., 10.,  8.,  8., 10., 10., 10.,  3.,  3., 14.])\n",
      "cls loss 238.5966033935547  loc loss 15.776727676391602\n",
      "cls loss 443.56427001953125  loc loss 31.973220825195312\n",
      "cls loss 187.59283447265625  loc loss 8.256725311279297\n",
      "cls loss 326.26422119140625  loc loss 17.65880012512207\n",
      "cls loss 455.31304931640625  loc loss 37.1474723815918\n",
      "cls loss 378.0286865234375  loc loss 28.84441375732422\n",
      "cls loss 219.64797973632812  loc loss 14.991199493408203\n",
      "cls loss 290.848388671875  loc loss 17.43094825744629\n",
      "cls loss 499.1329345703125  loc loss 32.47822570800781\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42., 42.,  1.])\n",
      "cls loss 449.658447265625  loc loss 27.453266143798828\n",
      "cls loss 389.0863037109375  loc loss 21.255069732666016\n",
      "cls loss 498.30767822265625  loc loss 37.33709716796875\n",
      "cls loss 549.1334228515625  loc loss 31.035015106201172\n",
      "cls loss 374.03497314453125  loc loss 21.287738800048828\n",
      "cls loss 442.8840637207031  loc loss 30.495532989501953\n",
      "cls loss 257.68145751953125  loc loss 17.377058029174805\n",
      "cls loss 282.4994812011719  loc loss 21.840078353881836\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20.])\n",
      "cls loss 207.90936279296875  loc loss 13.157800674438477\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([11.])\n",
      "cls loss 289.7314758300781  loc loss 13.90938949584961\n",
      "cls loss 167.2307586669922  loc loss 12.390240669250488\n",
      "cls loss 442.71490478515625  loc loss 35.847232818603516\n",
      "cls loss 184.14418029785156  loc loss 9.778619766235352\n",
      "cls loss 384.71527099609375  loc loss 27.674715042114258\n",
      "cls loss 215.9573211669922  loc loss 15.277094841003418\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 35., 27.])\n",
      "cls loss 398.1265869140625  loc loss 23.755496978759766\n",
      "cls loss 463.88555908203125  loc loss 36.38533020019531\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 305.084228515625  loc loss 19.3671932220459\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([42.,  1.])\n",
      "cls loss 396.06622314453125  loc loss 25.568132400512695\n",
      "cls loss 415.05975341796875  loc loss 19.192771911621094\n",
      "cls loss 487.587158203125  loc loss 25.869497299194336\n",
      "cls loss 642.9591064453125  loc loss 29.112077713012695\n",
      "cls loss 507.17913818359375  loc loss 26.984437942504883\n",
      "cls loss 360.92626953125  loc loss 21.622032165527344\n",
      "cls loss 287.99176025390625  loc loss 20.644311904907227\n",
      "cls loss 174.5068817138672  loc loss 7.938814163208008\n",
      "cls loss 306.938232421875  loc loss 19.015960693359375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 1., 1.])\n",
      "cls loss 303.0137939453125  loc loss 20.961862564086914\n",
      "cls loss 370.81787109375  loc loss 26.115934371948242\n",
      "cls loss 357.34039306640625  loc loss 22.34303855895996\n",
      "cls loss 271.3690185546875  loc loss 19.736364364624023\n",
      "cls loss 341.728515625  loc loss 22.709720611572266\n",
      "cls loss 357.44390869140625  loc loss 27.009151458740234\n",
      "cls loss 544.1541137695312  loc loss 32.524539947509766\n",
      "cls loss 479.6622314453125  loc loss 36.563026428222656\n",
      "cls loss 411.84002685546875  loc loss 28.90608024597168\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 325.4688415527344  loc loss 26.129661560058594\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 467.82525634765625  loc loss 17.24363136291504\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([81.])\n",
      "cls loss 529.0908813476562  loc loss 28.84285545349121\n",
      "cls loss 305.5438537597656  loc loss 20.169063568115234\n",
      "cls loss 252.82115173339844  loc loss 10.458407402038574\n",
      "cls loss 335.54150390625  loc loss 18.079307556152344\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3.,  1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 19.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 19.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 479.86334228515625  loc loss 29.81941032409668\n",
      "cls loss 250.700439453125  loc loss 15.043618202209473\n",
      "cls loss 274.6258239746094  loc loss 16.171850204467773\n",
      "cls loss 523.1722412109375  loc loss 39.689151763916016\n",
      "cls loss 250.80496215820312  loc loss 17.39268684387207\n",
      "cls loss 320.21881103515625  loc loss 20.40277862548828\n",
      "cls loss 412.68182373046875  loc loss 26.237751007080078\n",
      "cls loss 306.8289794921875  loc loss 21.708864212036133\n",
      "cls loss 417.2678527832031  loc loss 22.027259826660156\n",
      "cls loss 447.40325927734375  loc loss 28.596515655517578\n",
      "cls loss 616.7771606445312  loc loss 51.775535583496094\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 81.])\n",
      "cls loss 399.9417419433594  loc loss 20.27326774597168\n",
      "cls loss 364.633056640625  loc loss 21.203899383544922\n",
      "cls loss 367.86700439453125  loc loss 20.876733779907227\n",
      "cls loss 307.3798828125  loc loss 15.35408878326416\n",
      "cls loss 264.1076965332031  loc loss 15.951164245605469\n",
      "cls loss 331.52239990234375  loc loss 24.15422248840332\n",
      "cls loss 234.66580200195312  loc loss 15.566248893737793\n",
      "cls loss 212.20664978027344  loc loss 12.679964065551758\n",
      "cls loss 255.5050811767578  loc loss 16.615354537963867\n",
      "cls loss 354.83575439453125  loc loss 24.80229949951172\n",
      "cls loss 335.09722900390625  loc loss 27.237934112548828\n",
      "cls loss 331.01605224609375  loc loss 21.949193954467773\n",
      "cls loss 198.66415405273438  loc loss 13.966249465942383\n",
      "cls loss 703.5211791992188  loc loss 47.571109771728516\n",
      "cls loss 379.94140625  loc loss 26.969371795654297\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 337.4761962890625  loc loss 17.598857879638672\n",
      "cls loss 377.5005187988281  loc loss 23.862241744995117\n",
      "cls loss 274.29156494140625  loc loss 19.475860595703125\n",
      "cls loss 450.62103271484375  loc loss 32.82205581665039\n",
      "cls loss 437.52020263671875  loc loss 29.382402420043945\n",
      "cls loss 398.843994140625  loc loss 26.795124053955078\n",
      "cls loss 286.9376525878906  loc loss 21.07370376586914\n",
      "cls loss 266.36761474609375  loc loss 16.535776138305664\n",
      "cls loss 388.6585388183594  loc loss 23.38006591796875\n",
      "cls loss 471.35418701171875  loc loss 31.923553466796875\n",
      "cls loss 401.06207275390625  loc loss 23.332117080688477\n",
      "cls loss 525.4811401367188  loc loss 33.57078170776367\n",
      "cls loss 589.2694091796875  loc loss 42.6636962890625\n",
      "cls loss 387.0635986328125  loc loss 24.866744995117188\n",
      "cls loss 560.4892578125  loc loss 43.27820587158203\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1., 38., 47.,  1.,  1.,  1.,  1.,  1., 62.])\n",
      "cls loss 334.3548583984375  loc loss 18.809255599975586\n",
      "cls loss 404.11260986328125  loc loss 30.178922653198242\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 441.0895690917969  loc loss 25.755470275878906\n",
      "cls loss 507.38446044921875  loc loss 36.31520080566406\n",
      "cls loss 326.120849609375  loc loss 17.327089309692383\n",
      "cls loss 390.20855712890625  loc loss 33.4354248046875\n",
      "cls loss 383.51885986328125  loc loss 26.77310562133789\n",
      "cls loss 209.6514129638672  loc loss 8.798382759094238\n",
      "cls loss 328.3833312988281  loc loss 23.248672485351562\n",
      "cls loss 289.8955383300781  loc loss 14.205227851867676\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1., 35.])\n",
      "cls loss 316.9208984375  loc loss 18.519365310668945\n",
      "cls loss 478.23480224609375  loc loss 26.15606689453125\n",
      "cls loss 494.9648132324219  loc loss 27.43118667602539\n",
      "cls loss 431.213134765625  loc loss 32.93613052368164\n",
      "cls loss 370.4336853027344  loc loss 24.54575538635254\n",
      "cls loss 478.67486572265625  loc loss 37.21552658081055\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 260.923828125  loc loss 14.655418395996094\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 366.51312255859375  loc loss 16.769081115722656\n",
      "cls loss 554.6529541015625  loc loss 39.695472717285156\n",
      "cls loss 714.0220336914062  loc loss 57.641780853271484\n",
      "cls loss 341.94873046875  loc loss 20.28567886352539\n",
      "cls loss 300.342529296875  loc loss 18.70098876953125\n",
      "cls loss 313.6560974121094  loc loss 15.9081392288208\n",
      "cls loss 357.8990478515625  loc loss 20.491960525512695\n",
      "cls loss 304.8063659667969  loc loss 13.620737075805664\n",
      "cls loss 567.14697265625  loc loss 38.807655334472656\n",
      "cls loss 466.1807861328125  loc loss 27.3751277923584\n",
      "cls loss 201.30775451660156  loc loss 14.936807632446289\n",
      "cls loss 415.5389404296875  loc loss 25.528512954711914\n",
      "cls loss 579.7531127929688  loc loss 41.76504135131836\n",
      "cls loss 421.10650634765625  loc loss 28.13675880432129\n",
      "cls loss 379.6080322265625  loc loss 22.69365692138672\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.])\n",
      "cls loss 361.1280517578125  loc loss 25.549915313720703\n",
      "cls loss 369.463623046875  loc loss 22.348087310791016\n",
      "cls loss 436.74267578125  loc loss 26.26483154296875\n",
      "cls loss 741.9428100585938  loc loss 51.973793029785156\n",
      "cls loss 262.4891357421875  loc loss 13.460676193237305\n",
      "cls loss 350.7974853515625  loc loss 19.726070404052734\n",
      "cls loss 271.49481201171875  loc loss 17.098201751708984\n",
      "cls loss 315.62896728515625  loc loss 22.414077758789062\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 21., 21., 21.])\n",
      "cls loss 299.0531005859375  loc loss 18.837833404541016\n",
      "cls loss 328.8365783691406  loc loss 17.493492126464844\n",
      "cls loss 324.43780517578125  loc loss 21.058956146240234\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 35.])\n",
      "cls loss 442.7772216796875  loc loss 27.13431739807129\n",
      "cls loss 161.28851318359375  loc loss 8.841397285461426\n",
      "cls loss 305.8049011230469  loc loss 16.438549041748047\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 285.1519775390625  loc loss 11.154004096984863\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 38., 38.,  9., 38.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1.,  1.])\n",
      "cls loss 310.9297180175781  loc loss 17.86087989807129\n",
      "cls loss 517.412353515625  loc loss 31.439712524414062\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 2.,  1., 77., 31., 10., 10.,  1.,  4., 10.])\n",
      "cls loss 231.61082458496094  loc loss 10.00979232788086\n",
      "cls loss 475.58612060546875  loc loss 27.743654251098633\n",
      "cls loss 938.896728515625  loc loss 52.39852523803711\n",
      "cls loss 298.4599914550781  loc loss 20.096189498901367\n",
      "cls loss 406.39617919921875  loc loss 29.12565803527832\n",
      "cls loss 264.5673828125  loc loss 14.969240188598633\n",
      "cls loss 262.1497802734375  loc loss 14.819845199584961\n",
      "cls loss 369.43023681640625  loc loss 23.058040618896484\n",
      "cls loss 360.120849609375  loc loss 24.787933349609375\n",
      "cls loss 346.3342590332031  loc loss 26.91092300415039\n",
      "cls loss 299.4346618652344  loc loss 15.034741401672363\n",
      "cls loss 310.62847900390625  loc loss 19.520172119140625\n",
      "cls loss 601.4769287109375  loc loss 37.179115295410156\n",
      "cls loss 560.9363403320312  loc loss 33.708683013916016\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1., 42., 42., 42., 42., 42., 42.,  1.,\n",
      "         1.,  1.,  1., 42.,  1.,  1., 42.,  1.])\n",
      "cls loss 313.9945068359375  loc loss 22.605297088623047\n",
      "cls loss 479.68756103515625  loc loss 26.44275665283203\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.])\n",
      "cls loss 199.8740692138672  loc loss 10.965082168579102\n",
      "cls loss 476.1808776855469  loc loss 29.842899322509766\n",
      "cls loss 351.9154052734375  loc loss 25.516845703125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([11.])\n",
      "cls loss 203.1112060546875  loc loss 14.68435001373291\n",
      "cls loss 231.48912048339844  loc loss 12.727250099182129\n",
      "cls loss 242.11199951171875  loc loss 14.27803897857666\n",
      "cls loss 440.62188720703125  loc loss 26.126680374145508\n",
      "cls loss 343.82647705078125  loc loss 21.58806037902832\n",
      "cls loss 373.50030517578125  loc loss 26.577754974365234\n",
      "cls loss 524.823974609375  loc loss 31.562946319580078\n",
      "cls loss 280.8459167480469  loc loss 18.14476203918457\n",
      "cls loss 622.3165893554688  loc loss 40.4111213684082\n",
      "cls loss 300.35601806640625  loc loss 18.0194091796875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 281.58404541015625  loc loss 17.067110061645508\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1., 38., 38., 42.])\n",
      "cls loss 389.02264404296875  loc loss 23.802282333374023\n",
      "cls loss 348.65777587890625  loc loss 19.43144416809082\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 307.7685852050781  loc loss 18.214508056640625\n",
      "cls loss 656.1480712890625  loc loss 40.18588638305664\n",
      "cls loss 385.40582275390625  loc loss 22.406352996826172\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10.,  3.,  3.,  6.,  8.,  8.,  1.,  1.,  1., 10.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 286.73834228515625  loc loss 17.059436798095703\n",
      "cls loss 200.02651977539062  loc loss 8.586645126342773\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10.,  3.])\n",
      "cls loss 272.0311584472656  loc loss 18.463220596313477\n",
      "cls loss 133.15267944335938  loc loss 8.275010108947754\n",
      "cls loss 355.74481201171875  loc loss 28.22968292236328\n",
      "cls loss 423.84332275390625  loc loss 30.351367950439453\n",
      "cls loss 314.810791015625  loc loss 18.855571746826172\n",
      "cls loss 168.85948181152344  loc loss 14.15500545501709\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 34.])\n",
      "cls loss 471.0954284667969  loc loss 34.890899658203125\n",
      "cls loss 634.4207153320312  loc loss 45.08625030517578\n",
      "cls loss 392.73297119140625  loc loss 27.515302658081055\n",
      "cls loss 312.9057312011719  loc loss 25.99180793762207\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.,  1.])\n",
      "cls loss 348.8050231933594  loc loss 16.86149787902832\n",
      "cls loss 583.5422973632812  loc loss 45.77289581298828\n",
      "cls loss 814.9298706054688  loc loss 56.48594665527344\n",
      "cls loss 642.5836181640625  loc loss 36.6977653503418\n",
      "cls loss 361.0690612792969  loc loss 21.28969955444336\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 372.1851501464844  loc loss 22.75909423828125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10.])\n",
      "cls loss 248.12625122070312  loc loss 14.556171417236328\n",
      "cls loss 371.6634826660156  loc loss 21.946996688842773\n",
      "cls loss 352.6543273925781  loc loss 24.906824111938477\n",
      "cls loss 223.99691772460938  loc loss 19.444149017333984\n",
      "cls loss 318.2320556640625  loc loss 26.104021072387695\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21.,\n",
      "        21.])\n",
      "cls loss 376.1585998535156  loc loss 30.361309051513672\n",
      "cls loss 333.8446044921875  loc loss 26.05626678466797\n",
      "cls loss 226.1138458251953  loc loss 14.785558700561523\n",
      "cls loss 513.4803466796875  loc loss 36.07014465332031\n",
      "cls loss 371.4233093261719  loc loss 26.079023361206055\n",
      "cls loss 280.18157958984375  loc loss 13.86412239074707\n",
      "cls loss 596.81396484375  loc loss 41.37055969238281\n",
      "cls loss 677.66796875  loc loss 53.85783004760742\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15., 85.])\n",
      "cls loss 464.7188720703125  loc loss 27.143966674804688\n",
      "cls loss 459.046142578125  loc loss 37.25154495239258\n",
      "cls loss 452.5669860839844  loc loss 36.31892013549805\n",
      "cls loss 345.5399475097656  loc loss 32.95423126220703\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 8., 8.])\n",
      "cls loss 268.45416259765625  loc loss 14.778804779052734\n",
      "cls loss 252.57049560546875  loc loss 24.66927146911621\n",
      "cls loss 326.17578125  loc loss 24.74391746520996\n",
      "cls loss 283.9640808105469  loc loss 18.675312042236328\n",
      "cls loss 307.0032043457031  loc loss 25.298828125\n",
      "cls loss 462.2215270996094  loc loss 32.499534606933594\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1., 35., 27., 27.,  1., 27.,  1.])\n",
      "cls loss 488.17291259765625  loc loss 55.231929779052734\n",
      "cls loss 308.246826171875  loc loss 24.070751190185547\n",
      "cls loss 313.4429016113281  loc loss 28.187353134155273\n",
      "cls loss 326.21807861328125  loc loss 29.95313835144043\n",
      "cls loss 292.26385498046875  loc loss 25.23625373840332\n",
      "cls loss 338.348388671875  loc loss 26.333526611328125\n",
      "cls loss 333.81890869140625  loc loss 24.203914642333984\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  2.,  2.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  2.,  2.])\n",
      "cls loss 160.40167236328125  loc loss 8.157000541687012\n",
      "cls loss 533.017822265625  loc loss 39.32835388183594\n",
      "cls loss 321.1127014160156  loc loss 24.26343536376953\n",
      "cls loss 578.58349609375  loc loss 56.500972747802734\n",
      "cls loss 218.76788330078125  loc loss 16.980419158935547\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 19., 19., 19., 16.])\n",
      "cls loss 221.8812255859375  loc loss 12.239991188049316\n",
      "cls loss 197.27694702148438  loc loss 11.125502586364746\n",
      "cls loss 320.0558166503906  loc loss 17.489723205566406\n",
      "cls loss 421.2183837890625  loc loss 30.149389266967773\n",
      "cls loss 161.44361877441406  loc loss 17.93473243713379\n",
      "cls loss 450.22796630859375  loc loss 35.72470474243164\n",
      "cls loss 333.7254638671875  loc loss 25.494068145751953\n",
      "cls loss 349.33258056640625  loc loss 23.692638397216797\n",
      "cls loss 458.97027587890625  loc loss 30.412931442260742\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 439.77447509765625  loc loss 22.115339279174805\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 648.7227783203125  loc loss 58.57050323486328\n",
      "cls loss 840.314208984375  loc loss 82.25205993652344\n",
      "cls loss 387.2967224121094  loc loss 29.535518646240234\n",
      "cls loss 377.6158447265625  loc loss 26.85584831237793\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3.,  3.,  3.,  3.,  3., 10.])\n",
      "cls loss 179.34625244140625  loc loss 12.516315460205078\n",
      "cls loss 407.0413513183594  loc loss 18.663042068481445\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 1., 1., 1., 3., 3., 3., 3.])\n",
      "cls loss 334.3190612792969  loc loss 15.685234069824219\n",
      "cls loss 628.199951171875  loc loss 41.2888298034668\n",
      "cls loss 525.9940795898438  loc loss 28.980615615844727\n",
      "cls loss 324.5809631347656  loc loss 17.456958770751953\n",
      "cls loss 504.01336669921875  loc loss 34.8974494934082\n",
      "cls loss 291.1056213378906  loc loss 20.37061309814453\n",
      "cls loss 481.8795166015625  loc loss 35.01458740234375\n",
      "cls loss 366.5537109375  loc loss 34.543739318847656\n",
      "cls loss 322.8691101074219  loc loss 25.190093994140625\n",
      "cls loss 748.046875  loc loss 65.84970092773438\n",
      "cls loss 475.9404296875  loc loss 35.583839416503906\n",
      "cls loss 307.4208984375  loc loss 15.243378639221191\n",
      "cls loss 179.64730834960938  loc loss 8.136468887329102\n",
      "cls loss 237.34368896484375  loc loss 13.591124534606934\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3., 10., 10., 10., 10., 10., 10., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10., 10., 10., 10., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 11., 10., 10., 10., 10., 10.,  3.,  3.,  3.,  3.,  3.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 11., 10., 10., 10., 10., 10.,  3.,  3.,  3.,  3.,  3.])\n",
      "cls loss 180.12283325195312  loc loss 9.210272789001465\n",
      "cls loss 257.81378173828125  loc loss 12.446388244628906\n",
      "cls loss 241.3167724609375  loc loss 14.345815658569336\n",
      "cls loss 221.66268920898438  loc loss 13.770050048828125\n",
      "cls loss 304.94049072265625  loc loss 28.609085083007812\n",
      "cls loss 215.13584899902344  loc loss 11.386570930480957\n",
      "cls loss 471.62615966796875  loc loss 32.12108612060547\n",
      "cls loss 442.58099365234375  loc loss 28.556379318237305\n",
      "cls loss 620.21826171875  loc loss 45.099117279052734\n",
      "cls loss 319.2204284667969  loc loss 21.268041610717773\n",
      "cls loss 540.970947265625  loc loss 31.50558090209961\n",
      "cls loss 404.4331359863281  loc loss 29.618064880371094\n",
      "cls loss 417.30035400390625  loc loss 29.109195709228516\n",
      "cls loss 394.92218017578125  loc loss 31.237886428833008\n",
      "cls loss 509.1565246582031  loc loss 44.058807373046875\n",
      "cls loss 483.4534912109375  loc loss 42.766754150390625\n",
      "cls loss 231.16159057617188  loc loss 18.009809494018555\n",
      "cls loss 502.51458740234375  loc loss 41.14891815185547\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 10.,  1., 18.])\n",
      "cls loss 206.19200134277344  loc loss 19.8117618560791\n",
      "cls loss 240.68692016601562  loc loss 12.74769115447998\n",
      "cls loss 444.78057861328125  loc loss 27.85470199584961\n",
      "cls loss 644.242431640625  loc loss 44.27021789550781\n",
      "cls loss 378.5408630371094  loc loss 25.077590942382812\n",
      "cls loss 590.7720336914062  loc loss 30.71868133544922\n",
      "cls loss 468.75518798828125  loc loss 28.572734832763672\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.,  1.,  1.])\n",
      "cls loss 525.8252563476562  loc loss 33.21409606933594\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1., 38.,  1.])\n",
      "cls loss 430.73114013671875  loc loss 31.778324127197266\n",
      "cls loss 632.3272705078125  loc loss 56.53916931152344\n",
      "cls loss 345.55828857421875  loc loss 28.16208839416504\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 456.119873046875  loc loss 33.425575256347656\n",
      "cls loss 369.84747314453125  loc loss 29.769542694091797\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3., 10.,  8.,  3., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.])\n",
      "cls loss 409.54986572265625  loc loss 34.16544723510742\n",
      "cls loss 273.4366149902344  loc loss 19.049558639526367\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3.,  3., 11.,  3., 10., 10.,  3.,  3., 10.])\n",
      "cls loss 260.2491149902344  loc loss 27.849403381347656\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3., 10., 10., 10.])\n",
      "cls loss 342.4472961425781  loc loss 19.544414520263672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 265.62066650390625  loc loss 19.232959747314453\n",
      "cls loss 362.8564453125  loc loss 30.381038665771484\n",
      "cls loss 531.3970336914062  loc loss 35.96125030517578\n",
      "cls loss 350.70391845703125  loc loss 23.998334884643555\n",
      "cls loss 279.5956115722656  loc loss 25.01539421081543\n",
      "cls loss 357.6170349121094  loc loss 23.6829891204834\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 9.,  9., 85., 85.])\n",
      "cls loss 300.77166748046875  loc loss 18.127531051635742\n",
      "cls loss 392.3550720214844  loc loss 31.132291793823242\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 572.503173828125  loc loss 52.49931716918945\n",
      "cls loss 472.7555847167969  loc loss 27.23625373840332\n",
      "cls loss 546.06005859375  loc loss 41.31531524658203\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10., 10., 10., 10.])\n",
      "cls loss 354.3453674316406  loc loss 24.74557876586914\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([13.])\n",
      "cls loss 554.6366577148438  loc loss 41.81468963623047\n",
      "cls loss 147.11602783203125  loc loss 9.694417953491211\n",
      "cls loss 224.96035766601562  loc loss 11.410755157470703\n",
      "cls loss 289.21533203125  loc loss 23.00745391845703\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19.,  1.,  1.,  1., 19., 19.])\n",
      "cls loss 322.5065612792969  loc loss 22.391881942749023\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 258.6584167480469  loc loss 21.872482299804688\n",
      "cls loss 390.18231201171875  loc loss 38.997859954833984\n",
      "cls loss 298.0907897949219  loc loss 21.097618103027344\n",
      "cls loss 421.8218078613281  loc loss 30.557456970214844\n",
      "cls loss 456.56683349609375  loc loss 42.77177047729492\n",
      "cls loss 344.521728515625  loc loss 25.691946029663086\n",
      "cls loss 557.5738525390625  loc loss 43.85603332519531\n",
      "cls loss 191.92807006835938  loc loss 9.782402038574219\n",
      "cls loss 360.0071716308594  loc loss 25.427745819091797\n",
      "cls loss 303.64556884765625  loc loss 16.513996124267578\n",
      "cls loss 334.7204895019531  loc loss 16.363006591796875\n",
      "cls loss 452.14251708984375  loc loss 28.207717895507812\n",
      "cls loss 346.9757080078125  loc loss 18.265193939208984\n",
      "cls loss 511.202880859375  loc loss 37.16423416137695\n",
      "cls loss 330.3084411621094  loc loss 22.691946029663086\n",
      "cls loss 429.8138427734375  loc loss 36.08031463623047\n",
      "cls loss 621.8268432617188  loc loss 43.00166320800781\n",
      "cls loss 337.57757568359375  loc loss 28.759807586669922\n",
      "cls loss 407.3709716796875  loc loss 27.35173225402832\n",
      "cls loss 490.708251953125  loc loss 42.68876266479492\n",
      "cls loss 577.0208740234375  loc loss 37.92054748535156\n",
      "cls loss 611.1204833984375  loc loss 36.58649444580078\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 5.])\n",
      "cls loss 141.75778198242188  loc loss 7.471315860748291\n",
      "cls loss 225.43942260742188  loc loss 9.638723373413086\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 13.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 6., 8., 8.])\n",
      "cls loss 177.34005737304688  loc loss 10.217978477478027\n",
      "cls loss 230.8313446044922  loc loss 12.183015823364258\n",
      "cls loss 457.33197021484375  loc loss 31.78515625\n",
      "cls loss 191.2032470703125  loc loss 13.299565315246582\n",
      "cls loss 408.2775573730469  loc loss 33.113929748535156\n",
      "cls loss 602.4874877929688  loc loss 52.7767219543457\n",
      "cls loss 391.641845703125  loc loss 31.3729248046875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([42., 42.,  1.,  1.,  1.,  1.,  1.,  1.,  1., 42., 42.])\n",
      "cls loss 405.7192077636719  loc loss 28.08681869506836\n",
      "cls loss 518.0400390625  loc loss 44.08919143676758\n",
      "cls loss 479.69232177734375  loc loss 33.89180374145508\n",
      "cls loss 304.26580810546875  loc loss 17.624128341674805\n",
      "cls loss 392.88470458984375  loc loss 19.99058723449707\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 612.2716064453125  loc loss 36.43641662597656\n",
      "cls loss 486.8033447265625  loc loss 36.24492263793945\n",
      "cls loss 286.4431457519531  loc loss 15.254785537719727\n",
      "cls loss 244.29696655273438  loc loss 15.934246063232422\n",
      "cls loss 326.32330322265625  loc loss 21.880584716796875\n",
      "cls loss 433.2813720703125  loc loss 32.95807647705078\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15.])\n",
      "cls loss 211.8597412109375  loc loss 10.283731460571289\n",
      "cls loss 369.2047119140625  loc loss 23.313325881958008\n",
      "cls loss 331.1470947265625  loc loss 23.41053581237793\n",
      "cls loss 594.534423828125  loc loss 38.063472747802734\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19.,  7.])\n",
      "cls loss 267.1171875  loc loss 15.15162467956543\n",
      "cls loss 526.2255859375  loc loss 39.06031036376953\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 475.59307861328125  loc loss 26.91757583618164\n",
      "cls loss 467.5863952636719  loc loss 31.660945892333984\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([38., 38.,  1., 18.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1., 18., 18.,  1.])\n",
      "cls loss 311.9199523925781  loc loss 18.028614044189453\n",
      "cls loss 300.455322265625  loc loss 16.059072494506836\n",
      "cls loss 592.2960205078125  loc loss 45.38261795043945\n",
      "cls loss 425.3927001953125  loc loss 27.673479080200195\n",
      "cls loss 353.78143310546875  loc loss 23.714345932006836\n",
      "cls loss 251.70164489746094  loc loss 17.567211151123047\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.])\n",
      "cls loss 139.82876586914062  loc loss 7.202486991882324\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([32.])\n",
      "cls loss 379.1426696777344  loc loss 20.74089813232422\n",
      "cls loss 340.97137451171875  loc loss 22.194067001342773\n",
      "cls loss 425.4223937988281  loc loss 33.07919692993164\n",
      "cls loss 365.59014892578125  loc loss 25.000551223754883\n",
      "cls loss 317.50323486328125  loc loss 17.792932510375977\n",
      "cls loss 508.0415344238281  loc loss 27.277873992919922\n",
      "cls loss 608.5694580078125  loc loss 35.55319595336914\n",
      "cls loss 432.27984619140625  loc loss 27.26592254638672\n",
      "cls loss 328.38165283203125  loc loss 22.171443939208984\n",
      "cls loss 530.6583251953125  loc loss 42.6334228515625\n",
      "cls loss 350.36700439453125  loc loss 20.732868194580078\n",
      "cls loss 632.2740478515625  loc loss 47.260528564453125\n",
      "cls loss 417.6873779296875  loc loss 26.070314407348633\n",
      "cls loss 333.2576904296875  loc loss 26.278928756713867\n",
      "cls loss 247.46261596679688  loc loss 14.597280502319336\n",
      "cls loss 307.3685302734375  loc loss 18.66618537902832\n",
      "cls loss 430.2044372558594  loc loss 32.54536437988281\n",
      "cls loss 495.6768798828125  loc loss 38.20262908935547\n",
      "cls loss 309.6916809082031  loc loss 20.315000534057617\n",
      "cls loss 480.1323547363281  loc loss 38.223541259765625\n",
      "cls loss 585.4127807617188  loc loss 41.879150390625\n",
      "cls loss 209.65843200683594  loc loss 14.442303657531738\n",
      "cls loss 573.3919677734375  loc loss 42.71025466918945\n",
      "cls loss 426.74615478515625  loc loss 33.10384750366211\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 558.36279296875  loc loss 46.371185302734375\n",
      "cls loss 225.78195190429688  loc loss 11.471776962280273\n",
      "cls loss 354.5375061035156  loc loss 23.991615295410156\n",
      "cls loss 356.19189453125  loc loss 26.45277214050293\n",
      "cls loss 306.5550537109375  loc loss 22.35283660888672\n",
      "cls loss 174.62640380859375  loc loss 14.16550064086914\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 9., 9., 1., 9., 9., 9., 9., 1., 9.])\n",
      "cls loss 798.4989013671875  loc loss 72.68916320800781\n",
      "cls loss 432.61993408203125  loc loss 24.585912704467773\n",
      "cls loss 673.50927734375  loc loss 51.744407653808594\n",
      "cls loss 258.96148681640625  loc loss 19.507226943969727\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 42., 42.])\n",
      "cls loss 430.51812744140625  loc loss 30.84926414489746\n",
      "cls loss 441.9360046386719  loc loss 34.389408111572266\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  2.,  1.,  1.,  1., 38.,\n",
      "         1.,  1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 38., 38., 38.,  1., 38., 38., 38.,  1.,  1., 38.,  1.,\n",
      "         1.])\n",
      "cls loss 271.87640380859375  loc loss 26.027103424072266\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  8.,  8.])\n",
      "cls loss 626.796630859375  loc loss 56.22914505004883\n",
      "cls loss 654.7969360351562  loc loss 67.96656036376953\n",
      "cls loss 227.05628967285156  loc loss 21.0670108795166\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([4., 1., 1., 4.])\n",
      "cls loss 369.48065185546875  loc loss 29.175203323364258\n",
      "cls loss 468.8096923828125  loc loss 33.65346145629883\n",
      "cls loss 185.041748046875  loc loss 11.071124076843262\n",
      "cls loss 231.63180541992188  loc loss 19.340801239013672\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([51.,  1.])\n",
      "cls loss 164.49781799316406  loc loss 7.951986789703369\n",
      "cls loss 240.4769287109375  loc loss 15.075157165527344\n",
      "cls loss 500.71612548828125  loc loss 25.059566497802734\n",
      "cls loss 460.928466796875  loc loss 37.00278091430664\n",
      "cls loss 719.712158203125  loc loss 37.46491241455078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 847.4664916992188  loc loss 57.009883880615234\n",
      "cls loss 350.0406494140625  loc loss 26.912010192871094\n",
      "cls loss 528.45458984375  loc loss 42.872100830078125\n",
      "cls loss 563.3072509765625  loc loss 41.7010498046875\n",
      "cls loss 411.2430419921875  loc loss 25.59324073791504\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  3.,  1.,  1.,  1.,  3.,  1.,  1.,\n",
      "         1.,  1.,  1.])\n",
      "cls loss 443.35430908203125  loc loss 22.11170196533203\n",
      "cls loss 457.0769958496094  loc loss 29.78080940246582\n",
      "cls loss 468.45867919921875  loc loss 25.15927505493164\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "cls loss 392.4769287109375  loc loss 26.68217658996582\n",
      "cls loss 219.8531494140625  loc loss 18.38368797302246\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3.])\n",
      "cls loss 169.43405151367188  loc loss 10.547094345092773\n",
      "cls loss 302.6826477050781  loc loss 23.738325119018555\n",
      "cls loss 290.2654724121094  loc loss 19.485631942749023\n",
      "cls loss 529.0635986328125  loc loss 34.98015594482422\n",
      "cls loss 231.58773803710938  loc loss 18.070911407470703\n",
      "cls loss 275.45001220703125  loc loss 22.610675811767578\n",
      "cls loss 786.9024658203125  loc loss 54.671199798583984\n",
      "cls loss 362.4818115234375  loc loss 27.04547119140625\n",
      "cls loss 267.60198974609375  loc loss 20.969358444213867\n",
      "cls loss 316.7477111816406  loc loss 20.88220977783203\n",
      "cls loss 291.34710693359375  loc loss 25.658777236938477\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 534.8019409179688  loc loss 41.62324142456055\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  9., 64., 64., 64., 64., 64., 64., 64., 64., 64.,  9.,  9.,  9.,\n",
      "         9.])\n",
      "cls loss 241.66165161132812  loc loss 16.24652099609375\n",
      "cls loss 786.6923828125  loc loss 62.10108947753906\n",
      "cls loss 416.57769775390625  loc loss 26.849660873413086\n",
      "cls loss 476.6025695800781  loc loss 32.71828079223633\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.,  3.,  3.])\n",
      "cls loss 306.16522216796875  loc loss 19.16318130493164\n",
      "cls loss 325.884033203125  loc loss 22.281015396118164\n",
      "cls loss 348.2532958984375  loc loss 26.007062911987305\n",
      "cls loss 349.677978515625  loc loss 24.851974487304688\n",
      "cls loss 407.7170104980469  loc loss 30.67337417602539\n",
      "cls loss 419.82574462890625  loc loss 30.458900451660156\n",
      "cls loss 375.47662353515625  loc loss 28.641855239868164\n",
      "cls loss 377.6373596191406  loc loss 23.349641799926758\n",
      "cls loss 470.4028015136719  loc loss 35.41179656982422\n",
      "cls loss 345.34954833984375  loc loss 23.055086135864258\n",
      "cls loss 258.0040283203125  loc loss 14.301275253295898\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21.])\n",
      "cls loss 212.40548706054688  loc loss 13.144511222839355\n",
      "cls loss 305.3745422363281  loc loss 27.295631408691406\n",
      "cls loss 463.9842529296875  loc loss 32.86166000366211\n",
      "cls loss 236.17636108398438  loc loss 13.376254081726074\n",
      "cls loss 375.21417236328125  loc loss 27.272953033447266\n",
      "cls loss 679.5252075195312  loc loss 37.35854721069336\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 42., 42.,  1.,  1.])\n",
      "cls loss 412.81982421875  loc loss 22.618450164794922\n",
      "cls loss 265.2409362792969  loc loss 17.574506759643555\n",
      "cls loss 371.78924560546875  loc loss 24.718456268310547\n",
      "cls loss 508.3337707519531  loc loss 40.58226013183594\n",
      "cls loss 318.32061767578125  loc loss 19.05523681640625\n",
      "cls loss 495.59259033203125  loc loss 33.943565368652344\n",
      "cls loss 432.00323486328125  loc loss 29.550512313842773\n",
      "cls loss 423.1185302734375  loc loss 27.341508865356445\n",
      "cls loss 344.7943115234375  loc loss 21.354631423950195\n",
      "cls loss 272.8190612792969  loc loss 18.406126022338867\n",
      "cls loss 214.03094482421875  loc loss 11.360896110534668\n",
      "cls loss 346.09649658203125  loc loss 23.359312057495117\n",
      "cls loss 539.0996704101562  loc loss 36.49631881713867\n",
      "cls loss 378.83319091796875  loc loss 23.90973663330078\n",
      "cls loss 370.55462646484375  loc loss 32.90718460083008\n",
      "cls loss 401.48101806640625  loc loss 27.5864315032959\n",
      "cls loss 594.2879638671875  loc loss 45.48297119140625\n",
      "cls loss 480.28192138671875  loc loss 30.37070083618164\n",
      "cls loss 516.2225952148438  loc loss 27.66349220275879\n",
      "cls loss 322.8948974609375  loc loss 14.320671081542969\n",
      "cls loss 460.36376953125  loc loss 25.36043930053711\n",
      "cls loss 403.07049560546875  loc loss 23.398242950439453\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 5., 5., 5., 5., 5., 5.])\n",
      "cls loss 249.97064208984375  loc loss 13.945056915283203\n",
      "cls loss 319.58538818359375  loc loss 19.50815200805664\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([13.])\n",
      "cls loss 236.90090942382812  loc loss 11.100061416625977\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([44., 10.,  1.,  1.,  1.])\n",
      "cls loss 206.814697265625  loc loss 15.976747512817383\n",
      "cls loss 365.759521484375  loc loss 24.615859985351562\n",
      "cls loss 339.81494140625  loc loss 20.468494415283203\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19., 19., 19., 19., 19., 19., 19.])\n",
      "cls loss 357.554443359375  loc loss 25.52455711364746\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([56.])\n",
      "cls loss 774.2392578125  loc loss 53.98451232910156\n",
      "cls loss 493.16864013671875  loc loss 37.12720489501953\n",
      "cls loss 626.5880126953125  loc loss 39.346038818359375\n",
      "cls loss 596.5880126953125  loc loss 43.19520950317383\n",
      "cls loss 363.7462158203125  loc loss 21.274850845336914\n",
      "cls loss 617.258544921875  loc loss 39.98978042602539\n",
      "cls loss 350.4447021484375  loc loss 23.543188095092773\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 36.])\n",
      "cls loss 445.82305908203125  loc loss 23.25686264038086\n",
      "cls loss 371.01800537109375  loc loss 25.25005340576172\n",
      "cls loss 348.7485046386719  loc loss 23.368080139160156\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5.])\n",
      "cls loss 405.1568603515625  loc loss 26.4886531829834\n",
      "cls loss 222.77508544921875  loc loss 11.708523750305176\n",
      "cls loss 525.11328125  loc loss 32.23057556152344\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "cls loss 452.5696105957031  loc loss 28.893367767333984\n",
      "cls loss 433.12249755859375  loc loss 28.922380447387695\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 455.3226318359375  loc loss 28.09801483154297\n",
      "cls loss 527.4273071289062  loc loss 31.44950294494629\n",
      "cls loss 454.690673828125  loc loss 36.50962829589844\n",
      "cls loss 310.55224609375  loc loss 20.048694610595703\n",
      "cls loss 345.17486572265625  loc loss 26.14694595336914\n",
      "cls loss 356.14581298828125  loc loss 20.828584671020508\n",
      "cls loss 600.4271240234375  loc loss 30.032466888427734\n",
      "cls loss 237.8979034423828  loc loss 11.710013389587402\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 11., 15., 10., 10., 10., 10., 10.])\n",
      "cls loss 552.922119140625  loc loss 37.00669479370117\n",
      "cls loss 335.6181945800781  loc loss 24.081539154052734\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3.])\n",
      "cls loss 345.43780517578125  loc loss 24.347759246826172\n",
      "cls loss 328.12939453125  loc loss 15.682552337646484\n",
      "cls loss 353.26434326171875  loc loss 17.552709579467773\n",
      "cls loss 471.1380615234375  loc loss 19.452648162841797\n",
      "cls loss 201.2380828857422  loc loss 8.91680908203125\n",
      "cls loss 363.10430908203125  loc loss 23.231151580810547\n",
      "cls loss 435.3683166503906  loc loss 27.741653442382812\n",
      "cls loss 380.7214660644531  loc loss 23.60306739807129\n",
      "cls loss 891.2244873046875  loc loss 55.29450225830078\n",
      "cls loss 596.990478515625  loc loss 34.97590637207031\n",
      "cls loss 370.32598876953125  loc loss 25.299789428710938\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  9.,  9.,  9.,  6.,  6., 85., 85.,  8.,  1.,  1.,  1.,  1.,\n",
      "         6.,  6.])\n",
      "cls loss 243.90933227539062  loc loss 18.552574157714844\n",
      "cls loss 631.6148071289062  loc loss 40.91349411010742\n",
      "cls loss 737.7296142578125  loc loss 43.99116134643555\n",
      "cls loss 454.778564453125  loc loss 30.587865829467773\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10.,  3.,  3., 10.])\n",
      "cls loss 290.69097900390625  loc loss 16.54063606262207\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([7.])\n",
      "cls loss 383.45562744140625  loc loss 24.248929977416992\n",
      "cls loss 365.99859619140625  loc loss 23.767948150634766\n",
      "cls loss 391.0319519042969  loc loss 33.4964599609375\n",
      "cls loss 648.0318603515625  loc loss 43.93564224243164\n",
      "cls loss 355.6819152832031  loc loss 23.872798919677734\n",
      "cls loss 557.4666748046875  loc loss 34.9173698425293\n",
      "cls loss 689.7828369140625  loc loss 38.66709518432617\n",
      "cls loss 452.4931640625  loc loss 27.337644577026367\n",
      "cls loss 500.5820007324219  loc loss 31.612003326416016\n",
      "cls loss 378.80755615234375  loc loss 27.261451721191406\n",
      "cls loss 548.8270263671875  loc loss 40.34220886230469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 421.928466796875  loc loss 29.04159927368164\n",
      "cls loss 299.099365234375  loc loss 19.19565200805664\n",
      "cls loss 488.75439453125  loc loss 35.421966552734375\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([62.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([62.])\n",
      "cls loss 219.27685546875  loc loss 10.746013641357422\n",
      "cls loss 336.16583251953125  loc loss 26.330463409423828\n",
      "cls loss 349.09173583984375  loc loss 24.48928451538086\n",
      "cls loss 219.37704467773438  loc loss 12.417596817016602\n",
      "cls loss 477.7039489746094  loc loss 36.72984313964844\n",
      "cls loss 488.03973388671875  loc loss 29.661460876464844\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([28.])\n",
      "cls loss 615.1612548828125  loc loss 30.270742416381836\n",
      "cls loss 454.9732666015625  loc loss 30.47336196899414\n",
      "cls loss 456.3207702636719  loc loss 31.93867301940918\n",
      "cls loss 506.9610290527344  loc loss 29.081562042236328\n",
      "cls loss 746.4998168945312  loc loss 42.841434478759766\n",
      "cls loss 425.75238037109375  loc loss 23.583446502685547\n",
      "cls loss 566.3153686523438  loc loss 28.99651527404785\n",
      "cls loss 460.452392578125  loc loss 33.41947555541992\n",
      "cls loss 732.5670166015625  loc loss 59.71528625488281\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([81.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 431.2578125  loc loss 19.282779693603516\n",
      "cls loss 332.1715087890625  loc loss 17.67305564880371\n",
      "cls loss 240.17153930664062  loc loss 16.22515106201172\n",
      "cls loss 212.41854858398438  loc loss 10.01237678527832\n",
      "cls loss 241.60476684570312  loc loss 17.1319580078125\n",
      "cls loss 301.72607421875  loc loss 18.5390567779541\n",
      "cls loss 310.9473876953125  loc loss 21.826738357543945\n",
      "cls loss 458.64923095703125  loc loss 37.166534423828125\n",
      "cls loss 559.6406860351562  loc loss 32.88678741455078\n",
      "cls loss 945.220703125  loc loss 65.66850280761719\n",
      "cls loss 373.09124755859375  loc loss 19.37163734436035\n",
      "cls loss 492.6462097167969  loc loss 35.227474212646484\n",
      "cls loss 334.2394104003906  loc loss 22.9422550201416\n",
      "cls loss 432.60638427734375  loc loss 23.48906707763672\n",
      "cls loss 395.91778564453125  loc loss 23.21042251586914\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([44., 44.])\n",
      "cls loss 352.83538818359375  loc loss 18.187028884887695\n",
      "cls loss 401.061279296875  loc loss 23.17799186706543\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15.])\n",
      "cls loss 365.2915344238281  loc loss 20.998905181884766\n",
      "cls loss 226.68572998046875  loc loss 11.522387504577637\n",
      "cls loss 389.82098388671875  loc loss 23.626405715942383\n",
      "cls loss 232.3200225830078  loc loss 11.924857139587402\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([1., 3., 3.])\n",
      "cls loss 264.0247802734375  loc loss 16.060327529907227\n",
      "cls loss 183.04200744628906  loc loss 13.141023635864258\n",
      "cls loss 346.29144287109375  loc loss 29.712635040283203\n",
      "cls loss 418.64813232421875  loc loss 26.421064376831055\n",
      "cls loss 352.187255859375  loc loss 25.194835662841797\n",
      "cls loss 301.4978942871094  loc loss 22.454378128051758\n",
      "cls loss 329.17047119140625  loc loss 23.869186401367188\n",
      "cls loss 448.31591796875  loc loss 27.250120162963867\n",
      "cls loss 293.30938720703125  loc loss 19.591936111450195\n",
      "cls loss 388.23895263671875  loc loss 30.614578247070312\n",
      "cls loss 280.9928283691406  loc loss 17.800533294677734\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 514.0565185546875  loc loss 29.28213119506836\n",
      "cls loss 608.60546875  loc loss 29.519323348999023\n",
      "cls loss 522.7378540039062  loc loss 39.17755126953125\n",
      "cls loss 519.2941284179688  loc loss 45.23122787475586\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10., 10., 10.,  1.,  1.,  1.,  1.,  1.,  1.,  8.,  8.,\n",
      "         1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10., 10., 10.,  1.,  1.,  1.,  1.,  1.,  1.,  8.,  8.,\n",
      "         1.])\n",
      "cls loss 409.5371398925781  loc loss 26.412334442138672\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 3., 3., 3.])\n",
      "cls loss 409.1773681640625  loc loss 25.89898681640625\n",
      "cls loss 254.24671936035156  loc loss 16.78351402282715\n",
      "cls loss 196.6651611328125  loc loss 10.330952644348145\n",
      "cls loss 389.0673828125  loc loss 29.987056732177734\n",
      "cls loss 275.870361328125  loc loss 14.033270835876465\n",
      "cls loss 353.4290771484375  loc loss 23.240476608276367\n",
      "cls loss 396.5544738769531  loc loss 25.74175453186035\n",
      "cls loss 523.8278198242188  loc loss 39.445953369140625\n",
      "cls loss 457.68792724609375  loc loss 25.530776977539062\n",
      "cls loss 410.9544372558594  loc loss 25.055278778076172\n",
      "cls loss 426.5486145019531  loc loss 34.48019027709961\n",
      "cls loss 304.16741943359375  loc loss 25.55133819580078\n",
      "cls loss 648.490966796875  loc loss 50.817378997802734\n",
      "cls loss 262.5689392089844  loc loss 14.992898941040039\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 509.2103271484375  loc loss 33.760677337646484\n",
      "cls loss 203.04891967773438  loc loss 10.086134910583496\n",
      "cls loss 538.7021484375  loc loss 42.54744338989258\n",
      "cls loss 271.760498046875  loc loss 17.218873977661133\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 34.])\n",
      "cls loss 458.424072265625  loc loss 26.985979080200195\n",
      "cls loss 247.09559631347656  loc loss 14.884696960449219\n",
      "cls loss 509.119384765625  loc loss 28.4437313079834\n",
      "cls loss 192.66937255859375  loc loss 12.762293815612793\n",
      "cls loss 378.74853515625  loc loss 25.644412994384766\n",
      "cls loss 384.2196044921875  loc loss 34.29487609863281\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 38.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 16., 16., 16.,  9.,  9.,  9., 16., 16., 16., 85.,  9.])\n",
      "cls loss 394.9041442871094  loc loss 29.54842758178711\n",
      "cls loss 426.6187744140625  loc loss 36.983760833740234\n",
      "cls loss 579.0964965820312  loc loss 48.59003829956055\n",
      "cls loss 891.7952880859375  loc loss 62.880008697509766\n",
      "cls loss 218.8427734375  loc loss 13.622373580932617\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3., 10.,  8.,  8., 10., 10., 10.,  3.,  3., 14.])\n",
      "cls loss 235.86758422851562  loc loss 16.109010696411133\n",
      "cls loss 438.9385681152344  loc loss 31.20698356628418\n",
      "cls loss 185.68118286132812  loc loss 8.886393547058105\n",
      "cls loss 322.2075500488281  loc loss 16.765655517578125\n",
      "cls loss 451.15887451171875  loc loss 33.070072174072266\n",
      "cls loss 373.0999450683594  loc loss 26.966609954833984\n",
      "cls loss 217.00823974609375  loc loss 13.429966926574707\n",
      "cls loss 287.0146179199219  loc loss 18.54947853088379\n",
      "cls loss 492.61993408203125  loc loss 36.26612091064453\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42., 42.,  1.])\n",
      "cls loss 444.9268798828125  loc loss 31.14834976196289\n",
      "cls loss 386.2929382324219  loc loss 27.163660049438477\n",
      "cls loss 497.28485107421875  loc loss 47.134037017822266\n",
      "cls loss 546.756591796875  loc loss 33.17772674560547\n",
      "cls loss 372.3962097167969  loc loss 23.698284149169922\n",
      "cls loss 439.23504638671875  loc loss 32.88841247558594\n",
      "cls loss 254.8887176513672  loc loss 18.229660034179688\n",
      "cls loss 279.56842041015625  loc loss 22.43239402770996\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20.])\n",
      "cls loss 206.7152099609375  loc loss 11.807035446166992\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([11.])\n",
      "cls loss 287.0577392578125  loc loss 14.030231475830078\n",
      "cls loss 165.84197998046875  loc loss 11.440766334533691\n",
      "cls loss 438.87969970703125  loc loss 34.0655632019043\n",
      "cls loss 182.11643981933594  loc loss 10.41598129272461\n",
      "cls loss 379.8143615722656  loc loss 28.51167869567871\n",
      "cls loss 213.452880859375  loc loss 14.540270805358887\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 35., 27.])\n",
      "cls loss 393.7225341796875  loc loss 24.161705017089844\n",
      "cls loss 459.49560546875  loc loss 37.01211929321289\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 301.57183837890625  loc loss 20.364131927490234\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([42.,  1.])\n",
      "cls loss 392.87060546875  loc loss 31.57284927368164\n",
      "cls loss 410.7734375  loc loss 22.285600662231445\n",
      "cls loss 481.1551818847656  loc loss 30.564598083496094\n",
      "cls loss 640.1166381835938  loc loss 30.93991470336914\n",
      "cls loss 505.01953125  loc loss 30.26287078857422\n",
      "cls loss 360.82611083984375  loc loss 22.741106033325195\n",
      "cls loss 286.3170471191406  loc loss 20.71086311340332\n",
      "cls loss 173.0987548828125  loc loss 7.662988662719727\n",
      "cls loss 302.9934387207031  loc loss 18.99093246459961\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 1., 1.])\n",
      "cls loss 301.33038330078125  loc loss 20.597761154174805\n",
      "cls loss 368.1334533691406  loc loss 30.3201904296875\n",
      "cls loss 355.00189208984375  loc loss 25.851211547851562\n",
      "cls loss 268.52984619140625  loc loss 22.689876556396484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 339.4810485839844  loc loss 26.917865753173828\n",
      "cls loss 354.3996276855469  loc loss 28.366039276123047\n",
      "cls loss 540.370361328125  loc loss 35.304866790771484\n",
      "cls loss 476.3368835449219  loc loss 36.70282745361328\n",
      "cls loss 407.58526611328125  loc loss 29.191574096679688\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 320.8038024902344  loc loss 27.16179847717285\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 462.5470275878906  loc loss 20.56656837463379\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([81.])\n",
      "cls loss 524.6934814453125  loc loss 38.396148681640625\n",
      "cls loss 303.5971984863281  loc loss 24.684354782104492\n",
      "cls loss 252.34494018554688  loc loss 15.114006996154785\n",
      "cls loss 333.7662658691406  loc loss 19.555557250976562\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3.,  1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 19.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 19.])\n",
      "cls loss 477.47393798828125  loc loss 34.68891525268555\n",
      "cls loss 248.9474639892578  loc loss 14.637054443359375\n",
      "cls loss 272.6706237792969  loc loss 15.14828872680664\n",
      "cls loss 518.7908935546875  loc loss 38.21206283569336\n",
      "cls loss 248.796630859375  loc loss 16.14130210876465\n",
      "cls loss 317.37677001953125  loc loss 20.929283142089844\n",
      "cls loss 409.34783935546875  loc loss 27.13609504699707\n",
      "cls loss 305.23040771484375  loc loss 25.904897689819336\n",
      "cls loss 414.0789489746094  loc loss 26.77411651611328\n",
      "cls loss 443.76416015625  loc loss 36.31782531738281\n",
      "cls loss 613.0242919921875  loc loss 60.91066360473633\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 81.])\n",
      "cls loss 395.58319091796875  loc loss 22.31199836730957\n",
      "cls loss 360.6147766113281  loc loss 21.511947631835938\n",
      "cls loss 364.456787109375  loc loss 19.625741958618164\n",
      "cls loss 305.0447082519531  loc loss 15.518964767456055\n",
      "cls loss 261.1108093261719  loc loss 15.559039115905762\n",
      "cls loss 331.08013916015625  loc loss 26.92168426513672\n",
      "cls loss 233.52151489257812  loc loss 18.579605102539062\n",
      "cls loss 211.24942016601562  loc loss 13.3921480178833\n",
      "cls loss 253.4263458251953  loc loss 19.38624382019043\n",
      "cls loss 353.102294921875  loc loss 25.592342376708984\n",
      "cls loss 334.9905700683594  loc loss 32.42403030395508\n",
      "cls loss 328.5181884765625  loc loss 24.167295455932617\n",
      "cls loss 197.2394256591797  loc loss 14.38177490234375\n",
      "cls loss 698.7699584960938  loc loss 44.470062255859375\n",
      "cls loss 377.460205078125  loc loss 26.478839874267578\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 334.18731689453125  loc loss 18.51373863220215\n",
      "cls loss 373.74951171875  loc loss 24.357194900512695\n",
      "cls loss 270.5457763671875  loc loss 19.2609806060791\n",
      "cls loss 445.8741455078125  loc loss 31.939851760864258\n",
      "cls loss 432.4024658203125  loc loss 29.012493133544922\n",
      "cls loss 393.92266845703125  loc loss 27.646595001220703\n",
      "cls loss 282.6321716308594  loc loss 21.053850173950195\n",
      "cls loss 263.9720458984375  loc loss 15.114086151123047\n",
      "cls loss 387.539306640625  loc loss 20.611352920532227\n",
      "cls loss 471.1900634765625  loc loss 29.54491424560547\n",
      "cls loss 398.8871154785156  loc loss 22.224929809570312\n",
      "cls loss 522.0391845703125  loc loss 32.24775695800781\n",
      "cls loss 588.5008544921875  loc loss 37.79080581665039\n",
      "cls loss 384.6451721191406  loc loss 23.911664962768555\n",
      "cls loss 556.7720947265625  loc loss 40.79806137084961\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1., 38., 47.,  1.,  1.,  1.,  1.,  1., 62.])\n",
      "cls loss 330.4825439453125  loc loss 17.50646209716797\n",
      "cls loss 400.3216857910156  loc loss 27.022138595581055\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 437.2921142578125  loc loss 26.09536361694336\n",
      "cls loss 504.03546142578125  loc loss 37.97185516357422\n",
      "cls loss 323.4032287597656  loc loss 15.650762557983398\n",
      "cls loss 386.63250732421875  loc loss 32.51383972167969\n",
      "cls loss 380.642578125  loc loss 23.795516967773438\n",
      "cls loss 206.25123596191406  loc loss 8.375974655151367\n",
      "cls loss 325.35040283203125  loc loss 20.19721031188965\n",
      "cls loss 288.422607421875  loc loss 13.876256942749023\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1., 35.])\n",
      "cls loss 315.62493896484375  loc loss 18.1943416595459\n",
      "cls loss 475.21197509765625  loc loss 25.915748596191406\n",
      "cls loss 494.3981018066406  loc loss 29.163366317749023\n",
      "cls loss 429.2644348144531  loc loss 34.83734130859375\n",
      "cls loss 369.8328552246094  loc loss 26.292991638183594\n",
      "cls loss 477.6397705078125  loc loss 36.17746353149414\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 259.38043212890625  loc loss 12.520008087158203\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 364.03668212890625  loc loss 15.695295333862305\n",
      "cls loss 549.44677734375  loc loss 32.992618560791016\n",
      "cls loss 709.3571166992188  loc loss 54.042945861816406\n",
      "cls loss 338.1649169921875  loc loss 19.1658935546875\n",
      "cls loss 297.5869445800781  loc loss 18.41317367553711\n",
      "cls loss 310.1395263671875  loc loss 16.247203826904297\n",
      "cls loss 355.0264892578125  loc loss 21.17652130126953\n",
      "cls loss 301.3536376953125  loc loss 12.638938903808594\n",
      "cls loss 563.7774658203125  loc loss 36.877559661865234\n",
      "cls loss 460.9958190917969  loc loss 27.77675437927246\n",
      "cls loss 199.829345703125  loc loss 15.088705062866211\n",
      "cls loss 411.1279602050781  loc loss 22.69746971130371\n",
      "cls loss 578.631103515625  loc loss 40.90525436401367\n",
      "cls loss 418.2950134277344  loc loss 28.766632080078125\n",
      "cls loss 379.70013427734375  loc loss 23.601823806762695\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.])\n",
      "cls loss 359.5255432128906  loc loss 28.172643661499023\n",
      "cls loss 367.6773681640625  loc loss 24.191701889038086\n",
      "cls loss 432.4663391113281  loc loss 26.570953369140625\n",
      "cls loss 736.82177734375  loc loss 54.67582321166992\n",
      "cls loss 260.2704772949219  loc loss 13.562186241149902\n",
      "cls loss 347.6466064453125  loc loss 20.187822341918945\n",
      "cls loss 268.2730407714844  loc loss 15.529927253723145\n",
      "cls loss 313.1041259765625  loc loss 23.236848831176758\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 21., 21., 21.])\n",
      "cls loss 295.3707580566406  loc loss 19.752052307128906\n",
      "cls loss 326.3743896484375  loc loss 20.329313278198242\n",
      "cls loss 321.1539306640625  loc loss 22.4965877532959\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 35.])\n",
      "cls loss 438.14111328125  loc loss 32.61497497558594\n",
      "cls loss 159.3121795654297  loc loss 10.927217483520508\n",
      "cls loss 303.2093505859375  loc loss 20.067142486572266\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 283.5799560546875  loc loss 13.784579277038574\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 38., 38.,  9., 38.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1.,  1.])\n",
      "cls loss 308.09521484375  loc loss 18.788129806518555\n",
      "cls loss 512.9862670898438  loc loss 29.355411529541016\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 2.,  1., 77., 31., 10., 10.,  1.,  4., 10.])\n",
      "cls loss 229.49935913085938  loc loss 9.749571800231934\n",
      "cls loss 473.33612060546875  loc loss 27.56644630432129\n",
      "cls loss 931.1033935546875  loc loss 52.67353820800781\n",
      "cls loss 296.46173095703125  loc loss 20.862598419189453\n",
      "cls loss 402.9285888671875  loc loss 29.404260635375977\n",
      "cls loss 261.449462890625  loc loss 16.560344696044922\n",
      "cls loss 259.2396240234375  loc loss 15.65506649017334\n",
      "cls loss 364.0791320800781  loc loss 23.57876205444336\n",
      "cls loss 354.47857666015625  loc loss 26.566673278808594\n",
      "cls loss 342.09893798828125  loc loss 26.59898567199707\n",
      "cls loss 296.094970703125  loc loss 14.674705505371094\n",
      "cls loss 307.33087158203125  loc loss 17.514423370361328\n",
      "cls loss 596.982177734375  loc loss 37.556175231933594\n",
      "cls loss 556.402099609375  loc loss 31.141666412353516\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1., 42., 42., 42., 42., 42., 42.,  1.,\n",
      "         1.,  1.,  1., 42.,  1.,  1., 42.,  1.])\n",
      "cls loss 312.04229736328125  loc loss 21.02313995361328\n",
      "cls loss 477.72412109375  loc loss 24.954519271850586\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.])\n",
      "cls loss 198.55453491210938  loc loss 10.704594612121582\n",
      "cls loss 474.4398193359375  loc loss 27.146150588989258\n",
      "cls loss 350.2442626953125  loc loss 28.0262508392334\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([11.])\n",
      "cls loss 201.77549743652344  loc loss 16.319908142089844\n",
      "cls loss 230.247314453125  loc loss 15.597583770751953\n",
      "cls loss 239.75372314453125  loc loss 17.860702514648438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 437.208740234375  loc loss 26.977680206298828\n",
      "cls loss 341.3616943359375  loc loss 22.330524444580078\n",
      "cls loss 370.8306884765625  loc loss 25.091350555419922\n",
      "cls loss 520.169921875  loc loss 28.601573944091797\n",
      "cls loss 278.4206237792969  loc loss 17.555606842041016\n",
      "cls loss 617.8727416992188  loc loss 39.29865646362305\n",
      "cls loss 296.99835205078125  loc loss 18.792104721069336\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.])\n",
      "cls loss 279.3470458984375  loc loss 19.438058853149414\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1., 38., 38., 42.])\n",
      "cls loss 386.76739501953125  loc loss 30.68844223022461\n",
      "cls loss 346.21221923828125  loc loss 21.751707077026367\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 306.859130859375  loc loss 19.79714012145996\n",
      "cls loss 652.6036376953125  loc loss 48.052772521972656\n",
      "cls loss 382.31689453125  loc loss 23.572961807250977\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3., 10.,  3.,  3.,  6.,  8.,  8.,  1.,  1.,  1., 10.])\n",
      "cls loss 283.8438720703125  loc loss 15.535537719726562\n",
      "cls loss 198.6253662109375  loc loss 6.921202659606934\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10.,  3.])\n",
      "cls loss 269.6620788574219  loc loss 18.33005714416504\n",
      "cls loss 131.5487823486328  loc loss 8.312479019165039\n",
      "cls loss 353.7797546386719  loc loss 27.692626953125\n",
      "cls loss 420.12542724609375  loc loss 31.557472229003906\n",
      "cls loss 312.89080810546875  loc loss 21.25330924987793\n",
      "cls loss 166.99473571777344  loc loss 16.082416534423828\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 34.])\n",
      "cls loss 467.16668701171875  loc loss 35.12362289428711\n",
      "cls loss 630.656005859375  loc loss 47.49127960205078\n",
      "cls loss 390.18975830078125  loc loss 32.87401580810547\n",
      "cls loss 309.9916076660156  loc loss 21.079792022705078\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.,  1.])\n",
      "cls loss 345.17840576171875  loc loss 15.442344665527344\n",
      "cls loss 579.3076171875  loc loss 41.114253997802734\n",
      "cls loss 810.017333984375  loc loss 52.43832778930664\n",
      "cls loss 638.4351806640625  loc loss 37.484161376953125\n",
      "cls loss 358.0021667480469  loc loss 23.365554809570312\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 367.0227355957031  loc loss 24.980636596679688\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10.])\n",
      "cls loss 246.3485107421875  loc loss 13.268745422363281\n",
      "cls loss 368.544189453125  loc loss 22.231887817382812\n",
      "cls loss 349.7791748046875  loc loss 23.351455688476562\n",
      "cls loss 221.6407012939453  loc loss 14.793657302856445\n",
      "cls loss 315.57012939453125  loc loss 22.778045654296875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21.,\n",
      "        21.])\n",
      "cls loss 371.02703857421875  loc loss 28.414384841918945\n",
      "cls loss 330.483154296875  loc loss 22.444904327392578\n",
      "cls loss 223.72988891601562  loc loss 12.944600105285645\n",
      "cls loss 508.95416259765625  loc loss 36.8848991394043\n",
      "cls loss 367.6463623046875  loc loss 26.29483413696289\n",
      "cls loss 276.29779052734375  loc loss 14.962662696838379\n",
      "cls loss 592.1721801757812  loc loss 43.020751953125\n",
      "cls loss 671.7120361328125  loc loss 52.75847244262695\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15., 85.])\n",
      "cls loss 460.4720458984375  loc loss 26.94146156311035\n",
      "cls loss 456.97137451171875  loc loss 35.32479476928711\n",
      "cls loss 449.79779052734375  loc loss 30.03685760498047\n",
      "cls loss 342.4873352050781  loc loss 25.311744689941406\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 8., 8.])\n",
      "cls loss 266.91290283203125  loc loss 12.767569541931152\n",
      "cls loss 250.56187438964844  loc loss 22.34051513671875\n",
      "cls loss 322.9890441894531  loc loss 23.57256507873535\n",
      "cls loss 281.2559814453125  loc loss 18.100296020507812\n",
      "cls loss 303.5168762207031  loc loss 23.789165496826172\n",
      "cls loss 459.0146179199219  loc loss 33.422264099121094\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1., 35., 27., 27.,  1., 27.,  1.])\n",
      "cls loss 484.6727600097656  loc loss 58.756813049316406\n",
      "cls loss 305.5122375488281  loc loss 24.616872787475586\n",
      "cls loss 309.96771240234375  loc loss 29.17525863647461\n",
      "cls loss 323.61834716796875  loc loss 28.363929748535156\n",
      "cls loss 289.04656982421875  loc loss 23.899198532104492\n",
      "cls loss 336.32830810546875  loc loss 25.50183868408203\n",
      "cls loss 330.884521484375  loc loss 25.893041610717773\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  2.,  2.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  2.,  2.])\n",
      "cls loss 158.78921508789062  loc loss 8.246883392333984\n",
      "cls loss 529.308837890625  loc loss 37.07075881958008\n",
      "cls loss 318.6260681152344  loc loss 21.67708396911621\n",
      "cls loss 573.2657470703125  loc loss 49.549774169921875\n",
      "cls loss 217.01846313476562  loc loss 18.271238327026367\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16., 16., 16., 19., 19., 19., 16.])\n",
      "cls loss 219.96490478515625  loc loss 12.106355667114258\n",
      "cls loss 196.4052276611328  loc loss 8.133148193359375\n",
      "cls loss 317.16693115234375  loc loss 16.183637619018555\n",
      "cls loss 419.05938720703125  loc loss 28.91786003112793\n",
      "cls loss 160.376220703125  loc loss 17.049121856689453\n",
      "cls loss 446.73480224609375  loc loss 36.38813400268555\n",
      "cls loss 331.30718994140625  loc loss 24.146991729736328\n",
      "cls loss 347.26129150390625  loc loss 25.3065185546875\n",
      "cls loss 456.24261474609375  loc loss 30.427186965942383\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 434.72149658203125  loc loss 19.961196899414062\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 643.05810546875  loc loss 55.2036018371582\n",
      "cls loss 834.3321533203125  loc loss 75.35491943359375\n",
      "cls loss 381.7975769042969  loc loss 24.839271545410156\n",
      "cls loss 374.00616455078125  loc loss 23.219629287719727\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3.,  3.,  3.,  3.,  3., 10.])\n",
      "cls loss 176.46835327148438  loc loss 10.559370040893555\n",
      "cls loss 402.13629150390625  loc loss 19.965055465698242\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 1., 1., 1., 3., 3., 3., 3.])\n",
      "cls loss 332.1855773925781  loc loss 15.741280555725098\n",
      "cls loss 623.808349609375  loc loss 40.85411071777344\n",
      "cls loss 524.09521484375  loc loss 29.479202270507812\n",
      "cls loss 323.6422424316406  loc loss 16.216468811035156\n",
      "cls loss 501.08343505859375  loc loss 36.00431823730469\n",
      "cls loss 289.2349853515625  loc loss 20.028783798217773\n",
      "cls loss 478.9061584472656  loc loss 31.687850952148438\n",
      "cls loss 364.6097717285156  loc loss 32.03739929199219\n",
      "cls loss 319.939453125  loc loss 22.60425567626953\n",
      "cls loss 743.4658813476562  loc loss 61.60420227050781\n",
      "cls loss 472.8917236328125  loc loss 36.538352966308594\n",
      "cls loss 304.74908447265625  loc loss 15.20545482635498\n",
      "cls loss 177.39720153808594  loc loss 9.253951072692871\n",
      "cls loss 235.1408233642578  loc loss 11.12278938293457\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3., 10., 10., 10., 10., 10., 10., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10., 10., 10., 10., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 11., 10., 10., 10., 10., 10.,  3.,  3.,  3.,  3.,  3.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 11., 10., 10., 10., 10., 10.,  3.,  3.,  3.,  3.,  3.])\n",
      "cls loss 177.7615966796875  loc loss 9.029959678649902\n",
      "cls loss 254.40919494628906  loc loss 11.152203559875488\n",
      "cls loss 239.55682373046875  loc loss 12.601339340209961\n",
      "cls loss 218.66494750976562  loc loss 10.417784690856934\n",
      "cls loss 302.5307312011719  loc loss 25.142772674560547\n",
      "cls loss 213.36526489257812  loc loss 9.866856575012207\n",
      "cls loss 469.45892333984375  loc loss 29.637052536010742\n",
      "cls loss 440.7960205078125  loc loss 26.214466094970703\n",
      "cls loss 615.7181396484375  loc loss 39.46670150756836\n",
      "cls loss 318.1081237792969  loc loss 21.315046310424805\n",
      "cls loss 537.4412841796875  loc loss 31.54796028137207\n",
      "cls loss 401.5489501953125  loc loss 27.548263549804688\n",
      "cls loss 414.4419860839844  loc loss 25.505558013916016\n",
      "cls loss 392.09368896484375  loc loss 27.437580108642578\n",
      "cls loss 504.8140869140625  loc loss 36.93354415893555\n",
      "cls loss 479.3607177734375  loc loss 34.1523323059082\n",
      "cls loss 229.0292510986328  loc loss 14.659382820129395\n",
      "cls loss 500.2899475097656  loc loss 36.70106887817383\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 10.,  1., 18.])\n",
      "cls loss 203.79513549804688  loc loss 17.446733474731445\n",
      "cls loss 237.34446716308594  loc loss 12.978455543518066\n",
      "cls loss 437.34423828125  loc loss 25.31232452392578\n",
      "cls loss 638.4964599609375  loc loss 40.33876037597656\n",
      "cls loss 374.0932312011719  loc loss 24.93207359313965\n",
      "cls loss 585.8536987304688  loc loss 28.186674118041992\n",
      "cls loss 467.17742919921875  loc loss 25.900972366333008\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.,  1.,  1.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 522.769775390625  loc loss 28.7148380279541\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1., 38.,  1.])\n",
      "cls loss 428.843994140625  loc loss 25.245540618896484\n",
      "cls loss 628.1866455078125  loc loss 49.543758392333984\n",
      "cls loss 343.61004638671875  loc loss 25.88051414489746\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 452.68316650390625  loc loss 29.849735260009766\n",
      "cls loss 367.4173889160156  loc loss 27.949718475341797\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3., 10.,  8.,  3., 10., 10., 10.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.])\n",
      "cls loss 406.1490478515625  loc loss 30.285470962524414\n",
      "cls loss 271.0298767089844  loc loss 19.170629501342773\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 3.,  3.,  3.,  3., 11.,  3., 10., 10.,  3.,  3., 10.])\n",
      "cls loss 256.6953125  loc loss 20.025102615356445\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10.,  3., 10., 10., 10.])\n",
      "cls loss 338.64813232421875  loc loss 18.45970916748047\n",
      "cls loss 262.673583984375  loc loss 16.92874526977539\n",
      "cls loss 358.9633483886719  loc loss 25.32815170288086\n",
      "cls loss 525.385986328125  loc loss 31.94976043701172\n",
      "cls loss 347.5663146972656  loc loss 22.202749252319336\n",
      "cls loss 276.9140625  loc loss 21.028783798217773\n",
      "cls loss 355.26324462890625  loc loss 22.052194595336914\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 9.,  9., 85., 85.])\n",
      "cls loss 298.57501220703125  loc loss 16.805212020874023\n",
      "cls loss 390.53167724609375  loc loss 28.80554962158203\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "cls loss 568.4983520507812  loc loss 44.414634704589844\n",
      "cls loss 468.8637390136719  loc loss 25.646955490112305\n",
      "cls loss 542.0194091796875  loc loss 40.465721130371094\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 10., 10., 10., 10., 10., 10.])\n",
      "cls loss 352.48846435546875  loc loss 23.08718490600586\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([13.])\n",
      "cls loss 550.8177490234375  loc loss 40.50315475463867\n",
      "cls loss 145.891357421875  loc loss 8.823662757873535\n",
      "cls loss 223.06723022460938  loc loss 10.84669303894043\n",
      "cls loss 286.36785888671875  loc loss 19.912811279296875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19.,  1.,  1.,  1., 19., 19.])\n",
      "cls loss 319.6849365234375  loc loss 21.186119079589844\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 256.73919677734375  loc loss 21.103309631347656\n",
      "cls loss 387.6483154296875  loc loss 35.963993072509766\n",
      "cls loss 295.42901611328125  loc loss 18.830974578857422\n",
      "cls loss 418.2451477050781  loc loss 28.558055877685547\n",
      "cls loss 452.9517822265625  loc loss 38.278594970703125\n",
      "cls loss 342.29852294921875  loc loss 23.18999481201172\n",
      "cls loss 553.4609375  loc loss 40.78692626953125\n",
      "cls loss 190.74623107910156  loc loss 8.50452995300293\n",
      "cls loss 356.5362548828125  loc loss 22.68047332763672\n",
      "cls loss 301.8890380859375  loc loss 15.388420104980469\n",
      "cls loss 332.75408935546875  loc loss 16.05019760131836\n",
      "cls loss 448.37139892578125  loc loss 25.748519897460938\n",
      "cls loss 342.7197265625  loc loss 16.509429931640625\n",
      "cls loss 507.30828857421875  loc loss 34.972251892089844\n",
      "cls loss 327.566650390625  loc loss 21.20380973815918\n",
      "cls loss 425.7115478515625  loc loss 32.6368408203125\n",
      "cls loss 615.8983154296875  loc loss 40.4171028137207\n",
      "cls loss 334.62481689453125  loc loss 26.628704071044922\n",
      "cls loss 404.03985595703125  loc loss 24.425922393798828\n",
      "cls loss 487.5931701660156  loc loss 39.808502197265625\n",
      "cls loss 574.2496337890625  loc loss 37.48434829711914\n",
      "cls loss 605.7950439453125  loc loss 33.89153289794922\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 5.])\n",
      "cls loss 139.40597534179688  loc loss 7.024211883544922\n",
      "cls loss 223.23402404785156  loc loss 9.278517723083496\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([10., 13.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3., 3., 3., 6., 8., 8.])\n",
      "cls loss 176.35513305664062  loc loss 10.136102676391602\n",
      "cls loss 229.23464965820312  loc loss 11.240588188171387\n",
      "cls loss 453.00482177734375  loc loss 30.447885513305664\n",
      "cls loss 189.6497344970703  loc loss 12.087732315063477\n",
      "cls loss 405.5116882324219  loc loss 29.70147705078125\n",
      "cls loss 599.9837036132812  loc loss 46.142601013183594\n",
      "cls loss 389.44757080078125  loc loss 28.668109893798828\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([42., 42.,  1.,  1.,  1.,  1.,  1.,  1.,  1., 42., 42.])\n",
      "cls loss 403.0086669921875  loc loss 24.701000213623047\n",
      "cls loss 513.7996826171875  loc loss 42.155818939208984\n",
      "cls loss 474.62738037109375  loc loss 33.18513488769531\n",
      "cls loss 301.2926025390625  loc loss 17.30440330505371\n",
      "cls loss 388.09771728515625  loc loss 19.191970825195312\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 607.3653564453125  loc loss 34.59709930419922\n",
      "cls loss 483.01348876953125  loc loss 32.31008529663086\n",
      "cls loss 283.9764404296875  loc loss 14.302023887634277\n",
      "cls loss 242.4188995361328  loc loss 14.66460132598877\n",
      "cls loss 324.83819580078125  loc loss 20.520544052124023\n",
      "cls loss 429.4416198730469  loc loss 30.151185989379883\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([15.])\n",
      "cls loss 210.68255615234375  loc loss 9.145891189575195\n",
      "cls loss 366.1622314453125  loc loss 21.73741340637207\n",
      "cls loss 328.8385925292969  loc loss 22.34759521484375\n",
      "cls loss 590.36376953125  loc loss 37.891624450683594\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([19.,  7.])\n",
      "cls loss 264.43701171875  loc loss 15.182208061218262\n",
      "cls loss 520.2611694335938  loc loss 38.378631591796875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1., 42.])\n",
      "cls loss 467.7650451660156  loc loss 28.321086883544922\n",
      "cls loss 463.7146301269531  loc loss 29.691993713378906\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([38., 38.,  1., 18.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1., 18., 18.,  1.])\n",
      "cls loss 309.7676696777344  loc loss 16.612703323364258\n",
      "cls loss 297.93707275390625  loc loss 14.504230499267578\n",
      "cls loss 586.6185302734375  loc loss 40.721614837646484\n",
      "cls loss 419.5973205566406  loc loss 28.193683624267578\n",
      "cls loss 351.0019226074219  loc loss 24.422718048095703\n",
      "cls loss 249.84976196289062  loc loss 18.1534481048584\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.])\n",
      "cls loss 137.72256469726562  loc loss 7.778048515319824\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([32.])\n",
      "cls loss 375.2165832519531  loc loss 23.26407241821289\n",
      "cls loss 338.83245849609375  loc loss 23.723491668701172\n",
      "cls loss 422.4490966796875  loc loss 32.9329719543457\n",
      "cls loss 362.82672119140625  loc loss 24.193984985351562\n",
      "cls loss 315.9850158691406  loc loss 17.81538963317871\n",
      "cls loss 504.40301513671875  loc loss 27.80792808532715\n",
      "cls loss 604.669189453125  loc loss 34.41242218017578\n",
      "cls loss 429.2874450683594  loc loss 25.51764488220215\n",
      "cls loss 326.0606689453125  loc loss 21.733783721923828\n",
      "cls loss 525.5450439453125  loc loss 40.23344421386719\n",
      "cls loss 346.78741455078125  loc loss 21.873584747314453\n",
      "cls loss 626.1466064453125  loc loss 47.013675689697266\n",
      "cls loss 412.4510498046875  loc loss 28.16054344177246\n",
      "cls loss 329.8393249511719  loc loss 27.403799057006836\n",
      "cls loss 243.16323852539062  loc loss 13.264700889587402\n",
      "cls loss 305.2453308105469  loc loss 19.048078536987305\n",
      "cls loss 426.522216796875  loc loss 31.116790771484375\n",
      "cls loss 492.5859680175781  loc loss 34.01508331298828\n",
      "cls loss 308.714599609375  loc loss 17.707538604736328\n",
      "cls loss 476.31353759765625  loc loss 32.00956726074219\n",
      "cls loss 581.625732421875  loc loss 37.820030212402344\n",
      "cls loss 207.85511779785156  loc loss 13.678505897521973\n",
      "cls loss 569.8451538085938  loc loss 39.72748565673828\n",
      "cls loss 423.52886962890625  loc loss 32.498046875\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 554.68359375  loc loss 48.5163688659668\n",
      "cls loss 222.4505615234375  loc loss 11.256402969360352\n",
      "cls loss 350.42095947265625  loc loss 24.15176773071289\n",
      "cls loss 351.91473388671875  loc loss 26.84444808959961\n",
      "cls loss 303.1566162109375  loc loss 18.49137306213379\n",
      "cls loss 172.89218139648438  loc loss 10.934800148010254\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([9., 9., 9., 1., 9., 9., 9., 9., 1., 9.])\n",
      "cls loss 791.2501831054688  loc loss 55.49488067626953\n",
      "cls loss 429.19244384765625  loc loss 21.188398361206055\n",
      "cls loss 668.550048828125  loc loss 48.369659423828125\n",
      "cls loss 256.6033935546875  loc loss 19.488676071166992\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 42., 42.])\n",
      "cls loss 426.5843200683594  loc loss 32.83041763305664\n",
      "cls loss 438.37005615234375  loc loss 33.20492172241211\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  2.,  1.,  1.,  1., 38.,\n",
      "         1.,  1.])\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([ 1.,  1.,  1., 38., 38., 38.,  1., 38., 38., 38.,  1.,  1., 38.,  1.,\n",
      "         1.])\n",
      "cls loss 271.40478515625  loc loss 24.10503387451172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  8.,  8.])\n",
      "cls loss 622.7420654296875  loc loss 48.70649719238281\n",
      "cls loss 652.3662109375  loc loss 57.36732864379883\n",
      "cls loss 224.97569274902344  loc loss 16.8135986328125\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([4., 1., 1., 4.])\n",
      "cls loss 364.95208740234375  loc loss 24.617464065551758\n",
      "cls loss 463.612060546875  loc loss 29.769729614257812\n",
      "cls loss 182.8629150390625  loc loss 9.760702133178711\n",
      "cls loss 229.06239318847656  loc loss 17.883018493652344\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([51.,  1.])\n",
      "cls loss 162.8504180908203  loc loss 7.462901592254639\n",
      "cls loss 238.3596954345703  loc loss 14.683857917785645\n",
      "cls loss 494.8438720703125  loc loss 24.597026824951172\n",
      "cls loss 456.13177490234375  loc loss 36.37020492553711\n",
      "cls loss 710.4524536132812  loc loss 36.56656265258789\n",
      "cls loss 840.2798461914062  loc loss 56.10204315185547\n",
      "cls loss 348.5530090332031  loc loss 22.062471389770508\n",
      "cls loss 528.567138671875  loc loss 38.30778503417969\n",
      "cls loss 559.31982421875  loc loss 38.59600067138672\n",
      "cls loss 411.5137939453125  loc loss 23.3170223236084\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85., 85.,  1.,  1.,  1.,  1.,  1.,  3.,  1.,  1.,  1.,  3.,  1.,  1.,\n",
      "         1.,  1.,  1.])\n",
      "cls loss 441.88763427734375  loc loss 19.66562271118164\n",
      "cls loss 454.0101318359375  loc loss 27.972156524658203\n",
      "cls loss 465.62506103515625  loc loss 23.45517349243164\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([5., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "cls loss 389.1400146484375  loc loss 24.205589294433594\n",
      "cls loss 217.887939453125  loc loss 17.164100646972656\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([3.])\n",
      "cls loss 166.99252319335938  loc loss 9.554455757141113\n",
      "cls loss 299.980712890625  loc loss 20.06568145751953\n",
      "cls loss 286.8132629394531  loc loss 18.845308303833008\n",
      "cls loss 525.1158447265625  loc loss 31.768407821655273\n",
      "cls loss 228.88760375976562  loc loss 17.273502349853516\n",
      "cls loss 272.9093017578125  loc loss 21.46954345703125\n",
      "cls loss 783.24267578125  loc loss 52.87636947631836\n",
      "cls loss 360.8729553222656  loc loss 25.79469871520996\n",
      "cls loss 265.31964111328125  loc loss 18.365413665771484\n",
      "cls loss 314.56103515625  loc loss 19.591737747192383\n",
      "cls loss 290.187744140625  loc loss 23.669227600097656\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.])\n",
      "cls loss 531.530517578125  loc loss 37.68645477294922\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([85.,  9., 64., 64., 64., 64., 64., 64., 64., 64., 64.,  9.,  9.,  9.,\n",
      "         9.])\n",
      "cls loss 239.48147583007812  loc loss 13.27341365814209\n",
      "cls loss 782.2241821289062  loc loss 58.00295639038086\n",
      "cls loss 414.81353759765625  loc loss 26.157062530517578\n",
      "cls loss 472.00042724609375  loc loss 31.333019256591797\n",
      "tensor(0)\n",
      "skipping\n",
      "tensor([16.,  3.,  3.])\n",
      "cls loss 305.14892578125  loc loss 17.725587844848633\n",
      "cls loss 323.71881103515625  loc loss 20.687721252441406\n",
      "cls loss 345.3173828125  loc loss 23.72953224182129\n",
      "cls loss 345.6571350097656  loc loss 23.648635864257812\n",
      "cls loss 402.750244140625  loc loss 27.01547622680664\n",
      "cls loss 416.5887451171875  loc loss 26.61414909362793\n",
      "cls loss 371.83758544921875  loc loss 25.549999237060547\n"
     ]
    }
   ],
   "source": [
    "collect = []\n",
    "\n",
    "for epoch in range(50):\n",
    "    for b in dl:\n",
    "        optimizer.zero_grad()\n",
    "        image, (bounding_boxes, labels) = b\n",
    "        image = image.to(device)\n",
    "        bounding_boxes = bounding_boxes.to(device)\n",
    "        labels = labels.to(device)\n",
    "        loc_pred, cls_pred = model(image)\n",
    "        total_loss = criterion(loc_pred, bounding_boxes, cls_pred, labels)\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        collect.append(total_loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fcc3e74ea20>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame([c.detach().cpu().numpy() for c in collect]).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(dl)\n",
    "# model = model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/i008/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:2351: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
      "/home/i008/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:2423: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed in nnms\n",
      "tensor([24])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "b = next(it)\n",
    "i = 0\n",
    "image, (bounding_boxes, labels) = b\n",
    "\n",
    "\n",
    "loc_pred, cls_pred = model(image.cuda())\n",
    "\n",
    "bbspred, labelpred, score  = ds.encoder.decode(\n",
    "    loc_pred[i].float().cpu(), \n",
    "    cls_pred[i].float().cpu(), \n",
    "    torch.Tensor([256, 256]).float().cpu()\n",
    ")\n",
    "\n",
    "image_to_show = np.moveaxis(\n",
    "    image[i].detach().cpu().numpy(),0, 2)\n",
    "\n",
    "matched_anchors_on_image = ia.BoundingBoxesOnImage(\n",
    "    [ia.BoundingBox(*b) for b in bbspred.detach().cpu().numpy()], shape=(256, 256))\n",
    "\n",
    "image_to_show = matched_anchors_on_image.draw_on_image(image_to_show, thickness=3)\n",
    "plt.imshow(image_to_show)\n",
    "plt.title('score ' + str(score))\n",
    "print(labelpred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mx, lab = cls_pred[0].sigmoid().max(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(data=mx.detach().cpu().numpy())\n",
    "df['lab'] = lab.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>lab</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12031</th>\n",
       "      <td>35.311420</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11588</th>\n",
       "      <td>34.022511</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12032</th>\n",
       "      <td>33.713486</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12025</th>\n",
       "      <td>33.456547</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11383</th>\n",
       "      <td>33.428032</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11384</th>\n",
       "      <td>31.917233</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11585</th>\n",
       "      <td>31.912079</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12029</th>\n",
       "      <td>31.866360</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12027</th>\n",
       "      <td>31.790777</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12028</th>\n",
       "      <td>31.151337</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11525</th>\n",
       "      <td>31.060528</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11377</th>\n",
       "      <td>30.901527</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11381</th>\n",
       "      <td>30.684996</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9356</th>\n",
       "      <td>30.455256</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12024</th>\n",
       "      <td>30.258509</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11586</th>\n",
       "      <td>30.103012</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11589</th>\n",
       "      <td>30.051392</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11583</th>\n",
       "      <td>29.886671</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12030</th>\n",
       "      <td>29.855108</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11590</th>\n",
       "      <td>29.721392</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11587</th>\n",
       "      <td>29.434282</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11380</th>\n",
       "      <td>29.266102</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11521</th>\n",
       "      <td>29.063705</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11591</th>\n",
       "      <td>29.061922</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11376</th>\n",
       "      <td>28.982666</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11520</th>\n",
       "      <td>28.836203</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11379</th>\n",
       "      <td>28.787664</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9353</th>\n",
       "      <td>28.676176</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12026</th>\n",
       "      <td>28.658121</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11584</th>\n",
       "      <td>28.114792</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8340</th>\n",
       "      <td>0.059796</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8889</th>\n",
       "      <td>0.059424</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7746</th>\n",
       "      <td>0.059196</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8007</th>\n",
       "      <td>0.058295</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8898</th>\n",
       "      <td>0.055166</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8574</th>\n",
       "      <td>0.054016</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8035</th>\n",
       "      <td>0.053593</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8286</th>\n",
       "      <td>0.052525</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8593</th>\n",
       "      <td>0.052300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8305</th>\n",
       "      <td>0.051953</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8620</th>\n",
       "      <td>0.047232</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8016</th>\n",
       "      <td>0.046814</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8583</th>\n",
       "      <td>0.045754</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8332</th>\n",
       "      <td>0.045544</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8043</th>\n",
       "      <td>0.045174</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8295</th>\n",
       "      <td>0.044166</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8602</th>\n",
       "      <td>0.043136</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8314</th>\n",
       "      <td>0.043130</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8323</th>\n",
       "      <td>0.039406</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8611</th>\n",
       "      <td>0.038754</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8025</th>\n",
       "      <td>0.038267</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8592</th>\n",
       "      <td>0.037167</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8034</th>\n",
       "      <td>0.036768</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8304</th>\n",
       "      <td>0.035717</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8619</th>\n",
       "      <td>0.034947</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8331</th>\n",
       "      <td>0.033166</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8601</th>\n",
       "      <td>0.030126</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8313</th>\n",
       "      <td>0.029024</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8610</th>\n",
       "      <td>0.027528</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8322</th>\n",
       "      <td>0.026622</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12276 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  lab\n",
       "12031  35.311420    1\n",
       "11588  34.022511   59\n",
       "12032  33.713486   53\n",
       "12025  33.456547   74\n",
       "11383  33.428032    1\n",
       "11384  31.917233   53\n",
       "11585  31.912079   62\n",
       "12029  31.866360   20\n",
       "12027  31.790777   11\n",
       "12028  31.151337   79\n",
       "11525  31.060528   18\n",
       "11377  30.901527   74\n",
       "11381  30.684996   20\n",
       "9356   30.455256   59\n",
       "12024  30.258509   12\n",
       "11586  30.103012    4\n",
       "11589  30.051392   87\n",
       "11583  29.886671   62\n",
       "12030  29.855108    1\n",
       "11590  29.721392    1\n",
       "11587  29.434282    1\n",
       "11380  29.266102   62\n",
       "11521  29.063705   20\n",
       "11591  29.061922    3\n",
       "11376  28.982666   12\n",
       "11520  28.836203   64\n",
       "11379  28.787664   11\n",
       "9353   28.676176   62\n",
       "12026  28.658121    1\n",
       "11584  28.114792   84\n",
       "...          ...  ...\n",
       "8340    0.059796    1\n",
       "8889    0.059424    1\n",
       "7746    0.059196    1\n",
       "8007    0.058295    1\n",
       "8898    0.055166    1\n",
       "8574    0.054016    1\n",
       "8035    0.053593    1\n",
       "8286    0.052525    1\n",
       "8593    0.052300    1\n",
       "8305    0.051953    1\n",
       "8620    0.047232    1\n",
       "8016    0.046814    1\n",
       "8583    0.045754    1\n",
       "8332    0.045544    1\n",
       "8043    0.045174    1\n",
       "8295    0.044166    1\n",
       "8602    0.043136    1\n",
       "8314    0.043130    1\n",
       "8323    0.039406    1\n",
       "8611    0.038754    1\n",
       "8025    0.038267    1\n",
       "8592    0.037167    1\n",
       "8034    0.036768    1\n",
       "8304    0.035717    1\n",
       "8619    0.034947    1\n",
       "8331    0.033166    1\n",
       "8601    0.030126    1\n",
       "8313    0.029024    1\n",
       "8610    0.027528    1\n",
       "8322    0.026622    1\n",
       "\n",
       "[12276 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/i008/anaconda3/lib/python3.6/site-packages/_pytest/fixtures.py:847: DeprecationWarning: The `convert` argument is deprecated in favor of `converter`.  It will be removed after 2019/01.\n",
      "  params = attr.ib(convert=attr.converters.optional(tuple))\n",
      "/home/i008/anaconda3/lib/python3.6/site-packages/_pytest/fixtures.py:849: DeprecationWarning: The `convert` argument is deprecated in favor of `converter`.  It will be removed after 2019/01.\n",
      "  ids = attr.ib(default=None, convert=_ensure_immutable_ids)\n"
     ]
    }
   ],
   "source": [
    "df = df.sort_values(0, ascending=False)\n",
    "df[0] = df[0] * 100\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {'supercategory': 'person', 'id': 1, 'name': 'person'},\n",
       " 2: {'supercategory': 'vehicle', 'id': 2, 'name': 'bicycle'},\n",
       " 3: {'supercategory': 'vehicle', 'id': 3, 'name': 'car'},\n",
       " 4: {'supercategory': 'vehicle', 'id': 4, 'name': 'motorcycle'},\n",
       " 5: {'supercategory': 'vehicle', 'id': 5, 'name': 'airplane'},\n",
       " 6: {'supercategory': 'vehicle', 'id': 6, 'name': 'bus'},\n",
       " 7: {'supercategory': 'vehicle', 'id': 7, 'name': 'train'},\n",
       " 8: {'supercategory': 'vehicle', 'id': 8, 'name': 'truck'},\n",
       " 9: {'supercategory': 'vehicle', 'id': 9, 'name': 'boat'},\n",
       " 10: {'supercategory': 'outdoor', 'id': 10, 'name': 'traffic light'},\n",
       " 11: {'supercategory': 'outdoor', 'id': 11, 'name': 'fire hydrant'},\n",
       " 13: {'supercategory': 'outdoor', 'id': 13, 'name': 'stop sign'},\n",
       " 14: {'supercategory': 'outdoor', 'id': 14, 'name': 'parking meter'},\n",
       " 15: {'supercategory': 'outdoor', 'id': 15, 'name': 'bench'},\n",
       " 16: {'supercategory': 'animal', 'id': 16, 'name': 'bird'},\n",
       " 17: {'supercategory': 'animal', 'id': 17, 'name': 'cat'},\n",
       " 18: {'supercategory': 'animal', 'id': 18, 'name': 'dog'},\n",
       " 19: {'supercategory': 'animal', 'id': 19, 'name': 'horse'},\n",
       " 20: {'supercategory': 'animal', 'id': 20, 'name': 'sheep'},\n",
       " 21: {'supercategory': 'animal', 'id': 21, 'name': 'cow'},\n",
       " 22: {'supercategory': 'animal', 'id': 22, 'name': 'elephant'},\n",
       " 23: {'supercategory': 'animal', 'id': 23, 'name': 'bear'},\n",
       " 24: {'supercategory': 'animal', 'id': 24, 'name': 'zebra'},\n",
       " 25: {'supercategory': 'animal', 'id': 25, 'name': 'giraffe'},\n",
       " 27: {'supercategory': 'accessory', 'id': 27, 'name': 'backpack'},\n",
       " 28: {'supercategory': 'accessory', 'id': 28, 'name': 'umbrella'},\n",
       " 31: {'supercategory': 'accessory', 'id': 31, 'name': 'handbag'},\n",
       " 32: {'supercategory': 'accessory', 'id': 32, 'name': 'tie'},\n",
       " 33: {'supercategory': 'accessory', 'id': 33, 'name': 'suitcase'},\n",
       " 34: {'supercategory': 'sports', 'id': 34, 'name': 'frisbee'},\n",
       " 35: {'supercategory': 'sports', 'id': 35, 'name': 'skis'},\n",
       " 36: {'supercategory': 'sports', 'id': 36, 'name': 'snowboard'},\n",
       " 37: {'supercategory': 'sports', 'id': 37, 'name': 'sports ball'},\n",
       " 38: {'supercategory': 'sports', 'id': 38, 'name': 'kite'},\n",
       " 39: {'supercategory': 'sports', 'id': 39, 'name': 'baseball bat'},\n",
       " 40: {'supercategory': 'sports', 'id': 40, 'name': 'baseball glove'},\n",
       " 41: {'supercategory': 'sports', 'id': 41, 'name': 'skateboard'},\n",
       " 42: {'supercategory': 'sports', 'id': 42, 'name': 'surfboard'},\n",
       " 43: {'supercategory': 'sports', 'id': 43, 'name': 'tennis racket'},\n",
       " 44: {'supercategory': 'kitchen', 'id': 44, 'name': 'bottle'},\n",
       " 46: {'supercategory': 'kitchen', 'id': 46, 'name': 'wine glass'},\n",
       " 47: {'supercategory': 'kitchen', 'id': 47, 'name': 'cup'},\n",
       " 48: {'supercategory': 'kitchen', 'id': 48, 'name': 'fork'},\n",
       " 49: {'supercategory': 'kitchen', 'id': 49, 'name': 'knife'},\n",
       " 50: {'supercategory': 'kitchen', 'id': 50, 'name': 'spoon'},\n",
       " 51: {'supercategory': 'kitchen', 'id': 51, 'name': 'bowl'},\n",
       " 52: {'supercategory': 'food', 'id': 52, 'name': 'banana'},\n",
       " 53: {'supercategory': 'food', 'id': 53, 'name': 'apple'},\n",
       " 54: {'supercategory': 'food', 'id': 54, 'name': 'sandwich'},\n",
       " 55: {'supercategory': 'food', 'id': 55, 'name': 'orange'},\n",
       " 56: {'supercategory': 'food', 'id': 56, 'name': 'broccoli'},\n",
       " 57: {'supercategory': 'food', 'id': 57, 'name': 'carrot'},\n",
       " 58: {'supercategory': 'food', 'id': 58, 'name': 'hot dog'},\n",
       " 59: {'supercategory': 'food', 'id': 59, 'name': 'pizza'},\n",
       " 60: {'supercategory': 'food', 'id': 60, 'name': 'donut'},\n",
       " 61: {'supercategory': 'food', 'id': 61, 'name': 'cake'},\n",
       " 62: {'supercategory': 'furniture', 'id': 62, 'name': 'chair'},\n",
       " 63: {'supercategory': 'furniture', 'id': 63, 'name': 'couch'},\n",
       " 64: {'supercategory': 'furniture', 'id': 64, 'name': 'potted plant'},\n",
       " 65: {'supercategory': 'furniture', 'id': 65, 'name': 'bed'},\n",
       " 67: {'supercategory': 'furniture', 'id': 67, 'name': 'dining table'},\n",
       " 70: {'supercategory': 'furniture', 'id': 70, 'name': 'toilet'},\n",
       " 72: {'supercategory': 'electronic', 'id': 72, 'name': 'tv'},\n",
       " 73: {'supercategory': 'electronic', 'id': 73, 'name': 'laptop'},\n",
       " 74: {'supercategory': 'electronic', 'id': 74, 'name': 'mouse'},\n",
       " 75: {'supercategory': 'electronic', 'id': 75, 'name': 'remote'},\n",
       " 76: {'supercategory': 'electronic', 'id': 76, 'name': 'keyboard'},\n",
       " 77: {'supercategory': 'electronic', 'id': 77, 'name': 'cell phone'},\n",
       " 78: {'supercategory': 'appliance', 'id': 78, 'name': 'microwave'},\n",
       " 79: {'supercategory': 'appliance', 'id': 79, 'name': 'oven'},\n",
       " 80: {'supercategory': 'appliance', 'id': 80, 'name': 'toaster'},\n",
       " 81: {'supercategory': 'appliance', 'id': 81, 'name': 'sink'},\n",
       " 82: {'supercategory': 'appliance', 'id': 82, 'name': 'refrigerator'},\n",
       " 84: {'supercategory': 'indoor', 'id': 84, 'name': 'book'},\n",
       " 85: {'supercategory': 'indoor', 'id': 85, 'name': 'clock'},\n",
       " 86: {'supercategory': 'indoor', 'id': 86, 'name': 'vase'},\n",
       " 87: {'supercategory': 'indoor', 'id': 87, 'name': 'scissors'},\n",
       " 88: {'supercategory': 'indoor', 'id': 88, 'name': 'teddy bear'},\n",
       " 89: {'supercategory': 'indoor', 'id': 89, 'name': 'hair drier'},\n",
       " 90: {'supercategory': 'indoor', 'id': 90, 'name': 'toothbrush'}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.coco.cats"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
